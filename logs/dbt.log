

============================== 2022-05-12 17:07:07.125229 | 47baacbd-99ea-4c78-b5d1-9a8fdd35f24a ==============================
17:07:07.125229 [info ] [MainThread]: Running with dbt=1.0.1
17:07:07.125437 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, project_name='learn-dbt', skip_profile_setup=False, defer=None, state=None, cls=<class 'dbt.task.init.InitTask'>, which='init', rpc_method=None)
17:07:07.125520 [debug] [MainThread]: Tracking: tracking
17:07:07.141291 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10797fe50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079ab7c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079ab1f0>]}
17:07:07.142442 [debug] [MainThread]: Starter project path: /opt/homebrew/Cellar/dbt-snowflake/1.0.0_1/libexec/lib/python3.9/site-packages/dbt/include/starter_project
08:01:39.980641 [info ] [MainThread]: Profile learn-dbt written to /Users/nigelbrown/.dbt/profiles.yml using target's profile_template.yml and your supplied values. Run 'dbt debug' to validate the connection.
08:01:39.985085 [info ] [MainThread]: 
Your new dbt project "learn-dbt" was created!

For more information on how to configure the profiles.yml file,
please consult the dbt documentation here:

  https://docs.getdbt.com/docs/configure-your-profile

One more thing:

Need help? Don't hesitate to reach out to us via GitHub issues or on Slack:

  https://community.getdbt.com/

Happy modeling!

08:01:39.986728 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10798c370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10798c190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10798c910>]}


============================== 2022-05-13 08:06:38.926001 | 62e784e7-e185-4ec5-94dd-2d0f94150f4c ==============================
08:06:38.926001 [info ] [MainThread]: Running with dbt=1.0.1
08:06:38.926191 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, config_dir=True, defer=None, state=None, cls=<class 'dbt.task.debug.DebugTask'>, which='debug', rpc_method=None)
08:06:38.926274 [debug] [MainThread]: Tracking: tracking
08:06:38.946532 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105cfbee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105cfbe50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105cfbfd0>]}
08:06:38.947618 [info ] [MainThread]: To view your profiles.yml file, run:

open /Users/nigelbrown/.dbt
08:06:38.947937 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105cfbf40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105cfb7f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105cbfb20>]}


============================== 2022-05-13 08:23:45.322453 | 812aa8a3-1c32-456a-b70e-52a6d0b08f2e ==============================
08:23:45.322453 [info ] [MainThread]: Running with dbt=1.0.1
08:23:45.322833 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, config_dir=False, defer=None, state=None, cls=<class 'dbt.task.debug.DebugTask'>, which='debug', rpc_method=None)
08:23:45.322956 [debug] [MainThread]: Tracking: tracking
08:23:45.337227 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d2d220>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105bd4d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105bd4400>]}
08:23:45.339321 [debug] [MainThread]: Executing "git --help"
08:23:45.356654 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--super-prefix=<path>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
08:23:45.357115 [debug] [MainThread]: STDERR: "b''"
08:23:45.357525 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d05c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d05c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d05190>]}


============================== 2022-05-13 08:35:22.710985 | cfc1122d-12bf-4662-abc5-5f25ffc3481d ==============================
08:35:22.710985 [info ] [MainThread]: Running with dbt=1.0.1
08:35:22.711179 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, config_dir=True, defer=None, state=None, cls=<class 'dbt.task.debug.DebugTask'>, which='debug', rpc_method=None)
08:35:22.711261 [debug] [MainThread]: Tracking: tracking
08:35:22.725769 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10688d220>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106854fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106854af0>]}
08:35:22.726457 [info ] [MainThread]: To view your profiles.yml file, run:

open /Users/nigelbrown/.dbt
08:35:22.726706 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106854d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106854df0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106854400>]}


============================== 2022-05-13 08:36:41.151161 | 1fa27abb-7d55-4a41-bce3-a5f71fccd934 ==============================
08:36:41.151161 [info ] [MainThread]: Running with dbt=1.0.1
08:36:41.151359 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, config_dir=False, defer=None, state=None, cls=<class 'dbt.task.debug.DebugTask'>, which='debug', rpc_method=None)
08:36:41.151491 [debug] [MainThread]: Tracking: tracking
08:36:41.161946 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079edb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079b4cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079b4d00>]}
08:36:41.167374 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079c7ca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079c4fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079c49a0>]}


============================== 2022-05-13 08:38:53.312621 | 5d3770fe-5bab-4e96-9f08-884e99361c79 ==============================
08:38:53.312621 [info ] [MainThread]: Running with dbt=1.0.1
08:38:53.312956 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, config_dir=False, defer=None, state=None, cls=<class 'dbt.task.debug.DebugTask'>, which='debug', rpc_method=None)
08:38:53.313053 [debug] [MainThread]: Tracking: tracking
08:38:53.326578 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105cd1b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105c98cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105c98d00>]}
08:38:53.332642 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105cabca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ca8fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ca89a0>]}


============================== 2022-05-13 08:39:32.561209 | fe429ea6-6bf7-4a1f-8fd0-acdb4d12452b ==============================
08:39:32.561209 [info ] [MainThread]: Running with dbt=1.0.1
08:39:32.561396 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, config_dir=False, defer=None, state=None, cls=<class 'dbt.task.debug.DebugTask'>, which='debug', rpc_method=None)
08:39:32.561475 [debug] [MainThread]: Tracking: tracking
08:39:32.571481 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e28d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e28130>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e14d60>]}
08:39:32.785124 [debug] [MainThread]: Executing "git --help"
08:39:32.800317 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--super-prefix=<path>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
08:39:32.800778 [debug] [MainThread]: STDERR: "b''"
08:39:32.806956 [debug] [MainThread]: Acquiring new snowflake connection "debug"
08:39:32.808166 [debug] [MainThread]: Using snowflake connection "debug"
08:39:32.808254 [debug] [MainThread]: On debug: select 1 as id
08:39:32.808330 [debug] [MainThread]: Opening a new connection, currently in state init
08:39:34.365745 [debug] [MainThread]: SQL status: SUCCESS 1 in 1.56 seconds
08:39:34.367769 [debug] [MainThread]: On debug: Close
08:39:34.667422 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105b86ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e280a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e28880>]}
08:39:35.547265 [debug] [MainThread]: Connection 'debug' was properly closed.


============================== 2022-05-13 08:42:53.845517 | 1395b417-50c3-433a-9d0e-cf01cb608eb8 ==============================
08:42:53.845517 [info ] [MainThread]: Running with dbt=1.0.1
08:42:53.845833 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, config_dir=False, defer=None, state=None, cls=<class 'dbt.task.debug.DebugTask'>, which='debug', rpc_method=None)
08:42:53.845916 [debug] [MainThread]: Tracking: tracking
08:42:53.860412 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067c39d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067c3fa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067c3e50>]}
08:42:54.068805 [debug] [MainThread]: Executing "git --help"
08:42:54.081592 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--super-prefix=<path>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
08:42:54.082104 [debug] [MainThread]: STDERR: "b''"
08:42:54.085855 [debug] [MainThread]: Acquiring new snowflake connection "debug"
08:42:54.086833 [debug] [MainThread]: Using snowflake connection "debug"
08:42:54.086942 [debug] [MainThread]: On debug: select 1 as id
08:42:54.087033 [debug] [MainThread]: Opening a new connection, currently in state init
08:42:55.063438 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.98 seconds
08:42:55.065249 [debug] [MainThread]: On debug: Close
08:42:55.329348 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1073a05b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1073a0670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1073970a0>]}
08:42:55.981829 [debug] [MainThread]: Connection 'debug' was properly closed.


============================== 2022-05-13 08:44:29.879832 | 2b26ca51-6616-4ab2-9e7d-245ab2c90ef0 ==============================
08:44:29.879832 [info ] [MainThread]: Running with dbt=1.0.1
08:44:29.880214 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
08:44:29.880318 [debug] [MainThread]: Tracking: tracking
08:44:29.880524 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11161bfa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11161bf40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11161bbb0>]}
08:44:29.887803 [info ] [MainThread]: Partial parse save file not found. Starting full parse.
08:44:29.887959 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '2b26ca51-6616-4ab2-9e7d-245ab2c90ef0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11165d2b0>]}
08:44:29.900263 [debug] [MainThread]: Parsing macros/catalog.sql
08:44:29.901731 [debug] [MainThread]: Parsing macros/adapters.sql
08:44:29.923022 [debug] [MainThread]: Parsing macros/materializations/merge.sql
08:44:29.924882 [debug] [MainThread]: Parsing macros/materializations/seed.sql
08:44:29.927280 [debug] [MainThread]: Parsing macros/materializations/view.sql
08:44:29.927892 [debug] [MainThread]: Parsing macros/materializations/table.sql
08:44:29.929333 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
08:44:29.933233 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
08:44:29.933648 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
08:44:29.935336 [debug] [MainThread]: Parsing macros/materializations/configs.sql
08:44:29.936344 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
08:44:29.937087 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
08:44:29.945530 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
08:44:29.951703 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
08:44:29.980328 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
08:44:29.982627 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
08:44:29.983619 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
08:44:29.984486 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
08:44:29.986540 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
08:44:29.991996 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
08:44:29.992680 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
08:44:29.997568 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
08:44:30.005230 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
08:44:30.008880 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
08:44:30.010271 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
08:44:30.014006 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
08:44:30.014614 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
08:44:30.015844 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
08:44:30.016875 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
08:44:30.019695 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
08:44:30.027793 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
08:44:30.028531 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
08:44:30.029655 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
08:44:30.030382 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
08:44:30.030796 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
08:44:30.031037 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
08:44:30.031342 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
08:44:30.031956 [debug] [MainThread]: Parsing macros/etc/statement.sql
08:44:30.033971 [debug] [MainThread]: Parsing macros/etc/datetime.sql
08:44:30.037965 [debug] [MainThread]: Parsing macros/adapters/schema.sql
08:44:30.038915 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
08:44:30.040107 [debug] [MainThread]: Parsing macros/adapters/relation.sql
08:44:30.044812 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
08:44:30.046227 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
08:44:30.048221 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
08:44:30.051589 [debug] [MainThread]: Parsing macros/adapters/columns.sql
08:44:30.056245 [debug] [MainThread]: Parsing tests/generic/builtin.sql
08:44:30.150335 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
08:44:30.155985 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
08:44:30.179913 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2b26ca51-6616-4ab2-9e7d-245ab2c90ef0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11173f040>]}
08:44:30.182575 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2b26ca51-6616-4ab2-9e7d-245ab2c90ef0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11173f280>]}
08:44:30.182702 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
08:44:30.183239 [info ] [MainThread]: 
08:44:30.183442 [debug] [MainThread]: Acquiring new snowflake connection "master"
08:44:30.183805 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
08:44:30.189814 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
08:44:30.189918 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
08:44:30.189981 [debug] [ThreadPool]: Opening a new connection, currently in state init
08:44:31.530954 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1.34 seconds
08:44:31.533971 [debug] [ThreadPool]: On list_analytics: Close
08:44:31.924504 [debug] [ThreadPool]: Acquiring new snowflake connection "create_analytics_dbt"
08:44:31.925259 [debug] [ThreadPool]: Acquiring new snowflake connection "create_analytics_dbt"
08:44:31.925694 [debug] [ThreadPool]: Creating schema "_ReferenceKey(database='analytics', schema='dbt', identifier=None)"
08:44:31.933322 [debug] [ThreadPool]: Using snowflake connection "create_analytics_dbt"
08:44:31.933624 [debug] [ThreadPool]: On create_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "create_analytics_dbt"} */
create schema if not exists analytics.dbt
08:44:31.933778 [debug] [ThreadPool]: Opening a new connection, currently in state closed
08:44:32.977319 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01a43c2c-3201-9cea-0000-0001205251ad
08:44:32.977626 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 003041 (42710): SQL compilation error:
Schema 'DBT' already exists, but current role has no privileges on it. If this is unexpected and you cannot resolve this problem, contact your system administrator. ACCOUNTADMIN role may be required to manage the privileges on the object.
08:44:32.977872 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro create_schema
08:44:32.977995 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
08:44:32.978160 [debug] [ThreadPool]: On create_analytics_dbt: Close
08:44:33.157067 [debug] [MainThread]: Connection 'master' was properly closed.
08:44:33.157525 [debug] [MainThread]: Connection 'create_analytics_dbt' was properly closed.
08:44:33.157948 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11173fa30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11173faf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111cce9d0>]}


============================== 2022-05-13 08:49:42.180202 | be2c0c8e-88f6-450e-9810-222a7f0c0fb8 ==============================
08:49:42.180202 [info ] [MainThread]: Running with dbt=1.0.1
08:49:42.180792 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
08:49:42.180927 [debug] [MainThread]: Tracking: tracking
08:49:42.181141 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067734c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106773460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067738b0>]}
08:49:42.225153 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
08:49:42.225317 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
08:49:42.228772 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'be2c0c8e-88f6-450e-9810-222a7f0c0fb8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067390d0>]}
08:49:42.232115 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'be2c0c8e-88f6-450e-9810-222a7f0c0fb8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10675d100>]}
08:49:42.232252 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
08:49:42.232828 [info ] [MainThread]: 
08:49:42.233074 [debug] [MainThread]: Acquiring new snowflake connection "master"
08:49:42.233579 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
08:49:42.240270 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
08:49:42.240418 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
08:49:42.240491 [debug] [ThreadPool]: Opening a new connection, currently in state init
08:49:43.509176 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.27 seconds
08:49:43.511424 [debug] [ThreadPool]: On list_analytics: Close
08:49:43.701032 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
08:49:43.709960 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
08:49:43.710158 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
08:49:43.710231 [debug] [ThreadPool]: Opening a new connection, currently in state closed
08:49:44.585244 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 0.87 seconds
08:49:44.587612 [debug] [ThreadPool]: On list_analytics_dbt: Close
08:49:44.965123 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
08:49:44.965643 [info ] [MainThread]: 
08:49:44.986594 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
08:49:44.986928 [info ] [Thread-1  ]: 1 of 2 START table model dbt.my_first_dbt_model................................. [RUN]
08:49:44.987345 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
08:49:44.987466 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
08:49:44.987584 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
08:49:44.989711 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
08:49:44.990311 [debug] [Thread-1  ]: finished collecting timing info
08:49:44.990435 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
08:49:45.008013 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
08:49:45.008935 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
08:49:45.009029 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
08:49:45.009116 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
08:49:45.806449 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a43c31-3201-9c86-0000-0001205223bd
08:49:45.806848 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 003001 (42501): SQL access control error:
Insufficient privileges to operate on schema 'DBT'
08:49:45.807216 [debug] [Thread-1  ]: finished collecting timing info
08:49:45.807460 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
08:49:46.110476 [debug] [Thread-1  ]: Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  003001 (42501): SQL access control error:
  Insufficient privileges to operate on schema 'DBT'
  compiled SQL at target/run/learn_dbt/models/example/my_first_dbt_model.sql
08:49:46.111449 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'be2c0c8e-88f6-450e-9810-222a7f0c0fb8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106cb4f40>]}
08:49:46.111920 [error] [Thread-1  ]: 1 of 2 ERROR creating table model dbt.my_first_dbt_model........................ [[31mERROR[0m in 1.12s]
08:49:46.112624 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
08:49:46.113139 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
08:49:46.113320 [info ] [Thread-1  ]: 2 of 2 SKIP relation dbt.my_second_dbt_model.................................... [[33mSKIP[0m]
08:49:46.113562 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
08:49:46.114476 [debug] [MainThread]: Acquiring new snowflake connection "master"
08:49:46.114952 [info ] [MainThread]: 
08:49:46.115283 [info ] [MainThread]: Finished running 1 table model, 1 view model in 3.88s.
08:49:46.115577 [debug] [MainThread]: Connection 'master' was properly closed.
08:49:46.115742 [debug] [MainThread]: Connection 'model.learn_dbt.my_first_dbt_model' was properly closed.
08:49:46.122841 [info ] [MainThread]: 
08:49:46.123193 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
08:49:46.123452 [info ] [MainThread]: 
08:49:46.123652 [error] [MainThread]: [33mDatabase Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)[0m
08:49:46.123853 [error] [MainThread]:   003001 (42501): SQL access control error:
08:49:46.124042 [error] [MainThread]:   Insufficient privileges to operate on schema 'DBT'
08:49:46.124399 [error] [MainThread]:   compiled SQL at target/run/learn_dbt/models/example/my_first_dbt_model.sql
08:49:46.124627 [info ] [MainThread]: 
08:49:46.124826 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=1 TOTAL=2
08:49:46.125137 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10675daf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10675dcd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e27fd0>]}


============================== 2022-05-13 08:51:38.314166 | 117a0d02-afd4-43c3-b040-1e3af1ea6193 ==============================
08:51:38.314166 [info ] [MainThread]: Running with dbt=1.0.1
08:51:38.314511 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
08:51:38.314650 [debug] [MainThread]: Tracking: tracking
08:51:38.314879 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076b32b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076b3eb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076b39a0>]}
08:51:38.354009 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
08:51:38.354151 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
08:51:38.357120 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '117a0d02-afd4-43c3-b040-1e3af1ea6193', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107675a90>]}
08:51:38.359935 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '117a0d02-afd4-43c3-b040-1e3af1ea6193', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10768f8b0>]}
08:51:38.360058 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
08:51:38.360579 [info ] [MainThread]: 
08:51:38.360769 [debug] [MainThread]: Acquiring new snowflake connection "master"
08:51:38.361089 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
08:51:38.366976 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
08:51:38.367065 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
08:51:38.367130 [debug] [ThreadPool]: Opening a new connection, currently in state init
08:51:39.419369 [debug] [ThreadPool]: SQL status: SUCCESS 2 in 1.05 seconds
08:51:39.421653 [debug] [ThreadPool]: On list_analytics: Close
08:51:41.032019 [debug] [ThreadPool]: Acquiring new snowflake connection "create_analytics_dbt"
08:51:41.032621 [debug] [ThreadPool]: Acquiring new snowflake connection "create_analytics_dbt"
08:51:41.032931 [debug] [ThreadPool]: Creating schema "_ReferenceKey(database='analytics', schema='dbt', identifier=None)"
08:51:41.039100 [debug] [ThreadPool]: Using snowflake connection "create_analytics_dbt"
08:51:41.039322 [debug] [ThreadPool]: On create_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "create_analytics_dbt"} */
create schema if not exists analytics.dbt
08:51:41.039470 [debug] [ThreadPool]: Opening a new connection, currently in state closed
08:51:42.052864 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1.01 seconds
08:51:42.055380 [debug] [ThreadPool]: On create_analytics_dbt: Close
08:51:42.222202 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
08:51:42.230662 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
08:51:42.230880 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
08:51:42.231037 [debug] [ThreadPool]: Opening a new connection, currently in state closed
08:51:43.145956 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 0.91 seconds
08:51:43.148370 [debug] [ThreadPool]: On list_analytics_dbt: Close
08:51:43.451450 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
08:51:43.451996 [info ] [MainThread]: 
08:51:43.455522 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
08:51:43.455966 [info ] [Thread-1  ]: 1 of 2 START table model dbt.my_first_dbt_model................................. [RUN]
08:51:43.456528 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
08:51:43.456720 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
08:51:43.456900 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
08:51:43.459887 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
08:51:43.460531 [debug] [Thread-1  ]: finished collecting timing info
08:51:43.460702 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
08:51:43.483240 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
08:51:43.484221 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
08:51:43.484344 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
08:51:43.484448 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
08:51:44.297597 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a43c33-3201-9c86-0000-00012052243d
08:51:44.297866 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.

08:51:44.298007 [debug] [Thread-1  ]: finished collecting timing info
08:51:44.298094 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
08:51:44.601223 [debug] [Thread-1  ]: Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
  
  compiled SQL at target/run/learn_dbt/models/example/my_first_dbt_model.sql
08:51:44.601778 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '117a0d02-afd4-43c3-b040-1e3af1ea6193', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a2e790>]}
08:51:44.602240 [error] [Thread-1  ]: 1 of 2 ERROR creating table model dbt.my_first_dbt_model........................ [[31mERROR[0m in 1.15s]
08:51:44.602662 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
08:51:44.603462 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
08:51:44.603756 [info ] [Thread-1  ]: 2 of 2 SKIP relation dbt.my_second_dbt_model.................................... [[33mSKIP[0m]
08:51:44.604137 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
08:51:44.605174 [debug] [MainThread]: Acquiring new snowflake connection "master"
08:51:44.605624 [info ] [MainThread]: 
08:51:44.605905 [info ] [MainThread]: Finished running 1 table model, 1 view model in 6.24s.
08:51:44.606172 [debug] [MainThread]: Connection 'master' was properly closed.
08:51:44.606305 [debug] [MainThread]: Connection 'model.learn_dbt.my_first_dbt_model' was properly closed.
08:51:44.612218 [info ] [MainThread]: 
08:51:44.612534 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
08:51:44.612792 [info ] [MainThread]: 
08:51:44.612993 [error] [MainThread]: [33mDatabase Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)[0m
08:51:44.613183 [error] [MainThread]:   000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
08:51:44.613363 [error] [MainThread]:   
08:51:44.613540 [error] [MainThread]:   compiled SQL at target/run/learn_dbt/models/example/my_first_dbt_model.sql
08:51:44.613723 [info ] [MainThread]: 
08:51:44.613902 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=1 TOTAL=2
08:51:44.614164 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106d1b1c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a03070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076a90a0>]}


============================== 2022-05-13 08:53:58.504709 | e363b1f0-3d52-40e5-a8e6-6d9af0bfc7db ==============================
08:53:58.504709 [info ] [MainThread]: Running with dbt=1.0.1
08:53:58.505207 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
08:53:58.505336 [debug] [MainThread]: Tracking: tracking
08:53:58.505547 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106abd610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106abdac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106abdb20>]}
08:53:58.547752 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
08:53:58.547894 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
08:53:58.550903 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e363b1f0-3d52-40e5-a8e6-6d9af0bfc7db', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106a8a2b0>]}
08:53:58.554053 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e363b1f0-3d52-40e5-a8e6-6d9af0bfc7db', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ac6ac0>]}
08:53:58.554203 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
08:53:58.554749 [info ] [MainThread]: 
08:53:58.554964 [debug] [MainThread]: Acquiring new snowflake connection "master"
08:53:58.555320 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
08:53:58.561281 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
08:53:58.561387 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
08:53:58.561452 [debug] [ThreadPool]: Opening a new connection, currently in state init
08:53:59.826366 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.26 seconds
08:53:59.828626 [debug] [ThreadPool]: On list_analytics: Close
08:54:00.020903 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
08:54:00.026231 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
08:54:00.026572 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
08:54:00.026740 [debug] [ThreadPool]: Opening a new connection, currently in state closed
08:54:00.978003 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 0.95 seconds
08:54:00.986588 [debug] [ThreadPool]: On list_analytics_dbt: Close
08:54:01.400351 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
08:54:01.400857 [info ] [MainThread]: 
08:54:01.405660 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
08:54:01.406027 [info ] [Thread-1  ]: 1 of 2 START table model dbt.my_first_dbt_model................................. [RUN]
08:54:01.406530 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
08:54:01.406694 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
08:54:01.407228 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
08:54:01.410203 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
08:54:01.410745 [debug] [Thread-1  ]: finished collecting timing info
08:54:01.410914 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
08:54:01.432703 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
08:54:01.433674 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
08:54:01.433895 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
08:54:01.434051 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
08:54:02.390464 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a43c36-3201-9c86-0000-000120522459
08:54:02.390825 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.

08:54:02.391066 [debug] [Thread-1  ]: finished collecting timing info
08:54:02.391198 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
08:54:02.554939 [debug] [Thread-1  ]: Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
  
  compiled SQL at target/run/learn_dbt/models/example/my_first_dbt_model.sql
08:54:02.556002 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e363b1f0-3d52-40e5-a8e6-6d9af0bfc7db', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1226e5df0>]}
08:54:02.556693 [error] [Thread-1  ]: 1 of 2 ERROR creating table model dbt.my_first_dbt_model........................ [[31mERROR[0m in 1.15s]
08:54:02.557318 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
08:54:02.558207 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
08:54:02.558559 [info ] [Thread-1  ]: 2 of 2 SKIP relation dbt.my_second_dbt_model.................................... [[33mSKIP[0m]
08:54:02.558937 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
08:54:02.559951 [debug] [MainThread]: Acquiring new snowflake connection "master"
08:54:02.560403 [info ] [MainThread]: 
08:54:02.560727 [info ] [MainThread]: Finished running 1 table model, 1 view model in 4.01s.
08:54:02.561019 [debug] [MainThread]: Connection 'master' was properly closed.
08:54:02.561177 [debug] [MainThread]: Connection 'model.learn_dbt.my_first_dbt_model' was properly closed.
08:54:02.568001 [info ] [MainThread]: 
08:54:02.568341 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
08:54:02.568582 [info ] [MainThread]: 
08:54:02.568786 [error] [MainThread]: [33mDatabase Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)[0m
08:54:02.568988 [error] [MainThread]:   000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
08:54:02.569170 [error] [MainThread]:   
08:54:02.569357 [error] [MainThread]:   compiled SQL at target/run/learn_dbt/models/example/my_first_dbt_model.sql
08:54:02.569550 [info ] [MainThread]: 
08:54:02.569990 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=1 TOTAL=2
08:54:02.570318 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1208776a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ac6070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1208c7b80>]}


============================== 2022-05-13 09:03:10.055375 | 391d4129-e590-4cd3-9371-422090825d89 ==============================
09:03:10.055375 [info ] [MainThread]: Running with dbt=1.0.1
09:03:10.055982 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
09:03:10.056171 [debug] [MainThread]: Tracking: tracking
09:03:10.056485 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bd91610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bd91ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bd91b20>]}
09:03:10.102002 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
09:03:10.102149 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
09:03:10.105242 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '391d4129-e590-4cd3-9371-422090825d89', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a913b50>]}
09:03:10.108159 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '391d4129-e590-4cd3-9371-422090825d89', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bd9aac0>]}
09:03:10.108319 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
09:03:10.108877 [info ] [MainThread]: 
09:03:10.109089 [debug] [MainThread]: Acquiring new snowflake connection "master"
09:03:10.109474 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
09:03:10.115583 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
09:03:10.115703 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
09:03:10.115786 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:03:11.519556 [debug] [ThreadPool]: SQL status: SUCCESS 2 in 1.4 seconds
09:03:11.522361 [debug] [ThreadPool]: On list_analytics: Close
09:03:11.915869 [debug] [ThreadPool]: Acquiring new snowflake connection "create_analytics_dbt"
09:03:11.916555 [debug] [ThreadPool]: Acquiring new snowflake connection "create_analytics_dbt"
09:03:11.916881 [debug] [ThreadPool]: Creating schema "_ReferenceKey(database='analytics', schema='dbt', identifier=None)"
09:03:11.923292 [debug] [ThreadPool]: Using snowflake connection "create_analytics_dbt"
09:03:11.923563 [debug] [ThreadPool]: On create_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "create_analytics_dbt"} */
create schema if not exists analytics.dbt
09:03:11.923715 [debug] [ThreadPool]: Opening a new connection, currently in state closed
09:03:12.865883 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.94 seconds
09:03:12.869531 [debug] [ThreadPool]: On create_analytics_dbt: Close
09:03:13.222630 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
09:03:13.227352 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
09:03:13.227479 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
09:03:13.227571 [debug] [ThreadPool]: Opening a new connection, currently in state closed
09:03:14.174402 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 0.95 seconds
09:03:14.176894 [debug] [ThreadPool]: On list_analytics_dbt: Close
09:03:14.562441 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
09:03:14.563024 [info ] [MainThread]: 
09:03:14.568118 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
09:03:14.568490 [info ] [Thread-1  ]: 1 of 2 START table model dbt.my_first_dbt_model................................. [RUN]
09:03:14.568975 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
09:03:14.569145 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
09:03:14.569310 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
09:03:14.572372 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
09:03:14.572953 [debug] [Thread-1  ]: finished collecting timing info
09:03:14.573122 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
09:03:14.593946 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
09:03:14.594830 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
09:03:14.594949 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
09:03:14.595045 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:03:15.491436 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a43c3f-3201-9c12-0000-000120521055
09:03:15.491846 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.

09:03:15.492217 [debug] [Thread-1  ]: finished collecting timing info
09:03:15.492470 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
09:03:15.677099 [debug] [Thread-1  ]: Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
  
  compiled SQL at target/run/learn_dbt/models/example/my_first_dbt_model.sql
09:03:15.677851 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '391d4129-e590-4cd3-9371-422090825d89', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c5de2b0>]}
09:03:15.678382 [error] [Thread-1  ]: 1 of 2 ERROR creating table model dbt.my_first_dbt_model........................ [[31mERROR[0m in 1.11s]
09:03:15.678817 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
09:03:15.679600 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
09:03:15.679942 [info ] [Thread-1  ]: 2 of 2 SKIP relation dbt.my_second_dbt_model.................................... [[33mSKIP[0m]
09:03:15.680398 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
09:03:15.681518 [debug] [MainThread]: Acquiring new snowflake connection "master"
09:03:15.681943 [info ] [MainThread]: 
09:03:15.682268 [info ] [MainThread]: Finished running 1 table model, 1 view model in 5.57s.
09:03:15.682554 [debug] [MainThread]: Connection 'master' was properly closed.
09:03:15.682716 [debug] [MainThread]: Connection 'model.learn_dbt.my_first_dbt_model' was properly closed.
09:03:15.688290 [info ] [MainThread]: 
09:03:15.688603 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
09:03:15.688847 [info ] [MainThread]: 
09:03:15.689046 [error] [MainThread]: [33mDatabase Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)[0m
09:03:15.689239 [error] [MainThread]:   000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
09:03:15.689424 [error] [MainThread]:   
09:03:15.689604 [error] [MainThread]:   compiled SQL at target/run/learn_dbt/models/example/my_first_dbt_model.sql
09:03:15.689789 [info ] [MainThread]: 
09:03:15.689971 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=1 TOTAL=2
09:03:15.690231 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bd9a070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bd9aeb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c45d4c0>]}


============================== 2022-05-13 09:05:11.508316 | 5049d4f0-fa56-4896-8f6f-56a08aa2f94c ==============================
09:05:11.508316 [info ] [MainThread]: Running with dbt=1.0.1
09:05:11.509537 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
09:05:11.509693 [debug] [MainThread]: Tracking: tracking
09:05:11.509897 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122733df0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122733c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1227338b0>]}
09:05:11.543198 [info ] [MainThread]: Unable to do partial parsing because profile has changed
09:05:11.543460 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '5049d4f0-fa56-4896-8f6f-56a08aa2f94c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122738e50>]}
09:05:11.553662 [debug] [MainThread]: Parsing macros/catalog.sql
09:05:11.554855 [debug] [MainThread]: Parsing macros/adapters.sql
09:05:11.574543 [debug] [MainThread]: Parsing macros/materializations/merge.sql
09:05:11.576425 [debug] [MainThread]: Parsing macros/materializations/seed.sql
09:05:11.578848 [debug] [MainThread]: Parsing macros/materializations/view.sql
09:05:11.579432 [debug] [MainThread]: Parsing macros/materializations/table.sql
09:05:11.580836 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
09:05:11.584836 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
09:05:11.585246 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
09:05:11.586954 [debug] [MainThread]: Parsing macros/materializations/configs.sql
09:05:11.587948 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
09:05:11.588686 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
09:05:11.596353 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
09:05:11.601843 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
09:05:11.607611 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
09:05:11.609672 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
09:05:11.610454 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
09:05:11.611239 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
09:05:11.613203 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
09:05:11.618652 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
09:05:11.619389 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
09:05:11.624394 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
09:05:11.632085 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
09:05:11.635697 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
09:05:11.636947 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
09:05:11.640411 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
09:05:11.640973 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
09:05:11.642180 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
09:05:11.643165 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
09:05:11.645974 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
09:05:11.654408 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
09:05:11.655262 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
09:05:11.656398 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
09:05:11.657117 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
09:05:11.657523 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
09:05:11.657762 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
09:05:11.658063 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
09:05:11.658676 [debug] [MainThread]: Parsing macros/etc/statement.sql
09:05:11.660935 [debug] [MainThread]: Parsing macros/etc/datetime.sql
09:05:11.665247 [debug] [MainThread]: Parsing macros/adapters/schema.sql
09:05:11.666286 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
09:05:11.667720 [debug] [MainThread]: Parsing macros/adapters/relation.sql
09:05:11.672277 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
09:05:11.673565 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
09:05:11.675548 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
09:05:11.678878 [debug] [MainThread]: Parsing macros/adapters/columns.sql
09:05:11.683595 [debug] [MainThread]: Parsing tests/generic/builtin.sql
09:05:11.779746 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
09:05:11.785221 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
09:05:11.808438 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5049d4f0-fa56-4896-8f6f-56a08aa2f94c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1227a29d0>]}
09:05:11.811006 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5049d4f0-fa56-4896-8f6f-56a08aa2f94c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122718850>]}
09:05:11.811135 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
09:05:11.811677 [info ] [MainThread]: 
09:05:11.811871 [debug] [MainThread]: Acquiring new snowflake connection "master"
09:05:11.812210 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
09:05:11.817987 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
09:05:11.818080 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
09:05:11.818152 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:05:12.627137 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.81 seconds
09:05:12.630374 [debug] [ThreadPool]: On list_analytics: Close
09:05:12.924422 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
09:05:12.933161 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
09:05:12.933426 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
09:05:12.933596 [debug] [ThreadPool]: Opening a new connection, currently in state closed
09:05:13.971256 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 1.04 seconds
09:05:13.973687 [debug] [ThreadPool]: On list_analytics_dbt: Close
09:05:14.156177 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
09:05:14.156821 [info ] [MainThread]: 
09:05:14.162008 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
09:05:14.162425 [info ] [Thread-1  ]: 1 of 2 START table model dbt.my_first_dbt_model................................. [RUN]
09:05:14.162966 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
09:05:14.163140 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
09:05:14.163674 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
09:05:14.166468 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
09:05:14.167057 [debug] [Thread-1  ]: finished collecting timing info
09:05:14.167234 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
09:05:14.189219 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
09:05:14.190061 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
09:05:14.190170 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
09:05:14.190258 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:05:15.026254 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a43c41-3201-9c12-0000-000120521061
09:05:15.026599 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.

09:05:15.026945 [debug] [Thread-1  ]: finished collecting timing info
09:05:15.027261 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
09:05:15.210646 [debug] [Thread-1  ]: Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
  
  compiled SQL at target/run/learn_dbt/models/example/my_first_dbt_model.sql
09:05:15.211010 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5049d4f0-fa56-4896-8f6f-56a08aa2f94c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122f30100>]}
09:05:15.211299 [error] [Thread-1  ]: 1 of 2 ERROR creating table model dbt.my_first_dbt_model........................ [[31mERROR[0m in 1.05s]
09:05:15.211516 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
09:05:15.212018 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
09:05:15.212272 [info ] [Thread-1  ]: 2 of 2 SKIP relation dbt.my_second_dbt_model.................................... [[33mSKIP[0m]
09:05:15.212573 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
09:05:15.213287 [debug] [MainThread]: Acquiring new snowflake connection "master"
09:05:15.213544 [info ] [MainThread]: 
09:05:15.213701 [info ] [MainThread]: Finished running 1 table model, 1 view model in 3.40s.
09:05:15.213834 [debug] [MainThread]: Connection 'master' was properly closed.
09:05:15.213904 [debug] [MainThread]: Connection 'model.learn_dbt.my_first_dbt_model' was properly closed.
09:05:15.216993 [info ] [MainThread]: 
09:05:15.217180 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
09:05:15.217328 [info ] [MainThread]: 
09:05:15.217448 [error] [MainThread]: [33mDatabase Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)[0m
09:05:15.217569 [error] [MainThread]:   000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
09:05:15.217684 [error] [MainThread]:   
09:05:15.217797 [error] [MainThread]:   compiled SQL at target/run/learn_dbt/models/example/my_first_dbt_model.sql
09:05:15.217919 [info ] [MainThread]: 
09:05:15.218037 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=1 TOTAL=2
09:05:15.218216 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1228335e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1227a2ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122c0a550>]}


============================== 2022-05-13 09:08:37.807686 | f30dde7d-7412-4489-82e8-931d87ba7f0c ==============================
09:08:37.807686 [info ] [MainThread]: Running with dbt=1.0.1
09:08:37.808029 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
09:08:37.808155 [debug] [MainThread]: Tracking: tracking
09:08:37.808337 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e48a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108237a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e832b0>]}
09:08:37.850417 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
09:08:37.850566 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
09:08:37.853690 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f30dde7d-7412-4489-82e8-931d87ba7f0c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1082150d0>]}
09:08:37.856405 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f30dde7d-7412-4489-82e8-931d87ba7f0c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10823edc0>]}
09:08:37.856541 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
09:08:37.857105 [info ] [MainThread]: 
09:08:37.857305 [debug] [MainThread]: Acquiring new snowflake connection "master"
09:08:37.857670 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
09:08:37.863694 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
09:08:37.863798 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
09:08:37.863867 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:08:38.934934 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.07 seconds
09:08:38.937153 [debug] [ThreadPool]: On list_analytics: Close
09:08:39.167172 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
09:08:39.176166 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
09:08:39.176435 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
09:08:39.176593 [debug] [ThreadPool]: Opening a new connection, currently in state closed
09:08:40.193802 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 1.02 seconds
09:08:40.196491 [debug] [ThreadPool]: On list_analytics_dbt: Close
09:08:40.599596 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
09:08:40.600685 [info ] [MainThread]: 
09:08:40.606392 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
09:08:40.606862 [info ] [Thread-1  ]: 1 of 2 START table model dbt.my_first_dbt_model................................. [RUN]
09:08:40.607441 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
09:08:40.607693 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
09:08:40.608475 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
09:08:40.611262 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
09:08:40.612024 [debug] [Thread-1  ]: finished collecting timing info
09:08:40.612212 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
09:08:40.633697 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
09:08:40.634459 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
09:08:40.634565 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
09:08:40.634654 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:08:42.724085 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.09 seconds
09:08:42.737381 [debug] [Thread-1  ]: finished collecting timing info
09:08:42.737780 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
09:08:42.907359 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f30dde7d-7412-4489-82e8-931d87ba7f0c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1085a5100>]}
09:08:42.907826 [info ] [Thread-1  ]: 1 of 2 OK created table model dbt.my_first_dbt_model............................ [[32mSUCCESS 1[0m in 2.30s]
09:08:42.908071 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
09:08:42.908713 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
09:08:42.909162 [info ] [Thread-1  ]: 2 of 2 START view model dbt.my_second_dbt_model................................. [RUN]
09:08:42.909579 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
09:08:42.909717 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
09:08:42.909843 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
09:08:42.912992 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
09:08:42.913635 [debug] [Thread-1  ]: finished collecting timing info
09:08:42.913793 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
09:08:42.928207 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
09:08:42.929045 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
09:08:42.929186 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */

  create or replace  view analytics.dbt.my_second_dbt_model 
  
   as (
    -- Use the `ref` function to select from other models

select *
from analytics.dbt.my_first_dbt_model
where id = 1
  );
09:08:42.929299 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:08:43.911558 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.98 seconds
09:08:43.914986 [debug] [Thread-1  ]: finished collecting timing info
09:08:43.915351 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
09:08:44.314355 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f30dde7d-7412-4489-82e8-931d87ba7f0c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1085b0d60>]}
09:08:44.316725 [info ] [Thread-1  ]: 2 of 2 OK created view model dbt.my_second_dbt_model............................ [[32mSUCCESS 1[0m in 1.40s]
09:08:44.317060 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
09:08:44.317717 [debug] [MainThread]: Acquiring new snowflake connection "master"
09:08:44.317936 [info ] [MainThread]: 
09:08:44.318094 [info ] [MainThread]: Finished running 1 table model, 1 view model in 6.46s.
09:08:44.318238 [debug] [MainThread]: Connection 'master' was properly closed.
09:08:44.318314 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
09:08:44.324380 [info ] [MainThread]: 
09:08:44.324742 [info ] [MainThread]: [32mCompleted successfully[0m
09:08:44.325040 [info ] [MainThread]: 
09:08:44.325268 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
09:08:44.325574 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1085b0b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1085a48b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10823bb20>]}


============================== 2022-05-13 09:22:35.513052 | f18ef690-fea8-4b16-8c9c-30db2b6baf7c ==============================
09:22:35.513052 [info ] [MainThread]: Running with dbt=1.0.1
09:22:35.513572 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
09:22:35.513709 [debug] [MainThread]: Tracking: tracking
09:22:35.513917 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11125f2b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11125fb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11125f9a0>]}
09:22:35.551296 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10794f0a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111255400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1112555b0>]}


============================== 2022-05-13 09:22:57.623011 | cdab71e1-726f-4a09-859e-c1749deddf84 ==============================
09:22:57.623011 [info ] [MainThread]: Running with dbt=1.0.1
09:22:57.623361 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
09:22:57.623486 [debug] [MainThread]: Tracking: tracking
09:22:57.623705 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a9031c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a903d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a903e50>]}
09:22:57.667223 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
09:22:57.667424 [debug] [MainThread]: Partial parsing: added file: learn_dbt://models/example/snowflake_customer_purchases.sql
09:22:57.667572 [debug] [MainThread]: Partial parsing: update schema file: learn_dbt://models/example/schema.yml
09:22:57.673349 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
09:22:57.693223 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cdab71e1-726f-4a09-859e-c1749deddf84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a8e1d30>]}
09:22:57.695997 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cdab71e1-726f-4a09-859e-c1749deddf84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a8e9820>]}
09:22:57.696139 [info ] [MainThread]: Found 3 models, 6 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
09:22:57.696743 [info ] [MainThread]: 
09:22:57.696942 [debug] [MainThread]: Acquiring new snowflake connection "master"
09:22:57.697411 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
09:22:57.703288 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
09:22:57.703391 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
09:22:57.703454 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:22:58.739887 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.04 seconds
09:22:58.741059 [debug] [ThreadPool]: On list_analytics: Close
09:22:58.990887 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
09:22:58.999000 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
09:22:58.999395 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
09:22:58.999572 [debug] [ThreadPool]: Opening a new connection, currently in state closed
09:22:59.989543 [debug] [ThreadPool]: SQL status: SUCCESS 2 in 0.99 seconds
09:22:59.993886 [debug] [ThreadPool]: On list_analytics_dbt: Close
09:23:00.376164 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
09:23:00.376755 [info ] [MainThread]: 
09:23:00.382575 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
09:23:00.383011 [info ] [Thread-1  ]: 1 of 3 START table model dbt.my_first_dbt_model................................. [RUN]
09:23:00.384101 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
09:23:00.384381 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
09:23:00.384576 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
09:23:00.387657 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
09:23:00.388367 [debug] [Thread-1  ]: finished collecting timing info
09:23:00.388573 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
09:23:00.409860 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
09:23:00.410820 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
09:23:00.410931 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
09:23:00.411026 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:23:02.404957 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.99 seconds
09:23:02.418484 [debug] [Thread-1  ]: finished collecting timing info
09:23:02.418872 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
09:23:02.614783 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cdab71e1-726f-4a09-859e-c1749deddf84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ad6ea60>]}
09:23:02.615651 [info ] [Thread-1  ]: 1 of 3 OK created table model dbt.my_first_dbt_model............................ [[32mSUCCESS 1[0m in 2.23s]
09:23:02.616131 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
09:23:02.616547 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
09:23:02.616895 [info ] [Thread-1  ]: 2 of 3 START table model dbt.snowflake_customer_purchases....................... [RUN]
09:23:02.617648 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
09:23:02.618039 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
09:23:02.618336 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
09:23:02.621553 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
09:23:02.622262 [debug] [Thread-1  ]: finished collecting timing info
09:23:02.622544 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
09:23:02.624889 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
09:23:02.626173 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
09:23:02.626352 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (

select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
;
09:23:02.626516 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:23:03.581819 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a43c53-3201-9c78-0000-00012052602d
09:23:03.582303 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 15 at position 0 unexpected ';'.
09:23:03.582655 [debug] [Thread-1  ]: finished collecting timing info
09:23:03.582760 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
09:23:03.746868 [debug] [Thread-1  ]: Database Error in model snowflake_customer_purchases (models/example/snowflake_customer_purchases.sql)
  001003 (42000): SQL compilation error:
  syntax error line 15 at position 0 unexpected ';'.
  compiled SQL at target/run/learn_dbt/models/example/snowflake_customer_purchases.sql
09:23:03.747460 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cdab71e1-726f-4a09-859e-c1749deddf84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cf66340>]}
09:23:03.747976 [error] [Thread-1  ]: 2 of 3 ERROR creating table model dbt.snowflake_customer_purchases.............. [[31mERROR[0m in 1.13s]
09:23:03.748403 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
09:23:03.748634 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
09:23:03.749060 [info ] [Thread-1  ]: 3 of 3 START view model dbt.my_second_dbt_model................................. [RUN]
09:23:03.749700 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
09:23:03.749916 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
09:23:03.750131 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
09:23:03.753408 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
09:23:03.754234 [debug] [Thread-1  ]: finished collecting timing info
09:23:03.754447 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
09:23:03.774682 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
09:23:03.775584 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
09:23:03.775723 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */

  create or replace  view analytics.dbt.my_second_dbt_model 
  
   as (
    -- Use the `ref` function to select from other models

select *
from analytics.dbt.my_first_dbt_model
where id = 1
  );
09:23:03.775825 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:23:04.785183 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.01 seconds
09:23:04.789841 [debug] [Thread-1  ]: finished collecting timing info
09:23:04.790237 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
09:23:05.184688 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cdab71e1-726f-4a09-859e-c1749deddf84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10adc0340>]}
09:23:05.185040 [info ] [Thread-1  ]: 3 of 3 OK created view model dbt.my_second_dbt_model............................ [[32mSUCCESS 1[0m in 1.44s]
09:23:05.185204 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
09:23:05.185765 [debug] [MainThread]: Acquiring new snowflake connection "master"
09:23:05.185968 [info ] [MainThread]: 
09:23:05.186091 [info ] [MainThread]: Finished running 2 table models, 1 view model in 7.49s.
09:23:05.186196 [debug] [MainThread]: Connection 'master' was properly closed.
09:23:05.186253 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
09:23:05.189553 [info ] [MainThread]: 
09:23:05.189769 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
09:23:05.189922 [info ] [MainThread]: 
09:23:05.190047 [error] [MainThread]: [33mDatabase Error in model snowflake_customer_purchases (models/example/snowflake_customer_purchases.sql)[0m
09:23:05.190171 [error] [MainThread]:   001003 (42000): SQL compilation error:
09:23:05.190285 [error] [MainThread]:   syntax error line 15 at position 0 unexpected ';'.
09:23:05.190397 [error] [MainThread]:   compiled SQL at target/run/learn_dbt/models/example/snowflake_customer_purchases.sql
09:23:05.190514 [info ] [MainThread]: 
09:23:05.190638 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=0 TOTAL=3
09:23:05.190818 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ada5b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ae12730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10adc08e0>]}


============================== 2022-05-13 09:23:56.121102 | 59fcf14f-3bbd-40b6-bb80-4cf0ee3c9889 ==============================
09:23:56.121102 [info ] [MainThread]: Running with dbt=1.0.1
09:23:56.121720 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
09:23:56.121856 [debug] [MainThread]: Tracking: tracking
09:23:56.122071 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1061439a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106143b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1061433a0>]}
09:23:56.166935 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
09:23:56.167214 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/snowflake_customer_purchases.sql
09:23:56.173041 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
09:23:56.192907 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '59fcf14f-3bbd-40b6-bb80-4cf0ee3c9889', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106267af0>]}
09:23:56.195625 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '59fcf14f-3bbd-40b6-bb80-4cf0ee3c9889', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106131400>]}
09:23:56.195758 [info ] [MainThread]: Found 3 models, 6 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
09:23:56.196357 [info ] [MainThread]: 
09:23:56.196558 [debug] [MainThread]: Acquiring new snowflake connection "master"
09:23:56.196987 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
09:23:56.202879 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
09:23:56.202977 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
09:23:56.203038 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:23:57.059138 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.86 seconds
09:23:57.061849 [debug] [ThreadPool]: On list_analytics: Close
09:23:57.228386 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
09:23:57.237720 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
09:23:57.237952 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
09:23:57.238112 [debug] [ThreadPool]: Opening a new connection, currently in state closed
09:23:58.112840 [debug] [ThreadPool]: SQL status: SUCCESS 2 in 0.87 seconds
09:23:58.115757 [debug] [ThreadPool]: On list_analytics_dbt: Close
09:23:58.374494 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
09:23:58.375138 [info ] [MainThread]: 
09:23:58.380193 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
09:23:58.380642 [info ] [Thread-1  ]: 1 of 3 START table model dbt.my_first_dbt_model................................. [RUN]
09:23:58.381885 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
09:23:58.382092 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
09:23:58.382263 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
09:23:58.385022 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
09:23:58.385624 [debug] [Thread-1  ]: finished collecting timing info
09:23:58.385839 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
09:23:58.406587 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
09:23:58.407318 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
09:23:58.407403 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
09:23:58.407469 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:24:00.139626 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.73 seconds
09:24:00.151966 [debug] [Thread-1  ]: finished collecting timing info
09:24:00.152355 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
09:24:00.321405 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '59fcf14f-3bbd-40b6-bb80-4cf0ee3c9889', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067d6820>]}
09:24:00.322068 [info ] [Thread-1  ]: 1 of 3 OK created table model dbt.my_first_dbt_model............................ [[32mSUCCESS 1[0m in 1.94s]
09:24:00.322504 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
09:24:00.322752 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
09:24:00.323152 [info ] [Thread-1  ]: 2 of 3 START table model dbt.snowflake_customer_purchases....................... [RUN]
09:24:00.323729 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
09:24:00.323930 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
09:24:00.324216 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
09:24:00.327527 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
09:24:00.328134 [debug] [Thread-1  ]: finished collecting timing info
09:24:00.328301 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
09:24:00.330545 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
09:24:00.331859 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
09:24:00.332047 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (

select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
09:24:00.332201 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:24:02.725651 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.39 seconds
09:24:02.731379 [debug] [Thread-1  ]: finished collecting timing info
09:24:02.731823 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
09:24:02.884596 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '59fcf14f-3bbd-40b6-bb80-4cf0ee3c9889', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067d6910>]}
09:24:02.885485 [info ] [Thread-1  ]: 2 of 3 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.56s]
09:24:02.885954 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
09:24:02.886259 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
09:24:02.886719 [info ] [Thread-1  ]: 3 of 3 START view model dbt.my_second_dbt_model................................. [RUN]
09:24:02.887403 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
09:24:02.887625 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
09:24:02.887836 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
09:24:02.890933 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
09:24:02.891568 [debug] [Thread-1  ]: finished collecting timing info
09:24:02.891743 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
09:24:02.911134 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
09:24:02.911905 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
09:24:02.912024 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */

  create or replace  view analytics.dbt.my_second_dbt_model 
  
   as (
    -- Use the `ref` function to select from other models

select *
from analytics.dbt.my_first_dbt_model
where id = 1
  );
09:24:02.912122 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:24:04.002332 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.09 seconds
09:24:04.005579 [debug] [Thread-1  ]: finished collecting timing info
09:24:04.005976 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
09:24:04.271108 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '59fcf14f-3bbd-40b6-bb80-4cf0ee3c9889', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108e64c10>]}
09:24:04.271733 [info ] [Thread-1  ]: 3 of 3 OK created view model dbt.my_second_dbt_model............................ [[32mSUCCESS 1[0m in 1.38s]
09:24:04.272173 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
09:24:04.273329 [debug] [MainThread]: Acquiring new snowflake connection "master"
09:24:04.273682 [info ] [MainThread]: 
09:24:04.273921 [info ] [MainThread]: Finished running 2 table models, 1 view model in 8.08s.
09:24:04.274121 [debug] [MainThread]: Connection 'master' was properly closed.
09:24:04.274225 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
09:24:04.279371 [info ] [MainThread]: 
09:24:04.279741 [info ] [MainThread]: [32mCompleted successfully[0m
09:24:04.280049 [info ] [MainThread]: 
09:24:04.280282 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
09:24:04.280595 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1066f9d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1061318e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1066f75b0>]}


============================== 2022-05-13 09:54:17.002977 | 4847f8b1-0605-40c5-8429-cd2e966440b7 ==============================
09:54:17.002977 [info ] [MainThread]: Running with dbt=1.0.1
09:54:17.003521 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
09:54:17.003664 [debug] [MainThread]: Tracking: tracking
09:54:17.003880 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1046e7190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1046e70a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1046e7b20>]}
09:54:17.048631 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
09:54:17.048843 [debug] [MainThread]: Partial parsing: added file: learn_dbt://models/example/snowflake_cumulative_sales.sql
09:54:17.049056 [debug] [MainThread]: Partial parsing: update schema file: learn_dbt://models/example/schema.yml
09:54:17.054680 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_cumulative_sales.sql
09:54:17.074629 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4847f8b1-0605-40c5-8429-cd2e966440b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10482e0d0>]}
09:54:17.077529 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4847f8b1-0605-40c5-8429-cd2e966440b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1046f4df0>]}
09:54:17.077666 [info ] [MainThread]: Found 4 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
09:54:17.078305 [info ] [MainThread]: 
09:54:17.078502 [debug] [MainThread]: Acquiring new snowflake connection "master"
09:54:17.078968 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
09:54:17.085193 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
09:54:17.085342 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
09:54:17.085414 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:54:18.159868 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.07 seconds
09:54:18.162222 [debug] [ThreadPool]: On list_analytics: Close
09:54:18.354693 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
09:54:18.363818 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
09:54:18.364061 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
09:54:18.364227 [debug] [ThreadPool]: Opening a new connection, currently in state closed
09:54:19.357991 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.99 seconds
09:54:19.363265 [debug] [ThreadPool]: On list_analytics_dbt: Close
09:54:19.733194 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
09:54:19.733990 [info ] [MainThread]: 
09:54:19.738795 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
09:54:19.739240 [info ] [Thread-1  ]: 1 of 4 START table model dbt.my_first_dbt_model................................. [RUN]
09:54:19.740129 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
09:54:19.740313 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
09:54:19.740481 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
09:54:19.743303 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
09:54:19.743906 [debug] [Thread-1  ]: finished collecting timing info
09:54:19.744076 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
09:54:19.765491 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
09:54:19.766440 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
09:54:19.766565 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
09:54:19.766667 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:54:21.500734 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.73 seconds
09:54:21.509106 [debug] [Thread-1  ]: finished collecting timing info
09:54:21.509364 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
09:54:21.714615 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4847f8b1-0605-40c5-8429-cd2e966440b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106944f40>]}
09:54:21.715589 [info ] [Thread-1  ]: 1 of 4 OK created table model dbt.my_first_dbt_model............................ [[32mSUCCESS 1[0m in 1.97s]
09:54:21.716061 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
09:54:21.716315 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
09:54:21.716749 [info ] [Thread-1  ]: 2 of 4 START table model dbt.snowflake_cumulative_sales......................... [RUN]
09:54:21.717504 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
09:54:21.717724 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
09:54:21.717924 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
09:54:21.721391 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
09:54:21.722029 [debug] [Thread-1  ]: finished collecting timing info
09:54:21.722206 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
09:54:21.724546 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
09:54:21.725787 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
09:54:21.725984 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (

select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate;
09:54:21.726138 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:54:22.359293 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a43c72-3201-9c12-0000-000120521525
09:54:22.359673 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 7 at position 20 unexpected ';'.
09:54:22.360024 [debug] [Thread-1  ]: finished collecting timing info
09:54:22.360261 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
09:54:22.522971 [debug] [Thread-1  ]: Database Error in model snowflake_cumulative_sales (models/example/snowflake_cumulative_sales.sql)
  001003 (42000): SQL compilation error:
  syntax error line 7 at position 20 unexpected ';'.
  compiled SQL at target/run/learn_dbt/models/example/snowflake_cumulative_sales.sql
09:54:22.523933 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4847f8b1-0605-40c5-8429-cd2e966440b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106977100>]}
09:54:22.524412 [error] [Thread-1  ]: 2 of 4 ERROR creating table model dbt.snowflake_cumulative_sales................ [[31mERROR[0m in 0.81s]
09:54:22.524808 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
09:54:22.524982 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
09:54:22.525300 [info ] [Thread-1  ]: 3 of 4 START table model dbt.snowflake_customer_purchases....................... [RUN]
09:54:22.525740 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
09:54:22.525895 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
09:54:22.526032 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
09:54:22.528213 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
09:54:22.528743 [debug] [Thread-1  ]: finished collecting timing info
09:54:22.528880 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
09:54:22.531249 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
09:54:22.532537 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
09:54:22.532719 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (

select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
09:54:22.532870 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:54:24.273982 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.74 seconds
09:54:24.276212 [debug] [Thread-1  ]: finished collecting timing info
09:54:24.276471 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
09:54:24.548797 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4847f8b1-0605-40c5-8429-cd2e966440b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104b899d0>]}
09:54:24.549565 [info ] [Thread-1  ]: 3 of 4 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.02s]
09:54:24.550028 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
09:54:24.550282 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
09:54:24.550691 [info ] [Thread-1  ]: 4 of 4 START view model dbt.my_second_dbt_model................................. [RUN]
09:54:24.551340 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
09:54:24.551553 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
09:54:24.551755 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
09:54:24.554614 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
09:54:24.555299 [debug] [Thread-1  ]: finished collecting timing info
09:54:24.555480 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
09:54:24.573856 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
09:54:24.574666 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
09:54:24.574784 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */

  create or replace  view analytics.dbt.my_second_dbt_model 
  
   as (
    -- Use the `ref` function to select from other models

select *
from analytics.dbt.my_first_dbt_model
where id = 1
  );
09:54:24.574890 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:54:25.501707 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.93 seconds
09:54:25.505830 [debug] [Thread-1  ]: finished collecting timing info
09:54:25.506231 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
09:54:25.676733 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4847f8b1-0605-40c5-8429-cd2e966440b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104ad0460>]}
09:54:25.677747 [info ] [Thread-1  ]: 4 of 4 OK created view model dbt.my_second_dbt_model............................ [[32mSUCCESS 1[0m in 1.13s]
09:54:25.678248 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
09:54:25.679660 [debug] [MainThread]: Acquiring new snowflake connection "master"
09:54:25.680152 [info ] [MainThread]: 
09:54:25.680501 [info ] [MainThread]: Finished running 3 table models, 1 view model in 8.60s.
09:54:25.680801 [debug] [MainThread]: Connection 'master' was properly closed.
09:54:25.680971 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
09:54:25.687377 [info ] [MainThread]: 
09:54:25.687752 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
09:54:25.688043 [info ] [MainThread]: 
09:54:25.688261 [error] [MainThread]: [33mDatabase Error in model snowflake_cumulative_sales (models/example/snowflake_cumulative_sales.sql)[0m
09:54:25.688458 [error] [MainThread]:   001003 (42000): SQL compilation error:
09:54:25.688645 [error] [MainThread]:   syntax error line 7 at position 20 unexpected ';'.
09:54:25.688826 [error] [MainThread]:   compiled SQL at target/run/learn_dbt/models/example/snowflake_cumulative_sales.sql
09:54:25.689021 [info ] [MainThread]: 
09:54:25.689207 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=1 SKIP=0 TOTAL=4
09:54:25.689587 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1047001c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106979d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1069701f0>]}


============================== 2022-05-13 09:54:41.082217 | d89147e0-651a-4b7b-ae3b-0a37710672dc ==============================
09:54:41.082217 [info ] [MainThread]: Running with dbt=1.0.1
09:54:41.082558 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
09:54:41.082670 [debug] [MainThread]: Tracking: tracking
09:54:41.082891 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e432b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e43b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e439a0>]}
09:54:41.126449 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
09:54:41.126724 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/snowflake_cumulative_sales.sql
09:54:41.131941 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_cumulative_sales.sql
09:54:41.151223 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd89147e0-651a-4b7b-ae3b-0a37710672dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10390b100>]}
09:54:41.154087 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd89147e0-651a-4b7b-ae3b-0a37710672dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e1b340>]}
09:54:41.154221 [info ] [MainThread]: Found 4 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
09:54:41.154863 [info ] [MainThread]: 
09:54:41.155073 [debug] [MainThread]: Acquiring new snowflake connection "master"
09:54:41.155571 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
09:54:41.161661 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
09:54:41.161791 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
09:54:41.161861 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:54:42.275029 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.11 seconds
09:54:42.278260 [debug] [ThreadPool]: On list_analytics: Close
09:54:42.495752 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
09:54:42.506304 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
09:54:42.506580 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
09:54:42.506749 [debug] [ThreadPool]: Opening a new connection, currently in state closed
09:54:43.436242 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.93 seconds
09:54:43.438668 [debug] [ThreadPool]: On list_analytics_dbt: Close
09:54:43.622459 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
09:54:43.622718 [info ] [MainThread]: 
09:54:43.627390 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
09:54:43.627811 [info ] [Thread-1  ]: 1 of 4 START table model dbt.my_first_dbt_model................................. [RUN]
09:54:43.628641 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
09:54:43.628816 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
09:54:43.628978 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
09:54:43.631627 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
09:54:43.632192 [debug] [Thread-1  ]: finished collecting timing info
09:54:43.632365 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
09:54:43.654012 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
09:54:43.654919 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
09:54:43.655040 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
09:54:43.655142 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:54:45.421579 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.77 seconds
09:54:45.435665 [debug] [Thread-1  ]: finished collecting timing info
09:54:45.435946 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
09:54:45.618324 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd89147e0-651a-4b7b-ae3b-0a37710672dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107065d60>]}
09:54:45.619080 [info ] [Thread-1  ]: 1 of 4 OK created table model dbt.my_first_dbt_model............................ [[32mSUCCESS 1[0m in 1.99s]
09:54:45.619532 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
09:54:45.619782 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
09:54:45.620216 [info ] [Thread-1  ]: 2 of 4 START table model dbt.snowflake_cumulative_sales......................... [RUN]
09:54:45.621032 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
09:54:45.621280 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
09:54:45.621488 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
09:54:45.624906 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
09:54:45.625661 [debug] [Thread-1  ]: finished collecting timing info
09:54:45.625831 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
09:54:45.628080 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
09:54:45.629309 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
09:54:45.629490 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (

select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
09:54:45.629645 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:54:47.001818 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.37 seconds
09:54:47.005242 [debug] [Thread-1  ]: finished collecting timing info
09:54:47.005710 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
09:54:47.168470 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd89147e0-651a-4b7b-ae3b-0a37710672dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1056faa60>]}
09:54:47.169156 [info ] [Thread-1  ]: 2 of 4 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 1.55s]
09:54:47.169678 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
09:54:47.169844 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
09:54:47.170041 [info ] [Thread-1  ]: 3 of 4 START table model dbt.snowflake_customer_purchases....................... [RUN]
09:54:47.170320 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
09:54:47.170405 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
09:54:47.170484 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
09:54:47.171879 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
09:54:47.172279 [debug] [Thread-1  ]: finished collecting timing info
09:54:47.172359 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
09:54:47.173630 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
09:54:47.174939 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
09:54:47.175136 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (

select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
09:54:47.175314 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:54:48.643809 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.47 seconds
09:54:48.646642 [debug] [Thread-1  ]: finished collecting timing info
09:54:48.647039 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
09:54:48.808018 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd89147e0-651a-4b7b-ae3b-0a37710672dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1070882b0>]}
09:54:48.809267 [info ] [Thread-1  ]: 3 of 4 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 1.64s]
09:54:48.809855 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
09:54:48.810110 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
09:54:48.810507 [info ] [Thread-1  ]: 4 of 4 START view model dbt.my_second_dbt_model................................. [RUN]
09:54:48.811170 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
09:54:48.811391 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
09:54:48.811610 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
09:54:48.814913 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
09:54:48.816755 [debug] [Thread-1  ]: finished collecting timing info
09:54:48.817083 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
09:54:48.835122 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
09:54:48.836057 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
09:54:48.836191 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */

  create or replace  view analytics.dbt.my_second_dbt_model 
  
   as (
    -- Use the `ref` function to select from other models

select *
from analytics.dbt.my_first_dbt_model
where id = 1
  );
09:54:48.836338 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:54:49.613498 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.78 seconds
09:54:49.616406 [debug] [Thread-1  ]: finished collecting timing info
09:54:49.616807 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
09:54:49.798509 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd89147e0-651a-4b7b-ae3b-0a37710672dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10531dd90>]}
09:54:49.799228 [info ] [Thread-1  ]: 4 of 4 OK created view model dbt.my_second_dbt_model............................ [[32mSUCCESS 1[0m in 0.99s]
09:54:49.799681 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
09:54:49.800998 [debug] [MainThread]: Acquiring new snowflake connection "master"
09:54:49.801477 [info ] [MainThread]: 
09:54:49.801811 [info ] [MainThread]: Finished running 3 table models, 1 view model in 8.65s.
09:54:49.802111 [debug] [MainThread]: Connection 'master' was properly closed.
09:54:49.802304 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
09:54:49.809201 [info ] [MainThread]: 
09:54:49.809556 [info ] [MainThread]: [32mCompleted successfully[0m
09:54:49.809935 [info ] [MainThread]: 
09:54:49.810164 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
09:54:49.810465 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e38e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e1ba30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105744640>]}


============================== 2022-05-13 10:07:46.864603 | 3cef4318-224c-46d2-bf0b-0c6246e1ac30 ==============================
10:07:46.864603 [info ] [MainThread]: Running with dbt=1.0.1
10:07:46.865245 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
10:07:46.865425 [debug] [MainThread]: Tracking: tracking
10:07:46.865687 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105793ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105793cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1057939d0>]}
10:07:46.912437 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 3 files changed.
10:07:46.912700 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/my_first_dbt_model.sql
10:07:46.912881 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/snowflake_cumulative_sales.sql
10:07:46.913000 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/snowflake_customer_purchases.sql
10:07:46.918857 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
10:07:46.924857 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_cumulative_sales.sql
10:07:46.925965 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
10:07:46.947093 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3cef4318-224c-46d2-bf0b-0c6246e1ac30', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10405e1f0>]}
10:07:46.950451 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3cef4318-224c-46d2-bf0b-0c6246e1ac30', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105771670>]}
10:07:46.950612 [info ] [MainThread]: Found 4 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
10:07:46.951242 [info ] [MainThread]: 
10:07:46.951466 [debug] [MainThread]: Acquiring new snowflake connection "master"
10:07:46.951907 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
10:07:46.958525 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
10:07:46.958677 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
10:07:46.958751 [debug] [ThreadPool]: Opening a new connection, currently in state init
10:07:48.150899 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.19 seconds
10:07:48.154857 [debug] [ThreadPool]: On list_analytics: Close
10:07:48.376099 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
10:07:48.393916 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
10:07:48.394378 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
10:07:48.394766 [debug] [ThreadPool]: Opening a new connection, currently in state closed
10:07:49.329158 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 0.93 seconds
10:07:49.334210 [debug] [ThreadPool]: On list_analytics_dbt: Close
10:07:49.551927 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
10:07:49.552789 [info ] [MainThread]: 
10:07:49.573368 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
10:07:49.573949 [info ] [Thread-1  ]: 1 of 4 START view model dbt.my_first_dbt_model.................................. [RUN]
10:07:49.574796 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
10:07:49.574928 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
10:07:49.575052 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
10:07:49.577034 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
10:07:49.577389 [debug] [Thread-1  ]: finished collecting timing info
10:07:49.577486 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
10:07:49.596537 [debug] [Thread-1  ]: Dropping relation "ANALYTICS"."DBT"."MY_FIRST_DBT_MODEL" because it is of type table
10:07:49.600605 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
10:07:49.600763 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */
drop table if exists "ANALYTICS"."DBT"."MY_FIRST_DBT_MODEL" cascade
10:07:49.600879 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:07:50.362081 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.76 seconds
10:07:50.388069 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
10:07:50.389222 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
10:07:50.389391 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */

  create or replace  view analytics.dbt.my_first_dbt_model 
  
   as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
10:07:50.595658 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.21 seconds
10:07:50.611859 [debug] [Thread-1  ]: finished collecting timing info
10:07:50.612381 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
10:07:50.971184 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3cef4318-224c-46d2-bf0b-0c6246e1ac30', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067c35e0>]}
10:07:50.972391 [info ] [Thread-1  ]: 1 of 4 OK created view model dbt.my_first_dbt_model............................. [[32mSUCCESS 1[0m in 1.40s]
10:07:50.973014 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
10:07:50.978611 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
10:07:50.979375 [info ] [Thread-1  ]: 2 of 4 START view model dbt.snowflake_cumulative_sales.......................... [RUN]
10:07:50.982462 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
10:07:50.983241 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
10:07:50.983576 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
10:07:50.989190 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
10:07:50.991706 [debug] [Thread-1  ]: finished collecting timing info
10:07:50.992163 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
10:07:50.997283 [debug] [Thread-1  ]: Dropping relation "ANALYTICS"."DBT"."SNOWFLAKE_CUMULATIVE_SALES" because it is of type table
10:07:50.999985 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
10:07:51.000325 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */
drop table if exists "ANALYTICS"."DBT"."SNOWFLAKE_CUMULATIVE_SALES" cascade
10:07:51.000554 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:07:51.574956 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.57 seconds
10:07:51.585579 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
10:07:51.588972 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
10:07:51.589260 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */

  create or replace  view analytics.dbt.snowflake_cumulative_sales 
  
   as (
    

select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
  );
10:07:51.830472 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.24 seconds
10:07:51.833574 [debug] [Thread-1  ]: finished collecting timing info
10:07:51.833877 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
10:07:52.032839 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3cef4318-224c-46d2-bf0b-0c6246e1ac30', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107830550>]}
10:07:52.035369 [info ] [Thread-1  ]: 2 of 4 OK created view model dbt.snowflake_cumulative_sales..................... [[32mSUCCESS 1[0m in 1.05s]
10:07:52.036209 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
10:07:52.036774 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
10:07:52.037103 [info ] [Thread-1  ]: 3 of 4 START view model dbt.snowflake_customer_purchases........................ [RUN]
10:07:52.047570 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
10:07:52.048086 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
10:07:52.048387 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
10:07:52.049893 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
10:07:52.050280 [debug] [Thread-1  ]: finished collecting timing info
10:07:52.050376 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
10:07:52.051884 [debug] [Thread-1  ]: Dropping relation "ANALYTICS"."DBT"."SNOWFLAKE_CUSTOMER_PURCHASES" because it is of type table
10:07:52.052933 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
10:07:52.053031 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */
drop table if exists "ANALYTICS"."DBT"."SNOWFLAKE_CUSTOMER_PURCHASES" cascade
10:07:52.053116 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:07:53.339277 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.29 seconds
10:07:53.344574 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
10:07:53.346546 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
10:07:53.346860 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */

  create or replace  view analytics.dbt.snowflake_customer_purchases 
  
   as (
    

select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
  );
10:07:53.655003 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.31 seconds
10:07:53.657899 [debug] [Thread-1  ]: finished collecting timing info
10:07:53.658510 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
10:07:53.989801 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3cef4318-224c-46d2-bf0b-0c6246e1ac30', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107875af0>]}
10:07:53.991083 [info ] [Thread-1  ]: 3 of 4 OK created view model dbt.snowflake_customer_purchases................... [[32mSUCCESS 1[0m in 1.95s]
10:07:53.993684 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
10:07:53.996859 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
10:07:54.002486 [info ] [Thread-1  ]: 4 of 4 START view model dbt.my_second_dbt_model................................. [RUN]
10:07:54.006182 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
10:07:54.006808 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
10:07:54.009639 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
10:07:54.011266 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
10:07:54.012090 [debug] [Thread-1  ]: finished collecting timing info
10:07:54.012296 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
10:07:54.014300 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
10:07:54.014942 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
10:07:54.015100 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */

  create or replace  view analytics.dbt.my_second_dbt_model 
  
   as (
    -- Use the `ref` function to select from other models

select *
from analytics.dbt.my_first_dbt_model
where id = 1
  );
10:07:54.015209 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:07:55.034350 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.02 seconds
10:07:55.038862 [debug] [Thread-1  ]: finished collecting timing info
10:07:55.039195 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
10:07:55.490963 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3cef4318-224c-46d2-bf0b-0c6246e1ac30', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1078758e0>]}
10:07:55.493667 [info ] [Thread-1  ]: 4 of 4 OK created view model dbt.my_second_dbt_model............................ [[32mSUCCESS 1[0m in 1.49s]
10:07:55.494468 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
10:07:55.504931 [debug] [MainThread]: Acquiring new snowflake connection "master"
10:07:55.511276 [info ] [MainThread]: 
10:07:55.511872 [info ] [MainThread]: Finished running 4 view models in 8.56s.
10:07:55.512221 [debug] [MainThread]: Connection 'master' was properly closed.
10:07:55.512397 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
10:07:55.518282 [info ] [MainThread]: 
10:07:55.518606 [info ] [MainThread]: [32mCompleted successfully[0m
10:07:55.518883 [info ] [MainThread]: 
10:07:55.519180 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
10:07:55.519591 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10579a160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1057716d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107844040>]}


============================== 2022-05-13 10:10:07.559830 | aa3b7e75-aa45-4ffa-bc80-b51313bbf248 ==============================
10:10:07.559830 [info ] [MainThread]: Running with dbt=1.0.1
10:10:07.560495 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
10:10:07.560702 [debug] [MainThread]: Tracking: tracking
10:10:07.561041 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10642bf70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10642b460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10642b8b0>]}
10:10:07.595867 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
10:10:07.596094 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'aa3b7e75-aa45-4ffa-bc80-b51313bbf248', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1064325e0>]}
10:10:07.609460 [debug] [MainThread]: Parsing macros/catalog.sql
10:10:07.610709 [debug] [MainThread]: Parsing macros/adapters.sql
10:10:07.631405 [debug] [MainThread]: Parsing macros/materializations/merge.sql
10:10:07.633495 [debug] [MainThread]: Parsing macros/materializations/seed.sql
10:10:07.636210 [debug] [MainThread]: Parsing macros/materializations/view.sql
10:10:07.636871 [debug] [MainThread]: Parsing macros/materializations/table.sql
10:10:07.638358 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
10:10:07.642432 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
10:10:07.642866 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
10:10:07.644637 [debug] [MainThread]: Parsing macros/materializations/configs.sql
10:10:07.645679 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
10:10:07.646448 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
10:10:07.654748 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
10:10:07.660599 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
10:10:07.666814 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
10:10:07.669164 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
10:10:07.670064 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
10:10:07.670895 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
10:10:07.673051 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
10:10:07.678747 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
10:10:07.679507 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
10:10:07.684772 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
10:10:07.692922 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
10:10:07.696696 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
10:10:07.698340 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
10:10:07.702226 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
10:10:07.702864 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
10:10:07.704158 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
10:10:07.705234 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
10:10:07.708216 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
10:10:07.716610 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
10:10:07.717503 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
10:10:07.718691 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
10:10:07.719578 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
10:10:07.720139 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
10:10:07.720512 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
10:10:07.720963 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
10:10:07.721611 [debug] [MainThread]: Parsing macros/etc/statement.sql
10:10:07.723792 [debug] [MainThread]: Parsing macros/etc/datetime.sql
10:10:07.728278 [debug] [MainThread]: Parsing macros/adapters/schema.sql
10:10:07.729391 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
10:10:07.730696 [debug] [MainThread]: Parsing macros/adapters/relation.sql
10:10:07.735561 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
10:10:07.736940 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
10:10:07.739368 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
10:10:07.743090 [debug] [MainThread]: Parsing macros/adapters/columns.sql
10:10:07.747809 [debug] [MainThread]: Parsing tests/generic/builtin.sql
10:10:07.845699 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
10:10:07.851737 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_cumulative_sales.sql
10:10:07.852833 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
10:10:07.853805 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
10:10:07.884430 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'aa3b7e75-aa45-4ffa-bc80-b51313bbf248', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10653e2b0>]}
10:10:07.887864 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'aa3b7e75-aa45-4ffa-bc80-b51313bbf248', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10653e280>]}
10:10:07.888074 [info ] [MainThread]: Found 4 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
10:10:07.888830 [info ] [MainThread]: 
10:10:07.889085 [debug] [MainThread]: Acquiring new snowflake connection "master"
10:10:07.889581 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
10:10:07.896310 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
10:10:07.896440 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
10:10:07.896509 [debug] [ThreadPool]: Opening a new connection, currently in state init
10:10:08.987528 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.09 seconds
10:10:08.991367 [debug] [ThreadPool]: On list_analytics: Close
10:10:09.304231 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
10:10:09.312608 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
10:10:09.312909 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
10:10:09.313074 [debug] [ThreadPool]: Opening a new connection, currently in state closed
10:10:10.295756 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 0.98 seconds
10:10:10.297897 [debug] [ThreadPool]: On list_analytics_dbt: Close
10:10:10.481390 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
10:10:10.483026 [info ] [MainThread]: 
10:10:10.486322 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
10:10:10.486599 [info ] [Thread-1  ]: 1 of 4 START view model dbt.my_first_dbt_model.................................. [RUN]
10:10:10.487179 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
10:10:10.487313 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
10:10:10.487427 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
10:10:10.490080 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
10:10:10.490704 [debug] [Thread-1  ]: finished collecting timing info
10:10:10.490894 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
10:10:10.511713 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
10:10:10.512673 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
10:10:10.512796 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */

  create or replace  view analytics.dbt.my_first_dbt_model 
  
   as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    

*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
10:10:10.512899 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:10:11.573986 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.06 seconds
10:10:11.579871 [debug] [Thread-1  ]: finished collecting timing info
10:10:11.580162 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
10:10:12.033431 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'aa3b7e75-aa45-4ffa-bc80-b51313bbf248', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079a6190>]}
10:10:12.033937 [info ] [Thread-1  ]: 1 of 4 OK created view model dbt.my_first_dbt_model............................. [[32mSUCCESS 1[0m in 1.55s]
10:10:12.034274 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
10:10:12.034453 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
10:10:12.034772 [info ] [Thread-1  ]: 2 of 4 START table model dbt.snowflake_cumulative_sales......................... [RUN]
10:10:12.035359 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
10:10:12.035535 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
10:10:12.035680 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
10:10:12.036906 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
10:10:12.037496 [debug] [Thread-1  ]: finished collecting timing info
10:10:12.037646 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
10:10:12.046255 [debug] [Thread-1  ]: Dropping relation "ANALYTICS"."DBT"."SNOWFLAKE_CUMULATIVE_SALES" because it is of type view
10:10:12.052982 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
10:10:12.053198 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */
drop view if exists "ANALYTICS"."DBT"."SNOWFLAKE_CUMULATIVE_SALES" cascade
10:10:12.053331 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:10:13.029692 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.98 seconds
10:10:13.041963 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
10:10:13.043621 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
10:10:13.043899 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
10:10:15.110511 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.07 seconds
10:10:15.118543 [debug] [Thread-1  ]: finished collecting timing info
10:10:15.118766 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
10:10:15.283924 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'aa3b7e75-aa45-4ffa-bc80-b51313bbf248', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079f7e80>]}
10:10:15.300691 [info ] [Thread-1  ]: 2 of 4 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 3.25s]
10:10:15.301587 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
10:10:15.301899 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
10:10:15.302225 [info ] [Thread-1  ]: 3 of 4 START table model dbt.snowflake_customer_purchases....................... [RUN]
10:10:15.303395 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
10:10:15.303664 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
10:10:15.303808 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
10:10:15.305111 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
10:10:15.305595 [debug] [Thread-1  ]: finished collecting timing info
10:10:15.305703 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
10:10:15.306701 [debug] [Thread-1  ]: Dropping relation "ANALYTICS"."DBT"."SNOWFLAKE_CUSTOMER_PURCHASES" because it is of type view
10:10:15.307913 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
10:10:15.308065 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */
drop view if exists "ANALYTICS"."DBT"."SNOWFLAKE_CUSTOMER_PURCHASES" cascade
10:10:15.308152 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:10:16.159893 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.85 seconds
10:10:16.162344 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
10:10:16.163813 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
10:10:16.164044 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
10:10:17.746974 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.58 seconds
10:10:17.749941 [debug] [Thread-1  ]: finished collecting timing info
10:10:17.750166 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
10:10:17.966155 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'aa3b7e75-aa45-4ffa-bc80-b51313bbf248', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b9cdc0>]}
10:10:17.966490 [info ] [Thread-1  ]: 3 of 4 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.66s]
10:10:17.966699 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
10:10:17.966819 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
10:10:17.967098 [info ] [Thread-1  ]: 4 of 4 START table model dbt.my_second_dbt_model................................ [RUN]
10:10:17.967501 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
10:10:17.967608 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
10:10:17.967711 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
10:10:17.969252 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
10:10:17.970341 [debug] [Thread-1  ]: finished collecting timing info
10:10:17.970468 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
10:10:17.971744 [debug] [Thread-1  ]: Dropping relation "ANALYTICS"."DBT"."MY_SECOND_DBT_MODEL" because it is of type view
10:10:17.972825 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
10:10:17.972922 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */
drop view if exists "ANALYTICS"."DBT"."MY_SECOND_DBT_MODEL" cascade
10:10:17.973006 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:10:18.617260 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.64 seconds
10:10:18.623686 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
10:10:18.626107 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
10:10:18.626482 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.my_first_dbt_model
where id = 1
      );
10:10:19.368150 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.74 seconds
10:10:19.370391 [debug] [Thread-1  ]: finished collecting timing info
10:10:19.370629 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
10:10:19.668536 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'aa3b7e75-aa45-4ffa-bc80-b51313bbf248', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107bd1d00>]}
10:10:19.669377 [info ] [Thread-1  ]: 4 of 4 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.70s]
10:10:19.670011 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
10:10:19.671743 [debug] [MainThread]: Acquiring new snowflake connection "master"
10:10:19.672322 [info ] [MainThread]: 
10:10:19.672688 [info ] [MainThread]: Finished running 1 view model, 3 table models in 11.78s.
10:10:19.672998 [debug] [MainThread]: Connection 'master' was properly closed.
10:10:19.673168 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
10:10:19.680319 [info ] [MainThread]: 
10:10:19.680747 [info ] [MainThread]: [32mCompleted successfully[0m
10:10:19.680904 [info ] [MainThread]: 
10:10:19.681013 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
10:10:19.681194 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10653ee50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10653ee80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079f4a00>]}


============================== 2022-05-13 10:11:40.046224 | f9ab338d-651f-4b5c-a4cd-fbdf0e252ff8 ==============================
10:11:40.046224 [info ] [MainThread]: Running with dbt=1.0.1
10:11:40.046813 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
10:11:40.046947 [debug] [MainThread]: Tracking: tracking
10:11:40.047173 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059c2070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059c21c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059c2d60>]}
10:11:40.091287 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
10:11:40.091565 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/my_first_dbt_model.sql
10:11:40.098147 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
10:11:40.117658 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f9ab338d-651f-4b5c-a4cd-fbdf0e252ff8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104523c10>]}
10:11:40.120622 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f9ab338d-651f-4b5c-a4cd-fbdf0e252ff8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059aecd0>]}
10:11:40.120755 [info ] [MainThread]: Found 4 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
10:11:40.121412 [info ] [MainThread]: 
10:11:40.121616 [debug] [MainThread]: Acquiring new snowflake connection "master"
10:11:40.122081 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
10:11:40.127930 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
10:11:40.128024 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
10:11:40.128088 [debug] [ThreadPool]: Opening a new connection, currently in state init
10:11:41.664125 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.54 seconds
10:11:41.666682 [debug] [ThreadPool]: On list_analytics: Close
10:11:42.068264 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
10:11:42.077650 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
10:11:42.077908 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
10:11:42.078071 [debug] [ThreadPool]: Opening a new connection, currently in state closed
10:11:43.023777 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 0.95 seconds
10:11:43.024909 [debug] [ThreadPool]: On list_analytics_dbt: Close
10:11:43.222683 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
10:11:43.223147 [info ] [MainThread]: 
10:11:43.227677 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
10:11:43.228184 [info ] [Thread-1  ]: 1 of 4 START table model dbt.my_first_dbt_model................................. [RUN]
10:11:43.229275 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
10:11:43.229428 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
10:11:43.229548 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
10:11:43.230860 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
10:11:43.231411 [debug] [Thread-1  ]: finished collecting timing info
10:11:43.231584 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
10:11:43.247157 [debug] [Thread-1  ]: Dropping relation "ANALYTICS"."DBT"."MY_FIRST_DBT_MODEL" because it is of type view
10:11:43.252066 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
10:11:43.252242 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */
drop view if exists "ANALYTICS"."DBT"."MY_FIRST_DBT_MODEL" cascade
10:11:43.252354 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:11:44.208918 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.96 seconds
10:11:44.222982 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
10:11:44.224447 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
10:11:44.224622 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
10:11:45.728459 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.5 seconds
10:11:45.749614 [debug] [Thread-1  ]: finished collecting timing info
10:11:45.750073 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
10:11:46.183459 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f9ab338d-651f-4b5c-a4cd-fbdf0e252ff8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ec23a0>]}
10:11:46.183819 [info ] [Thread-1  ]: 1 of 4 OK created table model dbt.my_first_dbt_model............................ [[32mSUCCESS 1[0m in 2.95s]
10:11:46.184028 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
10:11:46.184144 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
10:11:46.184516 [info ] [Thread-1  ]: 2 of 4 START table model dbt.snowflake_cumulative_sales......................... [RUN]
10:11:46.184877 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
10:11:46.184973 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
10:11:46.185061 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
10:11:46.186077 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
10:11:46.186476 [debug] [Thread-1  ]: finished collecting timing info
10:11:46.186575 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
10:11:46.188447 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
10:11:46.189104 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
10:11:46.189206 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
10:11:46.189293 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:11:48.181530 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.99 seconds
10:11:48.188969 [debug] [Thread-1  ]: finished collecting timing info
10:11:48.189545 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
10:11:48.365975 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f9ab338d-651f-4b5c-a4cd-fbdf0e252ff8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059ad5e0>]}
10:11:48.367050 [info ] [Thread-1  ]: 2 of 4 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 2.18s]
10:11:48.367698 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
10:11:48.368526 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
10:11:48.372650 [info ] [Thread-1  ]: 3 of 4 START table model dbt.snowflake_customer_purchases....................... [RUN]
10:11:48.374013 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
10:11:48.374471 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
10:11:48.378034 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
10:11:48.380153 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
10:11:48.382010 [debug] [Thread-1  ]: finished collecting timing info
10:11:48.382296 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
10:11:48.384771 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
10:11:48.385916 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
10:11:48.386095 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
10:11:48.386259 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:11:50.475895 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.09 seconds
10:11:50.483017 [debug] [Thread-1  ]: finished collecting timing info
10:11:50.483504 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
10:11:50.686506 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f9ab338d-651f-4b5c-a4cd-fbdf0e252ff8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105b91a30>]}
10:11:50.687182 [info ] [Thread-1  ]: 3 of 4 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.31s]
10:11:50.687586 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
10:11:50.687952 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
10:11:50.688666 [info ] [Thread-1  ]: 4 of 4 START table model dbt.my_second_dbt_model................................ [RUN]
10:11:50.689806 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
10:11:50.690228 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
10:11:50.694696 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
10:11:50.701589 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
10:11:50.702562 [debug] [Thread-1  ]: finished collecting timing info
10:11:50.702883 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
10:11:50.705072 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
10:11:50.706083 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
10:11:50.706314 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.my_first_dbt_model
where id = 1
      );
10:11:50.706459 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:11:52.001425 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.29 seconds
10:11:52.007036 [debug] [Thread-1  ]: finished collecting timing info
10:11:52.007732 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
10:11:52.170583 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f9ab338d-651f-4b5c-a4cd-fbdf0e252ff8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108f65d30>]}
10:11:52.171743 [info ] [Thread-1  ]: 4 of 4 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.48s]
10:11:52.172313 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
10:11:52.182554 [debug] [MainThread]: Acquiring new snowflake connection "master"
10:11:52.183033 [info ] [MainThread]: 
10:11:52.183297 [info ] [MainThread]: Finished running 4 table models in 12.06s.
10:11:52.183515 [debug] [MainThread]: Connection 'master' was properly closed.
10:11:52.183630 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
10:11:52.189749 [info ] [MainThread]: 
10:11:52.189993 [info ] [MainThread]: [32mCompleted successfully[0m
10:11:52.190160 [info ] [MainThread]: 
10:11:52.190286 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
10:11:52.190480 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059ad430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059aeac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105f4b190>]}


============================== 2022-05-13 10:22:40.475516 | b5ae4c6a-e79c-494d-a821-d98627e37916 ==============================
10:22:40.475516 [info ] [MainThread]: Running with dbt=1.0.1
10:22:40.476066 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
10:22:40.476192 [debug] [MainThread]: Tracking: tracking
10:22:40.476432 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10736ddc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10736d7f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107f626d0>]}
10:22:40.522042 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
10:22:40.522260 [debug] [MainThread]: Partial parsing: added file: learn_dbt://models/example/dates.sql
10:22:40.522460 [debug] [MainThread]: Partial parsing: update schema file: learn_dbt://models/example/schema.yml
10:22:40.527812 [debug] [MainThread]: 1603: static parser failed on example/dates.sql
10:22:40.536387 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/dates.sql
10:22:40.544631 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b5ae4c6a-e79c-494d-a821-d98627e37916', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ac40d0>]}
10:22:40.547794 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b5ae4c6a-e79c-494d-a821-d98627e37916', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105b8d1f0>]}
10:22:40.547939 [info ] [MainThread]: Found 5 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
10:22:40.548667 [info ] [MainThread]: 
10:22:40.548873 [debug] [MainThread]: Acquiring new snowflake connection "master"
10:22:40.549307 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
10:22:40.555292 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
10:22:40.555447 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
10:22:40.555520 [debug] [ThreadPool]: Opening a new connection, currently in state init
10:22:42.140268 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.58 seconds
10:22:42.141626 [debug] [ThreadPool]: On list_analytics: Close
10:22:42.628921 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
10:22:42.637539 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
10:22:42.637987 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
10:22:42.638158 [debug] [ThreadPool]: Opening a new connection, currently in state closed
10:22:43.660655 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.02 seconds
10:22:43.663529 [debug] [ThreadPool]: On list_analytics_dbt: Close
10:22:43.868965 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
10:22:43.870006 [info ] [MainThread]: 
10:22:43.876045 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
10:22:43.876787 [info ] [Thread-1  ]: 1 of 5 START incremental model dbt.dates........................................ [RUN]
10:22:43.877302 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
10:22:43.877479 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
10:22:43.877641 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
10:22:43.880957 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
10:22:43.881849 [debug] [Thread-1  ]: finished collecting timing info
10:22:43.882145 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
10:22:43.914867 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
10:22:43.915609 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:22:43.915712 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */


      create or replace transient table analytics.dbt.dates  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


      );
10:22:43.915798 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:22:46.320899 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.41 seconds
10:22:46.335237 [debug] [Thread-1  ]: finished collecting timing info
10:22:46.335648 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
10:22:46.676972 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b5ae4c6a-e79c-494d-a821-d98627e37916', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105b8d190>]}
10:22:46.677846 [info ] [Thread-1  ]: 1 of 5 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 2.80s]
10:22:46.678376 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
10:22:46.678660 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
10:22:46.679074 [info ] [Thread-1  ]: 2 of 5 START table model dbt.my_first_dbt_model................................. [RUN]
10:22:46.679797 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
10:22:46.679985 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
10:22:46.680156 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
10:22:46.681885 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
10:22:46.682567 [debug] [Thread-1  ]: finished collecting timing info
10:22:46.682748 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
10:22:46.692175 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
10:22:46.693323 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
10:22:46.693496 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
10:22:46.693610 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:22:48.245112 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.55 seconds
10:22:48.248337 [debug] [Thread-1  ]: finished collecting timing info
10:22:48.248667 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
10:22:48.437942 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b5ae4c6a-e79c-494d-a821-d98627e37916', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108793190>]}
10:22:48.438478 [info ] [Thread-1  ]: 2 of 5 OK created table model dbt.my_first_dbt_model............................ [[32mSUCCESS 1[0m in 1.76s]
10:22:48.438821 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
10:22:48.438995 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
10:22:48.439206 [info ] [Thread-1  ]: 3 of 5 START table model dbt.snowflake_cumulative_sales......................... [RUN]
10:22:48.439627 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
10:22:48.439907 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
10:22:48.440088 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
10:22:48.441198 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
10:22:48.442661 [debug] [Thread-1  ]: finished collecting timing info
10:22:48.442825 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
10:22:48.445223 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
10:22:48.446264 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
10:22:48.446437 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
10:22:48.446592 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:22:49.770067 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.32 seconds
10:22:49.773283 [debug] [Thread-1  ]: finished collecting timing info
10:22:49.773693 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
10:22:49.961223 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b5ae4c6a-e79c-494d-a821-d98627e37916', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108783310>]}
10:22:49.962345 [info ] [Thread-1  ]: 3 of 5 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 1.52s]
10:22:49.962910 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
10:22:49.963168 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
10:22:49.963457 [info ] [Thread-1  ]: 4 of 5 START table model dbt.snowflake_customer_purchases....................... [RUN]
10:22:49.964230 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
10:22:49.964478 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
10:22:49.964684 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
10:22:49.966159 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
10:22:49.966822 [debug] [Thread-1  ]: finished collecting timing info
10:22:49.966951 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
10:22:49.968933 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
10:22:49.969818 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
10:22:49.969979 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
10:22:49.970126 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:22:51.509218 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.54 seconds
10:22:51.512048 [debug] [Thread-1  ]: finished collecting timing info
10:22:51.512486 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
10:22:51.689990 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b5ae4c6a-e79c-494d-a821-d98627e37916', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108591c40>]}
10:22:51.691504 [info ] [Thread-1  ]: 4 of 5 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 1.73s]
10:22:51.691957 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
10:22:51.692162 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
10:22:51.692514 [info ] [Thread-1  ]: 5 of 5 START table model dbt.my_second_dbt_model................................ [RUN]
10:22:51.693084 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
10:22:51.693263 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
10:22:51.693430 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
10:22:51.696049 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
10:22:51.697682 [debug] [Thread-1  ]: finished collecting timing info
10:22:51.697917 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
10:22:51.700700 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
10:22:51.701698 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
10:22:51.701875 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.my_first_dbt_model
where id = 1
      );
10:22:51.702024 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:22:53.255479 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.55 seconds
10:22:53.258778 [debug] [Thread-1  ]: finished collecting timing info
10:22:53.259119 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
10:22:53.585650 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b5ae4c6a-e79c-494d-a821-d98627e37916', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1087e8190>]}
10:22:53.586065 [info ] [Thread-1  ]: 5 of 5 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.89s]
10:22:53.586306 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
10:22:53.587222 [debug] [MainThread]: Acquiring new snowflake connection "master"
10:22:53.587567 [info ] [MainThread]: 
10:22:53.587763 [info ] [MainThread]: Finished running 1 incremental model, 4 table models in 13.04s.
10:22:53.587924 [debug] [MainThread]: Connection 'master' was properly closed.
10:22:53.588010 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
10:22:53.592427 [info ] [MainThread]: 
10:22:53.592636 [info ] [MainThread]: [32mCompleted successfully[0m
10:22:53.592845 [info ] [MainThread]: 
10:22:53.593013 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
10:22:53.593260 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107f58a30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107f58cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108595280>]}


============================== 2022-05-13 10:23:58.873944 | 23c79a0b-2ec6-4c8b-bb70-1f3ce53759ff ==============================
10:23:58.873944 [info ] [MainThread]: Running with dbt=1.0.1
10:23:58.874506 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
10:23:58.874622 [debug] [MainThread]: Tracking: tracking
10:23:58.874846 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e95190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e950a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e95b20>]}
10:23:58.919476 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
10:23:58.919622 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
10:23:58.922837 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '23c79a0b-2ec6-4c8b-bb70-1f3ce53759ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e69100>]}
10:23:58.926150 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '23c79a0b-2ec6-4c8b-bb70-1f3ce53759ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106480fa0>]}
10:23:58.926287 [info ] [MainThread]: Found 5 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
10:23:58.927031 [info ] [MainThread]: 
10:23:58.927243 [debug] [MainThread]: Acquiring new snowflake connection "master"
10:23:58.927682 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
10:23:58.933842 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
10:23:58.933985 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
10:23:58.934054 [debug] [ThreadPool]: Opening a new connection, currently in state init
10:23:59.715391 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.78 seconds
10:23:59.719088 [debug] [ThreadPool]: On list_analytics: Close
10:24:00.139071 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
10:24:00.146720 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
10:24:00.146939 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
10:24:00.147052 [debug] [ThreadPool]: Opening a new connection, currently in state closed
10:24:01.317830 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1.17 seconds
10:24:01.319837 [debug] [ThreadPool]: On list_analytics_dbt: Close
10:24:01.483093 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
10:24:01.483626 [info ] [MainThread]: 
10:24:01.487668 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
10:24:01.488196 [info ] [Thread-1  ]: 1 of 5 START incremental model dbt.dates........................................ [RUN]
10:24:01.488509 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
10:24:01.488592 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
10:24:01.488676 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
10:24:01.496978 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
10:24:01.497654 [debug] [Thread-1  ]: finished collecting timing info
10:24:01.498006 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
10:24:01.529096 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:24:01.529299 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
10:24:01.529388 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:24:02.854987 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.33 seconds
10:24:02.866162 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:24:02.866460 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
10:24:02.975256 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.11 seconds
10:24:02.983665 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:24:02.983995 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
10:24:03.218934 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.23 seconds
10:24:03.226690 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:24:03.226974 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
10:24:03.324761 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.1 seconds
10:24:03.351791 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
10:24:03.354516 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:24:03.354683 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
10:24:03.537475 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.18 seconds
10:24:03.538585 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:24:03.538844 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
10:24:04.345712 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.81 seconds
10:24:04.346560 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:24:04.346793 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
10:24:04.582804 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.24 seconds
10:24:04.597293 [debug] [Thread-1  ]: finished collecting timing info
10:24:04.597685 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
10:24:04.891622 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '23c79a0b-2ec6-4c8b-bb70-1f3ce53759ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107041220>]}
10:24:04.892644 [info ] [Thread-1  ]: 1 of 5 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 3.40s]
10:24:04.893279 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
10:24:04.893549 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
10:24:04.893977 [info ] [Thread-1  ]: 2 of 5 START table model dbt.my_first_dbt_model................................. [RUN]
10:24:04.894596 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
10:24:04.894763 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
10:24:04.894908 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
10:24:04.896413 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
10:24:04.896997 [debug] [Thread-1  ]: finished collecting timing info
10:24:04.897160 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
10:24:04.907093 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
10:24:04.908239 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
10:24:04.908401 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
10:24:04.908536 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:24:06.427799 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.52 seconds
10:24:06.430605 [debug] [Thread-1  ]: finished collecting timing info
10:24:06.431182 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
10:24:06.612349 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '23c79a0b-2ec6-4c8b-bb70-1f3ce53759ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10726b460>]}
10:24:06.613509 [info ] [Thread-1  ]: 2 of 5 OK created table model dbt.my_first_dbt_model............................ [[32mSUCCESS 1[0m in 1.72s]
10:24:06.615451 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
10:24:06.615947 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
10:24:06.617513 [info ] [Thread-1  ]: 3 of 5 START table model dbt.snowflake_cumulative_sales......................... [RUN]
10:24:06.618272 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
10:24:06.618689 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
10:24:06.618923 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
10:24:06.620715 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
10:24:06.621417 [debug] [Thread-1  ]: finished collecting timing info
10:24:06.621623 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
10:24:06.625346 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
10:24:06.626373 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
10:24:06.626546 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
10:24:06.626702 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:24:08.810552 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.18 seconds
10:24:08.813982 [debug] [Thread-1  ]: finished collecting timing info
10:24:08.814447 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
10:24:09.092187 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '23c79a0b-2ec6-4c8b-bb70-1f3ce53759ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10740e3a0>]}
10:24:09.092929 [info ] [Thread-1  ]: 3 of 5 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 2.47s]
10:24:09.093376 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
10:24:09.093619 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
10:24:09.094065 [info ] [Thread-1  ]: 4 of 5 START table model dbt.snowflake_customer_purchases....................... [RUN]
10:24:09.094704 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
10:24:09.094919 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
10:24:09.095121 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
10:24:09.096933 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
10:24:09.097518 [debug] [Thread-1  ]: finished collecting timing info
10:24:09.097691 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
10:24:09.100081 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
10:24:09.101119 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
10:24:09.101252 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
10:24:09.101372 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:24:11.145268 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.04 seconds
10:24:11.150441 [debug] [Thread-1  ]: finished collecting timing info
10:24:11.150733 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
10:24:11.314221 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '23c79a0b-2ec6-4c8b-bb70-1f3ce53759ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107426580>]}
10:24:11.314740 [info ] [Thread-1  ]: 4 of 5 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.22s]
10:24:11.315040 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
10:24:11.315213 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
10:24:11.315572 [info ] [Thread-1  ]: 5 of 5 START table model dbt.my_second_dbt_model................................ [RUN]
10:24:11.316037 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
10:24:11.316173 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
10:24:11.316304 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
10:24:11.318332 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
10:24:11.319131 [debug] [Thread-1  ]: finished collecting timing info
10:24:11.319312 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
10:24:11.321581 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
10:24:11.322413 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
10:24:11.322650 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.my_first_dbt_model
where id = 1
      );
10:24:11.322779 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:24:13.201459 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.88 seconds
10:24:13.205212 [debug] [Thread-1  ]: finished collecting timing info
10:24:13.205582 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
10:24:13.391513 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '23c79a0b-2ec6-4c8b-bb70-1f3ce53759ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107214af0>]}
10:24:13.392370 [info ] [Thread-1  ]: 5 of 5 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 2.08s]
10:24:13.392790 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
10:24:13.394010 [debug] [MainThread]: Acquiring new snowflake connection "master"
10:24:13.394487 [info ] [MainThread]: 
10:24:13.394787 [info ] [MainThread]: Finished running 1 incremental model, 4 table models in 14.47s.
10:24:13.395034 [debug] [MainThread]: Connection 'master' was properly closed.
10:24:13.395168 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
10:24:13.402255 [info ] [MainThread]: 
10:24:13.402580 [info ] [MainThread]: [32mCompleted successfully[0m
10:24:13.402873 [info ] [MainThread]: 
10:24:13.403102 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
10:24:13.403499 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106eb6be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10730c730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107269b80>]}


============================== 2022-05-13 10:27:13.941039 | b085d19b-3e35-4321-ace1-821965bfeecd ==============================
10:27:13.941039 [info ] [MainThread]: Running with dbt=1.0.1
10:27:13.941584 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
10:27:13.941714 [debug] [MainThread]: Tracking: tracking
10:27:13.941943 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x118421520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x118421100>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x118421280>]}
10:27:13.986426 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
10:27:13.986715 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/my_first_dbt_model.sql
10:27:13.992423 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
10:27:14.013643 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b085d19b-3e35-4321-ace1-821965bfeecd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075758e0>]}
10:27:14.016617 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b085d19b-3e35-4321-ace1-821965bfeecd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107935eb0>]}
10:27:14.016751 [info ] [MainThread]: Found 5 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
10:27:14.017495 [info ] [MainThread]: 
10:27:14.017729 [debug] [MainThread]: Acquiring new snowflake connection "master"
10:27:14.018141 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
10:27:14.024103 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
10:27:14.024192 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
10:27:14.024258 [debug] [ThreadPool]: Opening a new connection, currently in state init
10:27:15.134093 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.11 seconds
10:27:15.139788 [debug] [ThreadPool]: On list_analytics: Close
10:27:15.329902 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
10:27:15.339704 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
10:27:15.339982 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
10:27:15.340143 [debug] [ThreadPool]: Opening a new connection, currently in state closed
10:27:16.246134 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 0.91 seconds
10:27:16.249078 [debug] [ThreadPool]: On list_analytics_dbt: Close
10:27:16.427611 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
10:27:16.427976 [info ] [MainThread]: 
10:27:16.431385 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
10:27:16.431927 [info ] [Thread-1  ]: 1 of 4 START incremental model dbt.dates........................................ [RUN]
10:27:16.432430 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
10:27:16.432543 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
10:27:16.432639 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
10:27:16.438538 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
10:27:16.439108 [debug] [Thread-1  ]: finished collecting timing info
10:27:16.439228 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
10:27:16.468724 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:27:16.468943 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
10:27:16.469033 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:27:18.390949 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.92 seconds
10:27:18.408115 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:27:18.408370 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
10:27:18.517374 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.11 seconds
10:27:18.527283 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:27:18.527721 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
10:27:18.705042 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.18 seconds
10:27:18.717119 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:27:18.717378 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
10:27:18.833129 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.12 seconds
10:27:18.855766 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
10:27:18.858123 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:27:18.858258 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
10:27:19.093273 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.23 seconds
10:27:19.094039 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:27:19.094324 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
10:27:19.882306 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.79 seconds
10:27:19.882853 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:27:19.883070 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
10:27:20.143258 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.26 seconds
10:27:20.154967 [debug] [Thread-1  ]: finished collecting timing info
10:27:20.155304 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
10:27:20.345107 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b085d19b-3e35-4321-ace1-821965bfeecd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1072a80a0>]}
10:27:20.346120 [info ] [Thread-1  ]: 1 of 4 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 3.91s]
10:27:20.346728 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
10:27:20.346996 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
10:27:20.347613 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
10:27:20.347902 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
10:27:20.348133 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
10:27:20.350601 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
10:27:20.351133 [debug] [Thread-1  ]: finished collecting timing info
10:27:20.351378 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
10:27:20.351472 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
10:27:20.351672 [info ] [Thread-1  ]: 2 of 4 START table model dbt.snowflake_cumulative_sales......................... [RUN]
10:27:20.351875 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
10:27:20.351945 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
10:27:20.352010 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
10:27:20.352749 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
10:27:20.353019 [debug] [Thread-1  ]: finished collecting timing info
10:27:20.353104 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
10:27:20.362029 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
10:27:20.363060 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
10:27:20.363202 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
10:27:20.363330 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:27:21.845889 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.48 seconds
10:27:21.854512 [debug] [Thread-1  ]: finished collecting timing info
10:27:21.855137 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
10:27:22.021403 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b085d19b-3e35-4321-ace1-821965bfeecd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b2e5fd0>]}
10:27:22.021912 [info ] [Thread-1  ]: 2 of 4 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 1.67s]
10:27:22.022267 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
10:27:22.022466 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
10:27:22.022922 [info ] [Thread-1  ]: 3 of 4 START table model dbt.snowflake_customer_purchases....................... [RUN]
10:27:22.023607 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
10:27:22.023833 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
10:27:22.024046 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
10:27:22.025907 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
10:27:22.026791 [debug] [Thread-1  ]: finished collecting timing info
10:27:22.026968 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
10:27:22.029681 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
10:27:22.031055 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
10:27:22.031240 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
10:27:22.031395 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:27:24.072971 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.04 seconds
10:27:24.076198 [debug] [Thread-1  ]: finished collecting timing info
10:27:24.082590 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
10:27:24.340493 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b085d19b-3e35-4321-ace1-821965bfeecd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1187590a0>]}
10:27:24.341251 [info ] [Thread-1  ]: 3 of 4 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.32s]
10:27:24.341692 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
10:27:24.341892 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
10:27:24.342327 [info ] [Thread-1  ]: 4 of 4 START table model dbt.my_second_dbt_model................................ [RUN]
10:27:24.342923 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
10:27:24.343107 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
10:27:24.343271 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
10:27:24.352834 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
10:27:24.353477 [debug] [Thread-1  ]: finished collecting timing info
10:27:24.353647 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
10:27:24.355702 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
10:27:24.356815 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
10:27:24.356948 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (with __dbt__cte__my_first_dbt_model as (
/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
)-- Use the `ref` function to select from other models

select *
from __dbt__cte__my_first_dbt_model
where id = 1
      );
10:27:24.357063 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:27:25.654590 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.3 seconds
10:27:25.659022 [debug] [Thread-1  ]: finished collecting timing info
10:27:25.659503 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
10:27:25.831773 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b085d19b-3e35-4321-ace1-821965bfeecd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x118759760>]}
10:27:25.832399 [info ] [Thread-1  ]: 4 of 4 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.49s]
10:27:25.832841 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
10:27:25.834091 [debug] [MainThread]: Acquiring new snowflake connection "master"
10:27:25.834489 [info ] [MainThread]: 
10:27:25.834778 [info ] [MainThread]: Finished running 1 incremental model, 3 table models in 11.82s.
10:27:25.835230 [debug] [MainThread]: Connection 'master' was properly closed.
10:27:25.835613 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
10:27:25.842008 [info ] [MainThread]: 
10:27:25.842335 [info ] [MainThread]: [32mCompleted successfully[0m
10:27:25.842627 [info ] [MainThread]: 
10:27:25.842835 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
10:27:25.843113 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1072a84c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11842f5b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1191593a0>]}


============================== 2022-05-13 10:28:28.959836 | 9f672fa7-bca0-4677-ba30-16ff5b6bf7e8 ==============================
10:28:28.959836 [info ] [MainThread]: Running with dbt=1.0.1
10:28:28.960220 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
10:28:28.960353 [debug] [MainThread]: Tracking: tracking
10:28:28.960577 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112612580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1126120d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112612220>]}
10:28:29.002348 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
10:28:29.002488 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
10:28:29.005473 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9f672fa7-bca0-4677-ba30-16ff5b6bf7e8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112733fd0>]}
10:28:29.008660 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9f672fa7-bca0-4677-ba30-16ff5b6bf7e8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111b477f0>]}
10:28:29.008798 [info ] [MainThread]: Found 5 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
10:28:29.009461 [info ] [MainThread]: 
10:28:29.009661 [debug] [MainThread]: Acquiring new snowflake connection "master"
10:28:29.010147 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
10:28:29.016532 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
10:28:29.016654 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
10:28:29.016725 [debug] [ThreadPool]: Opening a new connection, currently in state init
10:28:29.812555 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.8 seconds
10:28:29.814837 [debug] [ThreadPool]: On list_analytics: Close
10:28:30.160995 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
10:28:30.169524 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
10:28:30.169765 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
10:28:30.169928 [debug] [ThreadPool]: Opening a new connection, currently in state closed
10:28:31.273550 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.1 seconds
10:28:31.276328 [debug] [ThreadPool]: On list_analytics_dbt: Close
10:28:31.726727 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
10:28:31.727373 [info ] [MainThread]: 
10:28:31.730805 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
10:28:31.731318 [info ] [Thread-1  ]: 1 of 4 START incremental model dbt.dates........................................ [RUN]
10:28:31.731679 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
10:28:31.731783 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
10:28:31.731879 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
10:28:31.737956 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
10:28:31.738469 [debug] [Thread-1  ]: finished collecting timing info
10:28:31.738573 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
10:28:31.766877 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:28:31.767120 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
10:28:31.767221 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:28:33.670015 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.9 seconds
10:28:33.682918 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:28:33.683275 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
10:28:33.838281 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.15 seconds
10:28:33.845247 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:28:33.845589 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
10:28:33.980484 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.13 seconds
10:28:33.991733 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:28:33.992021 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
10:28:34.196656 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.2 seconds
10:28:34.225900 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
10:28:34.228352 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:28:34.228538 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
10:28:34.367229 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.14 seconds
10:28:34.368049 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:28:34.368244 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
10:28:34.917145 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.55 seconds
10:28:34.918792 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:28:34.919189 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
10:28:35.241282 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.32 seconds
10:28:35.256119 [debug] [Thread-1  ]: finished collecting timing info
10:28:35.256413 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
10:28:35.899124 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f672fa7-bca0-4677-ba30-16ff5b6bf7e8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1127aa1f0>]}
10:28:35.899870 [info ] [Thread-1  ]: 1 of 4 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 4.17s]
10:28:35.900532 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
10:28:35.900916 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
10:28:35.901582 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
10:28:35.901819 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
10:28:35.902004 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
10:28:35.905279 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
10:28:35.906121 [debug] [Thread-1  ]: finished collecting timing info
10:28:35.906562 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
10:28:35.906764 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
10:28:35.907162 [info ] [Thread-1  ]: 2 of 4 START table model dbt.snowflake_cumulative_sales......................... [RUN]
10:28:35.907953 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
10:28:35.908183 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
10:28:35.908316 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
10:28:35.909287 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
10:28:35.909660 [debug] [Thread-1  ]: finished collecting timing info
10:28:35.909751 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
10:28:35.918069 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
10:28:35.918880 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
10:28:35.919015 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
10:28:35.919129 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:28:37.372169 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.45 seconds
10:28:37.375620 [debug] [Thread-1  ]: finished collecting timing info
10:28:37.375985 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
10:28:37.549663 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f672fa7-bca0-4677-ba30-16ff5b6bf7e8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1127b0880>]}
10:28:37.550010 [info ] [Thread-1  ]: 2 of 4 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 1.64s]
10:28:37.550219 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
10:28:37.550339 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
10:28:37.550563 [info ] [Thread-1  ]: 3 of 4 START table model dbt.snowflake_customer_purchases....................... [RUN]
10:28:37.550881 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
10:28:37.550975 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
10:28:37.551067 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
10:28:37.551900 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
10:28:37.552289 [debug] [Thread-1  ]: finished collecting timing info
10:28:37.552396 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
10:28:37.554101 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
10:28:37.555014 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
10:28:37.555124 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
10:28:37.555213 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:28:39.063901 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.51 seconds
10:28:39.067215 [debug] [Thread-1  ]: finished collecting timing info
10:28:39.067641 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
10:28:39.235011 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f672fa7-bca0-4677-ba30-16ff5b6bf7e8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1127b0e20>]}
10:28:39.235781 [info ] [Thread-1  ]: 3 of 4 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 1.68s]
10:28:39.236256 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
10:28:39.236508 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
10:28:39.236923 [info ] [Thread-1  ]: 4 of 4 START table model dbt.my_second_dbt_model................................ [RUN]
10:28:39.237589 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
10:28:39.237805 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
10:28:39.238007 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
10:28:39.249801 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
10:28:39.250484 [debug] [Thread-1  ]: finished collecting timing info
10:28:39.250655 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
10:28:39.252635 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
10:28:39.253563 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
10:28:39.253693 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (with __dbt__cte__my_first_dbt_model as (
/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
)-- Use the `ref` function to select from other models

select *
from __dbt__cte__my_first_dbt_model
where id = 1
      );
10:28:39.253806 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:28:40.726364 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.47 seconds
10:28:40.731888 [debug] [Thread-1  ]: finished collecting timing info
10:28:40.732278 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
10:28:41.189233 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f672fa7-bca0-4677-ba30-16ff5b6bf7e8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1127b05b0>]}
10:28:41.189914 [info ] [Thread-1  ]: 4 of 4 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.95s]
10:28:41.190224 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
10:28:41.191300 [debug] [MainThread]: Acquiring new snowflake connection "master"
10:28:41.191666 [info ] [MainThread]: 
10:28:41.191879 [info ] [MainThread]: Finished running 1 incremental model, 3 table models in 12.18s.
10:28:41.192061 [debug] [MainThread]: Connection 'master' was properly closed.
10:28:41.192159 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
10:28:41.197646 [info ] [MainThread]: 
10:28:41.198003 [info ] [MainThread]: [32mCompleted successfully[0m
10:28:41.198277 [info ] [MainThread]: 
10:28:41.198485 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
10:28:41.198792 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1049d6040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114ad1a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112b0f430>]}


============================== 2022-05-13 10:37:45.305180 | 49a4559c-d665-4d64-817f-b485e33b3fba ==============================
10:37:45.305180 [info ] [MainThread]: Running with dbt=1.0.1
10:37:45.305541 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
10:37:45.305660 [debug] [MainThread]: Tracking: tracking
10:37:45.305905 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c93f70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c93460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c938b0>]}
10:37:45.347958 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
10:37:45.348187 [debug] [MainThread]: Partial parsing: added file: learn_dbt://models/example/incremental_time.sql
10:37:45.348401 [debug] [MainThread]: Partial parsing: update schema file: learn_dbt://models/example/schema.yml
10:37:45.353977 [debug] [MainThread]: 1603: static parser failed on example/incremental_time.sql
10:37:45.362310 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_time.sql
10:37:45.370483 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '49a4559c-d665-4d64-817f-b485e33b3fba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102cd94f0>]}
10:37:45.373443 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '49a4559c-d665-4d64-817f-b485e33b3fba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c6d610>]}
10:37:45.373585 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
10:37:45.374297 [info ] [MainThread]: 
10:37:45.374496 [debug] [MainThread]: Acquiring new snowflake connection "master"
10:37:45.374901 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
10:37:45.381044 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
10:37:45.381182 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
10:37:45.381252 [debug] [ThreadPool]: Opening a new connection, currently in state init
10:37:46.441923 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.06 seconds
10:37:46.444023 [debug] [ThreadPool]: On list_analytics: Close
10:37:46.798257 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
10:37:46.807696 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
10:37:46.807878 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
10:37:46.808003 [debug] [ThreadPool]: Opening a new connection, currently in state closed
10:37:48.893965 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 2.09 seconds
10:37:48.897053 [debug] [ThreadPool]: On list_analytics_dbt: Close
10:37:49.065113 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
10:37:49.065669 [info ] [MainThread]: 
10:37:49.069516 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
10:37:49.070240 [info ] [Thread-1  ]: 1 of 5 START incremental model dbt.dates........................................ [RUN]
10:37:49.070735 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
10:37:49.070909 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
10:37:49.071271 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
10:37:49.076914 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
10:37:49.077504 [debug] [Thread-1  ]: finished collecting timing info
10:37:49.077664 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
10:37:49.108852 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:37:49.109057 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
10:37:49.109145 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:37:50.662306 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.55 seconds
10:37:50.672857 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:37:50.673171 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
10:37:50.793277 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.12 seconds
10:37:50.799320 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:37:50.799572 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
10:37:50.993148 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.19 seconds
10:37:50.999659 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:37:50.999873 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
10:37:51.099521 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.1 seconds
10:37:51.122003 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
10:37:51.124382 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:37:51.124519 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
10:37:51.263955 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.14 seconds
10:37:51.264619 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:37:51.264799 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
10:37:52.252040 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.99 seconds
10:37:52.252582 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:37:52.252799 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
10:37:52.462437 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.21 seconds
10:37:52.474700 [debug] [Thread-1  ]: finished collecting timing info
10:37:52.475025 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
10:37:52.694218 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '49a4559c-d665-4d64-817f-b485e33b3fba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a189a60>]}
10:37:52.697085 [info ] [Thread-1  ]: 1 of 5 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 3.62s]
10:37:52.697267 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
10:37:52.697357 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
10:37:52.697461 [info ] [Thread-1  ]: 2 of 5 START incremental model dbt.incremental_time............................. [RUN]
10:37:52.697669 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
10:37:52.697742 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
10:37:52.697815 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
10:37:52.699368 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
10:37:52.699914 [debug] [Thread-1  ]: finished collecting timing info
10:37:52.700063 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
10:37:52.701512 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
10:37:52.701981 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
10:37:52.702060 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */


      create or replace transient table analytics.dbt.incremental_time  as
      (

select to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) time
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where time <= current_time


      );
10:37:52.702126 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:37:54.131916 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.43 seconds
10:37:54.135313 [debug] [Thread-1  ]: finished collecting timing info
10:37:54.135655 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
10:37:54.322820 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '49a4559c-d665-4d64-817f-b485e33b3fba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a1acf40>]}
10:37:54.323596 [info ] [Thread-1  ]: 2 of 5 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 1.63s]
10:37:54.324068 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
10:37:54.324310 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
10:37:54.324837 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
10:37:54.325097 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
10:37:54.325305 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
10:37:54.328550 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
10:37:54.329222 [debug] [Thread-1  ]: finished collecting timing info
10:37:54.329597 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
10:37:54.329789 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
10:37:54.330175 [info ] [Thread-1  ]: 3 of 5 START table model dbt.snowflake_cumulative_sales......................... [RUN]
10:37:54.330796 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
10:37:54.331082 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
10:37:54.331267 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
10:37:54.333047 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
10:37:54.333634 [debug] [Thread-1  ]: finished collecting timing info
10:37:54.333806 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
10:37:54.342153 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
10:37:54.343115 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
10:37:54.343259 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
10:37:54.343380 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:37:55.762609 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.42 seconds
10:37:55.766088 [debug] [Thread-1  ]: finished collecting timing info
10:37:55.766451 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
10:37:55.961141 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '49a4559c-d665-4d64-817f-b485e33b3fba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a200e80>]}
10:37:55.961961 [info ] [Thread-1  ]: 3 of 5 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 1.63s]
10:37:55.962407 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
10:37:55.962651 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
10:37:55.963071 [info ] [Thread-1  ]: 4 of 5 START table model dbt.snowflake_customer_purchases....................... [RUN]
10:37:55.963720 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
10:37:55.963932 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
10:37:55.964135 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
10:37:55.965900 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
10:37:55.966643 [debug] [Thread-1  ]: finished collecting timing info
10:37:55.966836 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
10:37:55.969218 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
10:37:55.970377 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
10:37:55.970537 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
10:37:55.970678 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:37:57.577553 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.61 seconds
10:37:57.580279 [debug] [Thread-1  ]: finished collecting timing info
10:37:57.580627 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
10:37:57.851170 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '49a4559c-d665-4d64-817f-b485e33b3fba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a2495e0>]}
10:37:57.851880 [info ] [Thread-1  ]: 4 of 5 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 1.89s]
10:37:57.852299 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
10:37:57.852560 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
10:37:57.853020 [info ] [Thread-1  ]: 5 of 5 START table model dbt.my_second_dbt_model................................ [RUN]
10:37:57.854118 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
10:37:57.854400 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
10:37:57.854617 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
10:37:57.865727 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
10:37:57.866455 [debug] [Thread-1  ]: finished collecting timing info
10:37:57.866625 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
10:37:57.868739 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
10:37:57.869831 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
10:37:57.869977 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (with __dbt__cte__my_first_dbt_model as (
/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
)-- Use the `ref` function to select from other models

select *
from __dbt__cte__my_first_dbt_model
where id = 1
      );
10:37:57.870106 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:37:59.167299 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.3 seconds
10:37:59.171692 [debug] [Thread-1  ]: finished collecting timing info
10:37:59.172154 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
10:37:59.478576 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '49a4559c-d665-4d64-817f-b485e33b3fba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a1bbb50>]}
10:37:59.479085 [info ] [Thread-1  ]: 5 of 5 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.62s]
10:37:59.479346 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
10:37:59.480167 [debug] [MainThread]: Acquiring new snowflake connection "master"
10:37:59.480462 [info ] [MainThread]: 
10:37:59.480649 [info ] [MainThread]: Finished running 2 incremental models, 3 table models in 14.11s.
10:37:59.480804 [debug] [MainThread]: Connection 'master' was properly closed.
10:37:59.480897 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
10:37:59.486067 [info ] [MainThread]: 
10:37:59.486321 [info ] [MainThread]: [32mCompleted successfully[0m
10:37:59.486535 [info ] [MainThread]: 
10:37:59.486702 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
10:37:59.486957 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1055b68e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c80d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108331c40>]}


============================== 2022-05-13 10:38:49.118267 | 41174521-8b7a-4e81-b3df-0e3b0ccab80f ==============================
10:38:49.118267 [info ] [MainThread]: Running with dbt=1.0.1
10:38:49.118639 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
10:38:49.118759 [debug] [MainThread]: Tracking: tracking
10:38:49.119004 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119239520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119239100>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119239280>]}
10:38:49.161022 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
10:38:49.161162 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
10:38:49.164175 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '41174521-8b7a-4e81-b3df-0e3b0ccab80f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119225190>]}
10:38:49.167323 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '41174521-8b7a-4e81-b3df-0e3b0ccab80f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1181345e0>]}
10:38:49.167458 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
10:38:49.168204 [info ] [MainThread]: 
10:38:49.168412 [debug] [MainThread]: Acquiring new snowflake connection "master"
10:38:49.168860 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
10:38:49.174978 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
10:38:49.175098 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
10:38:49.175166 [debug] [ThreadPool]: Opening a new connection, currently in state init
10:38:49.967962 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.79 seconds
10:38:49.970775 [debug] [ThreadPool]: On list_analytics: Close
10:38:50.347042 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
10:38:50.355713 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
10:38:50.355965 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
10:38:50.356128 [debug] [ThreadPool]: Opening a new connection, currently in state closed
10:38:51.511202 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1.16 seconds
10:38:51.513375 [debug] [ThreadPool]: On list_analytics_dbt: Close
10:38:51.810224 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
10:38:51.811184 [info ] [MainThread]: 
10:38:51.815337 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
10:38:51.816131 [info ] [Thread-1  ]: 1 of 5 START incremental model dbt.dates........................................ [RUN]
10:38:51.816657 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
10:38:51.816829 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
10:38:51.816994 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
10:38:51.827062 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
10:38:51.827693 [debug] [Thread-1  ]: finished collecting timing info
10:38:51.827855 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
10:38:51.857456 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:38:51.857675 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
10:38:51.857767 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:38:53.243439 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.39 seconds
10:38:53.257049 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:38:53.257445 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
10:38:53.406593 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.15 seconds
10:38:53.412550 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:38:53.412809 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
10:38:53.527584 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.11 seconds
10:38:53.538431 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:38:53.538766 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
10:38:53.647571 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.11 seconds
10:38:53.666667 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
10:38:53.668621 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:38:53.668734 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
10:38:53.899495 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.23 seconds
10:38:53.901983 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:38:53.902261 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
10:38:54.291830 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.39 seconds
10:38:54.294135 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:38:54.294530 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
10:38:54.488616 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.19 seconds
10:38:54.504057 [debug] [Thread-1  ]: finished collecting timing info
10:38:54.504456 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
10:38:54.751233 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '41174521-8b7a-4e81-b3df-0e3b0ccab80f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104bdb940>]}
10:38:54.752427 [info ] [Thread-1  ]: 1 of 5 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 2.93s]
10:38:54.753068 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
10:38:54.753332 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
10:38:54.753764 [info ] [Thread-1  ]: 2 of 5 START incremental model dbt.incremental_time............................. [RUN]
10:38:54.754439 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
10:38:54.754656 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
10:38:54.754857 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
10:38:54.759168 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
10:38:54.759815 [debug] [Thread-1  ]: finished collecting timing info
10:38:54.760001 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
10:38:54.763589 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
10:38:54.763909 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) time
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where time <= current_time


	and time > (select max(time) from analytics.dbt.incremental_time)

      );
10:38:54.764090 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:38:56.074315 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.31 seconds
10:38:56.081646 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
10:38:56.082091 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
10:38:56.221763 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.14 seconds
10:38:56.226740 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
10:38:56.227088 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
10:38:56.390799 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.16 seconds
10:38:56.395464 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
10:38:56.395785 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
10:38:56.512757 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.12 seconds
10:38:56.517830 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
10:38:56.519576 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
10:38:56.519795 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
10:38:56.657110 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.14 seconds
10:38:56.657725 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
10:38:56.657984 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.time = DBT_INTERNAL_DEST.time
        

    
    when matched then update set
        "TIME" = DBT_INTERNAL_SOURCE."TIME"
    

    when not matched then insert
        ("TIME")
    values
        ("TIME")

;
10:38:57.468818 [debug] [Thread-1  ]: SQL status: SUCCESS 62 in 0.81 seconds
10:38:57.469747 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
10:38:57.470294 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
10:38:57.717950 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.25 seconds
10:38:57.727029 [debug] [Thread-1  ]: finished collecting timing info
10:38:57.727509 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
10:38:57.924220 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '41174521-8b7a-4e81-b3df-0e3b0ccab80f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119755a00>]}
10:38:57.926068 [info ] [Thread-1  ]: 2 of 5 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 3.17s]
10:38:57.926518 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
10:38:57.926663 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
10:38:57.926938 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
10:38:57.927046 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
10:38:57.927134 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
10:38:57.928667 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
10:38:57.929023 [debug] [Thread-1  ]: finished collecting timing info
10:38:57.929222 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
10:38:57.929319 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
10:38:57.929485 [info ] [Thread-1  ]: 3 of 5 START table model dbt.snowflake_cumulative_sales......................... [RUN]
10:38:57.929702 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
10:38:57.929828 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
10:38:57.929940 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
10:38:57.930677 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
10:38:57.931016 [debug] [Thread-1  ]: finished collecting timing info
10:38:57.931102 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
10:38:57.935649 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
10:38:57.936202 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
10:38:57.936287 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
10:38:57.936365 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:38:59.237027 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.3 seconds
10:38:59.240404 [debug] [Thread-1  ]: finished collecting timing info
10:38:59.240827 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
10:38:59.537095 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '41174521-8b7a-4e81-b3df-0e3b0ccab80f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119b0c3d0>]}
10:38:59.537774 [info ] [Thread-1  ]: 3 of 5 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 1.61s]
10:38:59.538207 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
10:38:59.538455 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
10:38:59.538865 [info ] [Thread-1  ]: 4 of 5 START table model dbt.snowflake_customer_purchases....................... [RUN]
10:38:59.539506 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
10:38:59.539716 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
10:38:59.539926 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
10:38:59.541912 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
10:38:59.542761 [debug] [Thread-1  ]: finished collecting timing info
10:38:59.542943 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
10:38:59.545750 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
10:38:59.547113 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
10:38:59.547291 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
10:38:59.547441 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:39:01.327510 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.78 seconds
10:39:01.331382 [debug] [Thread-1  ]: finished collecting timing info
10:39:01.331813 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
10:39:01.530890 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '41174521-8b7a-4e81-b3df-0e3b0ccab80f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1197557f0>]}
10:39:01.531843 [info ] [Thread-1  ]: 4 of 5 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 1.99s]
10:39:01.532338 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
10:39:01.532587 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
10:39:01.532988 [info ] [Thread-1  ]: 5 of 5 START table model dbt.my_second_dbt_model................................ [RUN]
10:39:01.533637 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
10:39:01.533845 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
10:39:01.534052 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
10:39:01.547138 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
10:39:01.547746 [debug] [Thread-1  ]: finished collecting timing info
10:39:01.547907 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
10:39:01.549837 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
10:39:01.550768 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
10:39:01.550893 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (with __dbt__cte__my_first_dbt_model as (
/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
)-- Use the `ref` function to select from other models

select *
from __dbt__cte__my_first_dbt_model
where id = 1
      );
10:39:01.551009 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:39:02.977705 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.43 seconds
10:39:02.980930 [debug] [Thread-1  ]: finished collecting timing info
10:39:02.981330 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
10:39:03.337672 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '41174521-8b7a-4e81-b3df-0e3b0ccab80f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119b26760>]}
10:39:03.338456 [info ] [Thread-1  ]: 5 of 5 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.80s]
10:39:03.338904 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
10:39:03.340263 [debug] [MainThread]: Acquiring new snowflake connection "master"
10:39:03.340737 [info ] [MainThread]: 
10:39:03.341077 [info ] [MainThread]: Finished running 2 incremental models, 3 table models in 14.17s.
10:39:03.341371 [debug] [MainThread]: Connection 'master' was properly closed.
10:39:03.341533 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
10:39:03.348303 [info ] [MainThread]: 
10:39:03.348653 [info ] [MainThread]: [32mCompleted successfully[0m
10:39:03.348951 [info ] [MainThread]: 
10:39:03.349174 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
10:39:03.349454 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1194a3c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1063e2670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119759820>]}


============================== 2022-05-13 10:43:03.805216 | af664626-bbe0-4961-8861-a4cf7189da6c ==============================
10:43:03.805216 [info ] [MainThread]: Running with dbt=1.0.1
10:43:03.805917 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
10:43:03.806094 [debug] [MainThread]: Tracking: tracking
10:43:03.806331 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1082b2190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1082b20a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1082b2b20>]}
10:43:03.852369 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
10:43:03.852676 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/incremental_time.sql
10:43:03.858150 [debug] [MainThread]: 1603: static parser failed on example/incremental_time.sql
10:43:03.866707 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_time.sql
10:43:03.874863 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'af664626-bbe0-4961-8861-a4cf7189da6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10841df70>]}
10:43:03.878402 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'af664626-bbe0-4961-8861-a4cf7189da6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104441a30>]}
10:43:03.878572 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
10:43:03.879314 [info ] [MainThread]: 
10:43:03.879537 [debug] [MainThread]: Acquiring new snowflake connection "master"
10:43:03.879956 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
10:43:03.885793 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
10:43:03.885882 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
10:43:03.885945 [debug] [ThreadPool]: Opening a new connection, currently in state init
10:43:04.700347 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.81 seconds
10:43:04.702690 [debug] [ThreadPool]: On list_analytics: Close
10:43:05.091785 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
10:43:05.101905 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
10:43:05.102230 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
10:43:05.102391 [debug] [ThreadPool]: Opening a new connection, currently in state closed
10:43:06.139680 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1.04 seconds
10:43:06.142605 [debug] [ThreadPool]: On list_analytics_dbt: Close
10:43:06.332725 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
10:43:06.333054 [info ] [MainThread]: 
10:43:06.337898 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
10:43:06.338713 [info ] [Thread-1  ]: 1 of 5 START incremental model dbt.dates........................................ [RUN]
10:43:06.339240 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
10:43:06.339412 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
10:43:06.339580 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
10:43:06.345562 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
10:43:06.346216 [debug] [Thread-1  ]: finished collecting timing info
10:43:06.346378 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
10:43:06.378129 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:43:06.378346 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
10:43:06.378440 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:43:08.326142 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.95 seconds
10:43:08.339227 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:43:08.339628 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
10:43:08.473015 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.13 seconds
10:43:08.478398 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:43:08.478609 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
10:43:08.691087 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.21 seconds
10:43:08.703882 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:43:08.704288 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
10:43:08.906381 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.2 seconds
10:43:08.928888 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
10:43:08.931321 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:43:08.931465 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
10:43:09.215977 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.28 seconds
10:43:09.217515 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:43:09.217774 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
10:43:10.004165 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.79 seconds
10:43:10.004670 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:43:10.004847 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
10:43:10.265214 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.26 seconds
10:43:10.279885 [debug] [Thread-1  ]: finished collecting timing info
10:43:10.280279 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
10:43:10.486812 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af664626-bbe0-4961-8861-a4cf7189da6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102e82040>]}
10:43:10.487854 [info ] [Thread-1  ]: 1 of 5 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 4.15s]
10:43:10.488310 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
10:43:10.488547 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
10:43:10.488970 [info ] [Thread-1  ]: 2 of 5 START incremental model dbt.incremental_time............................. [RUN]
10:43:10.489626 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
10:43:10.489846 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
10:43:10.490046 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
10:43:10.493876 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
10:43:10.494564 [debug] [Thread-1  ]: finished collecting timing info
10:43:10.494745 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
10:43:10.498409 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
10:43:10.498582 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
10:43:10.498725 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:43:11.486308 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a43ca3-3201-9c12-0000-0001205218b1
10:43:11.486680 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 002036 (42601): SQL compilation error:
Subquery containing correlated aggregate function [MAX(TIME_DIM.T_TIME)] can only appear in having or select clause
10:43:11.487038 [debug] [Thread-1  ]: finished collecting timing info
10:43:11.487262 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
10:43:11.675295 [debug] [Thread-1  ]: Database Error in model incremental_time (models/example/incremental_time.sql)
  002036 (42601): SQL compilation error:
  Subquery containing correlated aggregate function [MAX(TIME_DIM.T_TIME)] can only appear in having or select clause
10:43:11.676198 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af664626-bbe0-4961-8861-a4cf7189da6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c081370>]}
10:43:11.676814 [error] [Thread-1  ]: 2 of 5 ERROR creating incremental model dbt.incremental_time.................... [[31mERROR[0m in 1.19s]
10:43:11.677293 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
10:43:11.677534 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
10:43:11.678217 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
10:43:11.678494 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
10:43:11.678715 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
10:43:11.681965 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
10:43:11.682632 [debug] [Thread-1  ]: finished collecting timing info
10:43:11.683027 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
10:43:11.683239 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
10:43:11.683653 [info ] [Thread-1  ]: 3 of 5 START table model dbt.snowflake_cumulative_sales......................... [RUN]
10:43:11.684903 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
10:43:11.685132 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
10:43:11.685292 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
10:43:11.686668 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
10:43:11.687353 [debug] [Thread-1  ]: finished collecting timing info
10:43:11.687635 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
10:43:11.696001 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
10:43:11.696934 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
10:43:11.697066 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
10:43:11.697175 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:43:13.642419 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.95 seconds
10:43:13.645213 [debug] [Thread-1  ]: finished collecting timing info
10:43:13.645719 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
10:43:13.938452 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af664626-bbe0-4961-8861-a4cf7189da6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c0b1850>]}
10:43:13.939143 [info ] [Thread-1  ]: 3 of 5 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 2.25s]
10:43:13.939582 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
10:43:13.939828 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
10:43:13.940238 [info ] [Thread-1  ]: 4 of 5 START table model dbt.snowflake_customer_purchases....................... [RUN]
10:43:13.940889 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
10:43:13.941102 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
10:43:13.941306 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
10:43:13.943092 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
10:43:13.943734 [debug] [Thread-1  ]: finished collecting timing info
10:43:13.943861 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
10:43:13.945677 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
10:43:13.946811 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
10:43:13.947016 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
10:43:13.947122 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:43:15.573750 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.63 seconds
10:43:15.578034 [debug] [Thread-1  ]: finished collecting timing info
10:43:15.578438 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
10:43:15.764174 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af664626-bbe0-4961-8861-a4cf7189da6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1087d4c70>]}
10:43:15.765016 [info ] [Thread-1  ]: 4 of 5 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 1.82s]
10:43:15.765671 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
10:43:15.765936 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
10:43:15.766367 [info ] [Thread-1  ]: 5 of 5 START table model dbt.my_second_dbt_model................................ [RUN]
10:43:15.767088 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
10:43:15.767305 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
10:43:15.767501 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
10:43:15.778253 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
10:43:15.779028 [debug] [Thread-1  ]: finished collecting timing info
10:43:15.779200 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
10:43:15.781212 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
10:43:15.782317 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
10:43:15.782464 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (with __dbt__cte__my_first_dbt_model as (
/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
)-- Use the `ref` function to select from other models

select *
from __dbt__cte__my_first_dbt_model
where id = 1
      );
10:43:15.782588 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:43:17.207450 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.42 seconds
10:43:17.210668 [debug] [Thread-1  ]: finished collecting timing info
10:43:17.211111 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
10:43:17.720702 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af664626-bbe0-4961-8861-a4cf7189da6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1087d33a0>]}
10:43:17.723786 [info ] [Thread-1  ]: 5 of 5 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.95s]
10:43:17.724371 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
10:43:17.725806 [debug] [MainThread]: Acquiring new snowflake connection "master"
10:43:17.726378 [info ] [MainThread]: 
10:43:17.726743 [info ] [MainThread]: Finished running 2 incremental models, 3 table models in 13.85s.
10:43:17.727071 [debug] [MainThread]: Connection 'master' was properly closed.
10:43:17.727234 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
10:43:17.733893 [info ] [MainThread]: 
10:43:17.734252 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
10:43:17.734534 [info ] [MainThread]: 
10:43:17.734756 [error] [MainThread]: [33mDatabase Error in model incremental_time (models/example/incremental_time.sql)[0m
10:43:17.734980 [error] [MainThread]:   002036 (42601): SQL compilation error:
10:43:17.735186 [error] [MainThread]:   Subquery containing correlated aggregate function [MAX(TIME_DIM.T_TIME)] can only appear in having or select clause
10:43:17.735513 [info ] [MainThread]: 
10:43:17.735767 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
10:43:17.736052 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106fa6c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10442dd60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1087d4130>]}


============================== 2022-05-13 11:31:21.630030 | 591506dd-ca27-4580-a8bf-838d217489e2 ==============================
11:31:21.630030 [info ] [MainThread]: Running with dbt=1.0.1
11:31:21.630660 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
11:31:21.630798 [debug] [MainThread]: Tracking: tracking
11:31:21.631043 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079cb160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079cb070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079cb400>]}
11:31:21.677308 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
11:31:21.677503 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
11:31:21.680801 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '591506dd-ca27-4580-a8bf-838d217489e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079b10a0>]}
11:31:21.684491 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '591506dd-ca27-4580-a8bf-838d217489e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10681ec40>]}
11:31:21.684643 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
11:31:21.685417 [info ] [MainThread]: 
11:31:21.685650 [debug] [MainThread]: Acquiring new snowflake connection "master"
11:31:21.686107 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
11:31:21.692619 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
11:31:21.692763 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
11:31:21.692831 [debug] [ThreadPool]: Opening a new connection, currently in state init
11:31:22.675971 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.98 seconds
11:31:22.677112 [debug] [ThreadPool]: On list_analytics: Close
11:31:22.865627 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
11:31:22.876516 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
11:31:22.876827 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
11:31:22.876993 [debug] [ThreadPool]: Opening a new connection, currently in state closed
11:31:23.909742 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.03 seconds
11:31:23.912853 [debug] [ThreadPool]: On list_analytics_dbt: Close
11:31:24.117722 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
11:31:24.118394 [info ] [MainThread]: 
11:31:24.123272 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
11:31:24.124038 [info ] [Thread-1  ]: 1 of 5 START incremental model dbt.dates........................................ [RUN]
11:31:24.124536 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
11:31:24.124711 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
11:31:24.124887 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
11:31:24.133252 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
11:31:24.134294 [debug] [Thread-1  ]: finished collecting timing info
11:31:24.134454 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
11:31:24.164189 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
11:31:24.164415 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
11:31:24.164508 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:31:25.823176 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.66 seconds
11:31:25.833029 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
11:31:25.833276 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
11:31:25.978849 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.15 seconds
11:31:25.986390 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
11:31:25.986721 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
11:31:26.078422 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.09 seconds
11:31:26.091211 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
11:31:26.091576 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
11:31:26.211752 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.12 seconds
11:31:26.238296 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
11:31:26.240940 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
11:31:26.241086 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
11:31:26.386260 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.15 seconds
11:31:26.387154 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
11:31:26.387415 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
11:31:27.014724 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.63 seconds
11:31:27.015618 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
11:31:27.015853 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
11:31:27.262638 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.25 seconds
11:31:27.273967 [debug] [Thread-1  ]: finished collecting timing info
11:31:27.274336 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
11:31:27.449750 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '591506dd-ca27-4580-a8bf-838d217489e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104654190>]}
11:31:27.450546 [info ] [Thread-1  ]: 1 of 5 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 3.33s]
11:31:27.451078 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
11:31:27.451470 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
11:31:27.452067 [info ] [Thread-1  ]: 2 of 5 START incremental model dbt.incremental_time............................. [RUN]
11:31:27.452637 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
11:31:27.452818 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
11:31:27.452975 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
11:31:27.456365 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
11:31:27.458667 [debug] [Thread-1  ]: finished collecting timing info
11:31:27.458952 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
11:31:27.462598 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
11:31:27.463686 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
11:31:27.463850 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */


      create or replace transient table analytics.dbt.incremental_time  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


      );
11:31:27.463990 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:31:29.357062 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.89 seconds
11:31:29.366555 [debug] [Thread-1  ]: finished collecting timing info
11:31:29.367004 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
11:31:29.556591 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '591506dd-ca27-4580-a8bf-838d217489e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107eaef40>]}
11:31:29.557325 [info ] [Thread-1  ]: 2 of 5 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 2.10s]
11:31:29.557841 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
11:31:29.558099 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
11:31:29.558677 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
11:31:29.558919 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
11:31:29.559117 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
11:31:29.562406 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
11:31:29.564402 [debug] [Thread-1  ]: finished collecting timing info
11:31:29.564965 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
11:31:29.565198 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
11:31:29.565577 [info ] [Thread-1  ]: 3 of 5 START table model dbt.snowflake_cumulative_sales......................... [RUN]
11:31:29.566229 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
11:31:29.566479 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
11:31:29.566664 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
11:31:29.569479 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
11:31:29.570497 [debug] [Thread-1  ]: finished collecting timing info
11:31:29.570749 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
11:31:29.578557 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
11:31:29.579522 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
11:31:29.579665 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
11:31:29.579778 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:31:31.650276 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.07 seconds
11:31:31.654058 [debug] [Thread-1  ]: finished collecting timing info
11:31:31.654473 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
11:31:31.824354 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '591506dd-ca27-4580-a8bf-838d217489e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110302460>]}
11:31:31.825167 [info ] [Thread-1  ]: 3 of 5 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 2.26s]
11:31:31.825632 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
11:31:31.826029 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
11:31:31.826655 [info ] [Thread-1  ]: 4 of 5 START table model dbt.snowflake_customer_purchases....................... [RUN]
11:31:31.827387 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
11:31:31.827605 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
11:31:31.827814 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
11:31:31.829482 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
11:31:31.831134 [debug] [Thread-1  ]: finished collecting timing info
11:31:31.831390 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
11:31:31.834164 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
11:31:31.835444 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
11:31:31.835615 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
11:31:31.835777 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:31:34.219607 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.38 seconds
11:31:34.223012 [debug] [Thread-1  ]: finished collecting timing info
11:31:34.223345 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
11:31:34.386029 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '591506dd-ca27-4580-a8bf-838d217489e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107c968e0>]}
11:31:34.387240 [info ] [Thread-1  ]: 4 of 5 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.56s]
11:31:34.387851 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
11:31:34.388399 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
11:31:34.388986 [info ] [Thread-1  ]: 5 of 5 START table model dbt.my_second_dbt_model................................ [RUN]
11:31:34.389658 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
11:31:34.389878 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
11:31:34.390060 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
11:31:34.402092 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
11:31:34.404153 [debug] [Thread-1  ]: finished collecting timing info
11:31:34.404353 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
11:31:34.406219 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
11:31:34.407079 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
11:31:34.407161 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (with __dbt__cte__my_first_dbt_model as (
/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
)-- Use the `ref` function to select from other models

select *
from __dbt__cte__my_first_dbt_model
where id = 1
      );
11:31:34.407224 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:31:35.807802 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.4 seconds
11:31:35.813049 [debug] [Thread-1  ]: finished collecting timing info
11:31:35.813453 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
11:31:35.974506 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '591506dd-ca27-4580-a8bf-838d217489e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107e22b50>]}
11:31:35.975322 [info ] [Thread-1  ]: 5 of 5 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.58s]
11:31:35.975779 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
11:31:35.977147 [debug] [MainThread]: Acquiring new snowflake connection "master"
11:31:35.977643 [info ] [MainThread]: 
11:31:35.977988 [info ] [MainThread]: Finished running 2 incremental models, 3 table models in 14.29s.
11:31:35.978236 [debug] [MainThread]: Connection 'master' was properly closed.
11:31:35.978370 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
11:31:35.985153 [info ] [MainThread]: 
11:31:35.985521 [info ] [MainThread]: [32mCompleted successfully[0m
11:31:35.985828 [info ] [MainThread]: 
11:31:35.986035 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
11:31:35.986311 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110382580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10482bc70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107e96760>]}


============================== 2022-05-13 11:33:29.624616 | 5e05f29a-0035-47c2-b39e-248747587022 ==============================
11:33:29.624616 [info ] [MainThread]: Running with dbt=1.0.1
11:33:29.625262 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
11:33:29.625394 [debug] [MainThread]: Tracking: tracking
11:33:29.625602 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a378b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a37b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a37610>]}
11:33:29.670346 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
11:33:29.670672 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/my_first_dbt_model.sql
11:33:29.676380 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
11:33:29.696246 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5e05f29a-0035-47c2-b39e-248747587022', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b7df40>]}
11:33:29.699257 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5e05f29a-0035-47c2-b39e-248747587022', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105f8b5e0>]}
11:33:29.699394 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
11:33:29.700112 [info ] [MainThread]: 
11:33:29.700310 [debug] [MainThread]: Acquiring new snowflake connection "master"
11:33:29.700750 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
11:33:29.706658 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
11:33:29.706766 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
11:33:29.706830 [debug] [ThreadPool]: Opening a new connection, currently in state init
11:33:30.800438 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.09 seconds
11:33:30.803790 [debug] [ThreadPool]: On list_analytics: Close
11:33:31.347388 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
11:33:31.351474 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
11:33:31.351822 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
11:33:31.352026 [debug] [ThreadPool]: Opening a new connection, currently in state closed
11:33:32.274623 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.92 seconds
11:33:32.277624 [debug] [ThreadPool]: On list_analytics: Close
11:33:32.482200 [debug] [ThreadPool]: Acquiring new snowflake connection "create_analytics_dbt_nigel_test"
11:33:32.482884 [debug] [ThreadPool]: Acquiring new snowflake connection "create_analytics_dbt_nigel_test"
11:33:32.483206 [debug] [ThreadPool]: Creating schema "_ReferenceKey(database='analytics', schema='dbt_nigel_test', identifier=None)"
11:33:32.489470 [debug] [ThreadPool]: Using snowflake connection "create_analytics_dbt_nigel_test"
11:33:32.489713 [debug] [ThreadPool]: On create_analytics_dbt_nigel_test: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "create_analytics_dbt_nigel_test"} */
create schema if not exists analytics.dbt_nigel_test
11:33:32.489870 [debug] [ThreadPool]: Opening a new connection, currently in state closed
11:33:33.377848 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.89 seconds
11:33:33.379872 [debug] [ThreadPool]: On create_analytics_dbt_nigel_test: Close
11:33:33.548626 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
11:33:33.574844 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
11:33:33.582471 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
11:33:33.582723 [debug] [ThreadPool]: Opening a new connection, currently in state closed
11:33:34.789993 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1.21 seconds
11:33:34.793262 [debug] [ThreadPool]: On list_analytics_dbt: Close
11:33:34.979429 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt_nigel_test"
11:33:34.982461 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt_nigel_test"
11:33:34.982709 [debug] [ThreadPool]: On list_analytics_dbt_nigel_test: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt_nigel_test"} */

    show terse objects in analytics.dbt_nigel_test
11:33:34.982906 [debug] [ThreadPool]: Opening a new connection, currently in state closed
11:33:35.838811 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 0.86 seconds
11:33:35.841104 [debug] [ThreadPool]: On list_analytics_dbt_nigel_test: Close
11:33:36.017710 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
11:33:36.018406 [info ] [MainThread]: 
11:33:36.023680 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
11:33:36.024052 [info ] [Thread-1  ]: 1 of 6 START incremental model dbt.dates........................................ [RUN]
11:33:36.024546 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
11:33:36.024712 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
11:33:36.025309 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
11:33:36.035201 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
11:33:36.035829 [debug] [Thread-1  ]: finished collecting timing info
11:33:36.035986 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
11:33:36.065002 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
11:33:36.065169 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
11:33:36.065256 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:33:37.948913 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.88 seconds
11:33:37.960908 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
11:33:37.961206 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
11:33:38.331034 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.37 seconds
11:33:38.338420 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
11:33:38.338688 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
11:33:38.453228 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.11 seconds
11:33:38.466208 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
11:33:38.466674 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
11:33:38.581611 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.11 seconds
11:33:38.609745 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
11:33:38.612131 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
11:33:38.612262 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
11:33:38.744223 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.13 seconds
11:33:38.746726 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
11:33:38.747068 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
11:33:39.396049 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.65 seconds
11:33:39.396958 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
11:33:39.397980 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
11:33:39.580950 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.18 seconds
11:33:39.593927 [debug] [Thread-1  ]: finished collecting timing info
11:33:39.594326 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
11:33:39.815321 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5e05f29a-0035-47c2-b39e-248747587022', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1098436a0>]}
11:33:39.815872 [info ] [Thread-1  ]: 1 of 6 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 3.79s]
11:33:39.816288 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
11:33:39.816533 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
11:33:39.816948 [info ] [Thread-1  ]: 2 of 6 START incremental model dbt.incremental_time............................. [RUN]
11:33:39.817599 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
11:33:39.817860 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
11:33:39.818064 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
11:33:39.821910 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
11:33:39.822787 [debug] [Thread-1  ]: finished collecting timing info
11:33:39.822964 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
11:33:39.826606 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
11:33:39.826785 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
11:33:39.826920 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:33:41.904906 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.08 seconds
11:33:41.909321 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
11:33:41.909650 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
11:33:42.145893 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.24 seconds
11:33:42.151448 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
11:33:42.151802 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
11:33:42.283899 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.13 seconds
11:33:42.288608 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
11:33:42.288868 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
11:33:42.653314 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.36 seconds
11:33:42.658127 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
11:33:42.660609 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
11:33:42.660847 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
11:33:42.853986 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.19 seconds
11:33:42.855132 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
11:33:42.855375 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
11:33:43.701160 [debug] [Thread-1  ]: SQL status: SUCCESS 132 in 0.85 seconds
11:33:43.702108 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
11:33:43.702461 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
11:33:44.052426 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.35 seconds
11:33:44.055607 [debug] [Thread-1  ]: finished collecting timing info
11:33:44.056070 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
11:33:44.442181 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5e05f29a-0035-47c2-b39e-248747587022', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109843880>]}
11:33:44.443009 [info ] [Thread-1  ]: 2 of 6 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 4.62s]
11:33:44.443485 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
11:33:44.443744 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
11:33:44.444162 [info ] [Thread-1  ]: 3 of 6 START table model dbt_nigel_test.first model............................. [RUN]
11:33:44.444822 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
11:33:44.445046 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
11:33:44.445254 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
11:33:44.449204 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
11:33:44.450151 [debug] [Thread-1  ]: finished collecting timing info
11:33:44.450446 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
11:33:44.459603 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
11:33:44.460680 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
11:33:44.460819 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt_nigel_test.first model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
11:33:44.460933 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:33:45.463337 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a43cd5-3201-9c12-0000-000120521929
11:33:45.463777 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 1 at position 72 unexpected 'as'.
11:33:45.464112 [debug] [Thread-1  ]: finished collecting timing info
11:33:45.464333 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
11:33:45.803332 [debug] [Thread-1  ]: Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  001003 (42000): SQL compilation error:
  syntax error line 1 at position 72 unexpected 'as'.
  compiled SQL at target/run/learn_dbt/models/example/my_first_dbt_model.sql
11:33:45.803992 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5e05f29a-0035-47c2-b39e-248747587022', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b80f970>]}
11:33:45.804503 [error] [Thread-1  ]: 3 of 6 ERROR creating table model dbt_nigel_test.first model.................... [[31mERROR[0m in 1.36s]
11:33:45.804952 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
11:33:45.805197 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
11:33:45.805711 [info ] [Thread-1  ]: 4 of 6 START table model dbt.snowflake_cumulative_sales......................... [RUN]
11:33:45.806751 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
11:33:45.807003 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
11:33:45.807183 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
11:33:45.808580 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
11:33:45.809134 [debug] [Thread-1  ]: finished collecting timing info
11:33:45.809294 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
11:33:45.812080 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
11:33:45.813113 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
11:33:45.813280 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
11:33:45.813426 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:33:47.411777 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.6 seconds
11:33:47.414471 [debug] [Thread-1  ]: finished collecting timing info
11:33:47.414857 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
11:33:47.602937 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5e05f29a-0035-47c2-b39e-248747587022', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b822580>]}
11:33:47.603709 [info ] [Thread-1  ]: 4 of 6 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 1.80s]
11:33:47.604285 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
11:33:47.604707 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
11:33:47.605141 [info ] [Thread-1  ]: 5 of 6 START table model dbt.snowflake_customer_purchases....................... [RUN]
11:33:47.605767 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
11:33:47.605959 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
11:33:47.606134 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
11:33:47.607959 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
11:33:47.608726 [debug] [Thread-1  ]: finished collecting timing info
11:33:47.608932 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
11:33:47.611961 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
11:33:47.613303 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
11:33:47.613489 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
11:33:47.613648 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:33:49.766577 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.15 seconds
11:33:49.769205 [debug] [Thread-1  ]: finished collecting timing info
11:33:49.769497 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
11:33:50.030245 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5e05f29a-0035-47c2-b39e-248747587022', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10981e910>]}
11:33:50.031381 [info ] [Thread-1  ]: 5 of 6 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.42s]
11:33:50.032003 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
11:33:50.032271 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
11:33:50.032608 [info ] [Thread-1  ]: 6 of 6 SKIP relation dbt.my_second_dbt_model.................................... [[33mSKIP[0m]
11:33:50.033076 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
11:33:50.034429 [debug] [MainThread]: Acquiring new snowflake connection "master"
11:33:50.034989 [info ] [MainThread]: 
11:33:50.035343 [info ] [MainThread]: Finished running 2 incremental models, 4 table models in 20.33s.
11:33:50.035661 [debug] [MainThread]: Connection 'master' was properly closed.
11:33:50.035828 [debug] [MainThread]: Connection 'model.learn_dbt.snowflake_customer_purchases' was properly closed.
11:33:50.042480 [info ] [MainThread]: 
11:33:50.042913 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
11:33:50.043363 [info ] [MainThread]: 
11:33:50.043585 [error] [MainThread]: [33mDatabase Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)[0m
11:33:50.043785 [error] [MainThread]:   001003 (42000): SQL compilation error:
11:33:50.044013 [error] [MainThread]:   syntax error line 1 at position 72 unexpected 'as'.
11:33:50.044283 [error] [MainThread]:   compiled SQL at target/run/learn_dbt/models/example/my_first_dbt_model.sql
11:33:50.044500 [info ] [MainThread]: 
11:33:50.044697 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=1 TOTAL=6
11:33:50.045019 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104b0ecd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105f26f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109828610>]}


============================== 2022-05-13 11:36:52.301461 | b05ae46b-a079-4f2c-9b61-93925b65de27 ==============================
11:36:52.301461 [info ] [MainThread]: Running with dbt=1.0.1
11:36:52.302081 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
11:36:52.302196 [debug] [MainThread]: Tracking: tracking
11:36:52.302410 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1050072b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105007eb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1050079a0>]}
11:36:52.348081 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
11:36:52.348435 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/my_first_dbt_model.sql
11:36:52.354175 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
11:36:52.373622 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b05ae46b-a079-4f2c-9b61-93925b65de27', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x101371580>]}
11:36:52.376617 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b05ae46b-a079-4f2c-9b61-93925b65de27', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104fe5610>]}
11:36:52.376754 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
11:36:52.377499 [info ] [MainThread]: 
11:36:52.377697 [debug] [MainThread]: Acquiring new snowflake connection "master"
11:36:52.378143 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
11:36:52.384271 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
11:36:52.384408 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
11:36:52.384480 [debug] [ThreadPool]: Opening a new connection, currently in state init
11:36:53.390304 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.01 seconds
11:36:53.392552 [debug] [ThreadPool]: On list_analytics: Close
11:36:53.567485 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
11:36:53.570482 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
11:36:53.570748 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
11:36:53.570942 [debug] [ThreadPool]: Opening a new connection, currently in state closed
11:36:54.618073 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.05 seconds
11:36:54.619296 [debug] [ThreadPool]: On list_analytics: Close
11:36:54.824386 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
11:36:54.833233 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
11:36:54.833529 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
11:36:54.833690 [debug] [ThreadPool]: Opening a new connection, currently in state closed
11:36:55.644732 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 0.81 seconds
11:36:55.647540 [debug] [ThreadPool]: On list_analytics_dbt: Close
11:36:55.834668 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt_nigel_test"
11:36:55.837948 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt_nigel_test"
11:36:55.838339 [debug] [ThreadPool]: On list_analytics_dbt_nigel_test: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt_nigel_test"} */

    show terse objects in analytics.dbt_nigel_test
11:36:55.838539 [debug] [ThreadPool]: Opening a new connection, currently in state closed
11:36:56.501085 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 0.66 seconds
11:36:56.503702 [debug] [ThreadPool]: On list_analytics_dbt_nigel_test: Close
11:36:56.684324 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
11:36:56.684855 [info ] [MainThread]: 
11:36:56.690086 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
11:36:56.690493 [info ] [Thread-1  ]: 1 of 6 START incremental model dbt.dates........................................ [RUN]
11:36:56.691407 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
11:36:56.691615 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
11:36:56.691796 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
11:36:56.702172 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
11:36:56.702817 [debug] [Thread-1  ]: finished collecting timing info
11:36:56.702958 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
11:36:56.731492 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
11:36:56.731670 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
11:36:56.731756 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:36:58.322723 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.59 seconds
11:36:58.336494 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
11:36:58.336815 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
11:36:58.465984 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.13 seconds
11:36:58.472664 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
11:36:58.472872 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
11:36:58.599468 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.13 seconds
11:36:58.611633 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
11:36:58.611925 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
11:36:58.717485 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.11 seconds
11:36:58.744423 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
11:36:58.746875 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
11:36:58.746999 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
11:36:58.880542 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.13 seconds
11:36:58.882450 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
11:36:58.883116 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
11:36:59.254142 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.37 seconds
11:36:59.254925 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
11:36:59.255156 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
11:36:59.423355 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.17 seconds
11:36:59.438255 [debug] [Thread-1  ]: finished collecting timing info
11:36:59.438674 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
11:36:59.648489 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b05ae46b-a079-4f2c-9b61-93925b65de27', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1052f1430>]}
11:36:59.649576 [info ] [Thread-1  ]: 1 of 6 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 2.96s]
11:36:59.650155 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
11:36:59.650413 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
11:36:59.650822 [info ] [Thread-1  ]: 2 of 6 START incremental model dbt.incremental_time............................. [RUN]
11:36:59.651463 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
11:36:59.651680 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
11:36:59.651876 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
11:36:59.656032 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
11:36:59.656789 [debug] [Thread-1  ]: finished collecting timing info
11:36:59.656962 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
11:36:59.660692 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
11:36:59.660891 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
11:36:59.661042 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:37:00.890895 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.23 seconds
11:37:00.896673 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
11:37:00.897017 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
11:37:01.010264 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.11 seconds
11:37:01.014797 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
11:37:01.015079 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
11:37:01.145459 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.13 seconds
11:37:01.150722 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
11:37:01.150955 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
11:37:01.417758 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.27 seconds
11:37:01.422779 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
11:37:01.425142 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
11:37:01.425367 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
11:37:01.604082 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.18 seconds
11:37:01.604817 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
11:37:01.605052 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
11:37:02.557017 [debug] [Thread-1  ]: SQL status: SUCCESS 200 in 0.95 seconds
11:37:02.558879 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
11:37:02.561093 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
11:37:02.939284 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.38 seconds
11:37:02.942162 [debug] [Thread-1  ]: finished collecting timing info
11:37:02.942482 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
11:37:03.261977 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b05ae46b-a079-4f2c-9b61-93925b65de27', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10720e370>]}
11:37:03.262859 [info ] [Thread-1  ]: 2 of 6 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 3.61s]
11:37:03.263302 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
11:37:03.263556 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
11:37:03.263955 [info ] [Thread-1  ]: 3 of 6 START table model dbt_nigel_test.first_model............................. [RUN]
11:37:03.264597 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
11:37:03.264814 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
11:37:03.265019 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
11:37:03.268518 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
11:37:03.269178 [debug] [Thread-1  ]: finished collecting timing info
11:37:03.269356 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
11:37:03.278322 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
11:37:03.279485 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
11:37:03.279650 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt_nigel_test.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
11:37:03.279783 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:37:04.654052 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.37 seconds
11:37:04.665606 [debug] [Thread-1  ]: finished collecting timing info
11:37:04.665954 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
11:37:05.021661 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b05ae46b-a079-4f2c-9b61-93925b65de27', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10720e760>]}
11:37:05.023033 [info ] [Thread-1  ]: 3 of 6 OK created table model dbt_nigel_test.first_model........................ [[32mSUCCESS 1[0m in 1.76s]
11:37:05.023644 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
11:37:05.023901 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
11:37:05.024324 [info ] [Thread-1  ]: 4 of 6 START table model dbt.snowflake_cumulative_sales......................... [RUN]
11:37:05.025070 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
11:37:05.025324 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
11:37:05.025575 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
11:37:05.026969 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
11:37:05.027859 [debug] [Thread-1  ]: finished collecting timing info
11:37:05.028077 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
11:37:05.030973 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
11:37:05.032296 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
11:37:05.032481 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
11:37:05.032633 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:37:07.115468 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.08 seconds
11:37:07.118939 [debug] [Thread-1  ]: finished collecting timing info
11:37:07.119353 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
11:37:07.395556 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b05ae46b-a079-4f2c-9b61-93925b65de27', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10720e250>]}
11:37:07.396395 [info ] [Thread-1  ]: 4 of 6 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 2.37s]
11:37:07.396861 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
11:37:07.397107 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
11:37:07.397515 [info ] [Thread-1  ]: 5 of 6 START table model dbt.snowflake_customer_purchases....................... [RUN]
11:37:07.398169 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
11:37:07.398385 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
11:37:07.398589 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
11:37:07.400393 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
11:37:07.401089 [debug] [Thread-1  ]: finished collecting timing info
11:37:07.401282 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
11:37:07.403980 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
11:37:07.405373 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
11:37:07.405553 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
11:37:07.405708 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:37:09.955808 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.55 seconds
11:37:09.963065 [debug] [Thread-1  ]: finished collecting timing info
11:37:09.963500 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
11:37:10.439017 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b05ae46b-a079-4f2c-9b61-93925b65de27', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10720e100>]}
11:37:10.439605 [info ] [Thread-1  ]: 5 of 6 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 3.04s]
11:37:10.439933 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
11:37:10.440109 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
11:37:10.440396 [info ] [Thread-1  ]: 6 of 6 START table model dbt.my_second_dbt_model................................ [RUN]
11:37:10.440937 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
11:37:10.441119 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
11:37:10.441314 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
11:37:10.443844 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
11:37:10.444658 [debug] [Thread-1  ]: finished collecting timing info
11:37:10.444839 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
11:37:10.447304 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
11:37:10.448178 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
11:37:10.448342 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt_nigel_test.first_model
where id = 1
      );
11:37:10.448487 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:37:12.083363 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.63 seconds
11:37:12.085492 [debug] [Thread-1  ]: finished collecting timing info
11:37:12.085710 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
11:37:12.473630 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b05ae46b-a079-4f2c-9b61-93925b65de27', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10720e340>]}
11:37:12.474445 [info ] [Thread-1  ]: 6 of 6 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 2.03s]
11:37:12.474833 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
11:37:12.476226 [debug] [MainThread]: Acquiring new snowflake connection "master"
11:37:12.476847 [info ] [MainThread]: 
11:37:12.477218 [info ] [MainThread]: Finished running 2 incremental models, 4 table models in 20.10s.
11:37:12.477536 [debug] [MainThread]: Connection 'master' was properly closed.
11:37:12.477704 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
11:37:12.484242 [info ] [MainThread]: 
11:37:12.484578 [info ] [MainThread]: [32mCompleted successfully[0m
11:37:12.484872 [info ] [MainThread]: 
11:37:12.485106 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
11:37:12.485412 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104ffdfa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10528c1f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053e5dc0>]}


============================== 2022-05-13 11:55:13.046402 | 4a1cd0d8-dde2-4aa4-8880-68e3dbe33074 ==============================
11:55:13.046402 [info ] [MainThread]: Running with dbt=1.0.1
11:55:13.046992 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
11:55:13.047122 [debug] [MainThread]: Tracking: tracking
11:55:13.047336 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1061b4e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1061b4a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1061b4d30>]}
11:55:13.091478 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
11:55:13.091793 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/my_first_dbt_model.sql
11:55:13.097322 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
11:55:13.117015 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4a1cd0d8-dde2-4aa4-8880-68e3dbe33074', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105202040>]}
11:55:13.120122 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4a1cd0d8-dde2-4aa4-8880-68e3dbe33074', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105778b20>]}
11:55:13.120257 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
11:55:13.120980 [info ] [MainThread]: 
11:55:13.121185 [debug] [MainThread]: Acquiring new snowflake connection "master"
11:55:13.121609 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytic_test"
11:55:13.127373 [debug] [ThreadPool]: Using snowflake connection "list_analytic_test"
11:55:13.127478 [debug] [ThreadPool]: On list_analytic_test: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytic_test"} */

    show terse schemas in database analytic_test
    limit 10000
11:55:13.127553 [debug] [ThreadPool]: Opening a new connection, currently in state init
11:55:14.006781 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01a43ceb-3201-9c86-0000-000120522de1
11:55:14.006983 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 002043 (02000): SQL compilation error:
Object does not exist, or operation cannot be performed.
11:55:14.007117 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro list_schemas
11:55:14.007179 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
11:55:14.007301 [debug] [ThreadPool]: On list_analytic_test: Close
11:55:14.174054 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
11:55:14.177918 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
11:55:14.178180 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
11:55:14.178379 [debug] [ThreadPool]: Opening a new connection, currently in state closed
11:55:14.867726 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 0.69 seconds
11:55:14.869731 [debug] [ThreadPool]: On list_analytics: Close
11:55:15.051358 [debug] [MainThread]: Connection 'master' was properly closed.
11:55:15.051840 [debug] [MainThread]: Connection 'list_analytics' was properly closed.
11:55:15.052281 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10507e160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10618cbe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106544a60>]}


============================== 2022-05-13 11:57:12.170548 | a36575dd-b926-424a-b1e6-231f1e866068 ==============================
11:57:12.170548 [info ] [MainThread]: Running with dbt=1.0.1
11:57:12.170916 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
11:57:12.171054 [debug] [MainThread]: Tracking: tracking
11:57:12.171259 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1104728b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110472b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110472610>]}
11:57:12.213961 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
11:57:12.214118 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
11:57:12.217400 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a36575dd-b926-424a-b1e6-231f1e866068', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11043e040>]}
11:57:12.220771 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a36575dd-b926-424a-b1e6-231f1e866068', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110454eb0>]}
11:57:12.220925 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
11:57:12.221764 [info ] [MainThread]: 
11:57:12.222092 [debug] [MainThread]: Acquiring new snowflake connection "master"
11:57:12.222560 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
11:57:12.228741 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
11:57:12.228901 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
11:57:12.228993 [debug] [ThreadPool]: Opening a new connection, currently in state init
11:57:13.051352 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 0.82 seconds
11:57:13.053220 [debug] [ThreadPool]: On list_analytics: Close
11:57:13.210249 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytic_test"
11:57:13.212883 [debug] [ThreadPool]: Using snowflake connection "list_analytic_test"
11:57:13.213121 [debug] [ThreadPool]: On list_analytic_test: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytic_test"} */

    show terse schemas in database analytic_test
    limit 10000
11:57:13.213278 [debug] [ThreadPool]: Opening a new connection, currently in state closed
11:57:13.724112 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01a43ced-3201-9c12-0000-000120521a85
11:57:13.724671 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 002043 (02000): SQL compilation error:
Object does not exist, or operation cannot be performed.
11:57:13.725167 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro list_schemas
11:57:13.725366 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
11:57:13.725648 [debug] [ThreadPool]: On list_analytic_test: Close
11:57:13.911271 [debug] [MainThread]: Connection 'master' was properly closed.
11:57:13.911779 [debug] [MainThread]: Connection 'list_analytic_test' was properly closed.
11:57:13.912093 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1071da130>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1071c7e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1109f1fa0>]}


============================== 2022-05-13 11:57:30.832906 | 655bf4f2-cea4-419e-9606-da9e1017f2fa ==============================
11:57:30.832906 [info ] [MainThread]: Running with dbt=1.0.1
11:57:30.833306 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
11:57:30.833429 [debug] [MainThread]: Tracking: tracking
11:57:30.833634 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a8bbf70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a8bbc40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a8bb8b0>]}
11:57:30.876228 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
11:57:30.876604 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/my_first_dbt_model.sql
11:57:30.881954 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
11:57:30.900986 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '655bf4f2-cea4-419e-9606-da9e1017f2fa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10969a460>]}
11:57:30.904213 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '655bf4f2-cea4-419e-9606-da9e1017f2fa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a8995e0>]}
11:57:30.904382 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
11:57:30.905251 [info ] [MainThread]: 
11:57:30.905500 [debug] [MainThread]: Acquiring new snowflake connection "master"
11:57:30.905993 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
11:57:30.912189 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
11:57:30.912331 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
11:57:30.912405 [debug] [ThreadPool]: Opening a new connection, currently in state init
11:57:31.656945 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 0.74 seconds
11:57:31.660308 [debug] [ThreadPool]: On list_analytics: Close
11:57:31.856970 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_test"
11:57:31.859938 [debug] [ThreadPool]: Using snowflake connection "list_analytics_test"
11:57:31.860195 [debug] [ThreadPool]: On list_analytics_test: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_test"} */

    show terse schemas in database analytics_test
    limit 10000
11:57:31.860383 [debug] [ThreadPool]: Opening a new connection, currently in state closed
11:57:32.663661 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.8 seconds
11:57:32.666342 [debug] [ThreadPool]: On list_analytics_test: Close
11:57:32.836155 [debug] [ThreadPool]: Acquiring new snowflake connection "create_analytics_test_dbt_nigel_test"
11:57:32.836708 [debug] [ThreadPool]: Acquiring new snowflake connection "create_analytics_test_dbt_nigel_test"
11:57:32.837017 [debug] [ThreadPool]: Creating schema "_ReferenceKey(database='analytics_test', schema='dbt_nigel_test', identifier=None)"
11:57:32.843771 [debug] [ThreadPool]: Using snowflake connection "create_analytics_test_dbt_nigel_test"
11:57:32.844088 [debug] [ThreadPool]: On create_analytics_test_dbt_nigel_test: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "create_analytics_test_dbt_nigel_test"} */
create schema if not exists analytics_test.dbt_nigel_test
11:57:32.844253 [debug] [ThreadPool]: Opening a new connection, currently in state closed
11:57:33.376355 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.53 seconds
11:57:33.378105 [debug] [ThreadPool]: On create_analytics_test_dbt_nigel_test: Close
11:57:33.538174 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
11:57:33.546674 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
11:57:33.546958 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
11:57:33.547118 [debug] [ThreadPool]: Opening a new connection, currently in state closed
11:57:34.145322 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 0.6 seconds
11:57:34.148156 [debug] [ThreadPool]: On list_analytics_dbt: Close
11:57:34.315119 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_test_dbt_nigel_test"
11:57:34.318341 [debug] [ThreadPool]: Using snowflake connection "list_analytics_test_dbt_nigel_test"
11:57:34.318699 [debug] [ThreadPool]: On list_analytics_test_dbt_nigel_test: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_test_dbt_nigel_test"} */

    show terse objects in analytics_test.dbt_nigel_test
11:57:34.318905 [debug] [ThreadPool]: Opening a new connection, currently in state closed
11:57:34.808187 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 0.49 seconds
11:57:34.811899 [debug] [ThreadPool]: On list_analytics_test_dbt_nigel_test: Close
11:57:34.983265 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
11:57:34.984194 [info ] [MainThread]: 
11:57:34.990120 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
11:57:34.990580 [info ] [Thread-1  ]: 1 of 6 START incremental model dbt.dates........................................ [RUN]
11:57:34.991137 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
11:57:34.991304 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
11:57:34.991831 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
11:57:34.997486 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
11:57:34.998915 [debug] [Thread-1  ]: finished collecting timing info
11:57:34.999143 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
11:57:35.030584 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
11:57:35.030782 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
11:57:35.030872 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:57:36.816052 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.79 seconds
11:57:36.829490 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
11:57:36.829874 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
11:57:36.935152 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.11 seconds
11:57:36.943064 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
11:57:36.943415 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
11:57:37.031500 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.09 seconds
11:57:37.042609 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
11:57:37.042885 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
11:57:37.140267 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.1 seconds
11:57:37.168414 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
11:57:37.170776 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
11:57:37.170906 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
11:57:37.298921 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.13 seconds
11:57:37.299593 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
11:57:37.299782 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
11:57:37.854477 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.55 seconds
11:57:37.855959 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
11:57:37.856193 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
11:57:38.050109 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.19 seconds
11:57:38.064838 [debug] [Thread-1  ]: finished collecting timing info
11:57:38.065220 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
11:57:38.261818 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '655bf4f2-cea4-419e-9606-da9e1017f2fa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ac39190>]}
11:57:38.262297 [info ] [Thread-1  ]: 1 of 6 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 3.27s]
11:57:38.262490 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
11:57:38.262582 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
11:57:38.262687 [info ] [Thread-1  ]: 2 of 6 START incremental model dbt.incremental_time............................. [RUN]
11:57:38.263044 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
11:57:38.263313 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
11:57:38.263447 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
11:57:38.267386 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
11:57:38.269513 [debug] [Thread-1  ]: finished collecting timing info
11:57:38.269706 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
11:57:38.273566 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
11:57:38.273774 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
11:57:38.273914 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:57:39.505424 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.23 seconds
11:57:39.512413 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
11:57:39.512774 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
11:57:39.630330 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.12 seconds
11:57:39.635896 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
11:57:39.636238 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
11:57:39.744926 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.11 seconds
11:57:39.748999 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
11:57:39.749249 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
11:57:39.850536 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
11:57:39.855532 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
11:57:39.857997 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
11:57:39.858232 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
11:57:39.989554 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.13 seconds
11:57:39.990858 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
11:57:39.991109 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
11:57:40.912614 [debug] [Thread-1  ]: SQL status: SUCCESS 1238 in 0.92 seconds
11:57:40.913443 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
11:57:40.913644 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
11:57:41.219812 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.31 seconds
11:57:41.223270 [debug] [Thread-1  ]: finished collecting timing info
11:57:41.223720 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
11:57:41.400280 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '655bf4f2-cea4-419e-9606-da9e1017f2fa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cf9a7f0>]}
11:57:41.401034 [info ] [Thread-1  ]: 2 of 6 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 3.14s]
11:57:41.401465 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
11:57:41.402274 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
11:57:41.402575 [info ] [Thread-1  ]: 3 of 6 START table model analytics_test.dbt_nigel_test.first_model.............. [RUN]
11:57:41.402974 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
11:57:41.403097 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
11:57:41.403215 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
11:57:41.405694 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
11:57:41.407352 [debug] [Thread-1  ]: finished collecting timing info
11:57:41.407584 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
11:57:41.415151 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
11:57:41.416501 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
11:57:41.416725 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics_test.dbt_nigel_test.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
11:57:41.416839 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:57:42.655372 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.24 seconds
11:57:42.657958 [debug] [Thread-1  ]: finished collecting timing info
11:57:42.658308 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
11:57:42.821467 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '655bf4f2-cea4-419e-9606-da9e1017f2fa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ad9c9a0>]}
11:57:42.822291 [info ] [Thread-1  ]: 3 of 6 OK created table model analytics_test.dbt_nigel_test.first_model......... [[32mSUCCESS 1[0m in 1.42s]
11:57:42.822836 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
11:57:42.823072 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
11:57:42.823284 [info ] [Thread-1  ]: 4 of 6 START table model dbt.snowflake_cumulative_sales......................... [RUN]
11:57:42.823611 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
11:57:42.823708 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
11:57:42.823781 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
11:57:42.824473 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
11:57:42.825964 [debug] [Thread-1  ]: finished collecting timing info
11:57:42.826103 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
11:57:42.827648 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
11:57:42.828229 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
11:57:42.828308 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
11:57:42.828376 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:57:44.467681 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.64 seconds
11:57:44.472236 [debug] [Thread-1  ]: finished collecting timing info
11:57:44.472658 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
11:57:44.644048 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '655bf4f2-cea4-419e-9606-da9e1017f2fa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ad9c9d0>]}
11:57:44.646472 [info ] [Thread-1  ]: 4 of 6 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 1.82s]
11:57:44.646943 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
11:57:44.647183 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
11:57:44.647525 [info ] [Thread-1  ]: 5 of 6 START table model dbt.snowflake_customer_purchases....................... [RUN]
11:57:44.648507 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
11:57:44.648750 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
11:57:44.648956 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
11:57:44.650712 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
11:57:44.652666 [debug] [Thread-1  ]: finished collecting timing info
11:57:44.652967 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
11:57:44.655568 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
11:57:44.656805 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
11:57:44.656983 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
11:57:44.657132 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:57:46.211158 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.55 seconds
11:57:46.217686 [debug] [Thread-1  ]: finished collecting timing info
11:57:46.218136 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
11:57:46.406388 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '655bf4f2-cea4-419e-9606-da9e1017f2fa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ae52cd0>]}
11:57:46.418141 [info ] [Thread-1  ]: 5 of 6 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 1.76s]
11:57:46.418662 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
11:57:46.418934 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
11:57:46.421526 [info ] [Thread-1  ]: 6 of 6 START table model dbt.my_second_dbt_model................................ [RUN]
11:57:46.422164 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
11:57:46.422304 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
11:57:46.422430 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
11:57:46.424553 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
11:57:46.425689 [debug] [Thread-1  ]: finished collecting timing info
11:57:46.425918 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
11:57:46.428188 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
11:57:46.429181 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
11:57:46.429402 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics_test.dbt_nigel_test.first_model
where id = 1
      );
11:57:46.429560 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:57:47.574917 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.15 seconds
11:57:47.577648 [debug] [Thread-1  ]: finished collecting timing info
11:57:47.577966 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
11:57:47.769230 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '655bf4f2-cea4-419e-9606-da9e1017f2fa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a8abe20>]}
11:57:47.770088 [info ] [Thread-1  ]: 6 of 6 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.35s]
11:57:47.770486 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
11:57:47.771450 [debug] [MainThread]: Acquiring new snowflake connection "master"
11:57:47.772048 [info ] [MainThread]: 
11:57:47.772405 [info ] [MainThread]: Finished running 2 incremental models, 4 table models in 16.87s.
11:57:47.772551 [debug] [MainThread]: Connection 'master' was properly closed.
11:57:47.772623 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
11:57:47.776911 [info ] [MainThread]: 
11:57:47.777139 [info ] [MainThread]: [32mCompleted successfully[0m
11:57:47.777309 [info ] [MainThread]: 
11:57:47.777431 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
11:57:47.777626 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cf0e520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a899670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cf03070>]}


============================== 2022-05-13 11:59:39.762097 | 90a0ec53-a580-4ed2-9c15-925b0818b325 ==============================
11:59:39.762097 [info ] [MainThread]: Running with dbt=1.0.1
11:59:39.762653 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
11:59:39.762779 [debug] [MainThread]: Tracking: tracking
11:59:39.762985 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105a431c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105a43dc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105a43c10>]}
11:59:39.806910 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
11:59:39.807214 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/my_first_dbt_model.sql
11:59:39.812736 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
11:59:39.814575 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102eaf9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059f6550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059f62e0>]}


============================== 2022-05-13 12:00:08.576998 | 9f8aed9a-d9cc-48c4-89b7-9898a7744598 ==============================
12:00:08.576998 [info ] [MainThread]: Running with dbt=1.0.1
12:00:08.577374 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
12:00:08.577516 [debug] [MainThread]: Tracking: tracking
12:00:08.577716 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1118c33a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1118c3370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1118c36d0>]}
12:00:08.619193 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
12:00:08.619492 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/my_first_dbt_model.sql
12:00:08.624380 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
12:00:08.625554 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1118ae5b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1119c4220>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1119c42b0>]}


============================== 2022-05-13 12:00:52.918224 | bcf5a11b-1ead-4170-872c-bc8fe39e6597 ==============================
12:00:52.918224 [info ] [MainThread]: Running with dbt=1.0.1
12:00:52.918561 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
12:00:52.918687 [debug] [MainThread]: Tracking: tracking
12:00:52.918927 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11137ce20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11137ca90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11137cd30>]}
12:00:52.959999 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
12:00:52.960362 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/my_first_dbt_model.sql
12:00:52.965328 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
12:00:52.966530 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1025f6940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111343490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111343550>]}


============================== 2022-05-13 12:01:35.442046 | 0802810b-e55c-4cd3-9bd9-bc83c8fdfd64 ==============================
12:01:35.442046 [info ] [MainThread]: Running with dbt=1.0.1
12:01:35.442711 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
12:01:35.442891 [debug] [MainThread]: Tracking: tracking
12:01:35.443166 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1121906a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1121905b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112190250>]}
12:01:35.484033 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
12:01:35.484385 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/my_first_dbt_model.sql
12:01:35.489877 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
12:01:35.510442 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0802810b-e55c-4cd3-9bd9-bc83c8fdfd64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1122d2430>]}
12:01:35.513614 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0802810b-e55c-4cd3-9bd9-bc83c8fdfd64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105392160>]}
12:01:35.513754 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
12:01:35.514526 [info ] [MainThread]: 
12:01:35.514749 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:01:35.515227 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
12:01:35.521218 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
12:01:35.521326 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
12:01:35.521394 [debug] [ThreadPool]: Opening a new connection, currently in state init
12:01:36.568209 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.05 seconds
12:01:36.570620 [debug] [ThreadPool]: On list_analytics: Close
12:01:36.761776 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
12:01:36.773348 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
12:01:36.773695 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
12:01:36.773869 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:01:37.815598 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1.04 seconds
12:01:37.817709 [debug] [ThreadPool]: On list_analytics_dbt: Close
12:01:38.091852 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
12:01:38.092372 [info ] [MainThread]: 
12:01:38.097742 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
12:01:38.098485 [info ] [Thread-1  ]: 1 of 6 START incremental model dbt.dates........................................ [RUN]
12:01:38.099026 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
12:01:38.099205 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
12:01:38.099394 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
12:01:38.109247 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
12:01:38.109870 [debug] [Thread-1  ]: finished collecting timing info
12:01:38.110017 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
12:01:38.138561 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:01:38.138752 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
12:01:38.138840 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:01:40.015616 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.88 seconds
12:01:40.029303 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:01:40.029666 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
12:01:40.221070 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.19 seconds
12:01:40.227041 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:01:40.227276 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
12:01:40.323556 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.1 seconds
12:01:40.336041 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:01:40.336337 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
12:01:40.435961 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.1 seconds
12:01:40.464698 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
12:01:40.466888 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:01:40.467021 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
12:01:40.619438 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.15 seconds
12:01:40.622018 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:01:40.622358 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
12:01:41.347187 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.72 seconds
12:01:41.347753 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:01:41.348050 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
12:01:41.547111 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.2 seconds
12:01:41.569738 [debug] [Thread-1  ]: finished collecting timing info
12:01:41.570215 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
12:01:41.813181 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0802810b-e55c-4cd3-9bd9-bc83c8fdfd64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110dcd3a0>]}
12:01:41.813963 [info ] [Thread-1  ]: 1 of 6 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 3.71s]
12:01:41.814421 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
12:01:41.814670 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
12:01:41.815160 [info ] [Thread-1  ]: 2 of 6 START incremental model dbt.incremental_time............................. [RUN]
12:01:41.815744 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
12:01:41.815936 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
12:01:41.816124 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
12:01:41.820116 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
12:01:41.820867 [debug] [Thread-1  ]: finished collecting timing info
12:01:41.821050 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
12:01:41.824977 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:01:41.825220 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
12:01:41.825366 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:01:45.384546 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 3.56 seconds
12:01:45.393154 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:01:45.393506 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
12:01:45.750848 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.36 seconds
12:01:45.756753 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:01:45.757086 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
12:01:45.860077 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
12:01:45.864000 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:01:45.864163 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
12:01:46.101898 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.24 seconds
12:01:46.112030 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
12:01:46.114194 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:01:46.114386 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
12:01:46.424368 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.31 seconds
12:01:46.425353 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:01:46.425805 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
12:01:47.186031 [debug] [Thread-1  ]: SQL status: SUCCESS 244 in 0.76 seconds
12:01:47.187115 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:01:47.187347 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
12:01:47.449055 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.26 seconds
12:01:47.451625 [debug] [Thread-1  ]: finished collecting timing info
12:01:47.451875 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
12:01:47.684329 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0802810b-e55c-4cd3-9bd9-bc83c8fdfd64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11680d820>]}
12:01:47.685099 [info ] [Thread-1  ]: 2 of 6 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 5.87s]
12:01:47.685556 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
12:01:47.685810 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
12:01:47.686109 [info ] [Thread-1  ]: 3 of 6 START table model dbt.first_model........................................ [RUN]
12:01:47.686815 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
12:01:47.687050 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
12:01:47.687258 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
12:01:47.690826 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
12:01:47.691448 [debug] [Thread-1  ]: finished collecting timing info
12:01:47.691623 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
12:01:47.700819 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
12:01:47.701943 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
12:01:47.702097 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
12:01:47.702221 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:01:49.342253 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.64 seconds
12:01:49.345192 [debug] [Thread-1  ]: finished collecting timing info
12:01:49.345498 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
12:01:49.525521 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0802810b-e55c-4cd3-9bd9-bc83c8fdfd64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1126e7af0>]}
12:01:49.526223 [info ] [Thread-1  ]: 3 of 6 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 1.84s]
12:01:49.526669 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
12:01:49.526923 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
12:01:49.527388 [info ] [Thread-1  ]: 4 of 6 START table model dbt.snowflake_cumulative_sales......................... [RUN]
12:01:49.528182 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
12:01:49.528411 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
12:01:49.528611 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
12:01:49.530068 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
12:01:49.530840 [debug] [Thread-1  ]: finished collecting timing info
12:01:49.531041 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
12:01:49.533892 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
12:01:49.535132 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
12:01:49.535288 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
12:01:49.535421 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:01:51.070503 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.54 seconds
12:01:51.074556 [debug] [Thread-1  ]: finished collecting timing info
12:01:51.074960 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
12:01:51.259367 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0802810b-e55c-4cd3-9bd9-bc83c8fdfd64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116850b80>]}
12:01:51.260166 [info ] [Thread-1  ]: 4 of 6 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 1.73s]
12:01:51.260836 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
12:01:51.261129 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
12:01:51.261580 [info ] [Thread-1  ]: 5 of 6 START table model dbt.snowflake_customer_purchases....................... [RUN]
12:01:51.262268 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
12:01:51.262519 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
12:01:51.262759 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
12:01:51.264707 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
12:01:51.265450 [debug] [Thread-1  ]: finished collecting timing info
12:01:51.265661 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
12:01:51.268331 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
12:01:51.269601 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
12:01:51.269766 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
12:01:51.269910 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:01:53.014116 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.74 seconds
12:01:53.016649 [debug] [Thread-1  ]: finished collecting timing info
12:01:53.016936 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
12:01:53.202040 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0802810b-e55c-4cd3-9bd9-bc83c8fdfd64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1126818e0>]}
12:01:53.202798 [info ] [Thread-1  ]: 5 of 6 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 1.94s]
12:01:53.203259 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
12:01:53.203527 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
12:01:53.203975 [info ] [Thread-1  ]: 6 of 6 START table model dbt.my_second_dbt_model................................ [RUN]
12:01:53.204637 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
12:01:53.204873 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
12:01:53.205084 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
12:01:53.208221 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
12:01:53.209094 [debug] [Thread-1  ]: finished collecting timing info
12:01:53.209289 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
12:01:53.211841 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
12:01:53.212719 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
12:01:53.212896 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
where id = 1
      );
12:01:53.213049 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:01:54.434514 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.22 seconds
12:01:54.437522 [debug] [Thread-1  ]: finished collecting timing info
12:01:54.437814 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
12:01:55.482036 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0802810b-e55c-4cd3-9bd9-bc83c8fdfd64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116859190>]}
12:01:55.482756 [info ] [Thread-1  ]: 6 of 6 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 2.28s]
12:01:55.483199 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
12:01:55.484506 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:01:55.485070 [info ] [MainThread]: 
12:01:55.485431 [info ] [MainThread]: Finished running 2 incremental models, 4 table models in 19.97s.
12:01:55.485736 [debug] [MainThread]: Connection 'master' was properly closed.
12:01:55.485900 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
12:01:55.492056 [info ] [MainThread]: 
12:01:55.492386 [info ] [MainThread]: [32mCompleted successfully[0m
12:01:55.492680 [info ] [MainThread]: 
12:01:55.492889 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
12:01:55.493175 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112355550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112558850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11685c0a0>]}


============================== 2022-05-13 12:08:25.563610 | ada402ae-839d-40c2-9280-37bfef28344f ==============================
12:08:25.563610 [info ] [MainThread]: Running with dbt=1.0.1
12:08:25.564053 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
12:08:25.564175 [debug] [MainThread]: Tracking: tracking
12:08:25.564374 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107132730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107132af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107132640>]}
12:08:25.598269 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
12:08:25.598484 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'ada402ae-839d-40c2-9280-37bfef28344f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107152c70>]}
12:08:25.606960 [debug] [MainThread]: Parsing macros/catalog.sql
12:08:25.608145 [debug] [MainThread]: Parsing macros/adapters.sql
12:08:25.627424 [debug] [MainThread]: Parsing macros/materializations/merge.sql
12:08:25.629214 [debug] [MainThread]: Parsing macros/materializations/seed.sql
12:08:25.631741 [debug] [MainThread]: Parsing macros/materializations/view.sql
12:08:25.632339 [debug] [MainThread]: Parsing macros/materializations/table.sql
12:08:25.633750 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
12:08:25.637767 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
12:08:25.638187 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
12:08:25.639906 [debug] [MainThread]: Parsing macros/materializations/configs.sql
12:08:25.640914 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
12:08:25.641658 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
12:08:25.649398 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
12:08:25.654923 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
12:08:25.660732 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
12:08:25.662828 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
12:08:25.663618 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
12:08:25.664407 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
12:08:25.666410 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
12:08:25.671781 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
12:08:25.672451 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
12:08:25.677319 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
12:08:25.684968 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
12:08:25.688601 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
12:08:25.689866 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
12:08:25.693336 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
12:08:25.693898 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
12:08:25.695102 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
12:08:25.696095 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
12:08:25.698924 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
12:08:25.706819 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
12:08:25.707467 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
12:08:25.708546 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
12:08:25.709224 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
12:08:25.709624 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
12:08:25.709856 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
12:08:25.710154 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
12:08:25.710754 [debug] [MainThread]: Parsing macros/etc/statement.sql
12:08:25.712756 [debug] [MainThread]: Parsing macros/etc/datetime.sql
12:08:25.716641 [debug] [MainThread]: Parsing macros/adapters/schema.sql
12:08:25.717576 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
12:08:25.718752 [debug] [MainThread]: Parsing macros/adapters/relation.sql
12:08:25.723235 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
12:08:25.724496 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
12:08:25.726450 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
12:08:25.729729 [debug] [MainThread]: Parsing macros/adapters/columns.sql
12:08:25.734224 [debug] [MainThread]: Parsing tests/generic/builtin.sql
12:08:25.823515 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
12:08:25.829645 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
12:08:25.830213 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_cumulative_sales.sql
12:08:25.831226 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
12:08:25.832206 [debug] [MainThread]: 1603: static parser failed on example/dates.sql
12:08:25.835498 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/dates.sql
12:08:25.835958 [debug] [MainThread]: 1603: static parser failed on example/incremental_time.sql
12:08:25.837593 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_time.sql
12:08:25.838048 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
12:08:25.863601 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.learn_dbt.example.vars

12:08:25.865970 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ada402ae-839d-40c2-9280-37bfef28344f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10724d370>]}
12:08:25.868854 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ada402ae-839d-40c2-9280-37bfef28344f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10724ddc0>]}
12:08:25.868989 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
12:08:25.869709 [info ] [MainThread]: 
12:08:25.869920 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:08:25.870334 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
12:08:25.876331 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
12:08:25.876537 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
12:08:25.876613 [debug] [ThreadPool]: Opening a new connection, currently in state init
12:08:26.708131 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.83 seconds
12:08:26.711878 [debug] [ThreadPool]: On list_analytics: Close
12:08:26.948184 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
12:08:26.957020 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
12:08:26.957238 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
12:08:26.957394 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:08:27.499888 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 0.54 seconds
12:08:27.503408 [debug] [ThreadPool]: On list_analytics_dbt: Close
12:08:27.674649 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
12:08:27.675273 [info ] [MainThread]: 
12:08:27.680194 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
12:08:27.680859 [info ] [Thread-1  ]: 1 of 6 START incremental model dbt.dates........................................ [RUN]
12:08:27.681357 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
12:08:27.681527 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
12:08:27.681686 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
12:08:27.687438 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
12:08:27.688091 [debug] [Thread-1  ]: finished collecting timing info
12:08:27.688257 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
12:08:27.718566 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:08:27.718787 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
12:08:27.718880 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:08:29.923871 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.2 seconds
12:08:29.937508 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:08:29.937843 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
12:08:30.061991 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.12 seconds
12:08:30.069077 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:08:30.069450 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
12:08:30.196914 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.13 seconds
12:08:30.210213 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:08:30.210578 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
12:08:30.328122 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.12 seconds
12:08:30.354577 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
12:08:30.357101 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:08:30.357231 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
12:08:30.511335 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.15 seconds
12:08:30.512206 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:08:30.512418 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
12:08:31.461368 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.95 seconds
12:08:31.462032 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:08:31.462303 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
12:08:31.657982 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.2 seconds
12:08:31.671112 [debug] [Thread-1  ]: finished collecting timing info
12:08:31.671650 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
12:08:31.851048 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ada402ae-839d-40c2-9280-37bfef28344f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107250f10>]}
12:08:31.851765 [info ] [Thread-1  ]: 1 of 6 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 4.17s]
12:08:31.852232 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
12:08:31.852515 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
12:08:31.852890 [info ] [Thread-1  ]: 2 of 6 START incremental model dbt.incremental_time............................. [RUN]
12:08:31.854082 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
12:08:31.854366 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
12:08:31.854581 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
12:08:31.858696 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
12:08:31.859362 [debug] [Thread-1  ]: finished collecting timing info
12:08:31.859536 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
12:08:31.863119 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:08:31.863303 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
12:08:31.863448 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:08:33.508187 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.64 seconds
12:08:33.513463 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:08:33.513799 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
12:08:33.623191 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.11 seconds
12:08:33.628249 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:08:33.628509 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
12:08:33.751011 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.12 seconds
12:08:33.756746 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:08:33.756912 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
12:08:33.861606 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
12:08:33.866759 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
12:08:33.869002 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:08:33.869186 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
12:08:34.063600 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.19 seconds
12:08:34.064519 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:08:34.064709 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
12:08:34.842089 [debug] [Thread-1  ]: SQL status: SUCCESS 410 in 0.78 seconds
12:08:34.842747 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:08:34.842962 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
12:08:35.350893 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.51 seconds
12:08:35.354663 [debug] [Thread-1  ]: finished collecting timing info
12:08:35.355076 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
12:08:35.561981 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ada402ae-839d-40c2-9280-37bfef28344f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1096d6d90>]}
12:08:35.562623 [info ] [Thread-1  ]: 2 of 6 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 3.71s]
12:08:35.563074 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
12:08:35.563326 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
12:08:35.563732 [info ] [Thread-1  ]: 3 of 6 START table model dbt.first_model........................................ [RUN]
12:08:35.564381 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
12:08:35.564604 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
12:08:35.564824 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
12:08:35.569775 [debug] [Thread-1  ]: finished collecting timing info
12:08:35.570173 [debug] [Thread-1  ]: Compilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  Required var 'my_first_variable' not found in config:
  Vars supplied to my_first_dbt_model = {}
  
  > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
12:08:35.570455 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ada402ae-839d-40c2-9280-37bfef28344f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1096b6610>]}
12:08:35.570771 [error] [Thread-1  ]: 3 of 6 ERROR creating table model dbt.first_model............................... [[31mERROR[0m in 0.01s]
12:08:35.571086 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
12:08:35.571282 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
12:08:35.571724 [info ] [Thread-1  ]: 4 of 6 START table model dbt.snowflake_cumulative_sales......................... [RUN]
12:08:35.572176 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
12:08:35.572335 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
12:08:35.572490 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
12:08:35.573676 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
12:08:35.574445 [debug] [Thread-1  ]: finished collecting timing info
12:08:35.574609 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
12:08:35.582893 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
12:08:35.583873 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
12:08:35.584008 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
12:08:35.584121 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:08:36.991739 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.41 seconds
12:08:36.995269 [debug] [Thread-1  ]: finished collecting timing info
12:08:36.995694 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
12:08:37.198950 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ada402ae-839d-40c2-9280-37bfef28344f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1096da220>]}
12:08:37.199661 [info ] [Thread-1  ]: 4 of 6 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 1.63s]
12:08:37.200105 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
12:08:37.200357 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
12:08:37.200762 [info ] [Thread-1  ]: 5 of 6 START table model dbt.snowflake_customer_purchases....................... [RUN]
12:08:37.201453 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
12:08:37.201673 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
12:08:37.201880 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
12:08:37.203955 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
12:08:37.204781 [debug] [Thread-1  ]: finished collecting timing info
12:08:37.204990 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
12:08:37.207819 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
12:08:37.209324 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
12:08:37.209517 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
12:08:37.209680 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:08:39.345102 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.14 seconds
12:08:39.348709 [debug] [Thread-1  ]: finished collecting timing info
12:08:39.349140 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
12:08:39.547748 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ada402ae-839d-40c2-9280-37bfef28344f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10762b400>]}
12:08:39.548454 [info ] [Thread-1  ]: 5 of 6 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.35s]
12:08:39.548902 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
12:08:39.549147 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
12:08:39.549487 [info ] [Thread-1  ]: 6 of 6 SKIP relation dbt.my_second_dbt_model.................................... [[33mSKIP[0m]
12:08:39.549970 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
12:08:39.551238 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:08:39.551728 [info ] [MainThread]: 
12:08:39.552062 [info ] [MainThread]: Finished running 2 incremental models, 4 table models in 13.68s.
12:08:39.552355 [debug] [MainThread]: Connection 'master' was properly closed.
12:08:39.552517 [debug] [MainThread]: Connection 'model.learn_dbt.snowflake_customer_purchases' was properly closed.
12:08:39.558834 [info ] [MainThread]: 
12:08:39.559099 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
12:08:39.559329 [info ] [MainThread]: 
12:08:39.559521 [error] [MainThread]: [33mCompilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)[0m
12:08:39.559713 [error] [MainThread]:   Required var 'my_first_variable' not found in config:
12:08:39.560165 [error] [MainThread]:   Vars supplied to my_first_dbt_model = {}
12:08:39.560381 [error] [MainThread]:   
12:08:39.560570 [error] [MainThread]:   > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
12:08:39.560754 [error] [MainThread]:   > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
12:08:39.561052 [info ] [MainThread]: 
12:08:39.561254 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=1 TOTAL=6
12:08:39.561536 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10762b400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10764dcd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1096b0eb0>]}


============================== 2022-05-13 12:09:39.024472 | 3b51c2fd-a781-47ee-acd6-95f4a57ebd50 ==============================
12:09:39.024472 [info ] [MainThread]: Running with dbt=1.0.1
12:09:39.024867 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
12:09:39.024994 [debug] [MainThread]: Tracking: tracking
12:09:39.025215 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109c82250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109c82ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109c82910>]}
12:09:39.058832 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
12:09:39.059054 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '3b51c2fd-a781-47ee-acd6-95f4a57ebd50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1091c6340>]}
12:09:39.067971 [debug] [MainThread]: Parsing macros/catalog.sql
12:09:39.069203 [debug] [MainThread]: Parsing macros/adapters.sql
12:09:39.088341 [debug] [MainThread]: Parsing macros/materializations/merge.sql
12:09:39.090136 [debug] [MainThread]: Parsing macros/materializations/seed.sql
12:09:39.092623 [debug] [MainThread]: Parsing macros/materializations/view.sql
12:09:39.093207 [debug] [MainThread]: Parsing macros/materializations/table.sql
12:09:39.094622 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
12:09:39.098591 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
12:09:39.099002 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
12:09:39.100711 [debug] [MainThread]: Parsing macros/materializations/configs.sql
12:09:39.101715 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
12:09:39.102457 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
12:09:39.110212 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
12:09:39.115708 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
12:09:39.121537 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
12:09:39.123627 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
12:09:39.124414 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
12:09:39.125213 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
12:09:39.127195 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
12:09:39.132532 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
12:09:39.133215 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
12:09:39.138132 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
12:09:39.145789 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
12:09:39.149445 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
12:09:39.150703 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
12:09:39.154211 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
12:09:39.154773 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
12:09:39.155983 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
12:09:39.156982 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
12:09:39.159784 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
12:09:39.167675 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
12:09:39.168325 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
12:09:39.169413 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
12:09:39.170110 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
12:09:39.170518 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
12:09:39.170747 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
12:09:39.171040 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
12:09:39.171649 [debug] [MainThread]: Parsing macros/etc/statement.sql
12:09:39.173650 [debug] [MainThread]: Parsing macros/etc/datetime.sql
12:09:39.177552 [debug] [MainThread]: Parsing macros/adapters/schema.sql
12:09:39.178487 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
12:09:39.179659 [debug] [MainThread]: Parsing macros/adapters/relation.sql
12:09:39.184136 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
12:09:39.185418 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
12:09:39.187388 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
12:09:39.190665 [debug] [MainThread]: Parsing macros/adapters/columns.sql
12:09:39.195192 [debug] [MainThread]: Parsing tests/generic/builtin.sql
12:09:39.285677 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
12:09:39.291807 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
12:09:39.292346 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_cumulative_sales.sql
12:09:39.293420 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
12:09:39.294405 [debug] [MainThread]: 1603: static parser failed on example/dates.sql
12:09:39.298226 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/dates.sql
12:09:39.298841 [debug] [MainThread]: 1603: static parser failed on example/incremental_time.sql
12:09:39.300670 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_time.sql
12:09:39.301136 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
12:09:39.327205 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.learn_dbt.example.vars

12:09:39.329601 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3b51c2fd-a781-47ee-acd6-95f4a57ebd50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109dbefa0>]}
12:09:39.332490 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3b51c2fd-a781-47ee-acd6-95f4a57ebd50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109dbe700>]}
12:09:39.332623 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
12:09:39.333346 [info ] [MainThread]: 
12:09:39.333559 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:09:39.334000 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
12:09:39.339776 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
12:09:39.339876 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
12:09:39.339941 [debug] [ThreadPool]: Opening a new connection, currently in state init
12:09:40.116369 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.78 seconds
12:09:40.118138 [debug] [ThreadPool]: On list_analytics: Close
12:09:40.279009 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
12:09:40.282473 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
12:09:40.282582 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
12:09:40.282648 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:09:40.783459 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 0.5 seconds
12:09:40.786103 [debug] [ThreadPool]: On list_analytics_dbt: Close
12:09:40.955408 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
12:09:40.956097 [info ] [MainThread]: 
12:09:40.960069 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
12:09:40.960597 [info ] [Thread-1  ]: 1 of 6 START incremental model dbt.dates........................................ [RUN]
12:09:40.960981 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
12:09:40.961119 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
12:09:40.961236 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
12:09:40.967130 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
12:09:40.967731 [debug] [Thread-1  ]: finished collecting timing info
12:09:40.967884 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
12:09:40.998416 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:09:40.998588 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
12:09:40.998676 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:09:42.806960 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.81 seconds
12:09:42.816707 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:09:42.816899 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
12:09:42.946564 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.13 seconds
12:09:42.952264 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:09:42.952466 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
12:09:43.066225 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.11 seconds
12:09:43.081238 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:09:43.081575 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
12:09:43.181693 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.1 seconds
12:09:43.208689 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
12:09:43.211058 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:09:43.211185 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
12:09:43.331036 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.12 seconds
12:09:43.331899 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:09:43.332140 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
12:09:43.683783 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.35 seconds
12:09:43.684304 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:09:43.684495 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
12:09:43.882110 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.2 seconds
12:09:43.896641 [debug] [Thread-1  ]: finished collecting timing info
12:09:43.896969 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
12:09:44.080702 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3b51c2fd-a781-47ee-acd6-95f4a57ebd50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109d18b50>]}
12:09:44.081405 [info ] [Thread-1  ]: 1 of 6 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 3.12s]
12:09:44.081841 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
12:09:44.082084 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
12:09:44.082482 [info ] [Thread-1  ]: 2 of 6 START incremental model dbt.incremental_time............................. [RUN]
12:09:44.083139 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
12:09:44.083350 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
12:09:44.083552 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
12:09:44.087564 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
12:09:44.088355 [debug] [Thread-1  ]: finished collecting timing info
12:09:44.088535 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
12:09:44.092262 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:09:44.092447 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
12:09:44.092578 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:09:45.762770 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.67 seconds
12:09:45.767209 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:09:45.767469 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
12:09:46.140424 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.37 seconds
12:09:46.148777 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:09:46.149147 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
12:09:46.262872 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.11 seconds
12:09:46.268483 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:09:46.268761 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
12:09:46.389145 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.12 seconds
12:09:46.394293 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
12:09:46.396812 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:09:46.397007 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
12:09:46.532433 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.14 seconds
12:09:46.533354 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:09:46.533585 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
12:09:47.545880 [debug] [Thread-1  ]: SQL status: SUCCESS 72 in 1.01 seconds
12:09:47.547386 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:09:47.547655 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
12:09:47.851990 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.3 seconds
12:09:47.855200 [debug] [Thread-1  ]: finished collecting timing info
12:09:47.855543 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
12:09:48.045822 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3b51c2fd-a781-47ee-acd6-95f4a57ebd50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a283ca0>]}
12:09:48.046802 [info ] [Thread-1  ]: 2 of 6 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 3.96s]
12:09:48.047321 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
12:09:48.047571 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
12:09:48.047981 [info ] [Thread-1  ]: 3 of 6 START table model dbt.first_model........................................ [RUN]
12:09:48.048644 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
12:09:48.048849 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
12:09:48.049040 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
12:09:48.056594 [debug] [Thread-1  ]: finished collecting timing info
12:09:48.057038 [debug] [Thread-1  ]: Compilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  Required var 'my_first_variable' not found in config:
  Vars supplied to my_first_dbt_model = {}
  
  > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
12:09:48.057374 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3b51c2fd-a781-47ee-acd6-95f4a57ebd50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a63f190>]}
12:09:48.057740 [error] [Thread-1  ]: 3 of 6 ERROR creating table model dbt.first_model............................... [[31mERROR[0m in 0.01s]
12:09:48.058088 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
12:09:48.058247 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
12:09:48.058604 [info ] [Thread-1  ]: 4 of 6 START table model dbt.snowflake_cumulative_sales......................... [RUN]
12:09:48.059056 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
12:09:48.059201 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
12:09:48.059344 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
12:09:48.060567 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
12:09:48.061215 [debug] [Thread-1  ]: finished collecting timing info
12:09:48.061367 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
12:09:48.069329 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
12:09:48.070261 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
12:09:48.070392 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
12:09:48.070501 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:09:49.316238 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.25 seconds
12:09:49.321483 [debug] [Thread-1  ]: finished collecting timing info
12:09:49.321891 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
12:09:49.528589 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3b51c2fd-a781-47ee-acd6-95f4a57ebd50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a283f70>]}
12:09:49.529709 [info ] [Thread-1  ]: 4 of 6 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 1.47s]
12:09:49.530322 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
12:09:49.530598 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
12:09:49.531021 [info ] [Thread-1  ]: 5 of 6 START table model dbt.snowflake_customer_purchases....................... [RUN]
12:09:49.531706 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
12:09:49.532129 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
12:09:49.532394 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
12:09:49.534282 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
12:09:49.534987 [debug] [Thread-1  ]: finished collecting timing info
12:09:49.535192 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
12:09:49.537789 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
12:09:49.538873 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
12:09:49.539043 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
12:09:49.539188 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:09:51.128325 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.59 seconds
12:09:51.131724 [debug] [Thread-1  ]: finished collecting timing info
12:09:51.132112 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
12:09:51.323260 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3b51c2fd-a781-47ee-acd6-95f4a57ebd50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a283370>]}
12:09:51.323615 [info ] [Thread-1  ]: 5 of 6 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 1.79s]
12:09:51.323821 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
12:09:51.323937 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
12:09:51.324094 [info ] [Thread-1  ]: 6 of 6 SKIP relation dbt.my_second_dbt_model.................................... [[33mSKIP[0m]
12:09:51.324304 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
12:09:51.324998 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:09:51.325284 [info ] [MainThread]: 
12:09:51.325444 [info ] [MainThread]: Finished running 2 incremental models, 4 table models in 11.99s.
12:09:51.325581 [debug] [MainThread]: Connection 'master' was properly closed.
12:09:51.325656 [debug] [MainThread]: Connection 'model.learn_dbt.snowflake_customer_purchases' was properly closed.
12:09:51.330620 [info ] [MainThread]: 
12:09:51.331063 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
12:09:51.331274 [info ] [MainThread]: 
12:09:51.331433 [error] [MainThread]: [33mCompilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)[0m
12:09:51.331594 [error] [MainThread]:   Required var 'my_first_variable' not found in config:
12:09:51.331737 [error] [MainThread]:   Vars supplied to my_first_dbt_model = {}
12:09:51.331876 [error] [MainThread]:   
12:09:51.332015 [error] [MainThread]:   > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
12:09:51.332151 [error] [MainThread]:   > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
12:09:51.332300 [info ] [MainThread]: 
12:09:51.332443 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=1 TOTAL=6
12:09:51.332660 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109c5a7c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109dbe6a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a28d700>]}


============================== 2022-05-13 12:11:30.620026 | c1a196fc-9ba5-4a5d-aeff-a41b37a15527 ==============================
12:11:30.620026 [info ] [MainThread]: Running with dbt=1.0.1
12:11:30.620603 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
12:11:30.620730 [debug] [MainThread]: Tracking: tracking
12:11:30.620965 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11193d850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11193d760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11193d400>]}
12:11:30.673494 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
12:11:30.673798 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/my_first_dbt_model.sql
12:11:30.679268 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
12:11:30.686326 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
12:11:30.697893 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.learn_dbt.example.vars

12:11:30.700297 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c1a196fc-9ba5-4a5d-aeff-a41b37a15527', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111934c70>]}
12:11:30.703174 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c1a196fc-9ba5-4a5d-aeff-a41b37a15527', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c90760>]}
12:11:30.703307 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
12:11:30.704064 [info ] [MainThread]: 
12:11:30.704273 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:11:30.704710 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
12:11:30.710565 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
12:11:30.710683 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
12:11:30.710750 [debug] [ThreadPool]: Opening a new connection, currently in state init
12:11:31.503427 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.79 seconds
12:11:31.504698 [debug] [ThreadPool]: On list_analytics: Close
12:11:31.678195 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
12:11:31.686688 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
12:11:31.686949 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
12:11:31.687106 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:11:32.411804 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 0.72 seconds
12:11:32.414174 [debug] [ThreadPool]: On list_analytics_dbt: Close
12:11:32.592504 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
12:11:32.593183 [info ] [MainThread]: 
12:11:32.598528 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
12:11:32.599352 [info ] [Thread-1  ]: 1 of 6 START incremental model dbt.dates........................................ [RUN]
12:11:32.599868 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
12:11:32.600041 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
12:11:32.600198 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
12:11:32.609497 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
12:11:32.610164 [debug] [Thread-1  ]: finished collecting timing info
12:11:32.610304 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
12:11:32.639605 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:11:32.639840 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
12:11:32.639932 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:11:34.348024 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.71 seconds
12:11:34.362017 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:11:34.362410 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
12:11:34.477054 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.11 seconds
12:11:34.483858 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:11:34.484163 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
12:11:34.602125 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.12 seconds
12:11:34.614274 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:11:34.614545 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
12:11:34.737402 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.12 seconds
12:11:34.768721 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
12:11:34.771316 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:11:34.771455 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
12:11:34.921900 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.15 seconds
12:11:34.922546 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:11:34.922737 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
12:11:35.269429 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.35 seconds
12:11:35.269979 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:11:35.270330 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
12:11:35.467496 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.2 seconds
12:11:35.481745 [debug] [Thread-1  ]: finished collecting timing info
12:11:35.482185 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
12:11:35.653942 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c1a196fc-9ba5-4a5d-aeff-a41b37a15527', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111902490>]}
12:11:35.654647 [info ] [Thread-1  ]: 1 of 6 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 3.05s]
12:11:35.655077 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
12:11:35.655332 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
12:11:35.655729 [info ] [Thread-1  ]: 2 of 6 START incremental model dbt.incremental_time............................. [RUN]
12:11:35.656393 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
12:11:35.656623 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
12:11:35.656797 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
12:11:35.660575 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
12:11:35.661270 [debug] [Thread-1  ]: finished collecting timing info
12:11:35.661446 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
12:11:35.664727 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:11:35.664908 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
12:11:35.665035 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:11:37.316610 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.65 seconds
12:11:37.321152 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:11:37.321437 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
12:11:37.451529 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.13 seconds
12:11:37.455701 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:11:37.455949 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
12:11:37.564244 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.11 seconds
12:11:37.570441 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:11:37.570717 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
12:11:37.670259 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
12:11:37.673004 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
12:11:37.673881 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:11:37.673963 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
12:11:37.809522 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.14 seconds
12:11:37.809970 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:11:37.810134 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
12:11:38.545657 [debug] [Thread-1  ]: SQL status: SUCCESS 112 in 0.74 seconds
12:11:38.546980 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:11:38.547383 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
12:11:38.791091 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.24 seconds
12:11:38.794464 [debug] [Thread-1  ]: finished collecting timing info
12:11:38.794679 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
12:11:38.963777 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c1a196fc-9ba5-4a5d-aeff-a41b37a15527', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11220acd0>]}
12:11:38.965028 [info ] [Thread-1  ]: 2 of 6 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 3.31s]
12:11:38.965575 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
12:11:38.966074 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
12:11:38.966452 [info ] [Thread-1  ]: 3 of 6 START table model dbt.first_model........................................ [RUN]
12:11:38.967203 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
12:11:38.967403 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
12:11:38.967583 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
12:11:38.973957 [debug] [Thread-1  ]: finished collecting timing info
12:11:38.974368 [debug] [Thread-1  ]: Compilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  Required var 'my_first_variable' not found in config:
  Vars supplied to my_first_dbt_model = {}
  
  > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
12:11:38.974665 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c1a196fc-9ba5-4a5d-aeff-a41b37a15527', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111edb310>]}
12:11:38.975011 [error] [Thread-1  ]: 3 of 6 ERROR creating table model dbt.first_model............................... [[31mERROR[0m in 0.01s]
12:11:38.975344 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
12:11:38.975526 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
12:11:38.975742 [info ] [Thread-1  ]: 4 of 6 START table model dbt.snowflake_cumulative_sales......................... [RUN]
12:11:38.976166 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
12:11:38.976524 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
12:11:38.977048 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
12:11:38.978377 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
12:11:38.978952 [debug] [Thread-1  ]: finished collecting timing info
12:11:38.979111 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
12:11:38.987416 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
12:11:38.988436 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
12:11:38.988572 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
12:11:38.988688 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:11:40.698379 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.71 seconds
12:11:40.701267 [debug] [Thread-1  ]: finished collecting timing info
12:11:40.701688 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
12:11:40.889778 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c1a196fc-9ba5-4a5d-aeff-a41b37a15527', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111eabb80>]}
12:11:40.890578 [info ] [Thread-1  ]: 4 of 6 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 1.91s]
12:11:40.891041 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
12:11:40.891302 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
12:11:40.891707 [info ] [Thread-1  ]: 5 of 6 START table model dbt.snowflake_customer_purchases....................... [RUN]
12:11:40.892373 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
12:11:40.892586 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
12:11:40.892785 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
12:11:40.894559 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
12:11:40.895405 [debug] [Thread-1  ]: finished collecting timing info
12:11:40.895599 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
12:11:40.898396 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
12:11:40.899833 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
12:11:40.900016 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
12:11:40.900169 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:11:42.436923 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.54 seconds
12:11:42.439673 [debug] [Thread-1  ]: finished collecting timing info
12:11:42.440069 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
12:11:42.600277 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c1a196fc-9ba5-4a5d-aeff-a41b37a15527', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111d45400>]}
12:11:42.601012 [info ] [Thread-1  ]: 5 of 6 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 1.71s]
12:11:42.601461 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
12:11:42.601709 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
12:11:42.602037 [info ] [Thread-1  ]: 6 of 6 SKIP relation dbt.my_second_dbt_model.................................... [[33mSKIP[0m]
12:11:42.602509 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
12:11:42.603820 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:11:42.604310 [info ] [MainThread]: 
12:11:42.604644 [info ] [MainThread]: Finished running 2 incremental models, 4 table models in 11.90s.
12:11:42.604934 [debug] [MainThread]: Connection 'master' was properly closed.
12:11:42.605095 [debug] [MainThread]: Connection 'model.learn_dbt.snowflake_customer_purchases' was properly closed.
12:11:42.611635 [info ] [MainThread]: 
12:11:42.611940 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
12:11:42.612194 [info ] [MainThread]: 
12:11:42.612386 [error] [MainThread]: [33mCompilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)[0m
12:11:42.612581 [error] [MainThread]:   Required var 'my_first_variable' not found in config:
12:11:42.612995 [error] [MainThread]:   Vars supplied to my_first_dbt_model = {}
12:11:42.613225 [error] [MainThread]:   
12:11:42.613479 [error] [MainThread]:   > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
12:11:42.613693 [error] [MainThread]:   > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
12:11:42.613889 [info ] [MainThread]: 
12:11:42.614074 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=1 TOTAL=6
12:11:42.614346 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110b281c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c90670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111e7a670>]}


============================== 2022-05-13 12:15:56.358089 | 16c5c4bd-0652-4541-83d5-5f31db294bfe ==============================
12:15:56.358089 [info ] [MainThread]: Running with dbt=1.0.1
12:15:56.358683 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
12:15:56.358803 [debug] [MainThread]: Tracking: tracking
12:15:56.359014 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c832b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c83eb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c83910>]}
12:15:56.392783 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
12:15:56.393012 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '16c5c4bd-0652-4541-83d5-5f31db294bfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1042baaf0>]}
12:15:56.405466 [debug] [MainThread]: Parsing macros/catalog.sql
12:15:56.406710 [debug] [MainThread]: Parsing macros/adapters.sql
12:15:56.425932 [debug] [MainThread]: Parsing macros/materializations/merge.sql
12:15:56.427691 [debug] [MainThread]: Parsing macros/materializations/seed.sql
12:15:56.430165 [debug] [MainThread]: Parsing macros/materializations/view.sql
12:15:56.430759 [debug] [MainThread]: Parsing macros/materializations/table.sql
12:15:56.432158 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
12:15:56.436115 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
12:15:56.436526 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
12:15:56.438224 [debug] [MainThread]: Parsing macros/materializations/configs.sql
12:15:56.439228 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
12:15:56.439970 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
12:15:56.447633 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
12:15:56.453102 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
12:15:56.458860 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
12:15:56.460917 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
12:15:56.461697 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
12:15:56.462485 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
12:15:56.464457 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
12:15:56.469810 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
12:15:56.470480 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
12:15:56.475302 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
12:15:56.482913 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
12:15:56.486540 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
12:15:56.487792 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
12:15:56.491245 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
12:15:56.491804 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
12:15:56.493009 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
12:15:56.493999 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
12:15:56.496763 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
12:15:56.504596 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
12:15:56.505245 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
12:15:56.506326 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
12:15:56.507002 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
12:15:56.507395 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
12:15:56.507627 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
12:15:56.507924 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
12:15:56.508516 [debug] [MainThread]: Parsing macros/etc/statement.sql
12:15:56.510501 [debug] [MainThread]: Parsing macros/etc/datetime.sql
12:15:56.514374 [debug] [MainThread]: Parsing macros/adapters/schema.sql
12:15:56.515297 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
12:15:56.516465 [debug] [MainThread]: Parsing macros/adapters/relation.sql
12:15:56.520896 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
12:15:56.522157 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
12:15:56.524130 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
12:15:56.527495 [debug] [MainThread]: Parsing macros/adapters/columns.sql
12:15:56.532106 [debug] [MainThread]: Parsing tests/generic/builtin.sql
12:15:56.621284 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
12:15:56.627708 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
12:15:56.628234 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_cumulative_sales.sql
12:15:56.629311 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
12:15:56.630308 [debug] [MainThread]: 1603: static parser failed on example/dates.sql
12:15:56.633725 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/dates.sql
12:15:56.634223 [debug] [MainThread]: 1603: static parser failed on example/incremental_time.sql
12:15:56.635850 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_time.sql
12:15:56.636283 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
12:15:56.664397 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '16c5c4bd-0652-4541-83d5-5f31db294bfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104dd0fa0>]}
12:15:56.667595 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '16c5c4bd-0652-4541-83d5-5f31db294bfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104dd00a0>]}
12:15:56.667735 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
12:15:56.668485 [info ] [MainThread]: 
12:15:56.668701 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:15:56.669139 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
12:15:56.674935 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
12:15:56.675032 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
12:15:56.675103 [debug] [ThreadPool]: Opening a new connection, currently in state init
12:15:57.502913 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.83 seconds
12:15:57.505111 [debug] [ThreadPool]: On list_analytics: Close
12:15:57.686009 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
12:15:57.694779 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
12:15:57.695120 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
12:15:57.695291 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:15:58.396457 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 0.7 seconds
12:15:58.400535 [debug] [ThreadPool]: On list_analytics_dbt: Close
12:15:58.586091 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
12:15:58.586618 [info ] [MainThread]: 
12:15:58.590594 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
12:15:58.591528 [info ] [Thread-1  ]: 1 of 6 START incremental model dbt.dates........................................ [RUN]
12:15:58.592094 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
12:15:58.592268 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
12:15:58.592448 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
12:15:58.597414 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
12:15:58.598569 [debug] [Thread-1  ]: finished collecting timing info
12:15:58.598796 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
12:15:58.630008 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:15:58.630258 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
12:15:58.630348 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:16:00.306216 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.68 seconds
12:16:00.324565 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:16:00.324979 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
12:16:00.447284 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.12 seconds
12:16:00.454662 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:16:00.455036 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
12:16:00.558499 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.1 seconds
12:16:00.573254 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:16:00.573549 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
12:16:00.684375 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.11 seconds
12:16:00.710819 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
12:16:00.713192 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:16:00.713319 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
12:16:00.879716 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.17 seconds
12:16:00.881007 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:16:00.881221 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
12:16:01.303081 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.42 seconds
12:16:01.303636 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:16:01.303849 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
12:16:01.471085 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.17 seconds
12:16:01.485319 [debug] [Thread-1  ]: finished collecting timing info
12:16:01.485629 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
12:16:01.667130 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '16c5c4bd-0652-4541-83d5-5f31db294bfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053bf070>]}
12:16:01.667759 [info ] [Thread-1  ]: 1 of 6 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 3.08s]
12:16:01.668126 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
12:16:01.668329 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
12:16:01.668681 [info ] [Thread-1  ]: 2 of 6 START incremental model dbt.incremental_time............................. [RUN]
12:16:01.669204 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
12:16:01.669375 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
12:16:01.669535 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
12:16:01.673158 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
12:16:01.675219 [debug] [Thread-1  ]: finished collecting timing info
12:16:01.675462 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
12:16:01.679317 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:16:01.679524 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
12:16:01.679655 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:16:03.351311 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.67 seconds
12:16:03.354264 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:16:03.354456 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
12:16:03.477259 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.12 seconds
12:16:03.482964 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:16:03.483335 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
12:16:03.612647 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.13 seconds
12:16:03.617107 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:16:03.617329 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
12:16:03.760417 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.14 seconds
12:16:03.766029 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
12:16:03.768454 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:16:03.768665 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
12:16:03.912453 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.14 seconds
12:16:03.913332 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:16:03.913578 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
12:16:05.111777 [debug] [Thread-1  ]: SQL status: SUCCESS 266 in 1.2 seconds
12:16:05.112820 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:16:05.113015 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
12:16:05.500082 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.39 seconds
12:16:05.503916 [debug] [Thread-1  ]: finished collecting timing info
12:16:05.504374 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
12:16:05.700967 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '16c5c4bd-0652-4541-83d5-5f31db294bfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105193220>]}
12:16:05.701448 [info ] [Thread-1  ]: 2 of 6 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 4.03s]
12:16:05.701708 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
12:16:05.701843 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
12:16:05.702073 [info ] [Thread-1  ]: 3 of 6 START table model dbt.first_model........................................ [RUN]
12:16:05.702639 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
12:16:05.702848 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
12:16:05.703048 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
12:16:05.708941 [debug] [Thread-1  ]: finished collecting timing info
12:16:05.709235 [debug] [Thread-1  ]: Compilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  Required var 'my_first_variable' not found in config:
  Vars supplied to my_first_dbt_model = {}
  
  > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
12:16:05.709445 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '16c5c4bd-0652-4541-83d5-5f31db294bfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107376d30>]}
12:16:05.709685 [error] [Thread-1  ]: 3 of 6 ERROR creating table model dbt.first_model............................... [[31mERROR[0m in 0.01s]
12:16:05.709923 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
12:16:05.710061 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
12:16:05.710745 [info ] [Thread-1  ]: 4 of 6 START table model dbt.snowflake_cumulative_sales......................... [RUN]
12:16:05.711311 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
12:16:05.711484 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
12:16:05.711645 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
12:16:05.712943 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
12:16:05.713803 [debug] [Thread-1  ]: finished collecting timing info
12:16:05.714021 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
12:16:05.722010 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
12:16:05.722814 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
12:16:05.722942 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
12:16:05.723051 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:16:07.244378 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.52 seconds
12:16:07.247306 [debug] [Thread-1  ]: finished collecting timing info
12:16:07.247715 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
12:16:07.420396 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '16c5c4bd-0652-4541-83d5-5f31db294bfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1073769a0>]}
12:16:07.421166 [info ] [Thread-1  ]: 4 of 6 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 1.71s]
12:16:07.421725 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
12:16:07.421982 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
12:16:07.422449 [info ] [Thread-1  ]: 5 of 6 START table model dbt.snowflake_customer_purchases....................... [RUN]
12:16:07.423243 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
12:16:07.423595 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
12:16:07.423832 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
12:16:07.425690 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
12:16:07.426355 [debug] [Thread-1  ]: finished collecting timing info
12:16:07.426549 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
12:16:07.429159 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
12:16:07.430236 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
12:16:07.430396 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
12:16:07.430536 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:16:09.187272 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.76 seconds
12:16:09.196664 [debug] [Thread-1  ]: finished collecting timing info
12:16:09.197418 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
12:16:09.365535 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '16c5c4bd-0652-4541-83d5-5f31db294bfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10537eeb0>]}
12:16:09.366309 [info ] [Thread-1  ]: 5 of 6 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 1.94s]
12:16:09.366960 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
12:16:09.367348 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
12:16:09.367699 [info ] [Thread-1  ]: 6 of 6 SKIP relation dbt.my_second_dbt_model.................................... [[33mSKIP[0m]
12:16:09.368081 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
12:16:09.369345 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:16:09.369923 [info ] [MainThread]: 
12:16:09.370305 [info ] [MainThread]: Finished running 2 incremental models, 4 table models in 12.70s.
12:16:09.370606 [debug] [MainThread]: Connection 'master' was properly closed.
12:16:09.370780 [debug] [MainThread]: Connection 'model.learn_dbt.snowflake_customer_purchases' was properly closed.
12:16:09.377887 [info ] [MainThread]: 
12:16:09.378343 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
12:16:09.378753 [info ] [MainThread]: 
12:16:09.378981 [error] [MainThread]: [33mCompilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)[0m
12:16:09.379179 [error] [MainThread]:   Required var 'my_first_variable' not found in config:
12:16:09.379361 [error] [MainThread]:   Vars supplied to my_first_dbt_model = {}
12:16:09.379536 [error] [MainThread]:   
12:16:09.379709 [error] [MainThread]:   > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
12:16:09.379881 [error] [MainThread]:   > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
12:16:09.380071 [info ] [MainThread]: 
12:16:09.380253 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=1 TOTAL=6
12:16:09.380514 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10736e1f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1051955b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105193250>]}


============================== 2022-05-13 12:21:30.587276 | 9813d93a-c4ba-4b05-907f-e2a6574694bd ==============================
12:21:30.587276 [info ] [MainThread]: Running with dbt=1.0.1
12:21:30.587646 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
12:21:30.587771 [debug] [MainThread]: Tracking: tracking
12:21:30.588013 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1071907f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107190ca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107190d00>]}
12:21:30.622866 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
12:21:30.623092 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '9813d93a-c4ba-4b05-907f-e2a6574694bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10671c7f0>]}
12:21:30.634629 [debug] [MainThread]: Parsing macros/catalog.sql
12:21:30.635900 [debug] [MainThread]: Parsing macros/adapters.sql
12:21:30.656497 [debug] [MainThread]: Parsing macros/materializations/merge.sql
12:21:30.658424 [debug] [MainThread]: Parsing macros/materializations/seed.sql
12:21:30.661049 [debug] [MainThread]: Parsing macros/materializations/view.sql
12:21:30.661672 [debug] [MainThread]: Parsing macros/materializations/table.sql
12:21:30.663131 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
12:21:30.667221 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
12:21:30.667652 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
12:21:30.669414 [debug] [MainThread]: Parsing macros/materializations/configs.sql
12:21:30.670456 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
12:21:30.671221 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
12:21:30.679938 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
12:21:30.686013 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
12:21:30.692561 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
12:21:30.694985 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
12:21:30.695924 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
12:21:30.696750 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
12:21:30.698888 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
12:21:30.704546 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
12:21:30.705259 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
12:21:30.710600 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
12:21:30.718616 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
12:21:30.722439 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
12:21:30.723767 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
12:21:30.727371 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
12:21:30.727976 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
12:21:30.729234 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
12:21:30.730299 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
12:21:30.733211 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
12:21:30.741632 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
12:21:30.742387 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
12:21:30.743543 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
12:21:30.744258 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
12:21:30.744667 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
12:21:30.744905 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
12:21:30.745215 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
12:21:30.745834 [debug] [MainThread]: Parsing macros/etc/statement.sql
12:21:30.747905 [debug] [MainThread]: Parsing macros/etc/datetime.sql
12:21:30.752026 [debug] [MainThread]: Parsing macros/adapters/schema.sql
12:21:30.753036 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
12:21:30.754243 [debug] [MainThread]: Parsing macros/adapters/relation.sql
12:21:30.759107 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
12:21:30.760702 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
12:21:30.762783 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
12:21:30.766144 [debug] [MainThread]: Parsing macros/adapters/columns.sql
12:21:30.770956 [debug] [MainThread]: Parsing tests/generic/builtin.sql
12:21:30.862043 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
12:21:30.868407 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
12:21:30.868947 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_cumulative_sales.sql
12:21:30.870042 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
12:21:30.871022 [debug] [MainThread]: 1603: static parser failed on example/dates.sql
12:21:30.874366 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/dates.sql
12:21:30.874827 [debug] [MainThread]: 1603: static parser failed on example/incremental_time.sql
12:21:30.876453 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_time.sql
12:21:30.876899 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
12:21:30.902607 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.learn_dbt.example.vars

12:21:30.904998 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9813d93a-c4ba-4b05-907f-e2a6574694bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10722efa0>]}
12:21:30.907810 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9813d93a-c4ba-4b05-907f-e2a6574694bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10722efd0>]}
12:21:30.907951 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
12:21:30.908634 [info ] [MainThread]: 
12:21:30.908842 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:21:30.909318 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
12:21:30.915392 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
12:21:30.915517 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
12:21:30.915584 [debug] [ThreadPool]: Opening a new connection, currently in state init
12:21:31.728635 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.81 seconds
12:21:31.731128 [debug] [ThreadPool]: On list_analytics: Close
12:21:31.977975 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
12:21:31.983150 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
12:21:31.983303 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
12:21:31.983401 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:21:32.797659 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 0.81 seconds
12:21:32.801697 [debug] [ThreadPool]: On list_analytics_dbt: Close
12:21:33.139919 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
12:21:33.140601 [info ] [MainThread]: 
12:21:33.146295 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
12:21:33.147131 [info ] [Thread-1  ]: 1 of 6 START incremental model dbt.dates........................................ [RUN]
12:21:33.147629 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
12:21:33.147779 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
12:21:33.147917 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
12:21:33.153355 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
12:21:33.154286 [debug] [Thread-1  ]: finished collecting timing info
12:21:33.154551 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
12:21:33.184258 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:21:33.184447 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
12:21:33.184533 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:21:35.117822 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.93 seconds
12:21:35.124748 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:21:35.124881 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
12:21:35.277471 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.15 seconds
12:21:35.282293 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:21:35.282561 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
12:21:35.386619 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.1 seconds
12:21:35.400302 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:21:35.400639 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
12:21:35.516702 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.12 seconds
12:21:35.538665 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
12:21:35.540472 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:21:35.540613 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
12:21:35.663189 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.12 seconds
12:21:35.664195 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:21:35.664430 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
12:21:36.249476 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.58 seconds
12:21:36.249994 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:21:36.250175 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
12:21:36.444204 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.19 seconds
12:21:36.458139 [debug] [Thread-1  ]: finished collecting timing info
12:21:36.458475 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
12:21:36.658982 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9813d93a-c4ba-4b05-907f-e2a6574694bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10718a2e0>]}
12:21:36.659650 [info ] [Thread-1  ]: 1 of 6 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 3.51s]
12:21:36.660026 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
12:21:36.660183 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
12:21:36.660439 [info ] [Thread-1  ]: 2 of 6 START incremental model dbt.incremental_time............................. [RUN]
12:21:36.660847 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
12:21:36.660984 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
12:21:36.661115 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
12:21:36.663934 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
12:21:36.664573 [debug] [Thread-1  ]: finished collecting timing info
12:21:36.664705 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
12:21:36.667934 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:21:36.668106 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
12:21:36.668240 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:21:38.315056 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.65 seconds
12:21:38.319155 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:21:38.319364 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
12:21:38.434983 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.12 seconds
12:21:38.440613 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:21:38.440958 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
12:21:38.567731 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.13 seconds
12:21:38.575128 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:21:38.575448 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
12:21:38.767174 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.19 seconds
12:21:38.771272 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
12:21:38.773282 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:21:38.773506 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
12:21:38.900983 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.13 seconds
12:21:38.901978 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:21:38.902302 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
12:21:39.579874 [debug] [Thread-1  ]: SQL status: SUCCESS 335 in 0.68 seconds
12:21:39.580912 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:21:39.581137 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
12:21:39.862268 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.28 seconds
12:21:39.864607 [debug] [Thread-1  ]: finished collecting timing info
12:21:39.864749 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
12:21:40.059874 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9813d93a-c4ba-4b05-907f-e2a6574694bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076cc910>]}
12:21:40.060155 [info ] [Thread-1  ]: 2 of 6 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 3.40s]
12:21:40.060314 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
12:21:40.060405 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
12:21:40.060506 [info ] [Thread-1  ]: 3 of 6 START table model dbt.first_model........................................ [RUN]
12:21:40.060704 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
12:21:40.060777 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
12:21:40.060849 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
12:21:40.064063 [debug] [Thread-1  ]: finished collecting timing info
12:21:40.064288 [debug] [Thread-1  ]: Compilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  Required var 'my_first_variable' not found in config:
  Vars supplied to my_first_dbt_model = {}
  
  > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
12:21:40.064432 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9813d93a-c4ba-4b05-907f-e2a6574694bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a97ca0>]}
12:21:40.064589 [error] [Thread-1  ]: 3 of 6 ERROR creating table model dbt.first_model............................... [[31mERROR[0m in 0.00s]
12:21:40.064735 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
12:21:40.064820 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
12:21:40.065181 [info ] [Thread-1  ]: 4 of 6 START table model dbt.snowflake_cumulative_sales......................... [RUN]
12:21:40.065465 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
12:21:40.065545 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
12:21:40.065618 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
12:21:40.066276 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
12:21:40.066633 [debug] [Thread-1  ]: finished collecting timing info
12:21:40.066719 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
12:21:40.071310 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
12:21:40.071844 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
12:21:40.071925 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
12:21:40.071990 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:21:41.410697 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.34 seconds
12:21:41.414491 [debug] [Thread-1  ]: finished collecting timing info
12:21:41.414944 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
12:21:41.586205 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9813d93a-c4ba-4b05-907f-e2a6574694bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a97760>]}
12:21:41.586852 [info ] [Thread-1  ]: 4 of 6 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 1.52s]
12:21:41.587287 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
12:21:41.587530 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
12:21:41.587941 [info ] [Thread-1  ]: 5 of 6 START table model dbt.snowflake_customer_purchases....................... [RUN]
12:21:41.588604 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
12:21:41.588827 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
12:21:41.589040 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
12:21:41.591036 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
12:21:41.591647 [debug] [Thread-1  ]: finished collecting timing info
12:21:41.591814 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
12:21:41.594543 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
12:21:41.595948 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
12:21:41.596137 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
12:21:41.596294 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:21:43.215104 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.62 seconds
12:21:43.217347 [debug] [Thread-1  ]: finished collecting timing info
12:21:43.217528 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
12:21:43.750691 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9813d93a-c4ba-4b05-907f-e2a6574694bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074c0bb0>]}
12:21:43.751368 [info ] [Thread-1  ]: 5 of 6 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.16s]
12:21:43.751658 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
12:21:43.751784 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
12:21:43.751972 [info ] [Thread-1  ]: 6 of 6 SKIP relation dbt.my_second_dbt_model.................................... [[33mSKIP[0m]
12:21:43.752186 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
12:21:43.752851 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:21:43.753160 [info ] [MainThread]: 
12:21:43.753372 [info ] [MainThread]: Finished running 2 incremental models, 4 table models in 12.84s.
12:21:43.753523 [debug] [MainThread]: Connection 'master' was properly closed.
12:21:43.753636 [debug] [MainThread]: Connection 'model.learn_dbt.snowflake_customer_purchases' was properly closed.
12:21:43.757491 [info ] [MainThread]: 
12:21:43.757704 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
12:21:43.757887 [info ] [MainThread]: 
12:21:43.758019 [error] [MainThread]: [33mCompilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)[0m
12:21:43.758139 [error] [MainThread]:   Required var 'my_first_variable' not found in config:
12:21:43.758266 [error] [MainThread]:   Vars supplied to my_first_dbt_model = {}
12:21:43.758392 [error] [MainThread]:   
12:21:43.758516 [error] [MainThread]:   > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
12:21:43.758637 [error] [MainThread]:   > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
12:21:43.758876 [info ] [MainThread]: 
12:21:43.758995 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=1 TOTAL=6
12:21:43.759165 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107190e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076cc9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107375a30>]}


============================== 2022-05-13 12:22:46.414809 | a408b718-cf05-4808-8db3-16295bc429e0 ==============================
12:22:46.414809 [info ] [MainThread]: Running with dbt=1.0.1
12:22:46.415184 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
12:22:46.415313 [debug] [MainThread]: Tracking: tracking
12:22:46.415532 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104f92fa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104f928e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104f92910>]}
12:22:46.448389 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
12:22:46.448664 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'a408b718-cf05-4808-8db3-16295bc429e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104f98280>]}
12:22:46.459897 [debug] [MainThread]: Parsing macros/catalog.sql
12:22:46.461098 [debug] [MainThread]: Parsing macros/adapters.sql
12:22:46.480554 [debug] [MainThread]: Parsing macros/materializations/merge.sql
12:22:46.482337 [debug] [MainThread]: Parsing macros/materializations/seed.sql
12:22:46.484814 [debug] [MainThread]: Parsing macros/materializations/view.sql
12:22:46.485406 [debug] [MainThread]: Parsing macros/materializations/table.sql
12:22:46.486824 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
12:22:46.490786 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
12:22:46.491198 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
12:22:46.492918 [debug] [MainThread]: Parsing macros/materializations/configs.sql
12:22:46.493920 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
12:22:46.494665 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
12:22:46.502350 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
12:22:46.507851 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
12:22:46.513624 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
12:22:46.515690 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
12:22:46.516477 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
12:22:46.517274 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
12:22:46.519262 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
12:22:46.524633 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
12:22:46.525308 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
12:22:46.530138 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
12:22:46.537788 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
12:22:46.541391 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
12:22:46.542643 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
12:22:46.546099 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
12:22:46.546662 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
12:22:46.547877 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
12:22:46.548877 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
12:22:46.551665 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
12:22:46.559516 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
12:22:46.560157 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
12:22:46.561241 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
12:22:46.561921 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
12:22:46.562312 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
12:22:46.562541 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
12:22:46.562836 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
12:22:46.563438 [debug] [MainThread]: Parsing macros/etc/statement.sql
12:22:46.565424 [debug] [MainThread]: Parsing macros/etc/datetime.sql
12:22:46.569313 [debug] [MainThread]: Parsing macros/adapters/schema.sql
12:22:46.570238 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
12:22:46.571418 [debug] [MainThread]: Parsing macros/adapters/relation.sql
12:22:46.575888 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
12:22:46.577154 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
12:22:46.579094 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
12:22:46.582339 [debug] [MainThread]: Parsing macros/adapters/columns.sql
12:22:46.586831 [debug] [MainThread]: Parsing tests/generic/builtin.sql
12:22:46.677362 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
12:22:46.683570 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
12:22:46.684081 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_cumulative_sales.sql
12:22:46.685164 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
12:22:46.686155 [debug] [MainThread]: 1603: static parser failed on example/dates.sql
12:22:46.689495 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/dates.sql
12:22:46.689963 [debug] [MainThread]: 1603: static parser failed on example/incremental_time.sql
12:22:46.691616 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_time.sql
12:22:46.692060 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
12:22:46.717951 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.learn_dbt.example.vars

12:22:46.720321 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a408b718-cf05-4808-8db3-16295bc429e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1050838b0>]}
12:22:46.723170 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a408b718-cf05-4808-8db3-16295bc429e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105083160>]}
12:22:46.723299 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
12:22:46.723980 [info ] [MainThread]: 
12:22:46.724183 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:22:46.724631 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
12:22:46.730320 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
12:22:46.730444 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
12:22:46.730509 [debug] [ThreadPool]: Opening a new connection, currently in state init
12:22:48.111776 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.38 seconds
12:22:48.114152 [debug] [ThreadPool]: On list_analytics: Close
12:22:48.296457 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
12:22:48.305139 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
12:22:48.305409 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
12:22:48.305574 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:22:49.159950 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 0.85 seconds
12:22:49.163396 [debug] [ThreadPool]: On list_analytics_dbt: Close
12:22:49.347236 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
12:22:49.348899 [info ] [MainThread]: 
12:22:49.353971 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
12:22:49.354776 [info ] [Thread-1  ]: 1 of 6 START incremental model dbt.dates........................................ [RUN]
12:22:49.355281 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
12:22:49.355421 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
12:22:49.355558 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
12:22:49.360102 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
12:22:49.360718 [debug] [Thread-1  ]: finished collecting timing info
12:22:49.360898 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
12:22:49.389946 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:22:49.390151 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
12:22:49.390251 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:22:51.300869 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.91 seconds
12:22:51.313468 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:22:51.313827 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
12:22:51.460214 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.15 seconds
12:22:51.468824 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:22:51.469344 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
12:22:51.664109 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.19 seconds
12:22:51.676759 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:22:51.677078 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
12:22:51.804350 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.13 seconds
12:22:51.831307 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
12:22:51.833714 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:22:51.833848 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
12:22:51.965681 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.13 seconds
12:22:51.968254 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:22:51.968600 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
12:22:52.714187 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.75 seconds
12:22:52.714766 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:22:52.715101 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
12:22:52.922945 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.21 seconds
12:22:52.930922 [debug] [Thread-1  ]: finished collecting timing info
12:22:52.931303 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
12:22:53.212487 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a408b718-cf05-4808-8db3-16295bc429e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1050b33d0>]}
12:22:53.213246 [info ] [Thread-1  ]: 1 of 6 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 3.86s]
12:22:53.213714 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
12:22:53.213970 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
12:22:53.214406 [info ] [Thread-1  ]: 2 of 6 START incremental model dbt.incremental_time............................. [RUN]
12:22:53.215101 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
12:22:53.215339 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
12:22:53.215546 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
12:22:53.219537 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
12:22:53.220367 [debug] [Thread-1  ]: finished collecting timing info
12:22:53.220555 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
12:22:53.224351 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:22:53.224516 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
12:22:53.224643 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:22:54.809383 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.58 seconds
12:22:54.812979 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:22:54.813310 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
12:22:54.948397 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.13 seconds
12:22:54.954492 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:22:54.954923 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
12:22:55.066539 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.11 seconds
12:22:55.072123 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:22:55.072480 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
12:22:55.200821 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.13 seconds
12:22:55.205750 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
12:22:55.208201 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:22:55.208437 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
12:22:55.342044 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.13 seconds
12:22:55.342795 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:22:55.343758 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
12:22:56.124844 [debug] [Thread-1  ]: SQL status: SUCCESS 76 in 0.78 seconds
12:22:56.125702 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:22:56.125920 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
12:22:56.493899 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.37 seconds
12:22:56.498591 [debug] [Thread-1  ]: finished collecting timing info
12:22:56.498987 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
12:22:56.699911 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a408b718-cf05-4808-8db3-16295bc429e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10568e580>]}
12:22:56.700636 [info ] [Thread-1  ]: 2 of 6 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 3.48s]
12:22:56.701078 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
12:22:56.701329 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
12:22:56.701728 [info ] [Thread-1  ]: 3 of 6 START table model dbt.first_model........................................ [RUN]
12:22:56.702369 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
12:22:56.702583 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
12:22:56.702781 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
12:22:56.707833 [debug] [Thread-1  ]: finished collecting timing info
12:22:56.708220 [debug] [Thread-1  ]: Compilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  Required var 'my_first_variable' not found in config:
  Vars supplied to my_first_dbt_model = {}
  
  > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
12:22:56.708507 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a408b718-cf05-4808-8db3-16295bc429e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108d0b250>]}
12:22:56.708839 [error] [Thread-1  ]: 3 of 6 ERROR creating table model dbt.first_model............................... [[31mERROR[0m in 0.01s]
12:22:56.709343 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
12:22:56.709671 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
12:22:56.710174 [info ] [Thread-1  ]: 4 of 6 START table model dbt.snowflake_cumulative_sales......................... [RUN]
12:22:56.710739 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
12:22:56.710978 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
12:22:56.711140 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
12:22:56.712339 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
12:22:56.712829 [debug] [Thread-1  ]: finished collecting timing info
12:22:56.712972 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
12:22:56.721086 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
12:22:56.722053 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
12:22:56.722183 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
12:22:56.722299 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:22:58.511427 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.79 seconds
12:22:58.515249 [debug] [Thread-1  ]: finished collecting timing info
12:22:58.515627 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
12:22:58.683969 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a408b718-cf05-4808-8db3-16295bc429e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108d0bdf0>]}
12:22:58.684718 [info ] [Thread-1  ]: 4 of 6 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 1.97s]
12:22:58.685168 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
12:22:58.685413 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
12:22:58.685817 [info ] [Thread-1  ]: 5 of 6 START table model dbt.snowflake_customer_purchases....................... [RUN]
12:22:58.686442 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
12:22:58.686651 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
12:22:58.686843 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
12:22:58.688397 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
12:22:58.689028 [debug] [Thread-1  ]: finished collecting timing info
12:22:58.689174 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
12:22:58.691044 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
12:22:58.691770 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
12:22:58.691856 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
12:22:58.691932 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:23:00.720570 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.03 seconds
12:23:00.723462 [debug] [Thread-1  ]: finished collecting timing info
12:23:00.723787 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
12:23:00.915840 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a408b718-cf05-4808-8db3-16295bc429e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10563a370>]}
12:23:00.916869 [info ] [Thread-1  ]: 5 of 6 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.23s]
12:23:00.917439 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
12:23:00.917818 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
12:23:00.918057 [info ] [Thread-1  ]: 6 of 6 SKIP relation dbt.my_second_dbt_model.................................... [[33mSKIP[0m]
12:23:00.918439 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
12:23:00.919841 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:23:00.920344 [info ] [MainThread]: 
12:23:00.920665 [info ] [MainThread]: Finished running 2 incremental models, 4 table models in 14.20s.
12:23:00.920960 [debug] [MainThread]: Connection 'master' was properly closed.
12:23:00.921124 [debug] [MainThread]: Connection 'model.learn_dbt.snowflake_customer_purchases' was properly closed.
12:23:00.927368 [info ] [MainThread]: 
12:23:00.927602 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
12:23:00.927801 [info ] [MainThread]: 
12:23:00.927969 [error] [MainThread]: [33mCompilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)[0m
12:23:00.928135 [error] [MainThread]:   Required var 'my_first_variable' not found in config:
12:23:00.928292 [error] [MainThread]:   Vars supplied to my_first_dbt_model = {}
12:23:00.928469 [error] [MainThread]:   
12:23:00.928623 [error] [MainThread]:   > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
12:23:00.928773 [error] [MainThread]:   > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
12:23:00.928943 [info ] [MainThread]: 
12:23:00.929112 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=1 TOTAL=6
12:23:00.929388 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105681b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105681fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1057da670>]}


============================== 2022-05-13 12:24:06.416543 | cdc41580-7387-4ba3-b84c-fd72aa560133 ==============================
12:24:06.416543 [info ] [MainThread]: Running with dbt=1.0.1
12:24:06.416910 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
12:24:06.417043 [debug] [MainThread]: Tracking: tracking
12:24:06.417269 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074422b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107442b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107442910>]}
12:24:06.457225 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
12:24:06.457480 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/my_first_dbt_model.sql
12:24:06.462708 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
12:24:06.469230 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
12:24:06.481189 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.learn_dbt.example.vars

12:24:06.483733 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cdc41580-7387-4ba3-b84c-fd72aa560133', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10406fb20>]}
12:24:06.486850 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cdc41580-7387-4ba3-b84c-fd72aa560133', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10741bdf0>]}
12:24:06.487005 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
12:24:06.487773 [info ] [MainThread]: 
12:24:06.487991 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:24:06.488409 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
12:24:06.494434 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
12:24:06.494568 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
12:24:06.494663 [debug] [ThreadPool]: Opening a new connection, currently in state init
12:24:08.376961 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.88 seconds
12:24:08.379791 [debug] [ThreadPool]: On list_analytics: Close
12:24:08.613089 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
12:24:08.621569 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
12:24:08.621851 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
12:24:08.622015 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:24:09.255312 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 0.63 seconds
12:24:09.258588 [debug] [ThreadPool]: On list_analytics_dbt: Close
12:24:09.428080 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
12:24:09.428776 [info ] [MainThread]: 
12:24:09.432479 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
12:24:09.433247 [info ] [Thread-1  ]: 1 of 6 START incremental model dbt.dates........................................ [RUN]
12:24:09.433806 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
12:24:09.433986 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
12:24:09.434154 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
12:24:09.444182 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
12:24:09.444808 [debug] [Thread-1  ]: finished collecting timing info
12:24:09.444967 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
12:24:09.474301 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:24:09.474494 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
12:24:09.474584 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:24:11.492436 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.02 seconds
12:24:11.506060 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:24:11.506500 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
12:24:11.649465 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.14 seconds
12:24:11.656067 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:24:11.656280 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
12:24:11.870201 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.21 seconds
12:24:11.886057 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:24:11.886431 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
12:24:11.993415 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.11 seconds
12:24:12.020575 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
12:24:12.023047 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:24:12.023208 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
12:24:12.143523 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.12 seconds
12:24:12.145041 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:24:12.145385 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
12:24:12.685384 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.54 seconds
12:24:12.686165 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:24:12.686361 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
12:24:12.949994 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.26 seconds
12:24:12.962401 [debug] [Thread-1  ]: finished collecting timing info
12:24:12.962619 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
12:24:13.165037 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cdc41580-7387-4ba3-b84c-fd72aa560133', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10741b100>]}
12:24:13.166179 [info ] [Thread-1  ]: 1 of 6 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 3.73s]
12:24:13.166675 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
12:24:13.166954 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
12:24:13.167260 [info ] [Thread-1  ]: 2 of 6 START incremental model dbt.incremental_time............................. [RUN]
12:24:13.167974 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
12:24:13.168532 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
12:24:13.168808 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
12:24:13.171971 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
12:24:13.172736 [debug] [Thread-1  ]: finished collecting timing info
12:24:13.172899 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
12:24:13.176097 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:24:13.176333 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
12:24:13.176462 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:24:14.573221 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.4 seconds
12:24:14.582168 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:24:14.582549 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
12:24:14.691726 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.11 seconds
12:24:14.697258 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:24:14.697684 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
12:24:14.892650 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.19 seconds
12:24:14.898723 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:24:14.899087 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
12:24:15.021402 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.12 seconds
12:24:15.026163 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
12:24:15.028455 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:24:15.028687 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
12:24:15.149816 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.12 seconds
12:24:15.150442 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:24:15.150635 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
12:24:16.137086 [debug] [Thread-1  ]: SQL status: SUCCESS 80 in 0.99 seconds
12:24:16.139116 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:24:16.139435 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
12:24:16.396530 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.26 seconds
12:24:16.400039 [debug] [Thread-1  ]: finished collecting timing info
12:24:16.400409 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
12:24:16.768990 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cdc41580-7387-4ba3-b84c-fd72aa560133', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1104fcee0>]}
12:24:16.769776 [info ] [Thread-1  ]: 2 of 6 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 3.60s]
12:24:16.770222 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
12:24:16.770469 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
12:24:16.770871 [info ] [Thread-1  ]: 3 of 6 START table model dbt.first_model........................................ [RUN]
12:24:16.771510 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
12:24:16.771728 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
12:24:16.771937 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
12:24:16.778319 [debug] [Thread-1  ]: finished collecting timing info
12:24:16.778711 [debug] [Thread-1  ]: Compilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  'vars' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
12:24:16.778992 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cdc41580-7387-4ba3-b84c-fd72aa560133', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1104b1e80>]}
12:24:16.779319 [error] [Thread-1  ]: 3 of 6 ERROR creating table model dbt.first_model............................... [[31mERROR[0m in 0.01s]
12:24:16.779633 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
12:24:16.779807 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
12:24:16.780267 [info ] [Thread-1  ]: 4 of 6 START table model dbt.snowflake_cumulative_sales......................... [RUN]
12:24:16.780702 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
12:24:16.780856 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
12:24:16.780990 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
12:24:16.782326 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
12:24:16.782919 [debug] [Thread-1  ]: finished collecting timing info
12:24:16.783079 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
12:24:16.791050 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
12:24:16.791996 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
12:24:16.792126 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
12:24:16.792241 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:24:18.458073 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.67 seconds
12:24:18.460543 [debug] [Thread-1  ]: finished collecting timing info
12:24:18.460852 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
12:24:18.867965 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cdc41580-7387-4ba3-b84c-fd72aa560133', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1104fcdc0>]}
12:24:18.868982 [info ] [Thread-1  ]: 4 of 6 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 2.09s]
12:24:18.869599 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
12:24:18.869870 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
12:24:18.870294 [info ] [Thread-1  ]: 5 of 6 START table model dbt.snowflake_customer_purchases....................... [RUN]
12:24:18.870969 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
12:24:18.871194 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
12:24:18.871402 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
12:24:18.873327 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
12:24:18.874266 [debug] [Thread-1  ]: finished collecting timing info
12:24:18.874488 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
12:24:18.877406 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
12:24:18.878803 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
12:24:18.878994 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
12:24:18.879149 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:24:20.601058 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.72 seconds
12:24:20.604583 [debug] [Thread-1  ]: finished collecting timing info
12:24:20.605021 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
12:24:20.891667 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cdc41580-7387-4ba3-b84c-fd72aa560133', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1103ebd00>]}
12:24:20.892329 [info ] [Thread-1  ]: 5 of 6 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.02s]
12:24:20.892818 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
12:24:20.893091 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
12:24:20.893489 [info ] [Thread-1  ]: 6 of 6 SKIP relation dbt.my_second_dbt_model.................................... [[33mSKIP[0m]
12:24:20.894058 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
12:24:20.895465 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:24:20.896084 [info ] [MainThread]: 
12:24:20.896478 [info ] [MainThread]: Finished running 2 incremental models, 4 table models in 14.41s.
12:24:20.896841 [debug] [MainThread]: Connection 'master' was properly closed.
12:24:20.897063 [debug] [MainThread]: Connection 'model.learn_dbt.snowflake_customer_purchases' was properly closed.
12:24:20.903250 [info ] [MainThread]: 
12:24:20.903545 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
12:24:20.903777 [info ] [MainThread]: 
12:24:20.903974 [error] [MainThread]: [33mCompilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)[0m
12:24:20.904170 [error] [MainThread]:   'vars' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
12:24:20.904368 [info ] [MainThread]: 
12:24:20.904558 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=1 TOTAL=6
12:24:20.904848 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10741b130>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110340100>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110343460>]}


============================== 2022-05-13 12:26:29.577501 | efd946a2-9ac2-45ad-8f24-2edf6aa4e979 ==============================
12:26:29.577501 [info ] [MainThread]: Running with dbt=1.0.1
12:26:29.579364 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
12:26:29.579543 [debug] [MainThread]: Tracking: tracking
12:26:29.580190 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108267730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108267640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1082679d0>]}
12:26:29.616423 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
12:26:29.616666 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'efd946a2-9ac2-45ad-8f24-2edf6aa4e979', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108287f10>]}
12:26:29.628376 [debug] [MainThread]: Parsing macros/catalog.sql
12:26:29.629606 [debug] [MainThread]: Parsing macros/adapters.sql
12:26:29.648908 [debug] [MainThread]: Parsing macros/materializations/merge.sql
12:26:29.650675 [debug] [MainThread]: Parsing macros/materializations/seed.sql
12:26:29.653167 [debug] [MainThread]: Parsing macros/materializations/view.sql
12:26:29.653751 [debug] [MainThread]: Parsing macros/materializations/table.sql
12:26:29.655146 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
12:26:29.659087 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
12:26:29.659501 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
12:26:29.661201 [debug] [MainThread]: Parsing macros/materializations/configs.sql
12:26:29.662203 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
12:26:29.662939 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
12:26:29.670595 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
12:26:29.676069 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
12:26:29.681827 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
12:26:29.683899 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
12:26:29.684693 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
12:26:29.685478 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
12:26:29.687438 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
12:26:29.692786 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
12:26:29.693453 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
12:26:29.698270 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
12:26:29.705876 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
12:26:29.709486 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
12:26:29.710728 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
12:26:29.714170 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
12:26:29.714728 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
12:26:29.715931 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
12:26:29.716913 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
12:26:29.719692 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
12:26:29.727918 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
12:26:29.728686 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
12:26:29.729819 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
12:26:29.730522 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
12:26:29.730929 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
12:26:29.731166 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
12:26:29.731479 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
12:26:29.732099 [debug] [MainThread]: Parsing macros/etc/statement.sql
12:26:29.734183 [debug] [MainThread]: Parsing macros/etc/datetime.sql
12:26:29.738488 [debug] [MainThread]: Parsing macros/adapters/schema.sql
12:26:29.739570 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
12:26:29.740812 [debug] [MainThread]: Parsing macros/adapters/relation.sql
12:26:29.745495 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
12:26:29.746768 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
12:26:29.748784 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
12:26:29.752168 [debug] [MainThread]: Parsing macros/adapters/columns.sql
12:26:29.757207 [debug] [MainThread]: Parsing tests/generic/builtin.sql
12:26:29.849198 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
12:26:29.856304 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
12:26:29.856908 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_cumulative_sales.sql
12:26:29.857977 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
12:26:29.858969 [debug] [MainThread]: 1603: static parser failed on example/dates.sql
12:26:29.862312 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/dates.sql
12:26:29.862772 [debug] [MainThread]: 1603: static parser failed on example/incremental_time.sql
12:26:29.864403 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_time.sql
12:26:29.864836 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
12:26:29.892766 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'efd946a2-9ac2-45ad-8f24-2edf6aa4e979', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1083a0550>]}
12:26:29.897326 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'efd946a2-9ac2-45ad-8f24-2edf6aa4e979', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1083a0a30>]}
12:26:29.897498 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
12:26:29.898310 [info ] [MainThread]: 
12:26:29.898560 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:26:29.899079 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
12:26:29.905102 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
12:26:29.905214 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
12:26:29.905284 [debug] [ThreadPool]: Opening a new connection, currently in state init
12:26:30.931095 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.03 seconds
12:26:30.933537 [debug] [ThreadPool]: On list_analytics: Close
12:26:31.203994 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
12:26:31.212463 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
12:26:31.212746 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
12:26:31.212909 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:26:31.856574 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 0.64 seconds
12:26:31.859716 [debug] [ThreadPool]: On list_analytics_dbt: Close
12:26:32.051479 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
12:26:32.051900 [info ] [MainThread]: 
12:26:32.057201 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
12:26:32.057970 [info ] [Thread-1  ]: 1 of 6 START incremental model dbt.dates........................................ [RUN]
12:26:32.058466 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
12:26:32.058628 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
12:26:32.058785 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
12:26:32.065113 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
12:26:32.065836 [debug] [Thread-1  ]: finished collecting timing info
12:26:32.066059 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
12:26:32.095665 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:26:32.095882 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
12:26:32.096007 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:26:34.504588 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.41 seconds
12:26:34.518728 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:26:34.519112 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
12:26:34.643786 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.12 seconds
12:26:34.653840 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:26:34.654237 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
12:26:34.769005 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.11 seconds
12:26:34.781710 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:26:34.782014 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
12:26:35.001269 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.22 seconds
12:26:35.028936 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
12:26:35.031328 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:26:35.031463 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
12:26:35.181652 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.15 seconds
12:26:35.182669 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:26:35.182856 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
12:26:35.498951 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.32 seconds
12:26:35.499504 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:26:35.499689 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
12:26:35.667870 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.17 seconds
12:26:35.682310 [debug] [Thread-1  ]: finished collecting timing info
12:26:35.682660 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
12:26:35.857502 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'efd946a2-9ac2-45ad-8f24-2edf6aa4e979', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108345c40>]}
12:26:35.858122 [info ] [Thread-1  ]: 1 of 6 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 3.80s]
12:26:35.858594 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
12:26:35.858863 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
12:26:35.859324 [info ] [Thread-1  ]: 2 of 6 START incremental model dbt.incremental_time............................. [RUN]
12:26:35.859958 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
12:26:35.860180 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
12:26:35.860399 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
12:26:35.864425 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
12:26:35.865192 [debug] [Thread-1  ]: finished collecting timing info
12:26:35.865364 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
12:26:35.868952 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:26:35.869148 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
12:26:35.869282 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:26:37.400587 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.53 seconds
12:26:37.405814 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:26:37.406159 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
12:26:37.602913 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.19 seconds
12:26:37.607863 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:26:37.608224 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
12:26:37.740220 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.13 seconds
12:26:37.745540 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:26:37.745826 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
12:26:37.844286 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
12:26:37.853091 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
12:26:37.855259 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:26:37.855468 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
12:26:37.982747 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.13 seconds
12:26:37.983527 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:26:37.983728 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
12:26:38.713961 [debug] [Thread-1  ]: SQL status: SUCCESS 143 in 0.73 seconds
12:26:38.715146 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:26:38.715265 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
12:26:38.970525 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.26 seconds
12:26:38.973600 [debug] [Thread-1  ]: finished collecting timing info
12:26:38.974033 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
12:26:39.304288 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'efd946a2-9ac2-45ad-8f24-2edf6aa4e979', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108679520>]}
12:26:39.305563 [info ] [Thread-1  ]: 2 of 6 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 3.44s]
12:26:39.306146 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
12:26:39.306397 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
12:26:39.306685 [info ] [Thread-1  ]: 3 of 6 START table model dbt.first_model........................................ [RUN]
12:26:39.307403 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
12:26:39.307658 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
12:26:39.307866 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
12:26:39.314626 [debug] [Thread-1  ]: finished collecting timing info
12:26:39.315134 [debug] [Thread-1  ]: Compilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  'vars' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
12:26:39.315575 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'efd946a2-9ac2-45ad-8f24-2edf6aa4e979', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10830a6a0>]}
12:26:39.315950 [error] [Thread-1  ]: 3 of 6 ERROR creating table model dbt.first_model............................... [[31mERROR[0m in 0.01s]
12:26:39.316170 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
12:26:39.316284 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
12:26:39.316411 [info ] [Thread-1  ]: 4 of 6 START table model dbt.snowflake_cumulative_sales......................... [RUN]
12:26:39.316676 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
12:26:39.316912 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
12:26:39.317216 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
12:26:39.318522 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
12:26:39.319160 [debug] [Thread-1  ]: finished collecting timing info
12:26:39.319317 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
12:26:39.326423 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
12:26:39.327306 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
12:26:39.327448 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
12:26:39.327563 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:26:40.847225 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.52 seconds
12:26:40.851156 [debug] [Thread-1  ]: finished collecting timing info
12:26:40.851594 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
12:26:41.007812 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'efd946a2-9ac2-45ad-8f24-2edf6aa4e979', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a4d13a0>]}
12:26:41.008188 [info ] [Thread-1  ]: 4 of 6 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 1.69s]
12:26:41.008394 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
12:26:41.008510 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
12:26:41.008701 [info ] [Thread-1  ]: 5 of 6 START table model dbt.snowflake_customer_purchases....................... [RUN]
12:26:41.008992 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
12:26:41.009095 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
12:26:41.009191 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
12:26:41.010215 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
12:26:41.010744 [debug] [Thread-1  ]: finished collecting timing info
12:26:41.010961 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
12:26:41.013802 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
12:26:41.015142 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
12:26:41.015331 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
12:26:41.015485 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:26:42.768965 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.75 seconds
12:26:42.772814 [debug] [Thread-1  ]: finished collecting timing info
12:26:42.773200 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
12:26:42.926796 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'efd946a2-9ac2-45ad-8f24-2edf6aa4e979', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a4dcd60>]}
12:26:42.927693 [info ] [Thread-1  ]: 5 of 6 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 1.92s]
12:26:42.928140 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
12:26:42.928511 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
12:26:42.928811 [info ] [Thread-1  ]: 6 of 6 SKIP relation dbt.my_second_dbt_model.................................... [[33mSKIP[0m]
12:26:42.929082 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
12:26:42.930105 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:26:42.930625 [info ] [MainThread]: 
12:26:42.930928 [info ] [MainThread]: Finished running 2 incremental models, 4 table models in 13.03s.
12:26:42.931195 [debug] [MainThread]: Connection 'master' was properly closed.
12:26:42.931336 [debug] [MainThread]: Connection 'model.learn_dbt.snowflake_customer_purchases' was properly closed.
12:26:42.937390 [info ] [MainThread]: 
12:26:42.937707 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
12:26:42.937976 [info ] [MainThread]: 
12:26:42.938318 [error] [MainThread]: [33mCompilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)[0m
12:26:42.938584 [error] [MainThread]:   'vars' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
12:26:42.938823 [info ] [MainThread]: 
12:26:42.939046 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=1 TOTAL=6
12:26:42.939359 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108383e80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1083a0a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108729970>]}


============================== 2022-05-13 12:27:24.772339 | cfb3548c-7fc4-44b4-ac1f-4b22bd1c07e7 ==============================
12:27:24.772339 [info ] [MainThread]: Running with dbt=1.0.1
12:27:24.773069 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
12:27:24.773298 [debug] [MainThread]: Tracking: tracking
12:27:24.773546 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10430fe80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10430f4f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10430f9d0>]}
12:27:24.821928 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
12:27:24.822218 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/my_first_dbt_model.sql
12:27:24.827643 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
12:27:24.834534 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
12:27:24.848048 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cfb3548c-7fc4-44b4-ac1f-4b22bd1c07e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1032e3280>]}
12:27:24.851034 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cfb3548c-7fc4-44b4-ac1f-4b22bd1c07e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1042f8e50>]}
12:27:24.851165 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
12:27:24.851900 [info ] [MainThread]: 
12:27:24.852104 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:27:24.852544 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
12:27:24.858344 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
12:27:24.858442 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
12:27:24.858503 [debug] [ThreadPool]: Opening a new connection, currently in state init
12:27:25.823156 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.96 seconds
12:27:25.825636 [debug] [ThreadPool]: On list_analytics: Close
12:27:26.009967 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
12:27:26.016716 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
12:27:26.016911 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
12:27:26.017029 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:27:26.774149 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 0.76 seconds
12:27:26.777794 [debug] [ThreadPool]: On list_analytics_dbt: Close
12:27:26.942887 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
12:27:26.957196 [info ] [MainThread]: 
12:27:26.962564 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
12:27:26.963250 [info ] [Thread-1  ]: 1 of 6 START incremental model dbt.dates........................................ [RUN]
12:27:26.963799 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
12:27:26.964015 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
12:27:26.964226 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
12:27:26.973501 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
12:27:26.974144 [debug] [Thread-1  ]: finished collecting timing info
12:27:26.974302 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
12:27:27.003361 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:27:27.003512 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
12:27:27.003575 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:27:29.368266 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.36 seconds
12:27:29.379235 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:27:29.379585 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
12:27:29.659133 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.28 seconds
12:27:29.666996 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:27:29.667316 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
12:27:29.765279 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.1 seconds
12:27:29.778243 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:27:29.778637 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
12:27:29.917451 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.14 seconds
12:27:29.940972 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
12:27:29.943345 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:27:29.943470 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
12:27:30.062777 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.12 seconds
12:27:30.063852 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:27:30.064354 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
12:27:30.575623 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.51 seconds
12:27:30.576414 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:27:30.576687 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
12:27:30.839535 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.26 seconds
12:27:30.854618 [debug] [Thread-1  ]: finished collecting timing info
12:27:30.854995 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
12:27:31.302170 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cfb3548c-7fc4-44b4-ac1f-4b22bd1c07e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1042fc460>]}
12:27:31.302962 [info ] [Thread-1  ]: 1 of 6 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 4.34s]
12:27:31.303407 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
12:27:31.303649 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
12:27:31.304058 [info ] [Thread-1  ]: 2 of 6 START incremental model dbt.incremental_time............................. [RUN]
12:27:31.304703 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
12:27:31.304914 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
12:27:31.305111 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
12:27:31.308885 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
12:27:31.309693 [debug] [Thread-1  ]: finished collecting timing info
12:27:31.309882 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
12:27:31.313560 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:27:31.313734 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
12:27:31.313855 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:27:33.197672 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.88 seconds
12:27:33.202821 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:27:33.203183 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
12:27:33.344688 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.14 seconds
12:27:33.348260 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:27:33.348459 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
12:27:33.457790 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.11 seconds
12:27:33.463920 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:27:33.464294 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
12:27:33.717681 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.25 seconds
12:27:33.723149 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
12:27:33.726468 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:27:33.726692 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
12:27:33.892393 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.17 seconds
12:27:33.893276 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:27:33.893558 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
12:27:34.517501 [debug] [Thread-1  ]: SQL status: SUCCESS 56 in 0.62 seconds
12:27:34.518390 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:27:34.518689 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
12:27:34.833085 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.31 seconds
12:27:34.835061 [debug] [Thread-1  ]: finished collecting timing info
12:27:34.835254 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
12:27:35.021760 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cfb3548c-7fc4-44b4-ac1f-4b22bd1c07e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1047a5f40>]}
12:27:35.023227 [info ] [Thread-1  ]: 2 of 6 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 3.72s]
12:27:35.023874 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
12:27:35.024355 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
12:27:35.024741 [info ] [Thread-1  ]: 3 of 6 START table model dbt.first_model........................................ [RUN]
12:27:35.025144 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
12:27:35.025246 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
12:27:35.025342 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
12:27:35.029405 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
12:27:35.030164 [debug] [Thread-1  ]: finished collecting timing info
12:27:35.030345 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
12:27:35.039339 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
12:27:35.040532 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
12:27:35.040686 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *, True as first_variable
from source_data
where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
12:27:35.040813 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:27:36.442793 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.4 seconds
12:27:36.446339 [debug] [Thread-1  ]: finished collecting timing info
12:27:36.446816 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
12:27:36.649254 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cfb3548c-7fc4-44b4-ac1f-4b22bd1c07e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106581af0>]}
12:27:36.649676 [info ] [Thread-1  ]: 3 of 6 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 1.62s]
12:27:36.649905 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
12:27:36.650036 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
12:27:36.650171 [info ] [Thread-1  ]: 4 of 6 START table model dbt.snowflake_cumulative_sales......................... [RUN]
12:27:36.650460 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
12:27:36.650873 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
12:27:36.651127 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
12:27:36.652649 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
12:27:36.653207 [debug] [Thread-1  ]: finished collecting timing info
12:27:36.653378 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
12:27:36.655773 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
12:27:36.656754 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
12:27:36.656914 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
12:27:36.657054 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:27:38.068117 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.41 seconds
12:27:38.072219 [debug] [Thread-1  ]: finished collecting timing info
12:27:38.072778 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
12:27:38.470947 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cfb3548c-7fc4-44b4-ac1f-4b22bd1c07e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10655a4f0>]}
12:27:38.471572 [info ] [Thread-1  ]: 4 of 6 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 1.82s]
12:27:38.472150 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
12:27:38.472493 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
12:27:38.472829 [info ] [Thread-1  ]: 5 of 6 START table model dbt.snowflake_customer_purchases....................... [RUN]
12:27:38.473624 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
12:27:38.473902 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
12:27:38.474118 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
12:27:38.475966 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
12:27:38.476639 [debug] [Thread-1  ]: finished collecting timing info
12:27:38.476814 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
12:27:38.479411 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
12:27:38.480649 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
12:27:38.480815 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
12:27:38.480953 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:27:40.045389 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.56 seconds
12:27:40.048616 [debug] [Thread-1  ]: finished collecting timing info
12:27:40.048989 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
12:27:40.212032 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cfb3548c-7fc4-44b4-ac1f-4b22bd1c07e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10670bb80>]}
12:27:40.212738 [info ] [Thread-1  ]: 5 of 6 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 1.74s]
12:27:40.213180 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
12:27:40.213419 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
12:27:40.213808 [info ] [Thread-1  ]: 6 of 6 START table model dbt.my_second_dbt_model................................ [RUN]
12:27:40.214421 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
12:27:40.214622 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
12:27:40.214811 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
12:27:40.216249 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
12:27:40.217951 [debug] [Thread-1  ]: finished collecting timing info
12:27:40.218162 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
12:27:40.220838 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
12:27:40.222215 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
12:27:40.222455 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
where id = 1
      );
12:27:40.222612 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:27:42.546951 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.32 seconds
12:27:42.551442 [debug] [Thread-1  ]: finished collecting timing info
12:27:42.551850 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
12:27:42.739613 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cfb3548c-7fc4-44b4-ac1f-4b22bd1c07e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103624b20>]}
12:27:42.740260 [info ] [Thread-1  ]: 6 of 6 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 2.53s]
12:27:42.740692 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
12:27:42.742029 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:27:42.742595 [info ] [MainThread]: 
12:27:42.742958 [info ] [MainThread]: Finished running 2 incremental models, 4 table models in 17.89s.
12:27:42.743259 [debug] [MainThread]: Connection 'master' was properly closed.
12:27:42.743419 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
12:27:42.749995 [info ] [MainThread]: 
12:27:42.750318 [info ] [MainThread]: [32mCompleted successfully[0m
12:27:42.750579 [info ] [MainThread]: 
12:27:42.750766 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
12:27:42.751050 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10652df10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10655a880>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1046f8220>]}


============================== 2022-05-13 12:31:46.164409 | b06540f9-edcb-4312-a480-a7d7396aa90b ==============================
12:31:46.164409 [info ] [MainThread]: Running with dbt=1.0.1
12:31:46.165016 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
12:31:46.165133 [debug] [MainThread]: Tracking: tracking
12:31:46.165355 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1081a7e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1081a7a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1081a7d30>]}
12:31:46.201810 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108184490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1081844f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108184760>]}


============================== 2022-05-13 12:46:51.990580 | fee484f3-62b8-4d42-89ca-e8d63cfaed01 ==============================
12:46:51.990580 [info ] [MainThread]: Running with dbt=1.0.1
12:46:51.991178 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
12:46:51.991298 [debug] [MainThread]: Tracking: tracking
12:46:51.991534 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d1b8b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d1bb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d1b610>]}
12:46:52.028926 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d55b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d55520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1072079d0>]}


============================== 2022-05-13 12:48:32.965345 | a1cabe6d-e60f-497f-99d8-988dd970e14b ==============================
12:48:32.965345 [info ] [MainThread]: Running with dbt=1.0.1
12:48:32.965899 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
12:48:32.966048 [debug] [MainThread]: Tracking: tracking
12:48:32.966334 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113333eb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113333b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1133333a0>]}
12:48:33.014435 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
12:48:33.014790 [debug] [MainThread]: Partial parsing: update schema file: learn_dbt://models/example/schema.yml
12:48:33.022030 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
12:48:33.047461 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a1cabe6d-e60f-497f-99d8-988dd970e14b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1115a50d0>]}
12:48:33.050508 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a1cabe6d-e60f-497f-99d8-988dd970e14b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113310b80>]}
12:48:33.050645 [info ] [MainThread]: Found 6 models, 9 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
12:48:33.051378 [info ] [MainThread]: 
12:48:33.051581 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:48:33.052003 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
12:48:33.058023 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
12:48:33.058151 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
12:48:33.058216 [debug] [ThreadPool]: Opening a new connection, currently in state init
12:48:34.182983 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.12 seconds
12:48:34.186212 [debug] [ThreadPool]: On list_analytics: Close
12:48:34.561635 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
12:48:34.570501 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
12:48:34.570769 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
12:48:34.570931 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:48:35.301218 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 0.73 seconds
12:48:35.303403 [debug] [ThreadPool]: On list_analytics_dbt: Close
12:48:35.840426 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
12:48:35.841071 [info ] [MainThread]: 
12:48:35.845623 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
12:48:35.846321 [info ] [Thread-1  ]: 1 of 6 START incremental model dbt.dates........................................ [RUN]
12:48:35.846765 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
12:48:35.846904 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
12:48:35.847054 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
12:48:35.856852 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
12:48:35.858286 [debug] [Thread-1  ]: finished collecting timing info
12:48:35.858434 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
12:48:35.886907 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:48:35.887076 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
12:48:35.887165 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:48:38.386394 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.5 seconds
12:48:38.399216 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:48:38.399625 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
12:48:38.528355 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.13 seconds
12:48:38.535558 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:48:38.535891 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
12:48:38.727699 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.19 seconds
12:48:38.740458 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:48:38.740853 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
12:48:38.879998 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.14 seconds
12:48:38.901323 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
12:48:38.904541 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:48:38.904695 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
12:48:39.281001 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.38 seconds
12:48:39.281655 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:48:39.281841 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
12:48:39.891898 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.61 seconds
12:48:39.893357 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:48:39.893577 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
12:48:40.391717 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.5 seconds
12:48:40.405675 [debug] [Thread-1  ]: finished collecting timing info
12:48:40.406028 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
12:48:40.916897 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a1cabe6d-e60f-497f-99d8-988dd970e14b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106cd3040>]}
12:48:40.917751 [info ] [Thread-1  ]: 1 of 6 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 5.07s]
12:48:40.918223 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
12:48:40.918472 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
12:48:40.918883 [info ] [Thread-1  ]: 2 of 6 START incremental model dbt.incremental_time............................. [RUN]
12:48:40.919566 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
12:48:40.919791 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
12:48:40.919995 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
12:48:40.923988 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
12:48:40.925979 [debug] [Thread-1  ]: finished collecting timing info
12:48:40.926232 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
12:48:40.929847 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:48:40.930049 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
12:48:40.930187 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:48:42.422086 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.49 seconds
12:48:42.429011 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:48:42.429469 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
12:48:42.569884 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.14 seconds
12:48:42.573240 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:48:42.573421 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
12:48:42.679878 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.11 seconds
12:48:42.686171 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:48:42.686417 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
12:48:42.949804 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.26 seconds
12:48:42.955308 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
12:48:42.958926 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:48:42.959181 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
12:48:43.102930 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.14 seconds
12:48:43.103300 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:48:43.103431 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
12:48:43.996441 [debug] [Thread-1  ]: SQL status: SUCCESS 1269 in 0.89 seconds
12:48:43.997584 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:48:43.997830 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
12:48:44.336896 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.34 seconds
12:48:44.339681 [debug] [Thread-1  ]: finished collecting timing info
12:48:44.340029 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
12:48:44.711722 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a1cabe6d-e60f-497f-99d8-988dd970e14b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116913610>]}
12:48:44.712967 [info ] [Thread-1  ]: 2 of 6 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 3.79s]
12:48:44.713521 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
12:48:44.713698 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
12:48:44.714001 [info ] [Thread-1  ]: 3 of 6 START table model dbt.first_model........................................ [RUN]
12:48:44.714416 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
12:48:44.714552 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
12:48:44.714675 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
12:48:44.717916 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
12:48:44.718752 [debug] [Thread-1  ]: finished collecting timing info
12:48:44.718906 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
12:48:44.726683 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
12:48:44.727741 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
12:48:44.727880 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *, True as first_variable
from source_data
where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
12:48:44.727993 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:48:46.169233 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.44 seconds
12:48:46.172960 [debug] [Thread-1  ]: finished collecting timing info
12:48:46.173350 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
12:48:46.401985 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a1cabe6d-e60f-497f-99d8-988dd970e14b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116878ac0>]}
12:48:46.402702 [info ] [Thread-1  ]: 3 of 6 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 1.69s]
12:48:46.403419 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
12:48:46.403942 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
12:48:46.404465 [info ] [Thread-1  ]: 4 of 6 START table model dbt.snowflake_cumulative_sales......................... [RUN]
12:48:46.405254 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
12:48:46.405496 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
12:48:46.405699 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
12:48:46.407416 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
12:48:46.408506 [debug] [Thread-1  ]: finished collecting timing info
12:48:46.408730 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
12:48:46.411540 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
12:48:46.412740 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
12:48:46.412925 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
12:48:46.413078 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:48:48.231434 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.82 seconds
12:48:48.234692 [debug] [Thread-1  ]: finished collecting timing info
12:48:48.234981 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
12:48:48.434170 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a1cabe6d-e60f-497f-99d8-988dd970e14b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114954e20>]}
12:48:48.435234 [info ] [Thread-1  ]: 4 of 6 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 2.03s]
12:48:48.435697 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
12:48:48.436184 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
12:48:48.436647 [info ] [Thread-1  ]: 5 of 6 START table model dbt.snowflake_customer_purchases....................... [RUN]
12:48:48.437260 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
12:48:48.437459 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
12:48:48.437650 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
12:48:48.444600 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
12:48:48.446266 [debug] [Thread-1  ]: finished collecting timing info
12:48:48.446513 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
12:48:48.449139 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
12:48:48.450265 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
12:48:48.450407 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
12:48:48.450523 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:48:51.424871 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.97 seconds
12:48:51.428495 [debug] [Thread-1  ]: finished collecting timing info
12:48:51.428920 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
12:48:51.590752 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a1cabe6d-e60f-497f-99d8-988dd970e14b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11491af70>]}
12:48:51.591514 [info ] [Thread-1  ]: 5 of 6 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 3.15s]
12:48:51.591978 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
12:48:51.592247 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
12:48:51.592544 [info ] [Thread-1  ]: 6 of 6 START table model dbt.my_second_dbt_model................................ [RUN]
12:48:51.593246 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
12:48:51.593491 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
12:48:51.593692 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
12:48:51.596876 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
12:48:51.599049 [debug] [Thread-1  ]: finished collecting timing info
12:48:51.599242 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
12:48:51.601764 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
12:48:51.602797 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
12:48:51.602971 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
where id = 1
      );
12:48:51.603098 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:48:52.909509 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.31 seconds
12:48:52.913485 [debug] [Thread-1  ]: finished collecting timing info
12:48:52.913794 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
12:48:53.136745 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a1cabe6d-e60f-497f-99d8-988dd970e14b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11693a520>]}
12:48:53.137500 [info ] [Thread-1  ]: 6 of 6 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.54s]
12:48:53.137956 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
12:48:53.139587 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:48:53.140176 [info ] [MainThread]: 
12:48:53.140479 [info ] [MainThread]: Finished running 2 incremental models, 4 table models in 20.09s.
12:48:53.140731 [debug] [MainThread]: Connection 'master' was properly closed.
12:48:53.140865 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
12:48:53.147566 [info ] [MainThread]: 
12:48:53.147860 [info ] [MainThread]: [32mCompleted successfully[0m
12:48:53.148129 [info ] [MainThread]: 
12:48:53.148321 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
12:48:53.148584 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1149f7520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113310190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114959a90>]}


============================== 2022-05-13 12:48:59.703144 | 66bd61e9-63f4-4e5e-a7ae-cbcfd97032d9 ==============================
12:48:59.703144 [info ] [MainThread]: Running with dbt=1.0.1
12:48:59.703568 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, store_failures=False, indirect_selection='eager', threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.test.TestTask'>, which='test', rpc_method='test')
12:48:59.703716 [debug] [MainThread]: Tracking: tracking
12:48:59.703987 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11374b3d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11374b790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11374b850>]}
12:48:59.750225 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
12:48:59.750366 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
12:48:59.753515 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '66bd61e9-63f4-4e5e-a7ae-cbcfd97032d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113712220>]}
12:48:59.756666 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '66bd61e9-63f4-4e5e-a7ae-cbcfd97032d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111cb7970>]}
12:48:59.756807 [info ] [MainThread]: Found 6 models, 9 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
12:48:59.757575 [info ] [MainThread]: 
12:48:59.757785 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:48:59.758258 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
12:48:59.764217 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
12:48:59.764331 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
12:48:59.764396 [debug] [ThreadPool]: Opening a new connection, currently in state init
12:49:00.981936 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1.22 seconds
12:49:00.984645 [debug] [ThreadPool]: On list_analytics_dbt: Close
12:49:01.366194 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
12:49:01.366847 [info ] [MainThread]: 
12:49:01.373144 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_my_first_dbt_model_id.5fb22c2710
12:49:01.373531 [info ] [Thread-1  ]: 1 of 9 START test not_null_my_first_dbt_model_id................................ [RUN]
12:49:01.374175 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_my_first_dbt_model_id.5fb22c2710"
12:49:01.374349 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_my_first_dbt_model_id.5fb22c2710
12:49:01.374514 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_my_first_dbt_model_id.5fb22c2710
12:49:01.385302 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_my_first_dbt_model_id.5fb22c2710"
12:49:01.385979 [debug] [Thread-1  ]: finished collecting timing info
12:49:01.386129 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_my_first_dbt_model_id.5fb22c2710
12:49:01.398727 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_my_first_dbt_model_id.5fb22c2710"
12:49:01.399523 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_my_first_dbt_model_id.5fb22c2710"
12:49:01.399630 [debug] [Thread-1  ]: On test.learn_dbt.not_null_my_first_dbt_model_id.5fb22c2710: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_my_first_dbt_model_id.5fb22c2710"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.first_model
where id is null



      
    ) dbt_internal_test
12:49:01.399721 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:49:02.869431 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.47 seconds
12:49:02.872932 [debug] [Thread-1  ]: finished collecting timing info
12:49:02.873370 [debug] [Thread-1  ]: On test.learn_dbt.not_null_my_first_dbt_model_id.5fb22c2710: Close
12:49:03.398864 [info ] [Thread-1  ]: 1 of 9 PASS not_null_my_first_dbt_model_id...................................... [[32mPASS[0m in 2.02s]
12:49:03.399611 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_my_first_dbt_model_id.5fb22c2710
12:49:03.399877 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
12:49:03.400258 [info ] [Thread-1  ]: 2 of 9 START test not_null_my_second_dbt_model_id............................... [RUN]
12:49:03.400897 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"
12:49:03.401113 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
12:49:03.401306 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
12:49:03.406147 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"
12:49:03.406692 [debug] [Thread-1  ]: finished collecting timing info
12:49:03.406831 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
12:49:03.408267 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"
12:49:03.408946 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"
12:49:03.409065 [debug] [Thread-1  ]: On test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.my_second_dbt_model
where id is null



      
    ) dbt_internal_test
12:49:03.409174 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:49:04.445988 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.04 seconds
12:49:04.448328 [debug] [Thread-1  ]: finished collecting timing info
12:49:04.448530 [debug] [Thread-1  ]: On test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778: Close
12:49:04.716614 [info ] [Thread-1  ]: 2 of 9 PASS not_null_my_second_dbt_model_id..................................... [[32mPASS[0m in 1.32s]
12:49:04.717774 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
12:49:04.718125 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
12:49:04.718544 [info ] [Thread-1  ]: 3 of 9 START test not_null_snowflake_cumulative_sales_o_orderdate............... [RUN]
12:49:04.719335 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
12:49:04.719556 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
12:49:04.719766 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
12:49:04.724386 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
12:49:04.725383 [debug] [Thread-1  ]: finished collecting timing info
12:49:04.725665 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
12:49:04.728105 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
12:49:04.729328 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
12:49:04.729590 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.snowflake_cumulative_sales
where o_orderdate is null



      
    ) dbt_internal_test
12:49:04.729753 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:49:06.299165 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.57 seconds
12:49:06.302670 [debug] [Thread-1  ]: finished collecting timing info
12:49:06.303082 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856: Close
12:49:06.635216 [info ] [Thread-1  ]: 3 of 9 PASS not_null_snowflake_cumulative_sales_o_orderdate..................... [[32mPASS[0m in 1.92s]
12:49:06.635790 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
12:49:06.636035 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
12:49:06.636233 [info ] [Thread-1  ]: 4 of 9 START test not_null_snowflake_customer_purchases_c_custkey............... [RUN]
12:49:06.636954 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
12:49:06.637184 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
12:49:06.637382 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
12:49:06.642273 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
12:49:06.643004 [debug] [Thread-1  ]: finished collecting timing info
12:49:06.643211 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
12:49:06.645652 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
12:49:06.646711 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
12:49:06.646884 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.snowflake_customer_purchases
where c_custkey is null



      
    ) dbt_internal_test
12:49:06.647031 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:49:07.592704 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.95 seconds
12:49:07.599195 [debug] [Thread-1  ]: finished collecting timing info
12:49:07.599500 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502: Close
12:49:07.766919 [info ] [Thread-1  ]: 4 of 9 PASS not_null_snowflake_customer_purchases_c_custkey..................... [[32mPASS[0m in 1.13s]
12:49:07.767381 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
12:49:07.767592 [debug] [Thread-1  ]: Began running node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
12:49:07.767851 [info ] [Thread-1  ]: 5 of 9 START test relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ [RUN]
12:49:07.768364 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
12:49:07.768531 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
12:49:07.768688 [debug] [Thread-1  ]: Compiling test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
12:49:07.778303 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
12:49:07.778754 [debug] [Thread-1  ]: finished collecting timing info
12:49:07.778849 [debug] [Thread-1  ]: Began executing node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
12:49:07.779894 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
12:49:07.780680 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
12:49:07.780783 [debug] [Thread-1  ]: On test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select id as from_field
    from analytics.dbt.my_second_dbt_model
    where id is not null
),

parent as (
    select id as to_field
    from analytics.dbt.first_model
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
12:49:07.780849 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:49:08.669402 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.89 seconds
12:49:08.672595 [debug] [Thread-1  ]: finished collecting timing info
12:49:08.673046 [debug] [Thread-1  ]: On test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: Close
12:49:08.861041 [info ] [Thread-1  ]: 5 of 9 PASS relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_... [[32mPASS[0m in 1.09s]
12:49:08.861777 [debug] [Thread-1  ]: Finished running node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
12:49:08.862041 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
12:49:08.862236 [info ] [Thread-1  ]: 6 of 9 START test unique_my_first_dbt_model_id.................................. [RUN]
12:49:08.862873 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
12:49:08.863060 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
12:49:08.863229 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
12:49:08.869151 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
12:49:08.869734 [debug] [Thread-1  ]: finished collecting timing info
12:49:08.869883 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
12:49:08.871441 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
12:49:08.872323 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
12:49:08.872481 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.first_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
12:49:08.872779 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:49:09.851130 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.98 seconds
12:49:09.853176 [debug] [Thread-1  ]: finished collecting timing info
12:49:09.853425 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_first_dbt_model_id.16e066b321: Close
12:49:10.215049 [info ] [Thread-1  ]: 6 of 9 PASS unique_my_first_dbt_model_id........................................ [[32mPASS[0m in 1.35s]
12:49:10.215834 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
12:49:10.216091 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
12:49:10.216296 [info ] [Thread-1  ]: 7 of 9 START test unique_my_second_dbt_model_id................................. [RUN]
12:49:10.217013 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
12:49:10.217264 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
12:49:10.217480 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
12:49:10.221772 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
12:49:10.222515 [debug] [Thread-1  ]: finished collecting timing info
12:49:10.222690 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
12:49:10.224942 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
12:49:10.226184 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
12:49:10.226416 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.my_second_dbt_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
12:49:10.226555 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:49:11.260736 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.03 seconds
12:49:11.263474 [debug] [Thread-1  ]: finished collecting timing info
12:49:11.263904 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493: Close
12:49:11.421502 [info ] [Thread-1  ]: 7 of 9 PASS unique_my_second_dbt_model_id....................................... [[32mPASS[0m in 1.20s]
12:49:11.422368 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
12:49:11.422630 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
12:49:11.422832 [info ] [Thread-1  ]: 8 of 9 START test unique_snowflake_cumulative_sales_o_orderdate................. [RUN]
12:49:11.423567 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
12:49:11.423809 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
12:49:11.424018 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
12:49:11.428729 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
12:49:11.429576 [debug] [Thread-1  ]: finished collecting timing info
12:49:11.429762 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
12:49:11.432395 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
12:49:11.433823 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
12:49:11.434058 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    o_orderdate as unique_field,
    count(*) as n_records

from analytics.dbt.snowflake_cumulative_sales
where o_orderdate is not null
group by o_orderdate
having count(*) > 1



      
    ) dbt_internal_test
12:49:11.434193 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:49:12.176031 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.74 seconds
12:49:12.179507 [debug] [Thread-1  ]: finished collecting timing info
12:49:12.179898 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed: Close
12:49:12.339246 [info ] [Thread-1  ]: 8 of 9 PASS unique_snowflake_cumulative_sales_o_orderdate....................... [[32mPASS[0m in 0.92s]
12:49:12.340028 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
12:49:12.340239 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
12:49:12.340401 [info ] [Thread-1  ]: 9 of 9 START test unique_snowflake_customer_purchases_c_custkey................. [RUN]
12:49:12.340652 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
12:49:12.340727 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
12:49:12.340801 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
12:49:12.342848 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
12:49:12.343294 [debug] [Thread-1  ]: finished collecting timing info
12:49:12.343378 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
12:49:12.344522 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
12:49:12.345061 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
12:49:12.345132 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    c_custkey as unique_field,
    count(*) as n_records

from analytics.dbt.snowflake_customer_purchases
where c_custkey is not null
group by c_custkey
having count(*) > 1



      
    ) dbt_internal_test
12:49:12.345193 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:49:13.133123 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.79 seconds
12:49:13.136512 [debug] [Thread-1  ]: finished collecting timing info
12:49:13.136980 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f: Close
12:49:13.411942 [info ] [Thread-1  ]: 9 of 9 PASS unique_snowflake_customer_purchases_c_custkey....................... [[32mPASS[0m in 1.07s]
12:49:13.412807 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
12:49:13.414245 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:49:13.414710 [info ] [MainThread]: 
12:49:13.415040 [info ] [MainThread]: Finished running 9 tests in 13.66s.
12:49:13.415335 [debug] [MainThread]: Connection 'master' was properly closed.
12:49:13.415495 [debug] [MainThread]: Connection 'test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f' was properly closed.
12:49:13.422425 [info ] [MainThread]: 
12:49:13.422777 [info ] [MainThread]: [32mCompleted successfully[0m
12:49:13.423073 [info ] [MainThread]: 
12:49:13.423268 [info ] [MainThread]: Done. PASS=9 WARN=0 ERROR=0 SKIP=0 TOTAL=9
12:49:13.423542 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1139dc3a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107f223d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113f4ed60>]}


============================== 2022-05-13 12:50:19.774998 | c70dbfd4-d9be-495a-b9d0-78fd417eee6c ==============================
12:50:19.774998 [info ] [MainThread]: Running with dbt=1.0.1
12:50:19.775722 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
12:50:19.775953 [debug] [MainThread]: Tracking: tracking
12:50:19.776271 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110e43e80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110e43d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110e439d0>]}
12:50:19.822400 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
12:50:19.822733 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/my_second_dbt_model.sql
12:50:19.830192 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
12:50:19.856659 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c70dbfd4-d9be-495a-b9d0-78fd417eee6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110004ca0>]}
12:50:19.859602 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c70dbfd4-d9be-495a-b9d0-78fd417eee6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053821c0>]}
12:50:19.859741 [info ] [MainThread]: Found 6 models, 9 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
12:50:19.860561 [info ] [MainThread]: 
12:50:19.860837 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:50:19.861321 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
12:50:19.867637 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
12:50:19.867778 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
12:50:19.867846 [debug] [ThreadPool]: Opening a new connection, currently in state init
12:50:20.766303 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.9 seconds
12:50:20.768675 [debug] [ThreadPool]: On list_analytics: Close
12:50:21.081093 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
12:50:21.088948 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
12:50:21.089228 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
12:50:21.089377 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:50:21.651587 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 0.56 seconds
12:50:21.655311 [debug] [ThreadPool]: On list_analytics_dbt: Close
12:50:21.846358 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
12:50:21.847519 [info ] [MainThread]: 
12:50:21.852364 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
12:50:21.853110 [info ] [Thread-1  ]: 1 of 6 START incremental model dbt.dates........................................ [RUN]
12:50:21.853663 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
12:50:21.853847 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
12:50:21.854007 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
12:50:21.860863 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
12:50:21.861559 [debug] [Thread-1  ]: finished collecting timing info
12:50:21.861709 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
12:50:21.891699 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:50:21.891922 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
12:50:21.892014 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:50:24.130226 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.24 seconds
12:50:24.142821 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:50:24.143134 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
12:50:24.301365 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.16 seconds
12:50:24.309603 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:50:24.309896 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
12:50:24.418825 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.11 seconds
12:50:24.427789 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:50:24.428031 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
12:50:24.913828 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.49 seconds
12:50:24.937284 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
12:50:24.939636 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:50:24.939773 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
12:50:25.182711 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.24 seconds
12:50:25.183427 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:50:25.183633 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
12:50:25.798900 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.62 seconds
12:50:25.799649 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:50:25.799938 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
12:50:25.968948 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.17 seconds
12:50:25.982302 [debug] [Thread-1  ]: finished collecting timing info
12:50:25.982672 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
12:50:26.233782 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c70dbfd4-d9be-495a-b9d0-78fd417eee6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107f66a90>]}
12:50:26.234507 [info ] [Thread-1  ]: 1 of 6 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 4.38s]
12:50:26.235075 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
12:50:26.235396 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
12:50:26.235674 [info ] [Thread-1  ]: 2 of 6 START incremental model dbt.incremental_time............................. [RUN]
12:50:26.235952 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
12:50:26.236035 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
12:50:26.236119 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
12:50:26.237705 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
12:50:26.238073 [debug] [Thread-1  ]: finished collecting timing info
12:50:26.238157 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
12:50:26.240090 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:50:26.240435 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
12:50:26.240639 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:50:27.731614 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.49 seconds
12:50:27.736834 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:50:27.737165 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
12:50:29.016732 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 1.28 seconds
12:50:29.022047 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:50:29.022460 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
12:50:29.191814 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.17 seconds
12:50:29.196299 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:50:29.196567 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
12:50:29.375273 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.18 seconds
12:50:29.380184 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
12:50:29.382625 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:50:29.382850 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
12:50:29.525660 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.14 seconds
12:50:29.526788 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:50:29.527013 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
12:50:30.485822 [debug] [Thread-1  ]: SQL status: SUCCESS 105 in 0.96 seconds
12:50:30.486291 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:50:30.486479 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
12:50:31.012969 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.53 seconds
12:50:31.016903 [debug] [Thread-1  ]: finished collecting timing info
12:50:31.017149 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
12:50:31.189306 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c70dbfd4-d9be-495a-b9d0-78fd417eee6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1116d0430>]}
12:50:31.190113 [info ] [Thread-1  ]: 2 of 6 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 4.95s]
12:50:31.190564 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
12:50:31.190776 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
12:50:31.191118 [info ] [Thread-1  ]: 3 of 6 START table model dbt.first_model........................................ [RUN]
12:50:31.191691 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
12:50:31.191894 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
12:50:31.192058 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
12:50:31.195213 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
12:50:31.195802 [debug] [Thread-1  ]: finished collecting timing info
12:50:31.195928 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
12:50:31.202542 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
12:50:31.203195 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
12:50:31.203274 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *, True as first_variable
from source_data
where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
12:50:31.203337 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:50:32.667343 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.46 seconds
12:50:32.670654 [debug] [Thread-1  ]: finished collecting timing info
12:50:32.671073 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
12:50:33.044304 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c70dbfd4-d9be-495a-b9d0-78fd417eee6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1110f09d0>]}
12:50:33.045215 [info ] [Thread-1  ]: 3 of 6 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 1.85s]
12:50:33.045656 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
12:50:33.045778 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
12:50:33.046058 [info ] [Thread-1  ]: 4 of 6 START table model dbt.snowflake_cumulative_sales......................... [RUN]
12:50:33.046330 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
12:50:33.046417 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
12:50:33.046501 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
12:50:33.047287 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
12:50:33.047741 [debug] [Thread-1  ]: finished collecting timing info
12:50:33.047853 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
12:50:33.049642 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
12:50:33.050413 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
12:50:33.050524 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
12:50:33.050616 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:50:34.642762 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.59 seconds
12:50:34.646238 [debug] [Thread-1  ]: finished collecting timing info
12:50:34.646575 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
12:50:34.819159 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c70dbfd4-d9be-495a-b9d0-78fd417eee6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113d0a1c0>]}
12:50:34.819991 [info ] [Thread-1  ]: 4 of 6 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 1.77s]
12:50:34.820444 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
12:50:34.820694 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
12:50:34.821097 [info ] [Thread-1  ]: 5 of 6 START table model dbt.snowflake_customer_purchases....................... [RUN]
12:50:34.821748 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
12:50:34.821964 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
12:50:34.822175 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
12:50:34.823844 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
12:50:34.824525 [debug] [Thread-1  ]: finished collecting timing info
12:50:34.824692 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
12:50:34.826824 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
12:50:34.827685 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
12:50:34.827807 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
12:50:34.827907 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:50:37.000402 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.17 seconds
12:50:37.004176 [debug] [Thread-1  ]: finished collecting timing info
12:50:37.004510 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
12:50:37.337555 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c70dbfd4-d9be-495a-b9d0-78fd417eee6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1116a8250>]}
12:50:37.338428 [info ] [Thread-1  ]: 5 of 6 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.52s]
12:50:37.338889 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
12:50:37.339142 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
12:50:37.339559 [info ] [Thread-1  ]: 6 of 6 START table model dbt.my_second_dbt_model................................ [RUN]
12:50:37.340220 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
12:50:37.340455 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
12:50:37.340659 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
12:50:37.343146 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
12:50:37.343616 [debug] [Thread-1  ]: finished collecting timing info
12:50:37.343733 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
12:50:37.345198 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
12:50:37.345704 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
12:50:37.345802 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
union all
select 7 as id
      );
12:50:37.345888 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:50:38.054407 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a43d22-3201-9c86-0000-000120527171
12:50:38.054841 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 001789 (42601): SQL compilation error:
invalid number of result columns for set operator input branches, expected 2, got 1 in branch 2
12:50:38.055164 [debug] [Thread-1  ]: finished collecting timing info
12:50:38.055373 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
12:50:38.330522 [debug] [Thread-1  ]: Database Error in model my_second_dbt_model (models/example/my_second_dbt_model.sql)
  001789 (42601): SQL compilation error:
  invalid number of result columns for set operator input branches, expected 2, got 1 in branch 2
  compiled SQL at target/run/learn_dbt/models/example/my_second_dbt_model.sql
12:50:38.331337 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c70dbfd4-d9be-495a-b9d0-78fd417eee6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113d1b130>]}
12:50:38.331916 [error] [Thread-1  ]: 6 of 6 ERROR creating table model dbt.my_second_dbt_model....................... [[31mERROR[0m in 0.99s]
12:50:38.332531 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
12:50:38.333867 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:50:38.334367 [info ] [MainThread]: 
12:50:38.334699 [info ] [MainThread]: Finished running 2 incremental models, 4 table models in 18.47s.
12:50:38.334992 [debug] [MainThread]: Connection 'master' was properly closed.
12:50:38.335155 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
12:50:38.341941 [info ] [MainThread]: 
12:50:38.342274 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
12:50:38.342544 [info ] [MainThread]: 
12:50:38.342775 [error] [MainThread]: [33mDatabase Error in model my_second_dbt_model (models/example/my_second_dbt_model.sql)[0m
12:50:38.343002 [error] [MainThread]:   001789 (42601): SQL compilation error:
12:50:38.343221 [error] [MainThread]:   invalid number of result columns for set operator input branches, expected 2, got 1 in branch 2
12:50:38.343432 [error] [MainThread]:   compiled SQL at target/run/learn_dbt/models/example/my_second_dbt_model.sql
12:50:38.343626 [info ] [MainThread]: 
12:50:38.343814 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=1 SKIP=0 TOTAL=6
12:50:38.344091 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11154e5e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1101fd220>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1116d9790>]}


============================== 2022-05-13 12:52:22.827838 | d389c04d-7681-4f44-b5e3-cce5d7612073 ==============================
12:52:22.827838 [info ] [MainThread]: Running with dbt=1.0.1
12:52:22.828474 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
12:52:22.828608 [debug] [MainThread]: Tracking: tracking
12:52:22.828810 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107543370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107543be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075439d0>]}
12:52:22.873642 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
12:52:22.873967 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/my_second_dbt_model.sql
12:52:22.879670 [debug] [MainThread]: 1603: static parser failed on example/my_second_dbt_model.sql
12:52:22.886177 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_second_dbt_model.sql
12:52:22.905764 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd389c04d-7681-4f44-b5e3-cce5d7612073', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076c1ac0>]}
12:52:22.908763 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd389c04d-7681-4f44-b5e3-cce5d7612073', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105cbc430>]}
12:52:22.908898 [info ] [MainThread]: Found 6 models, 9 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
12:52:22.909645 [info ] [MainThread]: 
12:52:22.909845 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:52:22.910282 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
12:52:22.916228 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
12:52:22.916356 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
12:52:22.916418 [debug] [ThreadPool]: Opening a new connection, currently in state init
12:52:23.847243 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.93 seconds
12:52:23.850284 [debug] [ThreadPool]: On list_analytics: Close
12:52:24.060138 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
12:52:24.068554 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
12:52:24.068834 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
12:52:24.068997 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:52:24.714706 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 0.65 seconds
12:52:24.718470 [debug] [ThreadPool]: On list_analytics_dbt: Close
12:52:24.891068 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
12:52:24.891625 [info ] [MainThread]: 
12:52:24.897320 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
12:52:24.898251 [info ] [Thread-1  ]: 1 of 6 START incremental model dbt.dates........................................ [RUN]
12:52:24.898826 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
12:52:24.898994 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
12:52:24.899159 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
12:52:24.908756 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
12:52:24.909709 [debug] [Thread-1  ]: finished collecting timing info
12:52:24.909883 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
12:52:24.938128 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:52:24.938301 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
12:52:24.938388 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:52:26.643749 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.71 seconds
12:52:26.651936 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:52:26.652076 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
12:52:26.921792 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.27 seconds
12:52:26.927759 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:52:26.927961 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
12:52:27.026111 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.1 seconds
12:52:27.033250 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:52:27.033452 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
12:52:27.202454 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.17 seconds
12:52:27.229133 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
12:52:27.232342 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:52:27.232470 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
12:52:27.351722 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.12 seconds
12:52:27.353770 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:52:27.354128 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
12:52:28.010824 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.66 seconds
12:52:28.015390 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:52:28.015648 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
12:52:28.250236 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.23 seconds
12:52:28.264408 [debug] [Thread-1  ]: finished collecting timing info
12:52:28.264799 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
12:52:28.535300 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd389c04d-7681-4f44-b5e3-cce5d7612073', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059746a0>]}
12:52:28.535808 [info ] [Thread-1  ]: 1 of 6 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 3.64s]
12:52:28.536115 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
12:52:28.536289 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
12:52:28.536598 [info ] [Thread-1  ]: 2 of 6 START incremental model dbt.incremental_time............................. [RUN]
12:52:28.537083 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
12:52:28.537254 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
12:52:28.537416 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
12:52:28.540939 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
12:52:28.542445 [debug] [Thread-1  ]: finished collecting timing info
12:52:28.542612 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
12:52:28.546655 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:52:28.546964 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
12:52:28.547108 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:52:30.115990 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.57 seconds
12:52:30.121206 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:52:30.121560 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
12:52:30.546817 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.42 seconds
12:52:30.552452 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:52:30.552782 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
12:52:30.667653 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.11 seconds
12:52:30.672617 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:52:30.672853 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
12:52:30.791414 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.12 seconds
12:52:30.796966 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
12:52:30.799410 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:52:30.799627 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
12:52:31.067673 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.27 seconds
12:52:31.068239 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:52:31.068417 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
12:52:32.117046 [debug] [Thread-1  ]: SQL status: SUCCESS 123 in 1.05 seconds
12:52:32.118145 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:52:32.118357 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
12:52:32.641195 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.52 seconds
12:52:32.649863 [debug] [Thread-1  ]: finished collecting timing info
12:52:32.650500 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
12:52:32.820370 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd389c04d-7681-4f44-b5e3-cce5d7612073', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107c97e80>]}
12:52:32.821169 [info ] [Thread-1  ]: 2 of 6 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 4.28s]
12:52:32.821608 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
12:52:32.821835 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
12:52:32.822251 [info ] [Thread-1  ]: 3 of 6 START table model dbt.first_model........................................ [RUN]
12:52:32.822882 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
12:52:32.823060 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
12:52:32.823222 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
12:52:32.826981 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
12:52:32.828799 [debug] [Thread-1  ]: finished collecting timing info
12:52:32.829053 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
12:52:32.838152 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
12:52:32.839209 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
12:52:32.839355 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *, True as first_variable
from source_data
where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
12:52:32.839470 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:52:34.149356 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.31 seconds
12:52:34.151577 [debug] [Thread-1  ]: finished collecting timing info
12:52:34.151780 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
12:52:34.324904 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd389c04d-7681-4f44-b5e3-cce5d7612073', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d16f10>]}
12:52:34.325845 [info ] [Thread-1  ]: 3 of 6 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 1.50s]
12:52:34.326318 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
12:52:34.326583 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
12:52:34.327056 [info ] [Thread-1  ]: 4 of 6 START table model dbt.snowflake_cumulative_sales......................... [RUN]
12:52:34.327978 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
12:52:34.328381 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
12:52:34.328621 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
12:52:34.330407 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
12:52:34.332478 [debug] [Thread-1  ]: finished collecting timing info
12:52:34.332765 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
12:52:34.335297 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
12:52:34.336428 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
12:52:34.336604 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
12:52:34.336783 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:52:36.245824 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.91 seconds
12:52:36.249069 [debug] [Thread-1  ]: finished collecting timing info
12:52:36.249471 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
12:52:36.437459 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd389c04d-7681-4f44-b5e3-cce5d7612073', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107aead60>]}
12:52:36.438175 [info ] [Thread-1  ]: 4 of 6 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 2.11s]
12:52:36.438620 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
12:52:36.438861 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
12:52:36.439281 [info ] [Thread-1  ]: 5 of 6 START table model dbt.snowflake_customer_purchases....................... [RUN]
12:52:36.439988 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
12:52:36.440196 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
12:52:36.440394 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
12:52:36.442062 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
12:52:36.442876 [debug] [Thread-1  ]: finished collecting timing info
12:52:36.443074 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
12:52:36.445545 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
12:52:36.446805 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
12:52:36.446981 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
12:52:36.447124 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:52:38.500606 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.05 seconds
12:52:38.504013 [debug] [Thread-1  ]: finished collecting timing info
12:52:38.504461 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
12:52:38.739077 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd389c04d-7681-4f44-b5e3-cce5d7612073', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d4e9a0>]}
12:52:38.739690 [info ] [Thread-1  ]: 5 of 6 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.30s]
12:52:38.740106 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
12:52:38.740345 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
12:52:38.740741 [info ] [Thread-1  ]: 6 of 6 START table model dbt.my_second_dbt_model................................ [RUN]
12:52:38.741409 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
12:52:38.741642 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
12:52:38.741847 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
12:52:38.745423 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
12:52:38.747215 [debug] [Thread-1  ]: finished collecting timing info
12:52:38.747423 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
12:52:38.750146 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
12:52:38.751044 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
12:52:38.751377 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
union all
select 7 as id, , True as first_variable
      );
12:52:38.751561 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:52:39.404893 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a43d24-3201-9c86-0000-000120527199
12:52:39.405327 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 7 at position 16 unexpected ','.
12:52:39.405701 [debug] [Thread-1  ]: finished collecting timing info
12:52:39.405936 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
12:52:39.568358 [debug] [Thread-1  ]: Database Error in model my_second_dbt_model (models/example/my_second_dbt_model.sql)
  001003 (42000): SQL compilation error:
  syntax error line 7 at position 16 unexpected ','.
  compiled SQL at target/run/learn_dbt/models/example/my_second_dbt_model.sql
12:52:39.569028 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd389c04d-7681-4f44-b5e3-cce5d7612073', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d683a0>]}
12:52:39.569459 [error] [Thread-1  ]: 6 of 6 ERROR creating table model dbt.my_second_dbt_model....................... [[31mERROR[0m in 0.83s]
12:52:39.569853 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
12:52:39.571031 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:52:39.571389 [info ] [MainThread]: 
12:52:39.571620 [info ] [MainThread]: Finished running 2 incremental models, 4 table models in 16.66s.
12:52:39.571828 [debug] [MainThread]: Connection 'master' was properly closed.
12:52:39.571951 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
12:52:39.577392 [info ] [MainThread]: 
12:52:39.577633 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
12:52:39.577827 [info ] [MainThread]: 
12:52:39.577992 [error] [MainThread]: [33mDatabase Error in model my_second_dbt_model (models/example/my_second_dbt_model.sql)[0m
12:52:39.578161 [error] [MainThread]:   001003 (42000): SQL compilation error:
12:52:39.578318 [error] [MainThread]:   syntax error line 7 at position 16 unexpected ','.
12:52:39.578470 [error] [MainThread]:   compiled SQL at target/run/learn_dbt/models/example/my_second_dbt_model.sql
12:52:39.578635 [info ] [MainThread]: 
12:52:39.578793 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=1 SKIP=0 TOTAL=6
12:52:39.579037 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076e38b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076e35e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b34d90>]}


============================== 2022-05-13 12:53:09.438040 | da8ed36b-cc12-49f7-8fa7-df42e439473f ==============================
12:53:09.438040 [info ] [MainThread]: Running with dbt=1.0.1
12:53:09.438468 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
12:53:09.438606 [debug] [MainThread]: Tracking: tracking
12:53:09.438847 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1091eb250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1091ebb80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1091eb910>]}
12:53:09.480364 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
12:53:09.480673 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/my_second_dbt_model.sql
12:53:09.489052 [debug] [MainThread]: 1603: static parser failed on example/my_second_dbt_model.sql
12:53:09.495431 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_second_dbt_model.sql
12:53:09.516752 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'da8ed36b-cc12-49f7-8fa7-df42e439473f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108301700>]}
12:53:09.520098 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'da8ed36b-cc12-49f7-8fa7-df42e439473f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10565f610>]}
12:53:09.520241 [info ] [MainThread]: Found 6 models, 9 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
12:53:09.520950 [info ] [MainThread]: 
12:53:09.521153 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:53:09.521665 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
12:53:09.528058 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
12:53:09.528200 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
12:53:09.528272 [debug] [ThreadPool]: Opening a new connection, currently in state init
12:53:10.588507 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.06 seconds
12:53:10.590681 [debug] [ThreadPool]: On list_analytics: Close
12:53:12.737243 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
12:53:12.746375 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
12:53:12.746646 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
12:53:12.746813 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:53:13.617452 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 0.87 seconds
12:53:13.620420 [debug] [ThreadPool]: On list_analytics_dbt: Close
12:53:13.819872 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
12:53:13.823115 [info ] [MainThread]: 
12:53:13.826511 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
12:53:13.827089 [info ] [Thread-1  ]: 1 of 6 START incremental model dbt.dates........................................ [RUN]
12:53:13.827597 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
12:53:13.827724 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
12:53:13.827897 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
12:53:13.833534 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
12:53:13.834007 [debug] [Thread-1  ]: finished collecting timing info
12:53:13.834114 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
12:53:13.862950 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:53:13.863189 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
12:53:13.863296 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:53:15.134268 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.27 seconds
12:53:15.146604 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:53:15.146954 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
12:53:15.270624 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.12 seconds
12:53:15.277274 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:53:15.277564 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
12:53:15.567202 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.29 seconds
12:53:15.579842 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:53:15.580147 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
12:53:15.678496 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.1 seconds
12:53:15.704432 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
12:53:15.707233 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:53:15.707472 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
12:53:15.882052 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.17 seconds
12:53:15.882778 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:53:15.883571 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
12:53:16.222143 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.34 seconds
12:53:16.222824 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:53:16.223436 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
12:53:16.614707 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.39 seconds
12:53:16.624646 [debug] [Thread-1  ]: finished collecting timing info
12:53:16.624958 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
12:53:16.826344 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'da8ed36b-cc12-49f7-8fa7-df42e439473f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106d3eee0>]}
12:53:16.827073 [info ] [Thread-1  ]: 1 of 6 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 3.00s]
12:53:16.827531 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
12:53:16.827782 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
12:53:16.828177 [info ] [Thread-1  ]: 2 of 6 START incremental model dbt.incremental_time............................. [RUN]
12:53:16.828799 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
12:53:16.829026 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
12:53:16.829228 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
12:53:16.833037 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
12:53:16.833777 [debug] [Thread-1  ]: finished collecting timing info
12:53:16.833985 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
12:53:16.837669 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:53:16.837856 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
12:53:16.837987 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:53:18.194592 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.36 seconds
12:53:18.199632 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:53:18.200007 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
12:53:18.352551 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.15 seconds
12:53:18.357860 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:53:18.358304 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
12:53:18.475695 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.12 seconds
12:53:18.483638 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:53:18.484040 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
12:53:18.715383 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.23 seconds
12:53:18.720252 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
12:53:18.722624 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:53:18.722813 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
12:53:18.857796 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.13 seconds
12:53:18.858348 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:53:18.858461 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
12:53:19.627893 [debug] [Thread-1  ]: SQL status: SUCCESS 48 in 0.77 seconds
12:53:19.628665 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:53:19.628867 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
12:53:19.897705 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.27 seconds
12:53:19.900839 [debug] [Thread-1  ]: finished collecting timing info
12:53:19.901076 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
12:53:20.103694 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'da8ed36b-cc12-49f7-8fa7-df42e439473f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ab4da00>]}
12:53:20.104193 [info ] [Thread-1  ]: 2 of 6 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 3.28s]
12:53:20.104518 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
12:53:20.104694 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
12:53:20.104984 [info ] [Thread-1  ]: 3 of 6 START table model dbt.first_model........................................ [RUN]
12:53:20.105494 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
12:53:20.105646 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
12:53:20.105789 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
12:53:20.109174 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
12:53:20.109920 [debug] [Thread-1  ]: finished collecting timing info
12:53:20.110105 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
12:53:20.119010 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
12:53:20.120069 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
12:53:20.120211 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *, True as first_variable
from source_data
where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
12:53:20.120330 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:53:21.881709 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.76 seconds
12:53:21.885268 [debug] [Thread-1  ]: finished collecting timing info
12:53:21.885729 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
12:53:22.122921 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'da8ed36b-cc12-49f7-8fa7-df42e439473f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aa16340>]}
12:53:22.123575 [info ] [Thread-1  ]: 3 of 6 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 2.02s]
12:53:22.123993 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
12:53:22.124276 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
12:53:22.124591 [info ] [Thread-1  ]: 4 of 6 START table model dbt.snowflake_cumulative_sales......................... [RUN]
12:53:22.125080 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
12:53:22.125389 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
12:53:22.125778 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
12:53:22.127848 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
12:53:22.128669 [debug] [Thread-1  ]: finished collecting timing info
12:53:22.128867 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
12:53:22.131371 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
12:53:22.132328 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
12:53:22.132498 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
12:53:22.132643 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:53:23.701730 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.57 seconds
12:53:23.705156 [debug] [Thread-1  ]: finished collecting timing info
12:53:23.705412 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
12:53:23.924966 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'da8ed36b-cc12-49f7-8fa7-df42e439473f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ac0fd30>]}
12:53:23.925919 [info ] [Thread-1  ]: 4 of 6 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 1.80s]
12:53:23.926221 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
12:53:23.926338 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
12:53:23.926452 [info ] [Thread-1  ]: 5 of 6 START table model dbt.snowflake_customer_purchases....................... [RUN]
12:53:23.926702 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
12:53:23.926781 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
12:53:23.926860 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
12:53:23.927650 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
12:53:23.928397 [debug] [Thread-1  ]: finished collecting timing info
12:53:23.928680 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
12:53:23.931851 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
12:53:23.933173 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
12:53:23.933367 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
12:53:23.933525 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:53:25.828813 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.9 seconds
12:53:25.831548 [debug] [Thread-1  ]: finished collecting timing info
12:53:25.832011 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
12:53:26.077021 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'da8ed36b-cc12-49f7-8fa7-df42e439473f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ac12b50>]}
12:53:26.077774 [info ] [Thread-1  ]: 5 of 6 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.15s]
12:53:26.078181 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
12:53:26.078433 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
12:53:26.078902 [info ] [Thread-1  ]: 6 of 6 START table model dbt.my_second_dbt_model................................ [RUN]
12:53:26.079437 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
12:53:26.079620 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
12:53:26.079789 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
12:53:26.082788 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
12:53:26.083416 [debug] [Thread-1  ]: finished collecting timing info
12:53:26.083598 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
12:53:26.086111 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
12:53:26.087002 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
12:53:26.087168 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
union all
select 7 as id, True as first_variable
      );
12:53:26.087321 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:53:27.385385 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.3 seconds
12:53:27.388204 [debug] [Thread-1  ]: finished collecting timing info
12:53:27.388670 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
12:53:27.626164 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'da8ed36b-cc12-49f7-8fa7-df42e439473f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ac0ff70>]}
12:53:27.626946 [info ] [Thread-1  ]: 6 of 6 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.55s]
12:53:27.627409 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
12:53:27.628821 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:53:27.629401 [info ] [MainThread]: 
12:53:27.629769 [info ] [MainThread]: Finished running 2 incremental models, 4 table models in 18.11s.
12:53:27.630084 [debug] [MainThread]: Connection 'master' was properly closed.
12:53:27.630254 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
12:53:27.636984 [info ] [MainThread]: 
12:53:27.637392 [info ] [MainThread]: [32mCompleted successfully[0m
12:53:27.637711 [info ] [MainThread]: 
12:53:27.637946 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
12:53:27.638262 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a8f3b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a8f8f40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10abcf280>]}


============================== 2022-05-13 12:53:31.690788 | f5f5cdad-3550-4e7b-b3ab-70463e0bcb5f ==============================
12:53:31.690788 [info ] [MainThread]: Running with dbt=1.0.1
12:53:31.691185 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, store_failures=False, indirect_selection='eager', threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.test.TestTask'>, which='test', rpc_method='test')
12:53:31.691333 [debug] [MainThread]: Tracking: tracking
12:53:31.691557 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1134d3070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1134d31c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1134d3d60>]}
12:53:31.735060 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
12:53:31.735209 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
12:53:31.738439 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f5f5cdad-3550-4e7b-b3ab-70463e0bcb5f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11348f100>]}
12:53:31.741841 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f5f5cdad-3550-4e7b-b3ab-70463e0bcb5f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1129b4dc0>]}
12:53:31.741977 [info ] [MainThread]: Found 6 models, 9 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
12:53:31.742772 [info ] [MainThread]: 
12:53:31.742980 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:53:31.743476 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
12:53:31.749428 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
12:53:31.749544 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
12:53:31.749613 [debug] [ThreadPool]: Opening a new connection, currently in state init
12:53:32.637155 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 0.89 seconds
12:53:32.639830 [debug] [ThreadPool]: On list_analytics_dbt: Close
12:53:32.959954 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
12:53:32.960678 [info ] [MainThread]: 
12:53:32.965043 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_my_first_dbt_model_id.5fb22c2710
12:53:32.965405 [info ] [Thread-1  ]: 1 of 9 START test not_null_my_first_dbt_model_id................................ [RUN]
12:53:32.965933 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_my_first_dbt_model_id.5fb22c2710"
12:53:32.966104 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_my_first_dbt_model_id.5fb22c2710
12:53:32.966273 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_my_first_dbt_model_id.5fb22c2710
12:53:32.977628 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_my_first_dbt_model_id.5fb22c2710"
12:53:32.979193 [debug] [Thread-1  ]: finished collecting timing info
12:53:32.979348 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_my_first_dbt_model_id.5fb22c2710
12:53:32.992515 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_my_first_dbt_model_id.5fb22c2710"
12:53:32.993316 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_my_first_dbt_model_id.5fb22c2710"
12:53:32.993452 [debug] [Thread-1  ]: On test.learn_dbt.not_null_my_first_dbt_model_id.5fb22c2710: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_my_first_dbt_model_id.5fb22c2710"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.first_model
where id is null



      
    ) dbt_internal_test
12:53:32.993551 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:53:33.915858 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.92 seconds
12:53:33.919959 [debug] [Thread-1  ]: finished collecting timing info
12:53:33.920369 [debug] [Thread-1  ]: On test.learn_dbt.not_null_my_first_dbt_model_id.5fb22c2710: Close
12:53:34.098869 [info ] [Thread-1  ]: 1 of 9 PASS not_null_my_first_dbt_model_id...................................... [[32mPASS[0m in 1.13s]
12:53:34.099481 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_my_first_dbt_model_id.5fb22c2710
12:53:34.099757 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
12:53:34.100079 [info ] [Thread-1  ]: 2 of 9 START test not_null_my_second_dbt_model_id............................... [RUN]
12:53:34.100724 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"
12:53:34.101016 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
12:53:34.101234 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
12:53:34.104677 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"
12:53:34.105269 [debug] [Thread-1  ]: finished collecting timing info
12:53:34.105402 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
12:53:34.106700 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"
12:53:34.107402 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"
12:53:34.107524 [debug] [Thread-1  ]: On test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.my_second_dbt_model
where id is null



      
    ) dbt_internal_test
12:53:34.107636 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:53:35.199460 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.09 seconds
12:53:35.202309 [debug] [Thread-1  ]: finished collecting timing info
12:53:35.202731 [debug] [Thread-1  ]: On test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778: Close
12:53:35.593528 [info ] [Thread-1  ]: 2 of 9 PASS not_null_my_second_dbt_model_id..................................... [[32mPASS[0m in 1.49s]
12:53:35.594513 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
12:53:35.595039 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
12:53:35.595475 [info ] [Thread-1  ]: 3 of 9 START test not_null_snowflake_cumulative_sales_o_orderdate............... [RUN]
12:53:35.596165 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
12:53:35.596420 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
12:53:35.596650 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
12:53:35.601534 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
12:53:35.602404 [debug] [Thread-1  ]: finished collecting timing info
12:53:35.602618 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
12:53:35.605010 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
12:53:35.606011 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
12:53:35.606176 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.snowflake_cumulative_sales
where o_orderdate is null



      
    ) dbt_internal_test
12:53:35.606320 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:53:36.766409 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.16 seconds
12:53:36.772325 [debug] [Thread-1  ]: finished collecting timing info
12:53:36.772859 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856: Close
12:53:37.061716 [info ] [Thread-1  ]: 3 of 9 PASS not_null_snowflake_cumulative_sales_o_orderdate..................... [[32mPASS[0m in 1.47s]
12:53:37.062930 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
12:53:37.063275 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
12:53:37.063619 [info ] [Thread-1  ]: 4 of 9 START test not_null_snowflake_customer_purchases_c_custkey............... [RUN]
12:53:37.064297 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
12:53:37.064508 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
12:53:37.064708 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
12:53:37.069506 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
12:53:37.070278 [debug] [Thread-1  ]: finished collecting timing info
12:53:37.070460 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
12:53:37.072715 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
12:53:37.073728 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
12:53:37.073891 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.snowflake_customer_purchases
where c_custkey is null



      
    ) dbt_internal_test
12:53:37.074033 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:53:37.924046 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.85 seconds
12:53:37.926814 [debug] [Thread-1  ]: finished collecting timing info
12:53:37.927130 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502: Close
12:53:38.216511 [info ] [Thread-1  ]: 4 of 9 PASS not_null_snowflake_customer_purchases_c_custkey..................... [[32mPASS[0m in 1.15s]
12:53:38.217119 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
12:53:38.217379 [debug] [Thread-1  ]: Began running node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
12:53:38.217694 [info ] [Thread-1  ]: 5 of 9 START test relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ [RUN]
12:53:38.218334 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
12:53:38.218544 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
12:53:38.218737 [debug] [Thread-1  ]: Compiling test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
12:53:38.229352 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
12:53:38.230123 [debug] [Thread-1  ]: finished collecting timing info
12:53:38.230292 [debug] [Thread-1  ]: Began executing node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
12:53:38.232178 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
12:53:38.233382 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
12:53:38.233579 [debug] [Thread-1  ]: On test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select id as from_field
    from analytics.dbt.my_second_dbt_model
    where id is not null
),

parent as (
    select id as to_field
    from analytics.dbt.first_model
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
12:53:38.233726 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:53:39.157012 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.92 seconds
12:53:39.159469 [debug] [Thread-1  ]: finished collecting timing info
12:53:39.159821 [debug] [Thread-1  ]: On test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: Close
12:53:39.347609 [error] [Thread-1  ]: 5 of 9 FAIL 1 relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_. [[31mFAIL 1[0m in 1.13s]
12:53:39.348102 [debug] [Thread-1  ]: Finished running node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
12:53:39.348258 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
12:53:39.348478 [info ] [Thread-1  ]: 6 of 9 START test unique_my_first_dbt_model_id.................................. [RUN]
12:53:39.348843 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
12:53:39.348975 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
12:53:39.349097 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
12:53:39.355424 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
12:53:39.356016 [debug] [Thread-1  ]: finished collecting timing info
12:53:39.356171 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
12:53:39.357952 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
12:53:39.359065 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
12:53:39.359359 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.first_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
12:53:39.359511 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:53:39.989008 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.63 seconds
12:53:39.992280 [debug] [Thread-1  ]: finished collecting timing info
12:53:39.992684 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_first_dbt_model_id.16e066b321: Close
12:53:40.361342 [info ] [Thread-1  ]: 6 of 9 PASS unique_my_first_dbt_model_id........................................ [[32mPASS[0m in 1.01s]
12:53:40.361983 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
12:53:40.362203 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
12:53:40.362609 [info ] [Thread-1  ]: 7 of 9 START test unique_my_second_dbt_model_id................................. [RUN]
12:53:40.363145 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
12:53:40.363313 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
12:53:40.363473 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
12:53:40.367727 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
12:53:40.368365 [debug] [Thread-1  ]: finished collecting timing info
12:53:40.368532 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
12:53:40.370715 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
12:53:40.371804 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
12:53:40.371971 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.my_second_dbt_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
12:53:40.372117 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:53:41.320565 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.95 seconds
12:53:41.324352 [debug] [Thread-1  ]: finished collecting timing info
12:53:41.324666 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493: Close
12:53:41.500391 [info ] [Thread-1  ]: 7 of 9 PASS unique_my_second_dbt_model_id....................................... [[32mPASS[0m in 1.14s]
12:53:41.501530 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
12:53:41.501865 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
12:53:41.502198 [info ] [Thread-1  ]: 8 of 9 START test unique_snowflake_cumulative_sales_o_orderdate................. [RUN]
12:53:41.502763 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
12:53:41.502973 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
12:53:41.503170 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
12:53:41.508021 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
12:53:41.508609 [debug] [Thread-1  ]: finished collecting timing info
12:53:41.508783 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
12:53:41.511008 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
12:53:41.512198 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
12:53:41.512431 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    o_orderdate as unique_field,
    count(*) as n_records

from analytics.dbt.snowflake_cumulative_sales
where o_orderdate is not null
group by o_orderdate
having count(*) > 1



      
    ) dbt_internal_test
12:53:41.512630 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:53:43.056064 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.54 seconds
12:53:43.058775 [debug] [Thread-1  ]: finished collecting timing info
12:53:43.059139 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed: Close
12:53:43.351762 [info ] [Thread-1  ]: 8 of 9 PASS unique_snowflake_cumulative_sales_o_orderdate....................... [[32mPASS[0m in 1.85s]
12:53:43.353454 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
12:53:43.353713 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
12:53:43.353907 [info ] [Thread-1  ]: 9 of 9 START test unique_snowflake_customer_purchases_c_custkey................. [RUN]
12:53:43.354464 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
12:53:43.354667 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
12:53:43.355254 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
12:53:43.360382 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
12:53:43.361087 [debug] [Thread-1  ]: finished collecting timing info
12:53:43.361273 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
12:53:43.363412 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
12:53:43.364516 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
12:53:43.364681 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    c_custkey as unique_field,
    count(*) as n_records

from analytics.dbt.snowflake_customer_purchases
where c_custkey is not null
group by c_custkey
having count(*) > 1



      
    ) dbt_internal_test
12:53:43.364827 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:53:44.181606 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.82 seconds
12:53:44.185440 [debug] [Thread-1  ]: finished collecting timing info
12:53:44.185736 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f: Close
12:53:44.490884 [info ] [Thread-1  ]: 9 of 9 PASS unique_snowflake_customer_purchases_c_custkey....................... [[32mPASS[0m in 1.14s]
12:53:44.491884 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
12:53:44.494118 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:53:44.494763 [info ] [MainThread]: 
12:53:44.495139 [info ] [MainThread]: Finished running 9 tests in 12.75s.
12:53:44.495450 [debug] [MainThread]: Connection 'master' was properly closed.
12:53:44.495616 [debug] [MainThread]: Connection 'test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f' was properly closed.
12:53:44.502621 [info ] [MainThread]: 
12:53:44.502978 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
12:53:44.503271 [info ] [MainThread]: 
12:53:44.503506 [error] [MainThread]: [31mFailure in test relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ (models/example/schema.yml)[0m
12:53:44.504020 [error] [MainThread]:   Got 1 result, configured to fail if != 0
12:53:44.504429 [info ] [MainThread]: 
12:53:44.504693 [info ] [MainThread]:   compiled SQL at target/compiled/learn_dbt/models/example/schema.yml/relationships_my_second_dbt_mo_160f86f0431c50a9f09003e4d3e6dceb.sql
12:53:44.504952 [info ] [MainThread]: 
12:53:44.505172 [info ] [MainThread]: Done. PASS=8 WARN=0 ERROR=1 SKIP=0 TOTAL=9
12:53:44.505450 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11499de50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1134b0970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1168c7340>]}


============================== 2022-05-13 13:05:49.834436 | 469b18c5-b0f8-4334-a76f-246ce3fdd2fe ==============================
13:05:49.834436 [info ] [MainThread]: Running with dbt=1.0.1
13:05:49.834947 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
13:05:49.835084 [debug] [MainThread]: Tracking: tracking
13:05:49.835347 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1118896a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1118895b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111889250>]}
13:05:49.883933 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 2 files changed.
13:05:49.884269 [debug] [MainThread]: Partial parsing: added file: learn_dbt://tests/assert_under_10_percent_null.sql
13:05:49.884483 [debug] [MainThread]: Partial parsing: update schema file: learn_dbt://models/example/schema.yml
13:05:49.884578 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/my_first_dbt_model.sql
13:05:49.890596 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
13:05:49.897774 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
13:05:49.916011 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '469b18c5-b0f8-4334-a76f-246ce3fdd2fe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111af5fa0>]}
13:05:49.919045 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '469b18c5-b0f8-4334-a76f-246ce3fdd2fe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b2a580>]}
13:05:49.919184 [info ] [MainThread]: Found 6 models, 9 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
13:05:49.919918 [info ] [MainThread]: 
13:05:49.920117 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:05:49.920545 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
13:05:49.926492 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
13:05:49.926591 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
13:05:49.926653 [debug] [ThreadPool]: Opening a new connection, currently in state init
13:05:51.034014 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.11 seconds
13:05:51.036399 [debug] [ThreadPool]: On list_analytics: Close
13:05:51.229914 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
13:05:51.238546 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
13:05:51.238806 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
13:05:51.238941 [debug] [ThreadPool]: Opening a new connection, currently in state closed
13:05:52.238878 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1.0 seconds
13:05:52.241811 [debug] [ThreadPool]: On list_analytics_dbt: Close
13:05:52.475735 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
13:05:52.476253 [info ] [MainThread]: 
13:05:52.480632 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
13:05:52.481388 [info ] [Thread-1  ]: 1 of 6 START incremental model dbt.dates........................................ [RUN]
13:05:52.481910 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
13:05:52.482067 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
13:05:52.482222 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
13:05:52.492489 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
13:05:52.493483 [debug] [Thread-1  ]: finished collecting timing info
13:05:52.493682 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
13:05:52.525158 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:05:52.525356 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
13:05:52.525441 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:05:54.176758 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.65 seconds
13:05:54.189045 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:05:54.189312 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
13:05:54.292377 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.1 seconds
13:05:54.300579 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:05:54.300896 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
13:05:54.445705 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.14 seconds
13:05:54.456223 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:05:54.456489 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
13:05:54.610735 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.15 seconds
13:05:54.636013 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
13:05:54.638316 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:05:54.638448 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
13:05:54.768611 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.13 seconds
13:05:54.769583 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:05:54.769810 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
13:05:55.056013 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.29 seconds
13:05:55.056621 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:05:55.056807 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
13:05:55.397468 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.34 seconds
13:05:55.406641 [debug] [Thread-1  ]: finished collecting timing info
13:05:55.406898 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
13:05:55.622071 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '469b18c5-b0f8-4334-a76f-246ce3fdd2fe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b2a520>]}
13:05:55.622415 [info ] [Thread-1  ]: 1 of 6 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 3.14s]
13:05:55.622632 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
13:05:55.622754 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
13:05:55.623004 [info ] [Thread-1  ]: 2 of 6 START incremental model dbt.incremental_time............................. [RUN]
13:05:55.623359 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
13:05:55.623469 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
13:05:55.623569 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
13:05:55.626323 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
13:05:55.627152 [debug] [Thread-1  ]: finished collecting timing info
13:05:55.627316 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
13:05:55.629626 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:05:55.629742 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
13:05:55.629822 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:05:57.115483 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.49 seconds
13:05:57.117569 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:05:57.117679 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
13:05:57.321961 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.2 seconds
13:05:57.327507 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:05:57.327846 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
13:05:57.431484 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
13:05:57.434304 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:05:57.434455 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
13:05:57.588450 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.15 seconds
13:05:57.594617 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
13:05:57.597066 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:05:57.597272 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
13:05:57.732831 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.14 seconds
13:05:57.733541 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:05:57.734392 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
13:05:58.459723 [debug] [Thread-1  ]: SQL status: SUCCESS 759 in 0.72 seconds
13:05:58.460524 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:05:58.461015 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
13:05:58.766910 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.31 seconds
13:05:58.768671 [debug] [Thread-1  ]: finished collecting timing info
13:05:58.768888 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
13:05:58.970122 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '469b18c5-b0f8-4334-a76f-246ce3fdd2fe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112a50220>]}
13:05:58.971084 [info ] [Thread-1  ]: 2 of 6 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 3.35s]
13:05:58.971710 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
13:05:58.971967 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
13:05:58.972393 [info ] [Thread-1  ]: 3 of 6 START table model dbt.first_model........................................ [RUN]
13:05:58.973320 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
13:05:58.973550 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
13:05:58.973749 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
13:05:58.978064 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
13:05:58.978858 [debug] [Thread-1  ]: finished collecting timing info
13:05:58.979030 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
13:05:58.988064 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
13:05:58.989007 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
13:05:58.989139 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id

)

select *, True as first_variable
from source_data
where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
13:05:58.989248 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:06:00.084650 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.1 seconds
13:06:00.088253 [debug] [Thread-1  ]: finished collecting timing info
13:06:00.088558 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
13:06:00.273159 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '469b18c5-b0f8-4334-a76f-246ce3fdd2fe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112a62790>]}
13:06:00.273764 [info ] [Thread-1  ]: 3 of 6 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 1.30s]
13:06:00.274137 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
13:06:00.274327 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
13:06:00.274793 [info ] [Thread-1  ]: 4 of 6 START table model dbt.snowflake_cumulative_sales......................... [RUN]
13:06:00.275668 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
13:06:00.275852 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
13:06:00.276001 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
13:06:00.277436 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
13:06:00.278057 [debug] [Thread-1  ]: finished collecting timing info
13:06:00.278222 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
13:06:00.280574 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
13:06:00.281585 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
13:06:00.281748 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
13:06:00.281880 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:06:02.104617 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.82 seconds
13:06:02.107080 [debug] [Thread-1  ]: finished collecting timing info
13:06:02.107380 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
13:06:02.297276 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '469b18c5-b0f8-4334-a76f-246ce3fdd2fe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111f373a0>]}
13:06:02.298655 [info ] [Thread-1  ]: 4 of 6 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 2.02s]
13:06:02.299031 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
13:06:02.299223 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
13:06:02.299579 [info ] [Thread-1  ]: 5 of 6 START table model dbt.snowflake_customer_purchases....................... [RUN]
13:06:02.300135 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
13:06:02.300318 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
13:06:02.300486 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
13:06:02.302092 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
13:06:02.302783 [debug] [Thread-1  ]: finished collecting timing info
13:06:02.302939 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
13:06:02.306007 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
13:06:02.306669 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
13:06:02.306765 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
13:06:02.306850 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:06:04.373365 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.07 seconds
13:06:04.377045 [debug] [Thread-1  ]: finished collecting timing info
13:06:04.377409 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
13:06:04.666534 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '469b18c5-b0f8-4334-a76f-246ce3fdd2fe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112adce20>]}
13:06:04.667184 [info ] [Thread-1  ]: 5 of 6 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.37s]
13:06:04.667609 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
13:06:04.667843 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
13:06:04.668251 [info ] [Thread-1  ]: 6 of 6 START table model dbt.my_second_dbt_model................................ [RUN]
13:06:04.668958 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
13:06:04.669217 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
13:06:04.669430 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
13:06:04.672739 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
13:06:04.673596 [debug] [Thread-1  ]: finished collecting timing info
13:06:04.673780 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
13:06:04.676378 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
13:06:04.677338 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
13:06:04.677505 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
union all
select 7 as id, True as first_variable
      );
13:06:04.677635 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:06:06.233876 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.56 seconds
13:06:06.235795 [debug] [Thread-1  ]: finished collecting timing info
13:06:06.236030 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
13:06:06.391025 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '469b18c5-b0f8-4334-a76f-246ce3fdd2fe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111f379a0>]}
13:06:06.394313 [info ] [Thread-1  ]: 6 of 6 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.72s]
13:06:06.394995 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
13:06:06.396375 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:06:06.396885 [info ] [MainThread]: 
13:06:06.397186 [info ] [MainThread]: Finished running 2 incremental models, 4 table models in 16.48s.
13:06:06.397437 [debug] [MainThread]: Connection 'master' was properly closed.
13:06:06.397567 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
13:06:06.403800 [info ] [MainThread]: 
13:06:06.404026 [info ] [MainThread]: [32mCompleted successfully[0m
13:06:06.404193 [info ] [MainThread]: 
13:06:06.404317 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
13:06:06.404511 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110428970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10542b610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111f71760>]}


============================== 2022-05-13 13:06:16.684992 | c1490610-309a-4928-87a9-0aeb4bb34692 ==============================
13:06:16.684992 [info ] [MainThread]: Running with dbt=1.0.1
13:06:16.685385 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, store_failures=False, indirect_selection='eager', threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.test.TestTask'>, which='test', rpc_method='test')
13:06:16.685516 [debug] [MainThread]: Tracking: tracking
13:06:16.685752 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1084d30a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1084d3b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1084d33a0>]}
13:06:16.731736 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
13:06:16.731912 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
13:06:16.735521 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c1490610-309a-4928-87a9-0aeb4bb34692', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10849d100>]}
13:06:16.739132 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c1490610-309a-4928-87a9-0aeb4bb34692', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106100070>]}
13:06:16.739291 [info ] [MainThread]: Found 6 models, 9 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
13:06:16.740097 [info ] [MainThread]: 
13:06:16.740317 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:06:16.740809 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
13:06:16.747036 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
13:06:16.747186 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
13:06:16.747252 [debug] [ThreadPool]: Opening a new connection, currently in state init
13:06:17.752612 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1.01 seconds
13:06:17.756065 [debug] [ThreadPool]: On list_analytics_dbt: Close
13:06:17.956293 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
13:06:17.957042 [info ] [MainThread]: 
13:06:17.968617 [debug] [Thread-1  ]: Began running node test.learn_dbt.assert_under_10_percent_null
13:06:17.968895 [info ] [Thread-1  ]: 1 of 9 START test assert_under_10_percent_null.................................. [RUN]
13:06:17.969332 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.assert_under_10_percent_null"
13:06:17.969439 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.assert_under_10_percent_null
13:06:17.969535 [debug] [Thread-1  ]: Compiling test.learn_dbt.assert_under_10_percent_null
13:06:17.971177 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.assert_under_10_percent_null"
13:06:17.971599 [debug] [Thread-1  ]: finished collecting timing info
13:06:17.971696 [debug] [Thread-1  ]: Began executing node test.learn_dbt.assert_under_10_percent_null
13:06:17.981883 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.assert_under_10_percent_null"
13:06:17.982625 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.assert_under_10_percent_null"
13:06:17.982724 [debug] [Thread-1  ]: On test.learn_dbt.assert_under_10_percent_null: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.assert_under_10_percent_null"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      select sum (case when id is null then 1 else 0 end) / count(*) as total_nulls
from analytics.dbt.first_model
having sum (case when id is null then 1 else 0 end) / count(*) > .1
      
    ) dbt_internal_test
13:06:17.982835 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:06:18.766693 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.78 seconds
13:06:18.771596 [debug] [Thread-1  ]: finished collecting timing info
13:06:18.771996 [debug] [Thread-1  ]: On test.learn_dbt.assert_under_10_percent_null: Close
13:06:18.957477 [info ] [Thread-1  ]: 1 of 9 PASS assert_under_10_percent_null........................................ [[32mPASS[0m in 0.99s]
13:06:18.958563 [debug] [Thread-1  ]: Finished running node test.learn_dbt.assert_under_10_percent_null
13:06:18.958877 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
13:06:18.959076 [info ] [Thread-1  ]: 2 of 9 START test not_null_my_second_dbt_model_id............................... [RUN]
13:06:18.959637 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"
13:06:18.959833 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
13:06:18.960127 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
13:06:18.978261 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"
13:06:18.979723 [debug] [Thread-1  ]: finished collecting timing info
13:06:18.979906 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
13:06:18.981334 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"
13:06:18.982092 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"
13:06:18.982203 [debug] [Thread-1  ]: On test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.my_second_dbt_model
where id is null



      
    ) dbt_internal_test
13:06:18.982292 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:06:19.737069 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.75 seconds
13:06:19.739752 [debug] [Thread-1  ]: finished collecting timing info
13:06:19.740076 [debug] [Thread-1  ]: On test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778: Close
13:06:19.963577 [info ] [Thread-1  ]: 2 of 9 PASS not_null_my_second_dbt_model_id..................................... [[32mPASS[0m in 1.00s]
13:06:19.964422 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
13:06:19.964688 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
13:06:19.965259 [info ] [Thread-1  ]: 3 of 9 START test not_null_snowflake_cumulative_sales_o_orderdate............... [RUN]
13:06:19.966582 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
13:06:19.967516 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
13:06:19.967882 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
13:06:19.977071 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
13:06:19.977661 [debug] [Thread-1  ]: finished collecting timing info
13:06:19.977799 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
13:06:19.979106 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
13:06:19.979628 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
13:06:19.979714 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.snowflake_cumulative_sales
where o_orderdate is null



      
    ) dbt_internal_test
13:06:19.979791 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:06:20.676035 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.7 seconds
13:06:20.682440 [debug] [Thread-1  ]: finished collecting timing info
13:06:20.683659 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856: Close
13:06:20.948637 [info ] [Thread-1  ]: 3 of 9 PASS not_null_snowflake_cumulative_sales_o_orderdate..................... [[32mPASS[0m in 0.98s]
13:06:20.949809 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
13:06:20.950121 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
13:06:20.951089 [info ] [Thread-1  ]: 4 of 9 START test not_null_snowflake_customer_purchases_c_custkey............... [RUN]
13:06:20.952101 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
13:06:20.952534 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
13:06:20.952856 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
13:06:20.963667 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
13:06:20.964364 [debug] [Thread-1  ]: finished collecting timing info
13:06:20.964512 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
13:06:20.965783 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
13:06:20.966349 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
13:06:20.966438 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.snowflake_customer_purchases
where c_custkey is null



      
    ) dbt_internal_test
13:06:20.966518 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:06:21.951583 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.99 seconds
13:06:21.955587 [debug] [Thread-1  ]: finished collecting timing info
13:06:21.956010 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502: Close
13:06:22.155223 [info ] [Thread-1  ]: 4 of 9 PASS not_null_snowflake_customer_purchases_c_custkey..................... [[32mPASS[0m in 1.20s]
13:06:22.156174 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
13:06:22.156466 [debug] [Thread-1  ]: Began running node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
13:06:22.156697 [info ] [Thread-1  ]: 5 of 9 START test relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ [RUN]
13:06:22.158873 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
13:06:22.159568 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
13:06:22.159925 [debug] [Thread-1  ]: Compiling test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
13:06:22.177643 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
13:06:22.178178 [debug] [Thread-1  ]: finished collecting timing info
13:06:22.178282 [debug] [Thread-1  ]: Began executing node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
13:06:22.179392 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
13:06:22.180161 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
13:06:22.180255 [debug] [Thread-1  ]: On test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select id as from_field
    from analytics.dbt.my_second_dbt_model
    where id is not null
),

parent as (
    select id as to_field
    from analytics.dbt.first_model
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
13:06:22.180332 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:06:23.180359 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.0 seconds
13:06:23.184726 [debug] [Thread-1  ]: finished collecting timing info
13:06:23.185703 [debug] [Thread-1  ]: On test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: Close
13:06:23.537006 [error] [Thread-1  ]: 5 of 9 FAIL 1 relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_. [[31mFAIL 1[0m in 1.38s]
13:06:23.537941 [debug] [Thread-1  ]: Finished running node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
13:06:23.538830 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
13:06:23.539088 [info ] [Thread-1  ]: 6 of 9 START test unique_my_first_dbt_model_id.................................. [RUN]
13:06:23.539704 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
13:06:23.540017 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
13:06:23.540474 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
13:06:23.555396 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
13:06:23.557159 [debug] [Thread-1  ]: finished collecting timing info
13:06:23.557281 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
13:06:23.558893 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
13:06:23.560204 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
13:06:23.560408 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.first_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
13:06:23.560596 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:06:24.204014 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.64 seconds
13:06:24.207492 [debug] [Thread-1  ]: finished collecting timing info
13:06:24.207987 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_first_dbt_model_id.16e066b321: Close
13:06:24.422261 [info ] [Thread-1  ]: 6 of 9 PASS unique_my_first_dbt_model_id........................................ [[32mPASS[0m in 0.88s]
13:06:24.423266 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
13:06:24.440637 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:06:24.441062 [info ] [Thread-1  ]: 7 of 9 START test unique_my_second_dbt_model_id................................. [RUN]
13:06:24.442290 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
13:06:24.442584 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:06:24.442809 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:06:24.446392 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
13:06:24.447224 [debug] [Thread-1  ]: finished collecting timing info
13:06:24.447362 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:06:24.448547 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
13:06:24.449367 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
13:06:24.449466 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.my_second_dbt_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
13:06:24.449551 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:06:26.679550 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.23 seconds
13:06:26.682564 [debug] [Thread-1  ]: finished collecting timing info
13:06:26.683014 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493: Close
13:06:27.083417 [info ] [Thread-1  ]: 7 of 9 PASS unique_my_second_dbt_model_id....................................... [[32mPASS[0m in 2.64s]
13:06:27.086376 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:06:27.086853 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
13:06:27.087060 [info ] [Thread-1  ]: 8 of 9 START test unique_snowflake_cumulative_sales_o_orderdate................. [RUN]
13:06:27.087743 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
13:06:27.087959 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
13:06:27.088215 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
13:06:27.099576 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
13:06:27.100271 [debug] [Thread-1  ]: finished collecting timing info
13:06:27.100461 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
13:06:27.101936 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
13:06:27.102688 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
13:06:27.102804 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    o_orderdate as unique_field,
    count(*) as n_records

from analytics.dbt.snowflake_cumulative_sales
where o_orderdate is not null
group by o_orderdate
having count(*) > 1



      
    ) dbt_internal_test
13:06:27.102893 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:06:27.943085 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.84 seconds
13:06:27.946874 [debug] [Thread-1  ]: finished collecting timing info
13:06:27.947463 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed: Close
13:06:28.291853 [info ] [Thread-1  ]: 8 of 9 PASS unique_snowflake_cumulative_sales_o_orderdate....................... [[32mPASS[0m in 1.20s]
13:06:28.292806 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
13:06:28.293074 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
13:06:28.293580 [info ] [Thread-1  ]: 9 of 9 START test unique_snowflake_customer_purchases_c_custkey................. [RUN]
13:06:28.294309 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
13:06:28.294684 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
13:06:28.295066 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
13:06:28.306691 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
13:06:28.307190 [debug] [Thread-1  ]: finished collecting timing info
13:06:28.307296 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
13:06:28.308442 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
13:06:28.309164 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
13:06:28.309261 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    c_custkey as unique_field,
    count(*) as n_records

from analytics.dbt.snowflake_customer_purchases
where c_custkey is not null
group by c_custkey
having count(*) > 1



      
    ) dbt_internal_test
13:06:28.309348 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:06:29.294701 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.99 seconds
13:06:29.297615 [debug] [Thread-1  ]: finished collecting timing info
13:06:29.298574 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f: Close
13:06:29.509774 [info ] [Thread-1  ]: 9 of 9 PASS unique_snowflake_customer_purchases_c_custkey....................... [[32mPASS[0m in 1.22s]
13:06:29.511173 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
13:06:29.515487 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:06:29.516230 [info ] [MainThread]: 
13:06:29.517018 [info ] [MainThread]: Finished running 9 tests in 12.78s.
13:06:29.517376 [debug] [MainThread]: Connection 'master' was properly closed.
13:06:29.517552 [debug] [MainThread]: Connection 'test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f' was properly closed.
13:06:29.526934 [info ] [MainThread]: 
13:06:29.527242 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
13:06:29.527431 [info ] [MainThread]: 
13:06:29.527578 [error] [MainThread]: [31mFailure in test relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ (models/example/schema.yml)[0m
13:06:29.527739 [error] [MainThread]:   Got 1 result, configured to fail if != 0
13:06:29.527873 [info ] [MainThread]: 
13:06:29.528006 [info ] [MainThread]:   compiled SQL at target/compiled/learn_dbt/models/example/schema.yml/relationships_my_second_dbt_mo_160f86f0431c50a9f09003e4d3e6dceb.sql
13:06:29.528157 [info ] [MainThread]: 
13:06:29.528288 [info ] [MainThread]: Done. PASS=8 WARN=0 ERROR=1 SKIP=0 TOTAL=9
13:06:29.528505 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107268040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10866f6a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108828670>]}


============================== 2022-05-13 13:09:30.153515 | a9c9256d-98b7-4ece-89c9-af85175eb0a8 ==============================
13:09:30.153515 [info ] [MainThread]: Running with dbt=1.0.1
13:09:30.154135 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
13:09:30.154247 [debug] [MainThread]: Tracking: tracking
13:09:30.154478 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1085b73a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1085b7370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1085b76d0>]}
13:09:30.200906 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
13:09:30.201246 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/my_first_dbt_model.sql
13:09:30.207409 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
13:09:30.214422 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
13:09:30.227852 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a9c9256d-98b7-4ece-89c9-af85175eb0a8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108562130>]}
13:09:30.230958 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a9c9256d-98b7-4ece-89c9-af85175eb0a8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107577ee0>]}
13:09:30.231101 [info ] [MainThread]: Found 6 models, 9 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
13:09:30.231856 [info ] [MainThread]: 
13:09:30.232061 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:09:30.232499 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
13:09:30.238274 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
13:09:30.238382 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
13:09:30.238451 [debug] [ThreadPool]: Opening a new connection, currently in state init
13:09:31.315273 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.08 seconds
13:09:31.317245 [debug] [ThreadPool]: On list_analytics: Close
13:09:31.506094 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
13:09:31.514973 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
13:09:31.515196 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
13:09:31.515349 [debug] [ThreadPool]: Opening a new connection, currently in state closed
13:09:32.471047 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 0.96 seconds
13:09:32.474374 [debug] [ThreadPool]: On list_analytics_dbt: Close
13:09:32.820087 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
13:09:32.820690 [info ] [MainThread]: 
13:09:32.825736 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
13:09:32.826379 [info ] [Thread-1  ]: 1 of 6 START incremental model dbt.dates........................................ [RUN]
13:09:32.826868 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
13:09:32.827034 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
13:09:32.827201 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
13:09:32.836441 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
13:09:32.837398 [debug] [Thread-1  ]: finished collecting timing info
13:09:32.837547 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
13:09:32.865913 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:09:32.866096 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
13:09:32.866180 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:09:34.911699 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.05 seconds
13:09:34.928674 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:09:34.929004 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
13:09:35.051971 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.12 seconds
13:09:35.059005 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:09:35.059328 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
13:09:35.182040 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.12 seconds
13:09:35.194490 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:09:35.194770 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
13:09:35.436535 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.24 seconds
13:09:35.463231 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
13:09:35.465671 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:09:35.465795 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
13:09:35.622327 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.16 seconds
13:09:35.622945 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:09:35.623148 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
13:09:36.007849 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.38 seconds
13:09:36.008428 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:09:36.008655 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
13:09:36.235935 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.23 seconds
13:09:36.250206 [debug] [Thread-1  ]: finished collecting timing info
13:09:36.250616 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
13:09:36.614969 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a9c9256d-98b7-4ece-89c9-af85175eb0a8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1073f4cd0>]}
13:09:36.615884 [info ] [Thread-1  ]: 1 of 6 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 3.79s]
13:09:36.616410 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
13:09:36.616812 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
13:09:36.617292 [info ] [Thread-1  ]: 2 of 6 START incremental model dbt.incremental_time............................. [RUN]
13:09:36.617893 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
13:09:36.618102 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
13:09:36.618308 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
13:09:36.622390 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
13:09:36.623946 [debug] [Thread-1  ]: finished collecting timing info
13:09:36.624140 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
13:09:36.627839 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:09:36.628122 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
13:09:36.628269 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:09:38.308029 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.68 seconds
13:09:38.311614 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:09:38.311861 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
13:09:38.418166 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.11 seconds
13:09:38.424272 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:09:38.424619 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
13:09:38.665037 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.24 seconds
13:09:38.671342 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:09:38.671588 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
13:09:38.769544 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
13:09:38.774419 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
13:09:38.776554 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:09:38.776794 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
13:09:38.974860 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.2 seconds
13:09:38.975596 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:09:38.975906 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
13:09:39.685899 [debug] [Thread-1  ]: SQL status: SUCCESS 221 in 0.71 seconds
13:09:39.686864 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:09:39.687093 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
13:09:40.025157 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.34 seconds
13:09:40.028022 [debug] [Thread-1  ]: finished collecting timing info
13:09:40.028477 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
13:09:40.237312 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a9c9256d-98b7-4ece-89c9-af85175eb0a8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1089a5b80>]}
13:09:40.238113 [info ] [Thread-1  ]: 2 of 6 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 3.62s]
13:09:40.238565 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
13:09:40.238805 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
13:09:40.239202 [info ] [Thread-1  ]: 3 of 6 START table model dbt.first_model........................................ [RUN]
13:09:40.239830 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
13:09:40.240046 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
13:09:40.240209 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
13:09:40.243922 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
13:09:40.244661 [debug] [Thread-1  ]: finished collecting timing info
13:09:40.244840 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
13:09:40.253793 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
13:09:40.254790 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
13:09:40.254920 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id

)

select * 
from source_data


/*
select *, True as first_variable
from source_data
where id >= 1
*/
      );
13:09:40.255027 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:09:41.988485 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.73 seconds
13:09:41.991457 [debug] [Thread-1  ]: finished collecting timing info
13:09:41.991902 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
13:09:42.461773 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a9c9256d-98b7-4ece-89c9-af85175eb0a8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1089a5fa0>]}
13:09:42.462553 [info ] [Thread-1  ]: 3 of 6 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 2.22s]
13:09:42.462997 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
13:09:42.463239 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
13:09:42.463523 [info ] [Thread-1  ]: 4 of 6 START table model dbt.snowflake_cumulative_sales......................... [RUN]
13:09:42.464099 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
13:09:42.464304 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
13:09:42.464979 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
13:09:42.466811 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
13:09:42.468291 [debug] [Thread-1  ]: finished collecting timing info
13:09:42.468482 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
13:09:42.470046 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
13:09:42.470769 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
13:09:42.470915 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
13:09:42.471002 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:09:44.074853 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.6 seconds
13:09:44.079311 [debug] [Thread-1  ]: finished collecting timing info
13:09:44.079687 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
13:09:44.461649 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a9c9256d-98b7-4ece-89c9-af85175eb0a8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108959070>]}
13:09:44.462475 [info ] [Thread-1  ]: 4 of 6 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 2.00s]
13:09:44.463037 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
13:09:44.463283 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
13:09:44.463691 [info ] [Thread-1  ]: 5 of 6 START table model dbt.snowflake_customer_purchases....................... [RUN]
13:09:44.464371 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
13:09:44.464586 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
13:09:44.464776 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
13:09:44.466506 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
13:09:44.467279 [debug] [Thread-1  ]: finished collecting timing info
13:09:44.467427 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
13:09:44.470006 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
13:09:44.471382 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
13:09:44.471557 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
13:09:44.471708 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:09:46.447410 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.98 seconds
13:09:46.450641 [debug] [Thread-1  ]: finished collecting timing info
13:09:46.451051 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
13:09:46.630663 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a9c9256d-98b7-4ece-89c9-af85175eb0a8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a7ff3d0>]}
13:09:46.631713 [info ] [Thread-1  ]: 5 of 6 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.17s]
13:09:46.632256 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
13:09:46.632521 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
13:09:46.633068 [info ] [Thread-1  ]: 6 of 6 START table model dbt.my_second_dbt_model................................ [RUN]
13:09:46.634019 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
13:09:46.634234 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
13:09:46.634413 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
13:09:46.637661 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
13:09:46.639502 [debug] [Thread-1  ]: finished collecting timing info
13:09:46.639775 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
13:09:46.642668 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
13:09:46.643521 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
13:09:46.643728 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
union all
select 7 as id, True as first_variable
      );
13:09:46.643822 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:09:47.670429 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a43d35-3201-9c86-0000-000120527279
13:09:47.670741 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 001789 (42601): SQL compilation error:
invalid number of result columns for set operator input branches, expected 1, got 2 in branch 2
13:09:47.670976 [debug] [Thread-1  ]: finished collecting timing info
13:09:47.671091 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
13:09:48.021432 [debug] [Thread-1  ]: Database Error in model my_second_dbt_model (models/example/my_second_dbt_model.sql)
  001789 (42601): SQL compilation error:
  invalid number of result columns for set operator input branches, expected 1, got 2 in branch 2
  compiled SQL at target/run/learn_dbt/models/example/my_second_dbt_model.sql
13:09:48.023936 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a9c9256d-98b7-4ece-89c9-af85175eb0a8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1088b4be0>]}
13:09:48.024637 [error] [Thread-1  ]: 6 of 6 ERROR creating table model dbt.my_second_dbt_model....................... [[31mERROR[0m in 1.39s]
13:09:48.025230 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
13:09:48.026694 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:09:48.027292 [info ] [MainThread]: 
13:09:48.027637 [info ] [MainThread]: Finished running 2 incremental models, 4 table models in 17.80s.
13:09:48.027934 [debug] [MainThread]: Connection 'master' was properly closed.
13:09:48.028092 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
13:09:48.035120 [info ] [MainThread]: 
13:09:48.035603 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
13:09:48.035901 [info ] [MainThread]: 
13:09:48.036099 [error] [MainThread]: [33mDatabase Error in model my_second_dbt_model (models/example/my_second_dbt_model.sql)[0m
13:09:48.036292 [error] [MainThread]:   001789 (42601): SQL compilation error:
13:09:48.036474 [error] [MainThread]:   invalid number of result columns for set operator input branches, expected 1, got 2 in branch 2
13:09:48.036652 [error] [MainThread]:   compiled SQL at target/run/learn_dbt/models/example/my_second_dbt_model.sql
13:09:48.036842 [info ] [MainThread]: 
13:09:48.037025 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=1 SKIP=0 TOTAL=6
13:09:48.037302 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10634e6a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1078b51c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1089a53a0>]}


============================== 2022-05-13 13:10:18.933707 | 7e577291-569d-4211-a3e2-bc6ce2548906 ==============================
13:10:18.933707 [info ] [MainThread]: Running with dbt=1.0.1
13:10:18.934076 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
13:10:18.934206 [debug] [MainThread]: Tracking: tracking
13:10:18.934446 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1066d3f70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1066d3c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1066d38b0>]}
13:10:18.975300 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
13:10:18.975626 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/my_second_dbt_model.sql
13:10:18.980791 [debug] [MainThread]: 1603: static parser failed on example/my_second_dbt_model.sql
13:10:18.987103 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_second_dbt_model.sql
13:10:19.008488 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7e577291-569d-4211-a3e2-bc6ce2548906', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106862f40>]}
13:10:19.011583 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7e577291-569d-4211-a3e2-bc6ce2548906', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1010ea160>]}
13:10:19.011725 [info ] [MainThread]: Found 6 models, 9 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
13:10:19.012485 [info ] [MainThread]: 
13:10:19.012695 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:10:19.013129 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
13:10:19.019015 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
13:10:19.019116 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
13:10:19.019179 [debug] [ThreadPool]: Opening a new connection, currently in state init
13:10:20.152815 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.13 seconds
13:10:20.155888 [debug] [ThreadPool]: On list_analytics: Close
13:10:20.361833 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
13:10:20.370439 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
13:10:20.370705 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
13:10:20.370869 [debug] [ThreadPool]: Opening a new connection, currently in state closed
13:10:21.159046 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 0.79 seconds
13:10:21.161784 [debug] [ThreadPool]: On list_analytics_dbt: Close
13:10:21.359053 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
13:10:21.359498 [info ] [MainThread]: 
13:10:21.362207 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
13:10:21.362817 [info ] [Thread-1  ]: 1 of 6 START incremental model dbt.dates........................................ [RUN]
13:10:21.363258 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
13:10:21.363405 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
13:10:21.363549 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
13:10:21.374119 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
13:10:21.374782 [debug] [Thread-1  ]: finished collecting timing info
13:10:21.374951 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
13:10:21.405174 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:10:21.405326 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
13:10:21.405411 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:10:23.026304 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.62 seconds
13:10:23.036745 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:10:23.037041 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
13:10:23.195778 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.16 seconds
13:10:23.204830 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:10:23.205217 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
13:10:23.295040 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.09 seconds
13:10:23.306026 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:10:23.306416 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
13:10:23.408620 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.1 seconds
13:10:23.432066 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
13:10:23.434387 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:10:23.434529 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
13:10:23.669540 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.23 seconds
13:10:23.672305 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:10:23.672650 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
13:10:24.920697 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 1.25 seconds
13:10:24.921925 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:10:24.922445 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
13:10:25.192907 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.27 seconds
13:10:25.202047 [debug] [Thread-1  ]: finished collecting timing info
13:10:25.202319 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
13:10:25.415295 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7e577291-569d-4211-a3e2-bc6ce2548906', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102d4e850>]}
13:10:25.416114 [info ] [Thread-1  ]: 1 of 6 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 4.05s]
13:10:25.416593 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
13:10:25.416872 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
13:10:25.417452 [info ] [Thread-1  ]: 2 of 6 START incremental model dbt.incremental_time............................. [RUN]
13:10:25.418179 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
13:10:25.418392 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
13:10:25.418583 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
13:10:25.422521 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
13:10:25.423215 [debug] [Thread-1  ]: finished collecting timing info
13:10:25.423393 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
13:10:25.427073 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:10:25.427261 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
13:10:25.427419 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:10:26.815051 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.39 seconds
13:10:26.820010 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:10:26.820390 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
13:10:26.931508 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.11 seconds
13:10:26.937431 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:10:26.937760 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
13:10:27.036029 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
13:10:27.040924 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:10:27.041139 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
13:10:27.869046 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.83 seconds
13:10:27.871653 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
13:10:27.872746 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:10:27.872845 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
13:10:28.067591 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.19 seconds
13:10:28.068184 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:10:28.068369 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
13:10:28.910775 [debug] [Thread-1  ]: SQL status: SUCCESS 49 in 0.84 seconds
13:10:28.911904 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:10:28.912235 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
13:10:29.306404 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.39 seconds
13:10:29.310299 [debug] [Thread-1  ]: finished collecting timing info
13:10:29.310707 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
13:10:30.084536 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7e577291-569d-4211-a3e2-bc6ce2548906', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106885070>]}
13:10:30.085527 [info ] [Thread-1  ]: 2 of 6 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 4.67s]
13:10:30.086096 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
13:10:30.086356 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
13:10:30.086646 [info ] [Thread-1  ]: 3 of 6 START table model dbt.first_model........................................ [RUN]
13:10:30.087433 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
13:10:30.087708 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
13:10:30.087929 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
13:10:30.092214 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
13:10:30.093020 [debug] [Thread-1  ]: finished collecting timing info
13:10:30.093204 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
13:10:30.102122 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
13:10:30.103118 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
13:10:30.103248 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id

)

select * 
from source_data


/*
select *, True as first_variable
from source_data
where id >= 1
*/
      );
13:10:30.103363 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:10:31.811630 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.71 seconds
13:10:31.815068 [debug] [Thread-1  ]: finished collecting timing info
13:10:31.815442 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
13:10:33.194705 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7e577291-569d-4211-a3e2-bc6ce2548906', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f85e80>]}
13:10:33.195868 [info ] [Thread-1  ]: 3 of 6 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 3.11s]
13:10:33.196418 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
13:10:33.196681 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
13:10:33.197124 [info ] [Thread-1  ]: 4 of 6 START table model dbt.snowflake_cumulative_sales......................... [RUN]
13:10:33.198121 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
13:10:33.198437 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
13:10:33.198806 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
13:10:33.200683 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
13:10:33.201327 [debug] [Thread-1  ]: finished collecting timing info
13:10:33.201495 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
13:10:33.203972 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
13:10:33.204914 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
13:10:33.205076 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
13:10:33.205218 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:10:34.680830 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.48 seconds
13:10:34.684306 [debug] [Thread-1  ]: finished collecting timing info
13:10:34.684680 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
13:10:34.935878 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7e577291-569d-4211-a3e2-bc6ce2548906', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106aa1340>]}
13:10:34.936635 [info ] [Thread-1  ]: 4 of 6 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 1.74s]
13:10:34.937084 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
13:10:34.937324 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
13:10:34.937727 [info ] [Thread-1  ]: 5 of 6 START table model dbt.snowflake_customer_purchases....................... [RUN]
13:10:34.938350 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
13:10:34.938572 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
13:10:34.938768 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
13:10:34.939975 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
13:10:34.940489 [debug] [Thread-1  ]: finished collecting timing info
13:10:34.940637 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
13:10:34.943132 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
13:10:34.944477 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
13:10:34.944662 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
13:10:34.944812 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:10:37.824218 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.88 seconds
13:10:37.828638 [debug] [Thread-1  ]: finished collecting timing info
13:10:37.829023 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
13:10:38.039063 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7e577291-569d-4211-a3e2-bc6ce2548906', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106fc5220>]}
13:10:38.039887 [info ] [Thread-1  ]: 5 of 6 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 3.10s]
13:10:38.040365 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
13:10:38.040610 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
13:10:38.041045 [info ] [Thread-1  ]: 6 of 6 START table model dbt.my_second_dbt_model................................ [RUN]
13:10:38.041675 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
13:10:38.041870 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
13:10:38.042059 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
13:10:38.045472 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
13:10:38.046100 [debug] [Thread-1  ]: finished collecting timing info
13:10:38.046265 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
13:10:38.048767 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
13:10:38.049606 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
13:10:38.049772 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
/*
union all
select 7 as id, True as first_variable
*/
      );
13:10:38.049922 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:10:39.636041 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.59 seconds
13:10:39.637207 [debug] [Thread-1  ]: finished collecting timing info
13:10:39.637348 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
13:10:39.931319 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7e577291-569d-4211-a3e2-bc6ce2548906', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106fdbdc0>]}
13:10:39.931860 [info ] [Thread-1  ]: 6 of 6 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.89s]
13:10:39.932127 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
13:10:39.933200 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:10:39.933764 [info ] [MainThread]: 
13:10:39.934109 [info ] [MainThread]: Finished running 2 incremental models, 4 table models in 20.92s.
13:10:39.934404 [debug] [MainThread]: Connection 'master' was properly closed.
13:10:39.934561 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
13:10:39.940875 [info ] [MainThread]: 
13:10:39.941168 [info ] [MainThread]: [32mCompleted successfully[0m
13:10:39.941449 [info ] [MainThread]: 
13:10:39.941680 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
13:10:39.941986 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106aa3df0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068cff70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f8e6d0>]}


============================== 2022-05-13 13:10:45.150973 | 0eeebcfc-7927-4ab9-a084-4dc7581caf98 ==============================
13:10:45.150973 [info ] [MainThread]: Running with dbt=1.0.1
13:10:45.151341 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, store_failures=False, indirect_selection='eager', threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.test.TestTask'>, which='test', rpc_method='test')
13:10:45.151487 [debug] [MainThread]: Tracking: tracking
13:10:45.151714 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1082d31c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1082d3dc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1082d3c10>]}
13:10:45.194320 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
13:10:45.194459 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
13:10:45.197547 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0eeebcfc-7927-4ab9-a084-4dc7581caf98', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10829d040>]}
13:10:45.201136 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0eeebcfc-7927-4ab9-a084-4dc7581caf98', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1071284c0>]}
13:10:45.201309 [info ] [MainThread]: Found 6 models, 9 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
13:10:45.202114 [info ] [MainThread]: 
13:10:45.202340 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:10:45.202857 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
13:10:45.208844 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
13:10:45.208959 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
13:10:45.209025 [debug] [ThreadPool]: Opening a new connection, currently in state init
13:10:46.424624 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1.22 seconds
13:10:46.427457 [debug] [ThreadPool]: On list_analytics_dbt: Close
13:10:47.021280 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
13:10:47.021567 [info ] [MainThread]: 
13:10:47.024644 [debug] [Thread-1  ]: Began running node test.learn_dbt.assert_under_10_percent_null
13:10:47.024813 [info ] [Thread-1  ]: 1 of 9 START test assert_under_10_percent_null.................................. [RUN]
13:10:47.025099 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.assert_under_10_percent_null"
13:10:47.025195 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.assert_under_10_percent_null
13:10:47.025281 [debug] [Thread-1  ]: Compiling test.learn_dbt.assert_under_10_percent_null
13:10:47.027521 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.assert_under_10_percent_null"
13:10:47.028200 [debug] [Thread-1  ]: finished collecting timing info
13:10:47.028397 [debug] [Thread-1  ]: Began executing node test.learn_dbt.assert_under_10_percent_null
13:10:47.044131 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.assert_under_10_percent_null"
13:10:47.045255 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.assert_under_10_percent_null"
13:10:47.045388 [debug] [Thread-1  ]: On test.learn_dbt.assert_under_10_percent_null: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.assert_under_10_percent_null"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      select sum (case when id is null then 1 else 0 end) / count(*) as total_nulls
from analytics.dbt.first_model
having sum (case when id is null then 1 else 0 end) / count(*) > .1
      
    ) dbt_internal_test
13:10:47.045498 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:10:48.315498 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.27 seconds
13:10:48.318732 [debug] [Thread-1  ]: finished collecting timing info
13:10:48.319057 [debug] [Thread-1  ]: On test.learn_dbt.assert_under_10_percent_null: Close
13:10:48.539020 [error] [Thread-1  ]: 1 of 9 FAIL 1 assert_under_10_percent_null...................................... [[31mFAIL 1[0m in 1.51s]
13:10:48.539621 [debug] [Thread-1  ]: Finished running node test.learn_dbt.assert_under_10_percent_null
13:10:48.539897 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
13:10:48.540117 [info ] [Thread-1  ]: 2 of 9 START test not_null_my_second_dbt_model_id............................... [RUN]
13:10:48.540625 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"
13:10:48.540819 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
13:10:48.541126 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
13:10:48.553348 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"
13:10:48.554993 [debug] [Thread-1  ]: finished collecting timing info
13:10:48.555246 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
13:10:48.557043 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"
13:10:48.557812 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"
13:10:48.557933 [debug] [Thread-1  ]: On test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.my_second_dbt_model
where id is null



      
    ) dbt_internal_test
13:10:48.558044 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:10:49.566695 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.01 seconds
13:10:49.569856 [debug] [Thread-1  ]: finished collecting timing info
13:10:49.570251 [debug] [Thread-1  ]: On test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778: Close
13:10:49.886885 [error] [Thread-1  ]: 2 of 9 FAIL 1 not_null_my_second_dbt_model_id................................... [[31mFAIL 1[0m in 1.35s]
13:10:49.887571 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
13:10:49.887828 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
13:10:49.888146 [info ] [Thread-1  ]: 3 of 9 START test not_null_snowflake_cumulative_sales_o_orderdate............... [RUN]
13:10:49.888828 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
13:10:49.889046 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
13:10:49.889252 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
13:10:49.893955 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
13:10:49.894627 [debug] [Thread-1  ]: finished collecting timing info
13:10:49.894813 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
13:10:49.897005 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
13:10:49.897999 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
13:10:49.898360 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.snowflake_cumulative_sales
where o_orderdate is null



      
    ) dbt_internal_test
13:10:49.898590 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:10:50.573016 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.67 seconds
13:10:50.575828 [debug] [Thread-1  ]: finished collecting timing info
13:10:50.576145 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856: Close
13:10:50.936103 [info ] [Thread-1  ]: 3 of 9 PASS not_null_snowflake_cumulative_sales_o_orderdate..................... [[32mPASS[0m in 1.05s]
13:10:50.936941 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
13:10:50.937205 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
13:10:50.937550 [info ] [Thread-1  ]: 4 of 9 START test not_null_snowflake_customer_purchases_c_custkey............... [RUN]
13:10:50.938204 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
13:10:50.938421 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
13:10:50.938635 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
13:10:50.943870 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
13:10:50.944680 [debug] [Thread-1  ]: finished collecting timing info
13:10:50.944861 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
13:10:50.946745 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
13:10:50.947607 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
13:10:50.947849 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.snowflake_customer_purchases
where c_custkey is null



      
    ) dbt_internal_test
13:10:50.947985 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:10:51.806615 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.86 seconds
13:10:51.809157 [debug] [Thread-1  ]: finished collecting timing info
13:10:51.809482 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502: Close
13:10:52.228403 [info ] [Thread-1  ]: 4 of 9 PASS not_null_snowflake_customer_purchases_c_custkey..................... [[32mPASS[0m in 1.29s]
13:10:52.229199 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
13:10:52.229472 [debug] [Thread-1  ]: Began running node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
13:10:52.229815 [info ] [Thread-1  ]: 5 of 9 START test relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ [RUN]
13:10:52.230475 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
13:10:52.230690 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
13:10:52.230894 [debug] [Thread-1  ]: Compiling test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
13:10:52.241529 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
13:10:52.242288 [debug] [Thread-1  ]: finished collecting timing info
13:10:52.242441 [debug] [Thread-1  ]: Began executing node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
13:10:52.244330 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
13:10:52.245476 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
13:10:52.245601 [debug] [Thread-1  ]: On test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select id as from_field
    from analytics.dbt.my_second_dbt_model
    where id is not null
),

parent as (
    select id as to_field
    from analytics.dbt.first_model
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
13:10:52.245713 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:10:53.055839 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.81 seconds
13:10:53.059421 [debug] [Thread-1  ]: finished collecting timing info
13:10:53.059851 [debug] [Thread-1  ]: On test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: Close
13:10:53.310489 [info ] [Thread-1  ]: 5 of 9 PASS relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_... [[32mPASS[0m in 1.08s]
13:10:53.310979 [debug] [Thread-1  ]: Finished running node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
13:10:53.311148 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
13:10:53.311375 [info ] [Thread-1  ]: 6 of 9 START test unique_my_first_dbt_model_id.................................. [RUN]
13:10:53.311796 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
13:10:53.311929 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
13:10:53.312062 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
13:10:53.319785 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
13:10:53.320516 [debug] [Thread-1  ]: finished collecting timing info
13:10:53.320705 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
13:10:53.322540 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
13:10:53.323676 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
13:10:53.323827 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.first_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
13:10:53.323954 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:10:54.172730 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.85 seconds
13:10:54.176075 [debug] [Thread-1  ]: finished collecting timing info
13:10:54.176651 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_first_dbt_model_id.16e066b321: Close
13:10:54.472020 [info ] [Thread-1  ]: 6 of 9 PASS unique_my_first_dbt_model_id........................................ [[32mPASS[0m in 1.16s]
13:10:54.472956 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
13:10:54.473254 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:10:54.473474 [info ] [Thread-1  ]: 7 of 9 START test unique_my_second_dbt_model_id................................. [RUN]
13:10:54.474250 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
13:10:54.474515 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:10:54.474744 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:10:54.479597 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
13:10:54.480454 [debug] [Thread-1  ]: finished collecting timing info
13:10:54.480710 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:10:54.483126 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
13:10:54.484197 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
13:10:54.484348 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.my_second_dbt_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
13:10:54.484471 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:10:55.131925 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.65 seconds
13:10:55.137027 [debug] [Thread-1  ]: finished collecting timing info
13:10:55.137454 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493: Close
13:10:55.803945 [info ] [Thread-1  ]: 7 of 9 PASS unique_my_second_dbt_model_id....................................... [[32mPASS[0m in 1.33s]
13:10:55.804741 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:10:55.805011 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
13:10:55.805391 [info ] [Thread-1  ]: 8 of 9 START test unique_snowflake_cumulative_sales_o_orderdate................. [RUN]
13:10:55.806028 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
13:10:55.806238 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
13:10:55.806438 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
13:10:55.811138 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
13:10:55.811943 [debug] [Thread-1  ]: finished collecting timing info
13:10:55.812121 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
13:10:55.814328 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
13:10:55.815383 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
13:10:55.815711 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    o_orderdate as unique_field,
    count(*) as n_records

from analytics.dbt.snowflake_cumulative_sales
where o_orderdate is not null
group by o_orderdate
having count(*) > 1



      
    ) dbt_internal_test
13:10:55.815894 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:10:56.798675 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.98 seconds
13:10:56.802356 [debug] [Thread-1  ]: finished collecting timing info
13:10:56.802718 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed: Close
13:10:57.009948 [info ] [Thread-1  ]: 8 of 9 PASS unique_snowflake_cumulative_sales_o_orderdate....................... [[32mPASS[0m in 1.20s]
13:10:57.010746 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
13:10:57.011033 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
13:10:57.011344 [info ] [Thread-1  ]: 9 of 9 START test unique_snowflake_customer_purchases_c_custkey................. [RUN]
13:10:57.011948 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
13:10:57.012103 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
13:10:57.012259 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
13:10:57.016157 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
13:10:57.016823 [debug] [Thread-1  ]: finished collecting timing info
13:10:57.017030 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
13:10:57.018906 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
13:10:57.019646 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
13:10:57.019740 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    c_custkey as unique_field,
    count(*) as n_records

from analytics.dbt.snowflake_customer_purchases
where c_custkey is not null
group by c_custkey
having count(*) > 1



      
    ) dbt_internal_test
13:10:57.019828 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:10:58.667255 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.65 seconds
13:10:58.671778 [debug] [Thread-1  ]: finished collecting timing info
13:10:58.672216 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f: Close
13:10:58.874813 [info ] [Thread-1  ]: 9 of 9 PASS unique_snowflake_customer_purchases_c_custkey....................... [[32mPASS[0m in 1.86s]
13:10:58.875857 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
13:10:58.877526 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:10:58.878100 [info ] [MainThread]: 
13:10:58.878459 [info ] [MainThread]: Finished running 9 tests in 13.68s.
13:10:58.878763 [debug] [MainThread]: Connection 'master' was properly closed.
13:10:58.878928 [debug] [MainThread]: Connection 'test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f' was properly closed.
13:10:58.885657 [info ] [MainThread]: 
13:10:58.885986 [info ] [MainThread]: [31mCompleted with 2 errors and 0 warnings:[0m
13:10:58.886245 [info ] [MainThread]: 
13:10:58.886447 [error] [MainThread]: [31mFailure in test assert_under_10_percent_null (tests/assert_under_10_percent_null.sql)[0m
13:10:58.886683 [error] [MainThread]:   Got 1 result, configured to fail if != 0
13:10:58.886872 [info ] [MainThread]: 
13:10:58.887056 [info ] [MainThread]:   compiled SQL at target/compiled/learn_dbt/tests/assert_under_10_percent_null.sql
13:10:58.887245 [info ] [MainThread]: 
13:10:58.887421 [error] [MainThread]: [31mFailure in test not_null_my_second_dbt_model_id (models/example/schema.yml)[0m
13:10:58.887602 [error] [MainThread]:   Got 1 result, configured to fail if != 0
13:10:58.887775 [info ] [MainThread]: 
13:10:58.887947 [info ] [MainThread]:   compiled SQL at target/compiled/learn_dbt/models/example/schema.yml/not_null_my_second_dbt_model_id.sql
13:10:58.888141 [info ] [MainThread]: 
13:10:58.888316 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=2 SKIP=0 TOTAL=9
13:10:58.888582 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10874b1c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10293f940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108742460>]}


============================== 2022-05-13 13:11:15.826648 | 20efd4b4-7b8a-4b69-88be-4a716b54521d ==============================
13:11:15.826648 [info ] [MainThread]: Running with dbt=1.0.1
13:11:15.827036 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
13:11:15.827174 [debug] [MainThread]: Tracking: tracking
13:11:15.827374 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c9432b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c943eb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c9439a0>]}
13:11:15.869709 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
13:11:15.870046 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://tests/assert_under_10_percent_null.sql
13:11:15.885863 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '20efd4b4-7b8a-4b69-88be-4a716b54521d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11ca9f0d0>]}
13:11:15.889978 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '20efd4b4-7b8a-4b69-88be-4a716b54521d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c8ff4f0>]}
13:11:15.890158 [info ] [MainThread]: Found 6 models, 9 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
13:11:15.890937 [info ] [MainThread]: 
13:11:15.891184 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:11:15.891649 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
13:11:15.897687 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
13:11:15.897790 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
13:11:15.897865 [debug] [ThreadPool]: Opening a new connection, currently in state init
13:11:17.148753 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.25 seconds
13:11:17.150768 [debug] [ThreadPool]: On list_analytics: Close
13:11:17.380423 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
13:11:17.389317 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
13:11:17.389574 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
13:11:17.389731 [debug] [ThreadPool]: Opening a new connection, currently in state closed
13:11:18.373193 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 0.98 seconds
13:11:18.375668 [debug] [ThreadPool]: On list_analytics_dbt: Close
13:11:18.590388 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
13:11:18.591013 [info ] [MainThread]: 
13:11:18.594514 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
13:11:18.595362 [info ] [Thread-1  ]: 1 of 6 START incremental model dbt.dates........................................ [RUN]
13:11:18.595892 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
13:11:18.596062 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
13:11:18.596235 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
13:11:18.606243 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
13:11:18.606889 [debug] [Thread-1  ]: finished collecting timing info
13:11:18.607056 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
13:11:18.636916 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:11:18.637137 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
13:11:18.637230 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:11:20.907952 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.27 seconds
13:11:20.921388 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:11:20.921833 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
13:11:21.075767 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.15 seconds
13:11:21.087617 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:11:21.088079 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
13:11:21.338313 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.25 seconds
13:11:21.350721 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:11:21.351051 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
13:11:21.478633 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.13 seconds
13:11:21.503893 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
13:11:21.505914 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:11:21.506035 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
13:11:21.638090 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.13 seconds
13:11:21.639154 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:11:21.639373 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
13:11:22.099291 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.46 seconds
13:11:22.100116 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:11:22.100391 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
13:11:22.492806 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.39 seconds
13:11:22.507968 [debug] [Thread-1  ]: finished collecting timing info
13:11:22.508326 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
13:11:22.782443 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '20efd4b4-7b8a-4b69-88be-4a716b54521d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c8ffac0>]}
13:11:22.783353 [info ] [Thread-1  ]: 1 of 6 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 4.19s]
13:11:22.783851 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
13:11:22.784334 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
13:11:22.784843 [info ] [Thread-1  ]: 2 of 6 START incremental model dbt.incremental_time............................. [RUN]
13:11:22.785485 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
13:11:22.785696 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
13:11:22.785885 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
13:11:22.789885 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
13:11:22.790482 [debug] [Thread-1  ]: finished collecting timing info
13:11:22.790666 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
13:11:22.794227 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:11:22.794340 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
13:11:22.794419 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:11:24.177608 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.38 seconds
13:11:24.183504 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:11:24.183843 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
13:11:24.318466 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.13 seconds
13:11:24.321695 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:11:24.321866 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
13:11:24.601024 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.28 seconds
13:11:24.606772 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:11:24.607095 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
13:11:24.876863 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.27 seconds
13:11:24.881962 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
13:11:24.884272 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:11:24.884501 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
13:11:25.011909 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.13 seconds
13:11:25.013188 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:11:25.013390 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
13:11:25.756702 [debug] [Thread-1  ]: SQL status: SUCCESS 57 in 0.74 seconds
13:11:25.757872 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:11:25.758258 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
13:11:26.162300 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.4 seconds
13:11:26.165388 [debug] [Thread-1  ]: finished collecting timing info
13:11:26.165781 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
13:11:26.589468 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '20efd4b4-7b8a-4b69-88be-4a716b54521d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11cefa310>]}
13:11:26.590232 [info ] [Thread-1  ]: 2 of 6 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 3.80s]
13:11:26.590652 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
13:11:26.590918 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
13:11:26.591300 [info ] [Thread-1  ]: 3 of 6 START table model dbt.first_model........................................ [RUN]
13:11:26.591732 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
13:11:26.591860 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
13:11:26.591988 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
13:11:26.595035 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
13:11:26.595717 [debug] [Thread-1  ]: finished collecting timing info
13:11:26.595901 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
13:11:26.605586 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
13:11:26.606774 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
13:11:26.606940 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id

)

select * 
from source_data


/*
select *, True as first_variable
from source_data
where id >= 1
*/
      );
13:11:26.607055 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:11:28.355955 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.75 seconds
13:11:28.359960 [debug] [Thread-1  ]: finished collecting timing info
13:11:28.360354 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
13:11:28.682318 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '20efd4b4-7b8a-4b69-88be-4a716b54521d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11cefa040>]}
13:11:28.683073 [info ] [Thread-1  ]: 3 of 6 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 2.09s]
13:11:28.683526 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
13:11:28.683767 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
13:11:28.684160 [info ] [Thread-1  ]: 4 of 6 START table model dbt.snowflake_cumulative_sales......................... [RUN]
13:11:28.684855 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
13:11:28.685047 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
13:11:28.685242 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
13:11:28.687003 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
13:11:28.687714 [debug] [Thread-1  ]: finished collecting timing info
13:11:28.687876 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
13:11:28.690342 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
13:11:28.691387 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
13:11:28.691559 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
13:11:28.691704 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:11:30.842351 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.15 seconds
13:11:30.845137 [debug] [Thread-1  ]: finished collecting timing info
13:11:30.845510 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
13:11:31.071471 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '20efd4b4-7b8a-4b69-88be-4a716b54521d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11cefa160>]}
13:11:31.072394 [info ] [Thread-1  ]: 4 of 6 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 2.39s]
13:11:31.072848 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
13:11:31.073099 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
13:11:31.073483 [info ] [Thread-1  ]: 5 of 6 START table model dbt.snowflake_customer_purchases....................... [RUN]
13:11:31.074131 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
13:11:31.074352 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
13:11:31.074562 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
13:11:31.076353 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
13:11:31.077179 [debug] [Thread-1  ]: finished collecting timing info
13:11:31.077399 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
13:11:31.079938 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
13:11:31.081178 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
13:11:31.081341 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
13:11:31.081487 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:11:32.985974 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.9 seconds
13:11:32.989528 [debug] [Thread-1  ]: finished collecting timing info
13:11:32.989924 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
13:11:33.400079 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '20efd4b4-7b8a-4b69-88be-4a716b54521d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11fd81790>]}
13:11:33.400640 [info ] [Thread-1  ]: 5 of 6 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.33s]
13:11:33.401051 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
13:11:33.401277 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
13:11:33.401699 [info ] [Thread-1  ]: 6 of 6 START table model dbt.my_second_dbt_model................................ [RUN]
13:11:33.402176 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
13:11:33.402343 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
13:11:33.402514 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
13:11:33.405648 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
13:11:33.406307 [debug] [Thread-1  ]: finished collecting timing info
13:11:33.406493 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
13:11:33.408674 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
13:11:33.409426 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
13:11:33.409567 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
/*
union all
select 7 as id, True as first_variable
*/
      );
13:11:33.409693 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:11:34.625194 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.22 seconds
13:11:34.631759 [debug] [Thread-1  ]: finished collecting timing info
13:11:34.632180 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
13:11:34.793532 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '20efd4b4-7b8a-4b69-88be-4a716b54521d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11fd625b0>]}
13:11:34.794314 [info ] [Thread-1  ]: 6 of 6 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.39s]
13:11:34.794769 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
13:11:34.796136 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:11:34.796722 [info ] [MainThread]: 
13:11:34.797077 [info ] [MainThread]: Finished running 2 incremental models, 4 table models in 18.91s.
13:11:34.797377 [debug] [MainThread]: Connection 'master' was properly closed.
13:11:34.797547 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
13:11:34.804227 [info ] [MainThread]: 
13:11:34.804557 [info ] [MainThread]: [32mCompleted successfully[0m
13:11:34.804812 [info ] [MainThread]: 
13:11:34.805005 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
13:11:34.805266 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11cefeb80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11cefe7c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11fda4d90>]}


============================== 2022-05-13 13:12:06.309087 | 74571314-53b4-45d8-80fb-5aefefc907bb ==============================
13:12:06.309087 [info ] [MainThread]: Running with dbt=1.0.1
13:12:06.309451 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, store_failures=False, indirect_selection='eager', threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.test.TestTask'>, which='test', rpc_method='test')
13:12:06.309574 [debug] [MainThread]: Tracking: tracking
13:12:06.309806 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111d835b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111d83eb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111d83dc0>]}
13:12:06.351652 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
13:12:06.351786 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
13:12:06.354750 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '74571314-53b4-45d8-80fb-5aefefc907bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111d4d100>]}
13:12:06.357870 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '74571314-53b4-45d8-80fb-5aefefc907bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1109f6940>]}
13:12:06.358005 [info ] [MainThread]: Found 6 models, 9 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
13:12:06.358756 [info ] [MainThread]: 
13:12:06.358959 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:12:06.359404 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
13:12:06.365221 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
13:12:06.365332 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
13:12:06.365401 [debug] [ThreadPool]: Opening a new connection, currently in state init
13:12:07.684950 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1.32 seconds
13:12:07.688112 [debug] [ThreadPool]: On list_analytics_dbt: Close
13:12:07.921941 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
13:12:07.922612 [info ] [MainThread]: 
13:12:07.926481 [debug] [Thread-1  ]: Began running node test.learn_dbt.assert_under_10_percent_null
13:12:07.926737 [info ] [Thread-1  ]: 1 of 9 START test assert_under_10_percent_null.................................. [RUN]
13:12:07.927226 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.assert_under_10_percent_null"
13:12:07.927391 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.assert_under_10_percent_null
13:12:07.927552 [debug] [Thread-1  ]: Compiling test.learn_dbt.assert_under_10_percent_null
13:12:07.930633 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.assert_under_10_percent_null"
13:12:07.947372 [debug] [Thread-1  ]: finished collecting timing info
13:12:07.947665 [debug] [Thread-1  ]: Began executing node test.learn_dbt.assert_under_10_percent_null
13:12:07.962475 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.assert_under_10_percent_null"
13:12:07.963299 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.assert_under_10_percent_null"
13:12:07.963421 [debug] [Thread-1  ]: On test.learn_dbt.assert_under_10_percent_null: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.assert_under_10_percent_null"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      select sum (case when id is null then 1 else 0 end) / count(*) as total_nulls
from analytics.dbt.first_model
having sum (case when id is null then 1 else 0 end) / count(*) > .4
      
    ) dbt_internal_test
13:12:07.963522 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:12:08.996516 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.03 seconds
13:12:09.000089 [debug] [Thread-1  ]: finished collecting timing info
13:12:09.000445 [debug] [Thread-1  ]: On test.learn_dbt.assert_under_10_percent_null: Close
13:12:09.223113 [info ] [Thread-1  ]: 1 of 9 PASS assert_under_10_percent_null........................................ [[32mPASS[0m in 1.30s]
13:12:09.223621 [debug] [Thread-1  ]: Finished running node test.learn_dbt.assert_under_10_percent_null
13:12:09.223767 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
13:12:09.223994 [info ] [Thread-1  ]: 2 of 9 START test not_null_my_second_dbt_model_id............................... [RUN]
13:12:09.224396 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"
13:12:09.224510 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
13:12:09.224606 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
13:12:09.235048 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"
13:12:09.235475 [debug] [Thread-1  ]: finished collecting timing info
13:12:09.235577 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
13:12:09.236814 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"
13:12:09.237366 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"
13:12:09.237452 [debug] [Thread-1  ]: On test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.my_second_dbt_model
where id is null



      
    ) dbt_internal_test
13:12:09.237531 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:12:10.058615 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.82 seconds
13:12:10.062063 [debug] [Thread-1  ]: finished collecting timing info
13:12:10.062467 [debug] [Thread-1  ]: On test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778: Close
13:12:10.242181 [error] [Thread-1  ]: 2 of 9 FAIL 1 not_null_my_second_dbt_model_id................................... [[31mFAIL 1[0m in 1.02s]
13:12:10.242904 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
13:12:10.243164 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
13:12:10.243512 [info ] [Thread-1  ]: 3 of 9 START test not_null_snowflake_cumulative_sales_o_orderdate............... [RUN]
13:12:10.244209 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
13:12:10.244439 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
13:12:10.244637 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
13:12:10.249807 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
13:12:10.250737 [debug] [Thread-1  ]: finished collecting timing info
13:12:10.250951 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
13:12:10.252897 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
13:12:10.253873 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
13:12:10.254115 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.snowflake_cumulative_sales
where o_orderdate is null



      
    ) dbt_internal_test
13:12:10.254252 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:12:11.209676 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.96 seconds
13:12:11.212266 [debug] [Thread-1  ]: finished collecting timing info
13:12:11.212698 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856: Close
13:12:11.418272 [info ] [Thread-1  ]: 3 of 9 PASS not_null_snowflake_cumulative_sales_o_orderdate..................... [[32mPASS[0m in 1.17s]
13:12:11.419194 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
13:12:11.419564 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
13:12:11.419814 [info ] [Thread-1  ]: 4 of 9 START test not_null_snowflake_customer_purchases_c_custkey............... [RUN]
13:12:11.420577 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
13:12:11.420837 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
13:12:11.421057 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
13:12:11.426042 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
13:12:11.426897 [debug] [Thread-1  ]: finished collecting timing info
13:12:11.427090 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
13:12:11.429388 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
13:12:11.430425 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
13:12:11.430626 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.snowflake_customer_purchases
where c_custkey is null



      
    ) dbt_internal_test
13:12:11.430829 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:12:12.550825 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.12 seconds
13:12:12.552890 [debug] [Thread-1  ]: finished collecting timing info
13:12:12.553126 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502: Close
13:12:12.976425 [info ] [Thread-1  ]: 4 of 9 PASS not_null_snowflake_customer_purchases_c_custkey..................... [[32mPASS[0m in 1.56s]
13:12:12.977573 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
13:12:12.977996 [debug] [Thread-1  ]: Began running node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
13:12:12.978242 [info ] [Thread-1  ]: 5 of 9 START test relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ [RUN]
13:12:12.979025 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
13:12:12.979279 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
13:12:12.979489 [debug] [Thread-1  ]: Compiling test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
13:12:12.990385 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
13:12:12.991039 [debug] [Thread-1  ]: finished collecting timing info
13:12:12.991200 [debug] [Thread-1  ]: Began executing node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
13:12:12.993064 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
13:12:12.994222 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
13:12:12.994367 [debug] [Thread-1  ]: On test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select id as from_field
    from analytics.dbt.my_second_dbt_model
    where id is not null
),

parent as (
    select id as to_field
    from analytics.dbt.first_model
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
13:12:12.994495 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:12:14.288563 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.29 seconds
13:12:14.291820 [debug] [Thread-1  ]: finished collecting timing info
13:12:14.292086 [debug] [Thread-1  ]: On test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: Close
13:12:14.485133 [info ] [Thread-1  ]: 5 of 9 PASS relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_... [[32mPASS[0m in 1.51s]
13:12:14.486088 [debug] [Thread-1  ]: Finished running node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
13:12:14.486379 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
13:12:14.486718 [info ] [Thread-1  ]: 6 of 9 START test unique_my_first_dbt_model_id.................................. [RUN]
13:12:14.487427 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
13:12:14.487660 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
13:12:14.487865 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
13:12:14.496007 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
13:12:14.496801 [debug] [Thread-1  ]: finished collecting timing info
13:12:14.496987 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
13:12:14.498821 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
13:12:14.499974 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
13:12:14.500138 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.first_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
13:12:14.500272 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:12:15.439207 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.94 seconds
13:12:15.441933 [debug] [Thread-1  ]: finished collecting timing info
13:12:15.442435 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_first_dbt_model_id.16e066b321: Close
13:12:15.671297 [info ] [Thread-1  ]: 6 of 9 PASS unique_my_first_dbt_model_id........................................ [[32mPASS[0m in 1.18s]
13:12:15.672125 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
13:12:15.672391 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:12:15.672731 [info ] [Thread-1  ]: 7 of 9 START test unique_my_second_dbt_model_id................................. [RUN]
13:12:15.673385 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
13:12:15.673607 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:12:15.673817 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:12:15.678376 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
13:12:15.679070 [debug] [Thread-1  ]: finished collecting timing info
13:12:15.679265 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:12:15.681502 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
13:12:15.682489 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
13:12:15.682627 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.my_second_dbt_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
13:12:15.682875 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:12:16.691546 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.01 seconds
13:12:16.694938 [debug] [Thread-1  ]: finished collecting timing info
13:12:16.695396 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493: Close
13:12:17.056043 [info ] [Thread-1  ]: 7 of 9 PASS unique_my_second_dbt_model_id....................................... [[32mPASS[0m in 1.38s]
13:12:17.056744 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:12:17.057120 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
13:12:17.057495 [info ] [Thread-1  ]: 8 of 9 START test unique_snowflake_cumulative_sales_o_orderdate................. [RUN]
13:12:17.058137 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
13:12:17.058349 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
13:12:17.058543 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
13:12:17.063308 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
13:12:17.064099 [debug] [Thread-1  ]: finished collecting timing info
13:12:17.064342 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
13:12:17.066711 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
13:12:17.067941 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
13:12:17.068168 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    o_orderdate as unique_field,
    count(*) as n_records

from analytics.dbt.snowflake_cumulative_sales
where o_orderdate is not null
group by o_orderdate
having count(*) > 1



      
    ) dbt_internal_test
13:12:17.068365 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:12:17.959272 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.89 seconds
13:12:17.962584 [debug] [Thread-1  ]: finished collecting timing info
13:12:17.962996 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed: Close
13:12:18.142481 [info ] [Thread-1  ]: 8 of 9 PASS unique_snowflake_cumulative_sales_o_orderdate....................... [[32mPASS[0m in 1.08s]
13:12:18.143575 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
13:12:18.144000 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
13:12:18.144249 [info ] [Thread-1  ]: 9 of 9 START test unique_snowflake_customer_purchases_c_custkey................. [RUN]
13:12:18.145082 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
13:12:18.145345 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
13:12:18.145572 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
13:12:18.150386 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
13:12:18.150882 [debug] [Thread-1  ]: finished collecting timing info
13:12:18.151013 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
13:12:18.152741 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
13:12:18.153726 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
13:12:18.153884 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    c_custkey as unique_field,
    count(*) as n_records

from analytics.dbt.snowflake_customer_purchases
where c_custkey is not null
group by c_custkey
having count(*) > 1



      
    ) dbt_internal_test
13:12:18.154026 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:12:19.008363 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.85 seconds
13:12:19.011419 [debug] [Thread-1  ]: finished collecting timing info
13:12:19.011833 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f: Close
13:12:19.198778 [info ] [Thread-1  ]: 9 of 9 PASS unique_snowflake_customer_purchases_c_custkey....................... [[32mPASS[0m in 1.05s]
13:12:19.199823 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
13:12:19.201029 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:12:19.201552 [info ] [MainThread]: 
13:12:19.201864 [info ] [MainThread]: Finished running 9 tests in 12.84s.
13:12:19.202166 [debug] [MainThread]: Connection 'master' was properly closed.
13:12:19.202292 [debug] [MainThread]: Connection 'test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f' was properly closed.
13:12:19.208608 [info ] [MainThread]: 
13:12:19.209026 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
13:12:19.209320 [info ] [MainThread]: 
13:12:19.209550 [error] [MainThread]: [31mFailure in test not_null_my_second_dbt_model_id (models/example/schema.yml)[0m
13:12:19.209934 [error] [MainThread]:   Got 1 result, configured to fail if != 0
13:12:19.210184 [info ] [MainThread]: 
13:12:19.210415 [info ] [MainThread]:   compiled SQL at target/compiled/learn_dbt/models/example/schema.yml/not_null_my_second_dbt_model_id.sql
13:12:19.210812 [info ] [MainThread]: 
13:12:19.211071 [info ] [MainThread]: Done. PASS=8 WARN=0 ERROR=1 SKIP=0 TOTAL=9
13:12:19.211407 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112529be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11096c4f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112200550>]}


============================== 2022-05-13 13:14:36.838307 | b70a7687-eac6-4c4e-a241-d577c63bb9cd ==============================
13:14:36.838307 [info ] [MainThread]: Running with dbt=1.0.1
13:14:36.838705 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
13:14:36.838840 [debug] [MainThread]: Tracking: tracking
13:14:36.839081 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112891610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112891ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112891b20>]}
13:14:36.880799 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
13:14:36.881063 [debug] [MainThread]: Partial parsing: added file: learn_dbt://models/example/playing_with_tests.sql
13:14:36.886088 [debug] [MainThread]: 1699: static parser successfully parsed example/playing_with_tests.sql
13:14:36.895544 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b70a7687-eac6-4c4e-a241-d577c63bb9cd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1129d90d0>]}
13:14:36.898913 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b70a7687-eac6-4c4e-a241-d577c63bb9cd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112861be0>]}
13:14:36.899056 [info ] [MainThread]: Found 7 models, 9 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
13:14:36.899819 [info ] [MainThread]: 
13:14:36.900020 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:14:36.900501 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
13:14:36.906389 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
13:14:36.906500 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
13:14:36.906566 [debug] [ThreadPool]: Opening a new connection, currently in state init
13:14:38.091378 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.18 seconds
13:14:38.093912 [debug] [ThreadPool]: On list_analytics: Close
13:14:38.288991 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
13:14:38.297641 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
13:14:38.297896 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
13:14:38.298063 [debug] [ThreadPool]: Opening a new connection, currently in state closed
13:14:39.276962 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 0.98 seconds
13:14:39.280331 [debug] [ThreadPool]: On list_analytics_dbt: Close
13:14:39.594815 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
13:14:39.595962 [info ] [MainThread]: 
13:14:39.600763 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
13:14:39.601355 [info ] [Thread-1  ]: 1 of 7 START incremental model dbt.dates........................................ [RUN]
13:14:39.601975 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
13:14:39.602155 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
13:14:39.602338 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
13:14:39.612789 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
13:14:39.613436 [debug] [Thread-1  ]: finished collecting timing info
13:14:39.613592 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
13:14:39.642310 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:14:39.642491 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
13:14:39.642578 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:14:42.724546 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 3.08 seconds
13:14:42.737519 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:14:42.737848 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
13:14:42.873530 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.14 seconds
13:14:42.880637 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:14:42.880969 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
13:14:43.187702 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.31 seconds
13:14:43.198694 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:14:43.199012 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
13:14:43.305929 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.11 seconds
13:14:43.332770 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
13:14:43.335095 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:14:43.335220 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
13:14:43.811762 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.48 seconds
13:14:43.813017 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:14:43.813528 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
13:14:44.449235 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.64 seconds
13:14:44.449715 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:14:44.449924 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
13:14:44.756158 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.31 seconds
13:14:44.772434 [debug] [Thread-1  ]: finished collecting timing info
13:14:44.772856 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
13:14:44.983630 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b70a7687-eac6-4c4e-a241-d577c63bb9cd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1116ac6d0>]}
13:14:44.984292 [info ] [Thread-1  ]: 1 of 7 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 5.38s]
13:14:44.984748 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
13:14:44.984991 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
13:14:44.985398 [info ] [Thread-1  ]: 2 of 7 START incremental model dbt.incremental_time............................. [RUN]
13:14:44.986043 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
13:14:44.986265 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
13:14:44.986477 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
13:14:44.990466 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
13:14:44.992208 [debug] [Thread-1  ]: finished collecting timing info
13:14:44.992488 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
13:14:44.996207 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:14:44.996410 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
13:14:44.996552 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:14:46.853187 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.86 seconds
13:14:46.857912 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:14:46.858304 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
13:14:46.976714 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.12 seconds
13:14:46.985726 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:14:46.986105 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
13:14:47.082718 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
13:14:47.088071 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:14:47.088376 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
13:14:47.376727 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.29 seconds
13:14:47.382364 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
13:14:47.383501 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:14:47.383580 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
13:14:47.499969 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.12 seconds
13:14:47.502348 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:14:47.502662 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
13:14:48.292911 [debug] [Thread-1  ]: SQL status: SUCCESS 202 in 0.79 seconds
13:14:48.293767 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:14:48.294057 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
13:14:48.544230 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.25 seconds
13:14:48.549641 [debug] [Thread-1  ]: finished collecting timing info
13:14:48.550070 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
13:14:48.722394 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b70a7687-eac6-4c4e-a241-d577c63bb9cd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112db3fd0>]}
13:14:48.723222 [info ] [Thread-1  ]: 2 of 7 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 3.74s]
13:14:48.723677 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
13:14:48.723937 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
13:14:48.724355 [info ] [Thread-1  ]: 3 of 7 START table model dbt.first_model........................................ [RUN]
13:14:48.724985 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
13:14:48.725200 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
13:14:48.725397 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
13:14:48.729278 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
13:14:48.730027 [debug] [Thread-1  ]: finished collecting timing info
13:14:48.730210 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
13:14:48.739210 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
13:14:48.740255 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
13:14:48.740395 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id

)

select * 
from source_data


/*
select *, True as first_variable
from source_data
where id >= 1
*/
      );
13:14:48.740527 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:14:50.190088 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.45 seconds
13:14:50.193115 [debug] [Thread-1  ]: finished collecting timing info
13:14:50.193516 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
13:14:51.825593 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b70a7687-eac6-4c4e-a241-d577c63bb9cd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114d78df0>]}
13:14:51.826400 [info ] [Thread-1  ]: 3 of 7 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 3.10s]
13:14:51.826875 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
13:14:51.827127 [debug] [Thread-1  ]: Began running node model.learn_dbt.playing_with_tests
13:14:51.827531 [info ] [Thread-1  ]: 4 of 7 START table model dbt.playing_with_tests................................. [RUN]
13:14:51.828271 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.playing_with_tests"
13:14:51.828543 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.playing_with_tests
13:14:51.828764 [debug] [Thread-1  ]: Compiling model.learn_dbt.playing_with_tests
13:14:51.830512 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.playing_with_tests"
13:14:51.831224 [debug] [Thread-1  ]: finished collecting timing info
13:14:51.831407 [debug] [Thread-1  ]: Began executing node model.learn_dbt.playing_with_tests
13:14:51.833924 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.playing_with_tests"
13:14:51.834822 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
13:14:51.834988 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */


      create or replace transient table analytics.dbt.playing_with_tests  as
      (select * 
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF001"."CUSTOMER"
      );
13:14:51.835133 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:14:52.511399 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a43d3a-3201-9d36-0000-000120528345
13:14:52.511685 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 002003 (02000): SQL compilation error:
Schema 'SNOWFLAKE_SAMPLE_DATA.TPCH_SF001' does not exist or not authorized.
13:14:52.511917 [debug] [Thread-1  ]: finished collecting timing info
13:14:52.512034 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: Close
13:14:52.692330 [debug] [Thread-1  ]: Database Error in model playing_with_tests (models/example/playing_with_tests.sql)
  002003 (02000): SQL compilation error:
  Schema 'SNOWFLAKE_SAMPLE_DATA.TPCH_SF001' does not exist or not authorized.
  compiled SQL at target/run/learn_dbt/models/example/playing_with_tests.sql
13:14:52.692592 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b70a7687-eac6-4c4e-a241-d577c63bb9cd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114d81370>]}
13:14:52.692781 [error] [Thread-1  ]: 4 of 7 ERROR creating table model dbt.playing_with_tests........................ [[31mERROR[0m in 0.86s]
13:14:52.692940 [debug] [Thread-1  ]: Finished running node model.learn_dbt.playing_with_tests
13:14:52.693033 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
13:14:52.693129 [info ] [Thread-1  ]: 5 of 7 START table model dbt.snowflake_cumulative_sales......................... [RUN]
13:14:52.693332 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
13:14:52.693400 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
13:14:52.693469 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
13:14:52.694112 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
13:14:52.694572 [debug] [Thread-1  ]: finished collecting timing info
13:14:52.694678 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
13:14:52.695903 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
13:14:52.696401 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
13:14:52.696474 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
13:14:52.696539 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:14:54.587018 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.89 seconds
13:14:54.590013 [debug] [Thread-1  ]: finished collecting timing info
13:14:54.590370 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
13:14:54.801785 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b70a7687-eac6-4c4e-a241-d577c63bb9cd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114d60280>]}
13:14:54.803166 [info ] [Thread-1  ]: 5 of 7 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 2.11s]
13:14:54.803679 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
13:14:54.804048 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
13:14:54.804589 [info ] [Thread-1  ]: 6 of 7 START table model dbt.snowflake_customer_purchases....................... [RUN]
13:14:54.805609 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
13:14:54.805854 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
13:14:54.806065 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
13:14:54.807890 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
13:14:54.808658 [debug] [Thread-1  ]: finished collecting timing info
13:14:54.808835 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
13:14:54.811540 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
13:14:54.812849 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
13:14:54.813033 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
13:14:54.813207 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:14:56.532003 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.72 seconds
13:14:56.534941 [debug] [Thread-1  ]: finished collecting timing info
13:14:56.535485 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
13:14:56.819185 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b70a7687-eac6-4c4e-a241-d577c63bb9cd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114d6c550>]}
13:14:56.819923 [info ] [Thread-1  ]: 6 of 7 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.01s]
13:14:56.820373 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
13:14:56.820628 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
13:14:56.821026 [info ] [Thread-1  ]: 7 of 7 START table model dbt.my_second_dbt_model................................ [RUN]
13:14:56.821661 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
13:14:56.821886 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
13:14:56.822091 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
13:14:56.825384 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
13:14:56.826078 [debug] [Thread-1  ]: finished collecting timing info
13:14:56.826259 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
13:14:56.829019 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
13:14:56.830009 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
13:14:56.830173 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
/*
union all
select 7 as id, True as first_variable
*/
      );
13:14:56.830308 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:14:58.385224 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.55 seconds
13:14:58.388540 [debug] [Thread-1  ]: finished collecting timing info
13:14:58.388948 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
13:14:58.569223 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b70a7687-eac6-4c4e-a241-d577c63bb9cd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114f62070>]}
13:14:58.570023 [info ] [Thread-1  ]: 7 of 7 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.75s]
13:14:58.570481 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
13:14:58.571871 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:14:58.572438 [info ] [MainThread]: 
13:14:58.572785 [info ] [MainThread]: Finished running 2 incremental models, 5 table models in 21.67s.
13:14:58.573079 [debug] [MainThread]: Connection 'master' was properly closed.
13:14:58.573241 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
13:14:58.580826 [info ] [MainThread]: 
13:14:58.581205 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
13:14:58.581550 [info ] [MainThread]: 
13:14:58.581760 [error] [MainThread]: [33mDatabase Error in model playing_with_tests (models/example/playing_with_tests.sql)[0m
13:14:58.581958 [error] [MainThread]:   002003 (02000): SQL compilation error:
13:14:58.582144 [error] [MainThread]:   Schema 'SNOWFLAKE_SAMPLE_DATA.TPCH_SF001' does not exist or not authorized.
13:14:58.582326 [error] [MainThread]:   compiled SQL at target/run/learn_dbt/models/example/playing_with_tests.sql
13:14:58.582523 [info ] [MainThread]: 
13:14:58.582711 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=1 SKIP=0 TOTAL=7
13:14:58.582971 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112c2dbe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112c2de20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112c80550>]}


============================== 2022-05-13 13:16:26.080857 | bf9b6ca7-1f78-4b0b-8641-a38773cf924e ==============================
13:16:26.080857 [info ] [MainThread]: Running with dbt=1.0.1
13:16:26.081263 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
13:16:26.081437 [debug] [MainThread]: Tracking: tracking
13:16:26.081671 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f33370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f33be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f339d0>]}
13:16:26.123883 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
13:16:26.124192 [debug] [MainThread]: Partial parsing: update schema file: learn_dbt://models/example/schema.yml
13:16:26.142499 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'bf9b6ca7-1f78-4b0b-8641-a38773cf924e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107092040>]}
13:16:26.145575 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'bf9b6ca7-1f78-4b0b-8641-a38773cf924e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105a96670>]}
13:16:26.145707 [info ] [MainThread]: Found 7 models, 11 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
13:16:26.146502 [info ] [MainThread]: 
13:16:26.146708 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:16:26.147183 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
13:16:26.153058 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
13:16:26.153167 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
13:16:26.153235 [debug] [ThreadPool]: Opening a new connection, currently in state init
13:16:27.186035 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.03 seconds
13:16:27.188353 [debug] [ThreadPool]: On list_analytics: Close
13:16:27.518879 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
13:16:27.527810 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
13:16:27.528093 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
13:16:27.528255 [debug] [ThreadPool]: Opening a new connection, currently in state closed
13:16:28.232300 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 0.7 seconds
13:16:28.234984 [debug] [ThreadPool]: On list_analytics_dbt: Close
13:16:28.564109 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
13:16:28.564566 [info ] [MainThread]: 
13:16:28.566570 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
13:16:28.566815 [info ] [Thread-1  ]: 1 of 7 START incremental model dbt.dates........................................ [RUN]
13:16:28.567104 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
13:16:28.567199 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
13:16:28.567297 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
13:16:28.576939 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
13:16:28.577564 [debug] [Thread-1  ]: finished collecting timing info
13:16:28.577726 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
13:16:28.607583 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:16:28.607777 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
13:16:28.607862 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:16:30.290987 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.68 seconds
13:16:30.300446 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:16:30.300577 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
13:16:30.455238 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.15 seconds
13:16:30.464822 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:16:30.465157 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
13:16:30.725282 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.26 seconds
13:16:30.737999 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:16:30.738304 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
13:16:30.866639 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.13 seconds
13:16:30.889170 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
13:16:30.891505 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:16:30.891648 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
13:16:31.252080 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.36 seconds
13:16:31.252814 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:16:31.253021 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
13:16:31.771933 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.52 seconds
13:16:31.772414 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:16:31.772670 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
13:16:31.952683 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.18 seconds
13:16:31.967676 [debug] [Thread-1  ]: finished collecting timing info
13:16:31.968098 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
13:16:32.418841 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf9b6ca7-1f78-4b0b-8641-a38773cf924e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105c2cb50>]}
13:16:32.419599 [info ] [Thread-1  ]: 1 of 7 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 3.85s]
13:16:32.420050 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
13:16:32.420258 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
13:16:32.420614 [info ] [Thread-1  ]: 2 of 7 START incremental model dbt.incremental_time............................. [RUN]
13:16:32.421175 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
13:16:32.421364 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
13:16:32.421534 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
13:16:32.424994 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
13:16:32.425840 [debug] [Thread-1  ]: finished collecting timing info
13:16:32.426027 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
13:16:32.429708 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:16:32.429894 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
13:16:32.430023 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:16:34.996011 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.57 seconds
13:16:35.000048 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:16:35.000234 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
13:16:35.126321 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.13 seconds
13:16:35.131053 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:16:35.131301 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
13:16:35.505368 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.37 seconds
13:16:35.510030 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:16:35.510378 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
13:16:35.615938 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.11 seconds
13:16:35.621800 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
13:16:35.624209 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:16:35.624444 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
13:16:35.899929 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.28 seconds
13:16:35.900891 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:16:35.901082 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
13:16:36.948418 [debug] [Thread-1  ]: SQL status: SUCCESS 108 in 1.05 seconds
13:16:36.949180 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:16:36.949379 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
13:16:37.473351 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.52 seconds
13:16:37.476894 [debug] [Thread-1  ]: finished collecting timing info
13:16:37.477280 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
13:16:37.671791 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf9b6ca7-1f78-4b0b-8641-a38773cf924e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107542460>]}
13:16:37.672331 [info ] [Thread-1  ]: 2 of 7 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 5.25s]
13:16:37.672536 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
13:16:37.672630 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
13:16:37.672814 [info ] [Thread-1  ]: 3 of 7 START table model dbt.first_model........................................ [RUN]
13:16:37.673059 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
13:16:37.673136 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
13:16:37.673209 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
13:16:37.674912 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
13:16:37.675265 [debug] [Thread-1  ]: finished collecting timing info
13:16:37.675346 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
13:16:37.680632 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
13:16:37.681282 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
13:16:37.681362 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id

)

select * 
from source_data


/*
select *, True as first_variable
from source_data
where id >= 1
*/
      );
13:16:37.681429 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:16:39.046252 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.36 seconds
13:16:39.049689 [debug] [Thread-1  ]: finished collecting timing info
13:16:39.050054 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
13:16:39.219809 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf9b6ca7-1f78-4b0b-8641-a38773cf924e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107542130>]}
13:16:39.220379 [info ] [Thread-1  ]: 3 of 7 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 1.55s]
13:16:39.220676 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
13:16:39.220848 [debug] [Thread-1  ]: Began running node model.learn_dbt.playing_with_tests
13:16:39.221021 [info ] [Thread-1  ]: 4 of 7 START table model dbt.playing_with_tests................................. [RUN]
13:16:39.221512 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.playing_with_tests"
13:16:39.221732 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.playing_with_tests
13:16:39.221874 [debug] [Thread-1  ]: Compiling model.learn_dbt.playing_with_tests
13:16:39.223027 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.playing_with_tests"
13:16:39.223487 [debug] [Thread-1  ]: finished collecting timing info
13:16:39.223599 [debug] [Thread-1  ]: Began executing node model.learn_dbt.playing_with_tests
13:16:39.225392 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.playing_with_tests"
13:16:39.226133 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
13:16:39.226258 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */


      create or replace transient table analytics.dbt.playing_with_tests  as
      (select * 
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF001"."CUSTOMER"
      );
13:16:39.226360 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:16:39.850518 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a43d3c-3201-9d36-0000-000120528361
13:16:39.851115 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 002003 (02000): SQL compilation error:
Schema 'SNOWFLAKE_SAMPLE_DATA.TPCH_SF001' does not exist or not authorized.
13:16:39.851607 [debug] [Thread-1  ]: finished collecting timing info
13:16:39.851886 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: Close
13:16:40.094156 [debug] [Thread-1  ]: Database Error in model playing_with_tests (models/example/playing_with_tests.sql)
  002003 (02000): SQL compilation error:
  Schema 'SNOWFLAKE_SAMPLE_DATA.TPCH_SF001' does not exist or not authorized.
  compiled SQL at target/run/learn_dbt/models/example/playing_with_tests.sql
13:16:40.095745 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf9b6ca7-1f78-4b0b-8641-a38773cf924e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076c7af0>]}
13:16:40.096832 [error] [Thread-1  ]: 4 of 7 ERROR creating table model dbt.playing_with_tests........................ [[31mERROR[0m in 0.87s]
13:16:40.097372 [debug] [Thread-1  ]: Finished running node model.learn_dbt.playing_with_tests
13:16:40.097783 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
13:16:40.098395 [info ] [Thread-1  ]: 5 of 7 START table model dbt.snowflake_cumulative_sales......................... [RUN]
13:16:40.099099 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
13:16:40.099327 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
13:16:40.099533 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
13:16:40.101456 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
13:16:40.102326 [debug] [Thread-1  ]: finished collecting timing info
13:16:40.102525 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
13:16:40.105443 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
13:16:40.106685 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
13:16:40.106884 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
13:16:40.107030 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:16:41.842786 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.74 seconds
13:16:41.846019 [debug] [Thread-1  ]: finished collecting timing info
13:16:41.846480 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
13:16:42.259614 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf9b6ca7-1f78-4b0b-8641-a38773cf924e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107542ee0>]}
13:16:42.260162 [info ] [Thread-1  ]: 5 of 7 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 2.16s]
13:16:42.260448 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
13:16:42.260600 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
13:16:42.260893 [info ] [Thread-1  ]: 6 of 7 START table model dbt.snowflake_customer_purchases....................... [RUN]
13:16:42.261424 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
13:16:42.261715 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
13:16:42.261866 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
13:16:42.262957 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
13:16:42.263400 [debug] [Thread-1  ]: finished collecting timing info
13:16:42.263513 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
13:16:42.265243 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
13:16:42.266341 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
13:16:42.266504 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
13:16:42.266646 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:16:44.074876 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.81 seconds
13:16:44.077436 [debug] [Thread-1  ]: finished collecting timing info
13:16:44.077725 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
13:16:44.487145 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf9b6ca7-1f78-4b0b-8641-a38773cf924e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076bc100>]}
13:16:44.488296 [info ] [Thread-1  ]: 6 of 7 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.23s]
13:16:44.488870 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
13:16:44.489137 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
13:16:44.489576 [info ] [Thread-1  ]: 7 of 7 START table model dbt.my_second_dbt_model................................ [RUN]
13:16:44.490246 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
13:16:44.490468 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
13:16:44.490671 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
13:16:44.494183 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
13:16:44.494934 [debug] [Thread-1  ]: finished collecting timing info
13:16:44.495108 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
13:16:44.497581 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
13:16:44.498452 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
13:16:44.498612 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
/*
union all
select 7 as id, True as first_variable
*/
      );
13:16:44.498754 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:16:49.823588 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 5.32 seconds
13:16:49.826502 [debug] [Thread-1  ]: finished collecting timing info
13:16:49.826903 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
13:16:50.425476 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf9b6ca7-1f78-4b0b-8641-a38773cf924e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109d2b3a0>]}
13:16:50.426322 [info ] [Thread-1  ]: 7 of 7 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 5.94s]
13:16:50.426845 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
13:16:50.428210 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:16:50.428717 [info ] [MainThread]: 
13:16:50.429050 [info ] [MainThread]: Finished running 2 incremental models, 5 table models in 24.28s.
13:16:50.429342 [debug] [MainThread]: Connection 'master' was properly closed.
13:16:50.429505 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
13:16:50.436209 [info ] [MainThread]: 
13:16:50.436752 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
13:16:50.437107 [info ] [MainThread]: 
13:16:50.437361 [error] [MainThread]: [33mDatabase Error in model playing_with_tests (models/example/playing_with_tests.sql)[0m
13:16:50.437717 [error] [MainThread]:   002003 (02000): SQL compilation error:
13:16:50.437922 [error] [MainThread]:   Schema 'SNOWFLAKE_SAMPLE_DATA.TPCH_SF001' does not exist or not authorized.
13:16:50.438116 [error] [MainThread]:   compiled SQL at target/run/learn_dbt/models/example/playing_with_tests.sql
13:16:50.438316 [info ] [MainThread]: 
13:16:50.438504 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=1 SKIP=0 TOTAL=7
13:16:50.438767 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104f201f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104f2de80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075e6bb0>]}


============================== 2022-05-13 13:17:56.039052 | e4eab860-f552-4aee-bcda-6701c337849d ==============================
13:17:56.039052 [info ] [MainThread]: Running with dbt=1.0.1
13:17:56.039456 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
13:17:56.039741 [debug] [MainThread]: Tracking: tracking
13:17:56.040043 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e371c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e37dc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e37c10>]}
13:17:56.082054 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
13:17:56.082331 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/playing_with_tests.sql
13:17:56.087514 [debug] [MainThread]: 1699: static parser successfully parsed example/playing_with_tests.sql
13:17:56.106467 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e4eab860-f552-4aee-bcda-6701c337849d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104df20d0>]}
13:17:56.109476 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e4eab860-f552-4aee-bcda-6701c337849d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104103820>]}
13:17:56.109613 [info ] [MainThread]: Found 7 models, 11 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
13:17:56.110402 [info ] [MainThread]: 
13:17:56.110603 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:17:56.111068 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
13:17:56.117046 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
13:17:56.117157 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
13:17:56.117220 [debug] [ThreadPool]: Opening a new connection, currently in state init
13:17:57.140767 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.02 seconds
13:17:57.143617 [debug] [ThreadPool]: On list_analytics: Close
13:17:57.375760 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
13:17:57.384714 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
13:17:57.385004 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
13:17:57.385168 [debug] [ThreadPool]: Opening a new connection, currently in state closed
13:17:58.084868 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 0.7 seconds
13:17:58.088156 [debug] [ThreadPool]: On list_analytics_dbt: Close
13:17:58.251940 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
13:17:58.252716 [info ] [MainThread]: 
13:17:58.257112 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
13:17:58.257544 [info ] [Thread-1  ]: 1 of 7 START incremental model dbt.dates........................................ [RUN]
13:17:58.258065 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
13:17:58.258237 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
13:17:58.258397 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
13:17:58.267333 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
13:17:58.268035 [debug] [Thread-1  ]: finished collecting timing info
13:17:58.268166 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
13:17:58.297218 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:17:58.297444 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
13:17:58.297534 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:18:00.584194 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.29 seconds
13:18:00.597270 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:18:00.597611 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
13:18:00.895996 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.3 seconds
13:18:00.905109 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:18:00.905459 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
13:18:01.072070 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.17 seconds
13:18:01.082415 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:18:01.082755 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
13:18:01.422773 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.34 seconds
13:18:01.448279 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
13:18:01.451038 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:18:01.451205 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
13:18:01.639882 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.19 seconds
13:18:01.640572 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:18:01.640758 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
13:18:02.470849 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.83 seconds
13:18:02.471773 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:18:02.472089 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
13:18:02.652460 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.18 seconds
13:18:02.663688 [debug] [Thread-1  ]: finished collecting timing info
13:18:02.663998 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
13:18:02.995843 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4eab860-f552-4aee-bcda-6701c337849d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107468a30>]}
13:18:02.996733 [info ] [Thread-1  ]: 1 of 7 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 4.74s]
13:18:02.997075 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
13:18:02.997233 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
13:18:02.997478 [info ] [Thread-1  ]: 2 of 7 START incremental model dbt.incremental_time............................. [RUN]
13:18:02.997859 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
13:18:02.997989 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
13:18:02.998106 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
13:18:03.001924 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
13:18:03.002772 [debug] [Thread-1  ]: finished collecting timing info
13:18:03.002958 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
13:18:03.006159 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:18:03.006361 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
13:18:03.006478 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:18:04.502427 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.5 seconds
13:18:04.510075 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:18:04.510443 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
13:18:04.703175 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.19 seconds
13:18:04.711595 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:18:04.711964 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
13:18:04.808122 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
13:18:04.810904 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:18:04.811083 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
13:18:05.024076 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.21 seconds
13:18:05.028771 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
13:18:05.030532 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:18:05.030687 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
13:18:05.183150 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.15 seconds
13:18:05.184158 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:18:05.184383 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
13:18:06.072811 [debug] [Thread-1  ]: SQL status: SUCCESS 90 in 0.89 seconds
13:18:06.073777 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:18:06.074077 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
13:18:06.352241 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.28 seconds
13:18:06.354554 [debug] [Thread-1  ]: finished collecting timing info
13:18:06.354764 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
13:18:06.755324 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4eab860-f552-4aee-bcda-6701c337849d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074f66d0>]}
13:18:06.756054 [info ] [Thread-1  ]: 2 of 7 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 3.76s]
13:18:06.756497 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
13:18:06.756764 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
13:18:06.757188 [info ] [Thread-1  ]: 3 of 7 START table model dbt.first_model........................................ [RUN]
13:18:06.757900 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
13:18:06.758120 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
13:18:06.758322 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
13:18:06.762508 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
13:18:06.763362 [debug] [Thread-1  ]: finished collecting timing info
13:18:06.763538 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
13:18:06.770658 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
13:18:06.771758 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
13:18:06.771904 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id

)

select * 
from source_data


/*
select *, True as first_variable
from source_data
where id >= 1
*/
      );
13:18:06.772031 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:18:07.815602 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.04 seconds
13:18:07.818613 [debug] [Thread-1  ]: finished collecting timing info
13:18:07.819050 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
13:18:08.008921 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4eab860-f552-4aee-bcda-6701c337849d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10745d190>]}
13:18:08.009344 [info ] [Thread-1  ]: 3 of 7 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 1.25s]
13:18:08.009618 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
13:18:08.009766 [debug] [Thread-1  ]: Began running node model.learn_dbt.playing_with_tests
13:18:08.010044 [info ] [Thread-1  ]: 4 of 7 START table model dbt.playing_with_tests................................. [RUN]
13:18:08.010500 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.playing_with_tests"
13:18:08.010624 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.playing_with_tests
13:18:08.010745 [debug] [Thread-1  ]: Compiling model.learn_dbt.playing_with_tests
13:18:08.011793 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.playing_with_tests"
13:18:08.012311 [debug] [Thread-1  ]: finished collecting timing info
13:18:08.012437 [debug] [Thread-1  ]: Began executing node model.learn_dbt.playing_with_tests
13:18:08.014544 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.playing_with_tests"
13:18:08.015293 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
13:18:08.015419 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */


      create or replace transient table analytics.dbt.playing_with_tests  as
      (select * 
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER"
      );
13:18:08.015526 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:18:10.104686 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.09 seconds
13:18:10.108386 [debug] [Thread-1  ]: finished collecting timing info
13:18:10.108708 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: Close
13:18:10.442444 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4eab860-f552-4aee-bcda-6701c337849d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105135700>]}
13:18:10.443004 [info ] [Thread-1  ]: 4 of 7 OK created table model dbt.playing_with_tests............................ [[32mSUCCESS 1[0m in 2.43s]
13:18:10.443312 [debug] [Thread-1  ]: Finished running node model.learn_dbt.playing_with_tests
13:18:10.443576 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
13:18:10.443878 [info ] [Thread-1  ]: 5 of 7 START table model dbt.snowflake_cumulative_sales......................... [RUN]
13:18:10.444241 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
13:18:10.444368 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
13:18:10.444486 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
13:18:10.445603 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
13:18:10.446238 [debug] [Thread-1  ]: finished collecting timing info
13:18:10.446376 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
13:18:10.448589 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
13:18:10.449651 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
13:18:10.449850 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
13:18:10.449997 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:18:12.432997 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.98 seconds
13:18:12.435751 [debug] [Thread-1  ]: finished collecting timing info
13:18:12.436160 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
13:18:12.659364 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4eab860-f552-4aee-bcda-6701c337849d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053f1040>]}
13:18:12.660073 [info ] [Thread-1  ]: 5 of 7 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 2.22s]
13:18:12.660526 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
13:18:12.660786 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
13:18:12.661071 [info ] [Thread-1  ]: 6 of 7 START table model dbt.snowflake_customer_purchases....................... [RUN]
13:18:12.661793 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
13:18:12.662037 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
13:18:12.662248 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
13:18:12.663775 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
13:18:12.664339 [debug] [Thread-1  ]: finished collecting timing info
13:18:12.664503 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
13:18:12.667102 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
13:18:12.668528 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
13:18:12.668840 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
13:18:12.669010 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:18:14.463657 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.79 seconds
13:18:14.465387 [debug] [Thread-1  ]: finished collecting timing info
13:18:14.465613 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
13:18:14.625555 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4eab860-f552-4aee-bcda-6701c337849d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107518580>]}
13:18:14.626193 [info ] [Thread-1  ]: 6 of 7 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 1.96s]
13:18:14.626630 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
13:18:14.626868 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
13:18:14.627261 [info ] [Thread-1  ]: 7 of 7 START table model dbt.my_second_dbt_model................................ [RUN]
13:18:14.627890 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
13:18:14.628101 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
13:18:14.628296 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
13:18:14.631426 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
13:18:14.632043 [debug] [Thread-1  ]: finished collecting timing info
13:18:14.632214 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
13:18:14.634902 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
13:18:14.635962 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
13:18:14.636124 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
/*
union all
select 7 as id, True as first_variable
*/
      );
13:18:14.636265 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:18:16.038032 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.4 seconds
13:18:16.040946 [debug] [Thread-1  ]: finished collecting timing info
13:18:16.041175 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
13:18:16.210809 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4eab860-f552-4aee-bcda-6701c337849d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105350310>]}
13:18:16.211536 [info ] [Thread-1  ]: 7 of 7 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.58s]
13:18:16.212017 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
13:18:16.213339 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:18:16.213874 [info ] [MainThread]: 
13:18:16.214248 [info ] [MainThread]: Finished running 2 incremental models, 5 table models in 20.10s.
13:18:16.214548 [debug] [MainThread]: Connection 'master' was properly closed.
13:18:16.214711 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
13:18:16.221576 [info ] [MainThread]: 
13:18:16.221896 [info ] [MainThread]: [32mCompleted successfully[0m
13:18:16.222195 [info ] [MainThread]: 
13:18:16.222417 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
13:18:16.222641 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103a828e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103a82f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105356820>]}


============================== 2022-05-13 13:18:23.116920 | 06c1f92f-12a3-4f61-88b7-0ede0df80620 ==============================
13:18:23.116920 [info ] [MainThread]: Running with dbt=1.0.1
13:18:23.117281 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, store_failures=False, indirect_selection='eager', threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.test.TestTask'>, which='test', rpc_method='test')
13:18:23.117413 [debug] [MainThread]: Tracking: tracking
13:18:23.117627 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e1b1c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e1bf10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e1b460>]}
13:18:23.160182 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
13:18:23.160315 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
13:18:23.163399 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '06c1f92f-12a3-4f61-88b7-0ede0df80620', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106de7e20>]}
13:18:23.166800 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '06c1f92f-12a3-4f61-88b7-0ede0df80620', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104585d90>]}
13:18:23.166989 [info ] [MainThread]: Found 7 models, 11 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
13:18:23.168083 [info ] [MainThread]: 
13:18:23.168387 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:18:23.169008 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
13:18:23.175316 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
13:18:23.175425 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
13:18:23.175493 [debug] [ThreadPool]: Opening a new connection, currently in state init
13:18:24.016230 [debug] [ThreadPool]: SQL status: SUCCESS 7 in 0.84 seconds
13:18:24.019263 [debug] [ThreadPool]: On list_analytics_dbt: Close
13:18:24.296750 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
13:18:24.297309 [info ] [MainThread]: 
13:18:24.301339 [debug] [Thread-1  ]: Began running node test.learn_dbt.assert_under_10_percent_null
13:18:24.301569 [info ] [Thread-1  ]: 1 of 11 START test assert_under_10_percent_null................................. [RUN]
13:18:24.302031 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.assert_under_10_percent_null"
13:18:24.302191 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.assert_under_10_percent_null
13:18:24.302359 [debug] [Thread-1  ]: Compiling test.learn_dbt.assert_under_10_percent_null
13:18:24.305442 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.assert_under_10_percent_null"
13:18:24.306147 [debug] [Thread-1  ]: finished collecting timing info
13:18:24.306332 [debug] [Thread-1  ]: Began executing node test.learn_dbt.assert_under_10_percent_null
13:18:24.321121 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.assert_under_10_percent_null"
13:18:24.322074 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.assert_under_10_percent_null"
13:18:24.322204 [debug] [Thread-1  ]: On test.learn_dbt.assert_under_10_percent_null: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.assert_under_10_percent_null"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      select sum (case when id is null then 1 else 0 end) / count(*) as total_nulls
from analytics.dbt.first_model
having sum (case when id is null then 1 else 0 end) / count(*) > .4
      
    ) dbt_internal_test
13:18:24.322305 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:18:25.182065 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.86 seconds
13:18:25.186277 [debug] [Thread-1  ]: finished collecting timing info
13:18:25.186683 [debug] [Thread-1  ]: On test.learn_dbt.assert_under_10_percent_null: Close
13:18:25.459287 [info ] [Thread-1  ]: 1 of 11 PASS assert_under_10_percent_null....................................... [[32mPASS[0m in 1.16s]
13:18:25.459958 [debug] [Thread-1  ]: Finished running node test.learn_dbt.assert_under_10_percent_null
13:18:25.460223 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
13:18:25.460552 [info ] [Thread-1  ]: 2 of 11 START test not_null_my_second_dbt_model_id.............................. [RUN]
13:18:25.461242 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"
13:18:25.461398 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
13:18:25.461677 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
13:18:25.472920 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"
13:18:25.473817 [debug] [Thread-1  ]: finished collecting timing info
13:18:25.473976 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
13:18:25.476932 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"
13:18:25.477712 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"
13:18:25.477840 [debug] [Thread-1  ]: On test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.my_second_dbt_model
where id is null



      
    ) dbt_internal_test
13:18:25.477955 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:18:26.249343 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.77 seconds
13:18:26.258481 [debug] [Thread-1  ]: finished collecting timing info
13:18:26.258988 [debug] [Thread-1  ]: On test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778: Close
13:18:26.497352 [error] [Thread-1  ]: 2 of 11 FAIL 1 not_null_my_second_dbt_model_id.................................. [[31mFAIL 1[0m in 1.04s]
13:18:26.497851 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
13:18:26.498058 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4
13:18:26.498537 [info ] [Thread-1  ]: 3 of 11 START test not_null_playing_with_tests_c_custkey........................ [RUN]
13:18:26.498983 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4"
13:18:26.499119 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4
13:18:26.499454 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4
13:18:26.504843 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4"
13:18:26.505447 [debug] [Thread-1  ]: finished collecting timing info
13:18:26.505624 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4
13:18:26.507379 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4"
13:18:26.508332 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4"
13:18:26.508496 [debug] [Thread-1  ]: On test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.playing_with_tests
where c_custkey is null



      
    ) dbt_internal_test
13:18:26.508919 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:18:27.270438 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.76 seconds
13:18:27.273878 [debug] [Thread-1  ]: finished collecting timing info
13:18:27.274310 [debug] [Thread-1  ]: On test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4: Close
13:18:27.539904 [info ] [Thread-1  ]: 3 of 11 PASS not_null_playing_with_tests_c_custkey.............................. [[32mPASS[0m in 1.04s]
13:18:27.540669 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4
13:18:27.540962 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
13:18:27.541323 [info ] [Thread-1  ]: 4 of 11 START test not_null_snowflake_cumulative_sales_o_orderdate.............. [RUN]
13:18:27.542015 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
13:18:27.542223 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
13:18:27.542413 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
13:18:27.546715 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
13:18:27.547245 [debug] [Thread-1  ]: finished collecting timing info
13:18:27.547412 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
13:18:27.549554 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
13:18:27.550487 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
13:18:27.550630 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.snowflake_cumulative_sales
where o_orderdate is null



      
    ) dbt_internal_test
13:18:27.550754 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:18:28.337976 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.79 seconds
13:18:28.340914 [debug] [Thread-1  ]: finished collecting timing info
13:18:28.341255 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856: Close
13:18:28.602282 [info ] [Thread-1  ]: 4 of 11 PASS not_null_snowflake_cumulative_sales_o_orderdate.................... [[32mPASS[0m in 1.06s]
13:18:28.602899 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
13:18:28.603114 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
13:18:28.603385 [info ] [Thread-1  ]: 5 of 11 START test not_null_snowflake_customer_purchases_c_custkey.............. [RUN]
13:18:28.604007 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
13:18:28.604220 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
13:18:28.604421 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
13:18:28.609277 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
13:18:28.610028 [debug] [Thread-1  ]: finished collecting timing info
13:18:28.610209 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
13:18:28.612396 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
13:18:28.613375 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
13:18:28.613658 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.snowflake_customer_purchases
where c_custkey is null



      
    ) dbt_internal_test
13:18:28.613793 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:18:29.373779 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.76 seconds
13:18:29.377301 [debug] [Thread-1  ]: finished collecting timing info
13:18:29.377633 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502: Close
13:18:29.627766 [info ] [Thread-1  ]: 5 of 11 PASS not_null_snowflake_customer_purchases_c_custkey.................... [[32mPASS[0m in 1.02s]
13:18:29.628193 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
13:18:29.628315 [debug] [Thread-1  ]: Began running node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
13:18:29.628470 [info ] [Thread-1  ]: 6 of 11 START test relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ [RUN]
13:18:29.628756 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
13:18:29.628849 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
13:18:29.628937 [debug] [Thread-1  ]: Compiling test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
13:18:29.634505 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
13:18:29.634931 [debug] [Thread-1  ]: finished collecting timing info
13:18:29.635037 [debug] [Thread-1  ]: Began executing node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
13:18:29.636176 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
13:18:29.636890 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
13:18:29.636981 [debug] [Thread-1  ]: On test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select id as from_field
    from analytics.dbt.my_second_dbt_model
    where id is not null
),

parent as (
    select id as to_field
    from analytics.dbt.first_model
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
13:18:29.637059 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:18:30.485951 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.85 seconds
13:18:30.489788 [debug] [Thread-1  ]: finished collecting timing info
13:18:30.490270 [debug] [Thread-1  ]: On test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: Close
13:18:30.934899 [info ] [Thread-1  ]: 6 of 11 PASS relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.. [[32mPASS[0m in 1.31s]
13:18:30.935594 [debug] [Thread-1  ]: Finished running node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
13:18:30.935849 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
13:18:30.936169 [info ] [Thread-1  ]: 7 of 11 START test unique_my_first_dbt_model_id................................. [RUN]
13:18:30.936878 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
13:18:30.937093 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
13:18:30.937293 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
13:18:30.945813 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
13:18:30.946602 [debug] [Thread-1  ]: finished collecting timing info
13:18:30.946839 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
13:18:30.948675 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
13:18:30.949737 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
13:18:30.949885 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.first_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
13:18:30.950013 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:18:32.105562 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.16 seconds
13:18:32.108682 [debug] [Thread-1  ]: finished collecting timing info
13:18:32.109093 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_first_dbt_model_id.16e066b321: Close
13:18:32.459262 [info ] [Thread-1  ]: 7 of 11 PASS unique_my_first_dbt_model_id....................................... [[32mPASS[0m in 1.52s]
13:18:32.459964 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
13:18:32.460228 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:18:32.460431 [info ] [Thread-1  ]: 8 of 11 START test unique_my_second_dbt_model_id................................ [RUN]
13:18:32.461156 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
13:18:32.461405 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:18:32.461612 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:18:32.466520 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
13:18:32.467411 [debug] [Thread-1  ]: finished collecting timing info
13:18:32.467596 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:18:32.469862 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
13:18:32.470949 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
13:18:32.471103 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.my_second_dbt_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
13:18:32.471242 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:18:33.457228 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.99 seconds
13:18:33.459881 [debug] [Thread-1  ]: finished collecting timing info
13:18:33.460186 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493: Close
13:18:33.861912 [info ] [Thread-1  ]: 8 of 11 PASS unique_my_second_dbt_model_id...................................... [[32mPASS[0m in 1.40s]
13:18:33.862635 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:18:33.862920 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550
13:18:33.863202 [info ] [Thread-1  ]: 9 of 11 START test unique_playing_with_tests_c_custkey.......................... [RUN]
13:18:33.863780 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550"
13:18:33.864009 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550
13:18:33.864119 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550
13:18:33.867176 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550"
13:18:33.867625 [debug] [Thread-1  ]: finished collecting timing info
13:18:33.867850 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550
13:18:33.870404 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550"
13:18:33.871534 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550"
13:18:33.871703 [debug] [Thread-1  ]: On test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    c_custkey as unique_field,
    count(*) as n_records

from analytics.dbt.playing_with_tests
where c_custkey is not null
group by c_custkey
having count(*) > 1



      
    ) dbt_internal_test
13:18:33.871846 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:18:34.907938 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.04 seconds
13:18:34.910461 [debug] [Thread-1  ]: finished collecting timing info
13:18:34.910921 [debug] [Thread-1  ]: On test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550: Close
13:18:35.090164 [info ] [Thread-1  ]: 9 of 11 PASS unique_playing_with_tests_c_custkey................................ [[32mPASS[0m in 1.23s]
13:18:35.090801 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550
13:18:35.090969 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
13:18:35.091129 [info ] [Thread-1  ]: 10 of 11 START test unique_snowflake_cumulative_sales_o_orderdate............... [RUN]
13:18:35.091473 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
13:18:35.091569 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
13:18:35.091663 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
13:18:35.094294 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
13:18:35.095002 [debug] [Thread-1  ]: finished collecting timing info
13:18:35.095226 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
13:18:35.097209 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
13:18:35.097850 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
13:18:35.097943 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    o_orderdate as unique_field,
    count(*) as n_records

from analytics.dbt.snowflake_cumulative_sales
where o_orderdate is not null
group by o_orderdate
having count(*) > 1



      
    ) dbt_internal_test
13:18:35.098021 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:18:36.130183 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.03 seconds
13:18:36.132378 [debug] [Thread-1  ]: finished collecting timing info
13:18:36.132667 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed: Close
13:18:36.321550 [info ] [Thread-1  ]: 10 of 11 PASS unique_snowflake_cumulative_sales_o_orderdate..................... [[32mPASS[0m in 1.23s]
13:18:36.321960 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
13:18:36.322141 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
13:18:36.322401 [info ] [Thread-1  ]: 11 of 11 START test unique_snowflake_customer_purchases_c_custkey............... [RUN]
13:18:36.323159 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
13:18:36.323373 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
13:18:36.323579 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
13:18:36.328479 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
13:18:36.329154 [debug] [Thread-1  ]: finished collecting timing info
13:18:36.329319 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
13:18:36.331609 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
13:18:36.332797 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
13:18:36.333082 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    c_custkey as unique_field,
    count(*) as n_records

from analytics.dbt.snowflake_customer_purchases
where c_custkey is not null
group by c_custkey
having count(*) > 1



      
    ) dbt_internal_test
13:18:36.333269 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:18:37.296369 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.96 seconds
13:18:37.298597 [debug] [Thread-1  ]: finished collecting timing info
13:18:37.298845 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f: Close
13:18:37.616919 [info ] [Thread-1  ]: 11 of 11 PASS unique_snowflake_customer_purchases_c_custkey..................... [[32mPASS[0m in 1.29s]
13:18:37.617236 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
13:18:37.618007 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:18:37.618228 [info ] [MainThread]: 
13:18:37.618366 [info ] [MainThread]: Finished running 11 tests in 14.45s.
13:18:37.618486 [debug] [MainThread]: Connection 'master' was properly closed.
13:18:37.618554 [debug] [MainThread]: Connection 'test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f' was properly closed.
13:18:37.622075 [info ] [MainThread]: 
13:18:37.622257 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
13:18:37.622425 [info ] [MainThread]: 
13:18:37.622544 [error] [MainThread]: [31mFailure in test not_null_my_second_dbt_model_id (models/example/schema.yml)[0m
13:18:37.622673 [error] [MainThread]:   Got 1 result, configured to fail if != 0
13:18:37.622787 [info ] [MainThread]: 
13:18:37.622897 [info ] [MainThread]:   compiled SQL at target/compiled/learn_dbt/models/example/schema.yml/not_null_my_second_dbt_model_id.sql
13:18:37.623018 [info ] [MainThread]: 
13:18:37.623123 [info ] [MainThread]: Done. PASS=10 WARN=0 ERROR=1 SKIP=0 TOTAL=11
13:18:37.623291 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105b68e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106fc20a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110387820>]}


============================== 2022-05-13 13:23:52.923322 | 8f146740-bd48-4a2d-88c0-cd4adc3151f7 ==============================
13:23:52.923322 [info ] [MainThread]: Running with dbt=1.0.1
13:23:52.923863 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
13:23:52.923998 [debug] [MainThread]: Tracking: tracking
13:23:52.924210 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e8f850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e8f1c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e8fd60>]}
13:23:52.963929 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104fa68e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104fa6a60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104fa6dc0>]}


============================== 2022-05-13 13:25:11.319135 | 498dd6f5-7794-425a-a323-8ffd0a37be54 ==============================
13:25:11.319135 [info ] [MainThread]: Running with dbt=1.0.1
13:25:11.319458 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
13:25:11.319594 [debug] [MainThread]: Tracking: tracking
13:25:11.319823 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1113ff6a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1113ff7c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1113ffa90>]}
13:25:11.357651 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1114b5d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1114b5d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1114b5df0>]}


============================== 2022-05-13 13:25:51.164615 | c061952e-2467-423a-8f8b-c216d0a8d54a ==============================
13:25:51.164615 [info ] [MainThread]: Running with dbt=1.0.1
13:25:51.165099 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
13:25:51.165244 [debug] [MainThread]: Tracking: tracking
13:25:51.165461 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1050d31c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1050d3f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1050d3460>]}
13:25:51.213818 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
13:25:51.214167 [debug] [MainThread]: Partial parsing: update schema file: learn_dbt://models/example/schema.yml
13:25:51.219983 [debug] [MainThread]: 1699: static parser successfully parsed example/playing_with_tests.sql
13:25:51.246740 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c061952e-2467-423a-8f8b-c216d0a8d54a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1050c0700>]}
13:25:51.249852 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c061952e-2467-423a-8f8b-c216d0a8d54a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104263970>]}
13:25:51.249987 [info ] [MainThread]: Found 7 models, 12 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
13:25:51.250783 [info ] [MainThread]: 
13:25:51.250982 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:25:51.251437 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
13:25:51.257354 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
13:25:51.257490 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
13:25:51.257558 [debug] [ThreadPool]: Opening a new connection, currently in state init
13:25:52.246136 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.99 seconds
13:25:52.247693 [debug] [ThreadPool]: On list_analytics: Close
13:25:52.456085 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
13:25:52.465009 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
13:25:52.465294 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
13:25:52.465464 [debug] [ThreadPool]: Opening a new connection, currently in state closed
13:25:53.248496 [debug] [ThreadPool]: SQL status: SUCCESS 7 in 0.78 seconds
13:25:53.252051 [debug] [ThreadPool]: On list_analytics_dbt: Close
13:25:53.465603 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
13:25:53.466424 [info ] [MainThread]: 
13:25:53.472054 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
13:25:53.472510 [info ] [Thread-1  ]: 1 of 7 START incremental model dbt.dates........................................ [RUN]
13:25:53.473092 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
13:25:53.473272 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
13:25:53.473444 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
13:25:53.483194 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
13:25:53.484375 [debug] [Thread-1  ]: finished collecting timing info
13:25:53.484539 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
13:25:53.513376 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:25:53.513578 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
13:25:53.513669 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:25:55.163175 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.65 seconds
13:25:55.173299 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:25:55.173470 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
13:25:55.272622 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.1 seconds
13:25:55.279093 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:25:55.279391 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
13:25:55.379690 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.1 seconds
13:25:55.392895 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:25:55.393190 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
13:25:55.506992 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.11 seconds
13:25:55.528457 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
13:25:55.530837 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:25:55.530986 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
13:25:55.818923 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.29 seconds
13:25:55.820537 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:25:55.820808 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
13:25:56.394585 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.57 seconds
13:25:56.395041 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:25:56.395223 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
13:25:56.576680 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.18 seconds
13:25:56.590401 [debug] [Thread-1  ]: finished collecting timing info
13:25:56.590869 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
13:25:56.867947 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c061952e-2467-423a-8f8b-c216d0a8d54a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108544a60>]}
13:25:56.868831 [info ] [Thread-1  ]: 1 of 7 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 3.39s]
13:25:56.869272 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
13:25:56.869527 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
13:25:56.869922 [info ] [Thread-1  ]: 2 of 7 START incremental model dbt.incremental_time............................. [RUN]
13:25:56.870545 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
13:25:56.870761 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
13:25:56.870975 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
13:25:56.875072 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
13:25:56.877111 [debug] [Thread-1  ]: finished collecting timing info
13:25:56.877327 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
13:25:56.880934 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:25:56.881136 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
13:25:56.881266 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:25:58.154885 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.27 seconds
13:25:58.159963 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:25:58.160284 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
13:25:58.306830 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.15 seconds
13:25:58.309383 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:25:58.309512 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
13:25:58.402705 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.09 seconds
13:25:58.407734 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:25:58.408053 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
13:25:58.509681 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
13:25:58.515081 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
13:25:58.518513 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:25:58.518741 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
13:25:58.656580 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.14 seconds
13:25:58.657185 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:25:58.657389 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
13:25:59.221060 [debug] [Thread-1  ]: SQL status: SUCCESS 474 in 0.56 seconds
13:25:59.221788 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:25:59.221984 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
13:25:59.438369 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.22 seconds
13:25:59.441331 [debug] [Thread-1  ]: finished collecting timing info
13:25:59.441700 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
13:25:59.680916 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c061952e-2467-423a-8f8b-c216d0a8d54a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1056b4520>]}
13:25:59.681676 [info ] [Thread-1  ]: 2 of 7 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 2.81s]
13:25:59.682124 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
13:25:59.682373 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
13:25:59.682660 [info ] [Thread-1  ]: 3 of 7 START table model dbt.first_model........................................ [RUN]
13:25:59.683370 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
13:25:59.683624 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
13:25:59.683829 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
13:25:59.687989 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
13:25:59.690041 [debug] [Thread-1  ]: finished collecting timing info
13:25:59.690229 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
13:25:59.699336 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
13:25:59.700403 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
13:25:59.700545 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id

)

select * 
from source_data


/*
select *, True as first_variable
from source_data
where id >= 1
*/
      );
13:25:59.700677 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:26:00.838096 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.14 seconds
13:26:00.840886 [debug] [Thread-1  ]: finished collecting timing info
13:26:00.841210 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
13:26:01.153684 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c061952e-2467-423a-8f8b-c216d0a8d54a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1056b4d00>]}
13:26:01.154325 [info ] [Thread-1  ]: 3 of 7 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 1.47s]
13:26:01.154788 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
13:26:01.155043 [debug] [Thread-1  ]: Began running node model.learn_dbt.playing_with_tests
13:26:01.155534 [info ] [Thread-1  ]: 4 of 7 START table model dbt.playing_with_tests................................. [RUN]
13:26:01.156515 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.playing_with_tests"
13:26:01.156752 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.playing_with_tests
13:26:01.156951 [debug] [Thread-1  ]: Compiling model.learn_dbt.playing_with_tests
13:26:01.158609 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.playing_with_tests"
13:26:01.159349 [debug] [Thread-1  ]: finished collecting timing info
13:26:01.159520 [debug] [Thread-1  ]: Began executing node model.learn_dbt.playing_with_tests
13:26:01.161874 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.playing_with_tests"
13:26:01.162657 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
13:26:01.162823 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */


      create or replace transient table analytics.dbt.playing_with_tests  as
      (select * 
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER"
      );
13:26:01.162970 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:26:03.158282 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.0 seconds
13:26:03.160944 [debug] [Thread-1  ]: finished collecting timing info
13:26:03.161292 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: Close
13:26:03.329641 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c061952e-2467-423a-8f8b-c216d0a8d54a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1056b4940>]}
13:26:03.330130 [info ] [Thread-1  ]: 4 of 7 OK created table model dbt.playing_with_tests............................ [[32mSUCCESS 1[0m in 2.17s]
13:26:03.330373 [debug] [Thread-1  ]: Finished running node model.learn_dbt.playing_with_tests
13:26:03.330518 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
13:26:03.330754 [info ] [Thread-1  ]: 5 of 7 START table model dbt.snowflake_cumulative_sales......................... [RUN]
13:26:03.331118 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
13:26:03.331238 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
13:26:03.331349 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
13:26:03.332292 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
13:26:03.334011 [debug] [Thread-1  ]: finished collecting timing info
13:26:03.334149 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
13:26:03.335836 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
13:26:03.336506 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
13:26:03.336623 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
13:26:03.336719 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:26:06.366961 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 3.03 seconds
13:26:06.369736 [debug] [Thread-1  ]: finished collecting timing info
13:26:06.370077 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
13:26:06.532218 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c061952e-2467-423a-8f8b-c216d0a8d54a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108608490>]}
13:26:06.535655 [info ] [Thread-1  ]: 5 of 7 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 3.20s]
13:26:06.536170 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
13:26:06.536427 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
13:26:06.536931 [info ] [Thread-1  ]: 6 of 7 START table model dbt.snowflake_customer_purchases....................... [RUN]
13:26:06.537689 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
13:26:06.537916 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
13:26:06.538122 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
13:26:06.539930 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
13:26:06.541671 [debug] [Thread-1  ]: finished collecting timing info
13:26:06.541954 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
13:26:06.544746 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
13:26:06.546153 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
13:26:06.546363 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
13:26:06.546526 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:26:08.429156 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.88 seconds
13:26:08.432047 [debug] [Thread-1  ]: finished collecting timing info
13:26:08.432745 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
13:26:08.610077 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c061952e-2467-423a-8f8b-c216d0a8d54a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1057016a0>]}
13:26:08.610825 [info ] [Thread-1  ]: 6 of 7 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.07s]
13:26:08.611266 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
13:26:08.611506 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
13:26:08.611779 [info ] [Thread-1  ]: 7 of 7 START table model dbt.my_second_dbt_model................................ [RUN]
13:26:08.612485 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
13:26:08.612747 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
13:26:08.612961 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
13:26:08.616133 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
13:26:08.618235 [debug] [Thread-1  ]: finished collecting timing info
13:26:08.618431 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
13:26:08.620878 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
13:26:08.621916 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
13:26:08.622169 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
/*
union all
select 7 as id, True as first_variable
*/
      );
13:26:08.622459 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:26:10.022127 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.4 seconds
13:26:10.025789 [debug] [Thread-1  ]: finished collecting timing info
13:26:10.026186 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
13:26:10.192797 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c061952e-2467-423a-8f8b-c216d0a8d54a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1056f29a0>]}
13:26:10.194147 [info ] [Thread-1  ]: 7 of 7 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.58s]
13:26:10.194994 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
13:26:10.196922 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:26:10.197625 [info ] [MainThread]: 
13:26:10.198006 [info ] [MainThread]: Finished running 2 incremental models, 5 table models in 18.95s.
13:26:10.198314 [debug] [MainThread]: Connection 'master' was properly closed.
13:26:10.198483 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
13:26:10.207127 [info ] [MainThread]: 
13:26:10.207586 [info ] [MainThread]: [32mCompleted successfully[0m
13:26:10.207858 [info ] [MainThread]: 
13:26:10.208157 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
13:26:10.208465 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103c1d7f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105244640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1056dbc70>]}


============================== 2022-05-13 13:26:14.807225 | e1742851-5b6f-4231-aca0-63ec3ecc8c89 ==============================
13:26:14.807225 [info ] [MainThread]: Running with dbt=1.0.1
13:26:14.807658 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, store_failures=False, indirect_selection='eager', threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.test.TestTask'>, which='test', rpc_method='test')
13:26:14.807817 [debug] [MainThread]: Tracking: tracking
13:26:14.808039 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108ca7160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108ca7070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108ca7400>]}
13:26:14.852533 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
13:26:14.852686 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
13:26:14.855721 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e1742851-5b6f-4231-aca0-63ec3ecc8c89', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c91130>]}
13:26:14.859005 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e1742851-5b6f-4231-aca0-63ec3ecc8c89', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107aa7a90>]}
13:26:14.859138 [info ] [MainThread]: Found 7 models, 12 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
13:26:14.859983 [info ] [MainThread]: 
13:26:14.860187 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:26:14.860675 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
13:26:14.866526 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
13:26:14.866662 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
13:26:14.866729 [debug] [ThreadPool]: Opening a new connection, currently in state init
13:26:15.522955 [debug] [ThreadPool]: SQL status: SUCCESS 7 in 0.66 seconds
13:26:15.525348 [debug] [ThreadPool]: On list_analytics_dbt: Close
13:26:15.947547 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
13:26:15.948310 [info ] [MainThread]: 
13:26:15.952532 [debug] [Thread-1  ]: Began running node test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
13:26:15.952799 [info ] [Thread-1  ]: 1 of 12 START test accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE [RUN]
13:26:15.953145 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
13:26:15.953232 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
13:26:15.953310 [debug] [Thread-1  ]: Compiling test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
13:26:15.967844 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
13:26:15.968460 [debug] [Thread-1  ]: finished collecting timing info
13:26:15.968600 [debug] [Thread-1  ]: Began executing node test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
13:26:15.981026 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
13:26:15.982237 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
13:26:15.982370 [debug] [Thread-1  ]: On test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        c_mktsegment as value_field,
        count(*) as n_records

    from analytics.dbt.playing_with_tests
    group by c_mktsegment

)

select *
from all_values
where value_field not in (
    'BUILDING','AUTOMOBILE','MACHINERY','HOUSEHOLD','FURNITURE'
)



      
    ) dbt_internal_test
13:26:15.982473 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:26:17.377078 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.39 seconds
13:26:17.380719 [debug] [Thread-1  ]: finished collecting timing info
13:26:17.381122 [debug] [Thread-1  ]: On test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3: Close
13:26:17.556467 [info ] [Thread-1  ]: 1 of 12 PASS accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE [[32mPASS[0m in 1.60s]
13:26:17.557219 [debug] [Thread-1  ]: Finished running node test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
13:26:17.557490 [debug] [Thread-1  ]: Began running node test.learn_dbt.assert_under_10_percent_null
13:26:17.557700 [info ] [Thread-1  ]: 2 of 12 START test assert_under_10_percent_null................................. [RUN]
13:26:17.558427 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.assert_under_10_percent_null"
13:26:17.558686 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.assert_under_10_percent_null
13:26:17.558916 [debug] [Thread-1  ]: Compiling test.learn_dbt.assert_under_10_percent_null
13:26:17.561985 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.assert_under_10_percent_null"
13:26:17.563897 [debug] [Thread-1  ]: finished collecting timing info
13:26:17.564150 [debug] [Thread-1  ]: Began executing node test.learn_dbt.assert_under_10_percent_null
13:26:17.566646 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.assert_under_10_percent_null"
13:26:17.567967 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.assert_under_10_percent_null"
13:26:17.568181 [debug] [Thread-1  ]: On test.learn_dbt.assert_under_10_percent_null: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.assert_under_10_percent_null"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      select sum (case when id is null then 1 else 0 end) / count(*) as total_nulls
from analytics.dbt.first_model
having sum (case when id is null then 1 else 0 end) / count(*) > .4
      
    ) dbt_internal_test
13:26:17.568319 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:26:18.611465 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.04 seconds
13:26:18.614522 [debug] [Thread-1  ]: finished collecting timing info
13:26:18.614872 [debug] [Thread-1  ]: On test.learn_dbt.assert_under_10_percent_null: Close
13:26:18.887977 [info ] [Thread-1  ]: 2 of 12 PASS assert_under_10_percent_null....................................... [[32mPASS[0m in 1.33s]
13:26:18.888800 [debug] [Thread-1  ]: Finished running node test.learn_dbt.assert_under_10_percent_null
13:26:18.889081 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
13:26:18.889417 [info ] [Thread-1  ]: 3 of 12 START test not_null_my_second_dbt_model_id.............................. [RUN]
13:26:18.890145 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"
13:26:18.890446 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
13:26:18.890679 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
13:26:18.898668 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"
13:26:18.899537 [debug] [Thread-1  ]: finished collecting timing info
13:26:18.899811 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
13:26:18.901479 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"
13:26:18.902330 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"
13:26:18.902482 [debug] [Thread-1  ]: On test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.my_second_dbt_model
where id is null



      
    ) dbt_internal_test
13:26:18.902611 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:26:19.935706 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.03 seconds
13:26:19.938629 [debug] [Thread-1  ]: finished collecting timing info
13:26:19.938952 [debug] [Thread-1  ]: On test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778: Close
13:26:20.128235 [error] [Thread-1  ]: 3 of 12 FAIL 1 not_null_my_second_dbt_model_id.................................. [[31mFAIL 1[0m in 1.24s]
13:26:20.128797 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
13:26:20.129012 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4
13:26:20.129266 [info ] [Thread-1  ]: 4 of 12 START test not_null_playing_with_tests_c_custkey........................ [RUN]
13:26:20.129770 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4"
13:26:20.129944 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4
13:26:20.130041 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4
13:26:20.132755 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4"
13:26:20.133187 [debug] [Thread-1  ]: finished collecting timing info
13:26:20.133287 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4
13:26:20.134332 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4"
13:26:20.134856 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4"
13:26:20.134946 [debug] [Thread-1  ]: On test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.playing_with_tests
where c_custkey is null



      
    ) dbt_internal_test
13:26:20.135025 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:26:20.982257 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.85 seconds
13:26:20.985762 [debug] [Thread-1  ]: finished collecting timing info
13:26:20.986149 [debug] [Thread-1  ]: On test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4: Close
13:26:21.153861 [info ] [Thread-1  ]: 4 of 12 PASS not_null_playing_with_tests_c_custkey.............................. [[32mPASS[0m in 1.02s]
13:26:21.154475 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4
13:26:21.154744 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
13:26:21.155137 [info ] [Thread-1  ]: 5 of 12 START test not_null_snowflake_cumulative_sales_o_orderdate.............. [RUN]
13:26:21.156001 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
13:26:21.156245 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
13:26:21.156445 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
13:26:21.160931 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
13:26:21.161528 [debug] [Thread-1  ]: finished collecting timing info
13:26:21.161696 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
13:26:21.163858 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
13:26:21.164843 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
13:26:21.165006 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.snowflake_cumulative_sales
where o_orderdate is null



      
    ) dbt_internal_test
13:26:21.165352 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:26:22.030784 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.87 seconds
13:26:22.034803 [debug] [Thread-1  ]: finished collecting timing info
13:26:22.035234 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856: Close
13:26:22.205733 [info ] [Thread-1  ]: 5 of 12 PASS not_null_snowflake_cumulative_sales_o_orderdate.................... [[32mPASS[0m in 1.05s]
13:26:22.206308 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
13:26:22.206696 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
13:26:22.206940 [info ] [Thread-1  ]: 6 of 12 START test not_null_snowflake_customer_purchases_c_custkey.............. [RUN]
13:26:22.207583 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
13:26:22.207798 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
13:26:22.207992 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
13:26:22.212679 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
13:26:22.213284 [debug] [Thread-1  ]: finished collecting timing info
13:26:22.213460 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
13:26:22.215588 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
13:26:22.216520 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
13:26:22.216680 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.snowflake_customer_purchases
where c_custkey is null



      
    ) dbt_internal_test
13:26:22.216817 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:26:23.297176 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.08 seconds
13:26:23.300320 [debug] [Thread-1  ]: finished collecting timing info
13:26:23.300734 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502: Close
13:26:23.587542 [info ] [Thread-1  ]: 6 of 12 PASS not_null_snowflake_customer_purchases_c_custkey.................... [[32mPASS[0m in 1.38s]
13:26:23.588496 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
13:26:23.589003 [debug] [Thread-1  ]: Began running node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
13:26:23.589449 [info ] [Thread-1  ]: 7 of 12 START test relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ [RUN]
13:26:23.590113 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
13:26:23.590336 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
13:26:23.590548 [debug] [Thread-1  ]: Compiling test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
13:26:23.601392 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
13:26:23.602211 [debug] [Thread-1  ]: finished collecting timing info
13:26:23.602376 [debug] [Thread-1  ]: Began executing node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
13:26:23.604216 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
13:26:23.605446 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
13:26:23.605598 [debug] [Thread-1  ]: On test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select id as from_field
    from analytics.dbt.my_second_dbt_model
    where id is not null
),

parent as (
    select id as to_field
    from analytics.dbt.first_model
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
13:26:23.605730 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:26:24.523911 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.92 seconds
13:26:24.526185 [debug] [Thread-1  ]: finished collecting timing info
13:26:24.526401 [debug] [Thread-1  ]: On test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: Close
13:26:24.718941 [info ] [Thread-1  ]: 7 of 12 PASS relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.. [[32mPASS[0m in 1.13s]
13:26:24.723157 [debug] [Thread-1  ]: Finished running node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
13:26:24.724625 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
13:26:24.725785 [info ] [Thread-1  ]: 8 of 12 START test unique_my_first_dbt_model_id................................. [RUN]
13:26:24.726795 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
13:26:24.727043 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
13:26:24.727258 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
13:26:24.735385 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
13:26:24.736193 [debug] [Thread-1  ]: finished collecting timing info
13:26:24.736537 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
13:26:24.738486 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
13:26:24.739669 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
13:26:24.739826 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.first_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
13:26:24.739959 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:26:25.439419 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.7 seconds
13:26:25.441355 [debug] [Thread-1  ]: finished collecting timing info
13:26:25.441558 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_first_dbt_model_id.16e066b321: Close
13:26:25.662223 [info ] [Thread-1  ]: 8 of 12 PASS unique_my_first_dbt_model_id....................................... [[32mPASS[0m in 0.94s]
13:26:25.663072 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
13:26:25.663574 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:26:25.664025 [info ] [Thread-1  ]: 9 of 12 START test unique_my_second_dbt_model_id................................ [RUN]
13:26:25.664694 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
13:26:25.664884 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:26:25.665054 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:26:25.669359 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
13:26:25.669999 [debug] [Thread-1  ]: finished collecting timing info
13:26:25.670185 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:26:25.672523 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
13:26:25.673639 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
13:26:25.673816 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.my_second_dbt_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
13:26:25.673960 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:26:26.410090 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.74 seconds
13:26:26.413465 [debug] [Thread-1  ]: finished collecting timing info
13:26:26.413868 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493: Close
13:26:26.624937 [info ] [Thread-1  ]: 9 of 12 PASS unique_my_second_dbt_model_id...................................... [[32mPASS[0m in 0.96s]
13:26:26.625471 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:26:26.625691 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550
13:26:26.625944 [info ] [Thread-1  ]: 10 of 12 START test unique_playing_with_tests_c_custkey......................... [RUN]
13:26:26.626523 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550"
13:26:26.626700 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550
13:26:26.626872 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550
13:26:26.631051 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550"
13:26:26.632078 [debug] [Thread-1  ]: finished collecting timing info
13:26:26.632265 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550
13:26:26.634607 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550"
13:26:26.635962 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550"
13:26:26.636197 [debug] [Thread-1  ]: On test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    c_custkey as unique_field,
    count(*) as n_records

from analytics.dbt.playing_with_tests
where c_custkey is not null
group by c_custkey
having count(*) > 1



      
    ) dbt_internal_test
13:26:26.636358 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:26:27.529421 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.89 seconds
13:26:27.532657 [debug] [Thread-1  ]: finished collecting timing info
13:26:27.533058 [debug] [Thread-1  ]: On test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550: Close
13:26:27.798419 [info ] [Thread-1  ]: 10 of 12 PASS unique_playing_with_tests_c_custkey............................... [[32mPASS[0m in 1.17s]
13:26:27.799006 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550
13:26:27.799262 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
13:26:27.799575 [info ] [Thread-1  ]: 11 of 12 START test unique_snowflake_cumulative_sales_o_orderdate............... [RUN]
13:26:27.800282 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
13:26:27.800628 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
13:26:27.800844 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
13:26:27.805746 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
13:26:27.806511 [debug] [Thread-1  ]: finished collecting timing info
13:26:27.806700 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
13:26:27.808979 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
13:26:27.810132 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
13:26:27.810378 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    o_orderdate as unique_field,
    count(*) as n_records

from analytics.dbt.snowflake_cumulative_sales
where o_orderdate is not null
group by o_orderdate
having count(*) > 1



      
    ) dbt_internal_test
13:26:27.810514 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:26:28.714931 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.9 seconds
13:26:28.718013 [debug] [Thread-1  ]: finished collecting timing info
13:26:28.718451 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed: Close
13:26:28.920070 [info ] [Thread-1  ]: 11 of 12 PASS unique_snowflake_cumulative_sales_o_orderdate..................... [[32mPASS[0m in 1.12s]
13:26:28.920875 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
13:26:28.921296 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
13:26:28.921688 [info ] [Thread-1  ]: 12 of 12 START test unique_snowflake_customer_purchases_c_custkey............... [RUN]
13:26:28.922315 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
13:26:28.922531 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
13:26:28.922737 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
13:26:28.927847 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
13:26:28.928405 [debug] [Thread-1  ]: finished collecting timing info
13:26:28.928583 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
13:26:28.930804 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
13:26:28.932041 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
13:26:28.932381 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    c_custkey as unique_field,
    count(*) as n_records

from analytics.dbt.snowflake_customer_purchases
where c_custkey is not null
group by c_custkey
having count(*) > 1



      
    ) dbt_internal_test
13:26:28.932575 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:26:29.788039 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.86 seconds
13:26:29.791626 [debug] [Thread-1  ]: finished collecting timing info
13:26:29.792063 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f: Close
13:26:29.951009 [info ] [Thread-1  ]: 12 of 12 PASS unique_snowflake_customer_purchases_c_custkey..................... [[32mPASS[0m in 1.03s]
13:26:29.952182 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
13:26:29.953813 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:26:29.954337 [info ] [MainThread]: 
13:26:29.954681 [info ] [MainThread]: Finished running 12 tests in 15.09s.
13:26:29.954984 [debug] [MainThread]: Connection 'master' was properly closed.
13:26:29.955152 [debug] [MainThread]: Connection 'test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f' was properly closed.
13:26:29.962369 [info ] [MainThread]: 
13:26:29.962697 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
13:26:29.962971 [info ] [MainThread]: 
13:26:29.963199 [error] [MainThread]: [31mFailure in test not_null_my_second_dbt_model_id (models/example/schema.yml)[0m
13:26:29.963451 [error] [MainThread]:   Got 1 result, configured to fail if != 0
13:26:29.963914 [info ] [MainThread]: 
13:26:29.964159 [info ] [MainThread]:   compiled SQL at target/compiled/learn_dbt/models/example/schema.yml/not_null_my_second_dbt_model_id.sql
13:26:29.964391 [info ] [MainThread]: 
13:26:29.964581 [info ] [MainThread]: Done. PASS=11 WARN=0 ERROR=1 SKIP=0 TOTAL=12
13:26:29.964857 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109d75520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108e310d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1099d75b0>]}


============================== 2022-05-13 13:35:59.767368 | b3356159-50d4-4610-b128-871c8a9cb7af ==============================
13:35:59.767368 [info ] [MainThread]: Running with dbt=1.0.1
13:35:59.767733 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
13:35:59.767865 [debug] [MainThread]: Tracking: tracking
13:35:59.768084 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1056a2850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1056a2760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1056a2400>]}
13:35:59.810589 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
13:35:59.810827 [debug] [MainThread]: Partial parsing: added file: learn_dbt://tests/assert_accbal_less_than_100m.sql
13:35:59.825647 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b3356159-50d4-4610-b128-871c8a9cb7af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10592a0d0>]}
13:35:59.829141 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b3356159-50d4-4610-b128-871c8a9cb7af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10568db80>]}
13:35:59.829286 [info ] [MainThread]: Found 7 models, 13 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
13:35:59.830090 [info ] [MainThread]: 
13:35:59.830294 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:35:59.830764 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
13:35:59.836518 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
13:35:59.836617 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
13:35:59.836689 [debug] [ThreadPool]: Opening a new connection, currently in state init
13:36:00.922116 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.09 seconds
13:36:00.924327 [debug] [ThreadPool]: On list_analytics: Close
13:36:01.141676 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
13:36:01.147888 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
13:36:01.148101 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
13:36:01.148243 [debug] [ThreadPool]: Opening a new connection, currently in state closed
13:36:02.620277 [debug] [ThreadPool]: SQL status: SUCCESS 7 in 1.47 seconds
13:36:02.623177 [debug] [ThreadPool]: On list_analytics_dbt: Close
13:36:02.954753 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
13:36:02.955290 [info ] [MainThread]: 
13:36:02.957424 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
13:36:02.957643 [info ] [Thread-1  ]: 1 of 7 START incremental model dbt.dates........................................ [RUN]
13:36:02.957930 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
13:36:02.958022 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
13:36:02.958116 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
13:36:02.964157 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
13:36:02.964673 [debug] [Thread-1  ]: finished collecting timing info
13:36:02.964786 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
13:36:02.996403 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:36:02.996650 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
13:36:02.996752 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:36:05.126363 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.13 seconds
13:36:05.138188 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:36:05.138413 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
13:36:05.256851 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.12 seconds
13:36:05.264014 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:36:05.264392 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
13:36:05.570355 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.31 seconds
13:36:05.584953 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:36:05.585295 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
13:36:05.679333 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.09 seconds
13:36:05.705771 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
13:36:05.708180 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:36:05.708311 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
13:36:05.872694 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.16 seconds
13:36:05.873444 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:36:05.873594 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
13:36:06.373363 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.5 seconds
13:36:06.373832 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:36:06.374040 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
13:36:06.621891 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.25 seconds
13:36:06.634498 [debug] [Thread-1  ]: finished collecting timing info
13:36:06.634835 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
13:36:06.839723 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b3356159-50d4-4610-b128-871c8a9cb7af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105b4e460>]}
13:36:06.840458 [info ] [Thread-1  ]: 1 of 7 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 3.88s]
13:36:06.840920 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
13:36:06.841167 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
13:36:06.841598 [info ] [Thread-1  ]: 2 of 7 START incremental model dbt.incremental_time............................. [RUN]
13:36:06.842293 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
13:36:06.842526 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
13:36:06.842745 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
13:36:06.846768 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
13:36:06.847604 [debug] [Thread-1  ]: finished collecting timing info
13:36:06.847800 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
13:36:06.851640 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:36:06.851888 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
13:36:06.852037 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:36:08.338842 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.49 seconds
13:36:08.343103 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:36:08.343372 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
13:36:08.469989 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.13 seconds
13:36:08.475438 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:36:08.475778 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
13:36:08.587524 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.11 seconds
13:36:08.592612 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:36:08.592880 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
13:36:08.679988 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.09 seconds
13:36:08.685717 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
13:36:08.688297 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:36:08.688589 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
13:36:08.809164 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.12 seconds
13:36:08.809924 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:36:08.810295 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
13:36:09.708687 [debug] [Thread-1  ]: SQL status: SUCCESS 610 in 0.9 seconds
13:36:09.709527 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:36:09.709816 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
13:36:09.947838 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.24 seconds
13:36:09.952151 [debug] [Thread-1  ]: finished collecting timing info
13:36:09.952785 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
13:36:10.133456 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b3356159-50d4-4610-b128-871c8a9cb7af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105b9a5b0>]}
13:36:10.134594 [info ] [Thread-1  ]: 2 of 7 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 3.29s]
13:36:10.135376 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
13:36:10.135652 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
13:36:10.136091 [info ] [Thread-1  ]: 3 of 7 START table model dbt.first_model........................................ [RUN]
13:36:10.136758 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
13:36:10.136976 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
13:36:10.137183 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
13:36:10.141604 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
13:36:10.142408 [debug] [Thread-1  ]: finished collecting timing info
13:36:10.142625 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
13:36:10.152104 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
13:36:10.153248 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
13:36:10.153430 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id

)

select * 
from source_data


/*
select *, True as first_variable
from source_data
where id >= 1
*/
      );
13:36:10.153575 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:36:11.454034 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.3 seconds
13:36:11.457085 [debug] [Thread-1  ]: finished collecting timing info
13:36:11.457477 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
13:36:11.628435 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b3356159-50d4-4610-b128-871c8a9cb7af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107c9b190>]}
13:36:11.629058 [info ] [Thread-1  ]: 3 of 7 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 1.49s]
13:36:11.629332 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
13:36:11.629486 [debug] [Thread-1  ]: Began running node model.learn_dbt.playing_with_tests
13:36:11.629838 [info ] [Thread-1  ]: 4 of 7 START table model dbt.playing_with_tests................................. [RUN]
13:36:11.630222 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.playing_with_tests"
13:36:11.630342 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.playing_with_tests
13:36:11.630465 [debug] [Thread-1  ]: Compiling model.learn_dbt.playing_with_tests
13:36:11.631632 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.playing_with_tests"
13:36:11.632203 [debug] [Thread-1  ]: finished collecting timing info
13:36:11.632316 [debug] [Thread-1  ]: Began executing node model.learn_dbt.playing_with_tests
13:36:11.634259 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.playing_with_tests"
13:36:11.635047 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
13:36:11.635187 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */


      create or replace transient table analytics.dbt.playing_with_tests  as
      (select * 
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER"
      );
13:36:11.635298 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:36:13.554433 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.92 seconds
13:36:13.559569 [debug] [Thread-1  ]: finished collecting timing info
13:36:13.559948 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: Close
13:36:15.072928 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b3356159-50d4-4610-b128-871c8a9cb7af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105cd8c70>]}
13:36:15.073721 [info ] [Thread-1  ]: 4 of 7 OK created table model dbt.playing_with_tests............................ [[32mSUCCESS 1[0m in 3.44s]
13:36:15.074079 [debug] [Thread-1  ]: Finished running node model.learn_dbt.playing_with_tests
13:36:15.074337 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
13:36:15.074803 [info ] [Thread-1  ]: 5 of 7 START table model dbt.snowflake_cumulative_sales......................... [RUN]
13:36:15.075482 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
13:36:15.075733 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
13:36:15.075959 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
13:36:15.077374 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
13:36:15.078039 [debug] [Thread-1  ]: finished collecting timing info
13:36:15.078226 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
13:36:15.080661 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
13:36:15.081647 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
13:36:15.081819 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
13:36:15.081969 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:36:16.578660 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.5 seconds
13:36:16.583377 [debug] [Thread-1  ]: finished collecting timing info
13:36:16.583779 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
13:36:16.741462 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b3356159-50d4-4610-b128-871c8a9cb7af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107c83130>]}
13:36:16.742074 [info ] [Thread-1  ]: 5 of 7 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 1.67s]
13:36:16.742422 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
13:36:16.742886 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
13:36:16.743344 [info ] [Thread-1  ]: 6 of 7 START table model dbt.snowflake_customer_purchases....................... [RUN]
13:36:16.744013 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
13:36:16.744218 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
13:36:16.744417 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
13:36:16.746223 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
13:36:16.746969 [debug] [Thread-1  ]: finished collecting timing info
13:36:16.747162 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
13:36:16.749630 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
13:36:16.750741 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
13:36:16.750905 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
13:36:16.751053 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:36:18.729400 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.98 seconds
13:36:18.736503 [debug] [Thread-1  ]: finished collecting timing info
13:36:18.736993 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
13:36:18.895896 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b3356159-50d4-4610-b128-871c8a9cb7af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107c3bac0>]}
13:36:18.896960 [info ] [Thread-1  ]: 6 of 7 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.15s]
13:36:18.897468 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
13:36:18.897743 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
13:36:18.898022 [info ] [Thread-1  ]: 7 of 7 START table model dbt.my_second_dbt_model................................ [RUN]
13:36:18.901412 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
13:36:18.901852 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
13:36:18.902077 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
13:36:18.905159 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
13:36:18.905738 [debug] [Thread-1  ]: finished collecting timing info
13:36:18.905876 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
13:36:18.907657 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
13:36:18.908207 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
13:36:18.908309 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
/*
union all
select 7 as id, True as first_variable
*/
      );
13:36:18.908401 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:36:20.119530 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.21 seconds
13:36:20.123797 [debug] [Thread-1  ]: finished collecting timing info
13:36:20.124194 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
13:36:20.315887 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b3356159-50d4-4610-b128-871c8a9cb7af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107c3bfd0>]}
13:36:20.316793 [info ] [Thread-1  ]: 7 of 7 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.41s]
13:36:20.317291 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
13:36:20.318632 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:36:20.319060 [info ] [MainThread]: 
13:36:20.319317 [info ] [MainThread]: Finished running 2 incremental models, 5 table models in 20.49s.
13:36:20.319508 [debug] [MainThread]: Connection 'master' was properly closed.
13:36:20.319610 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
13:36:20.325989 [info ] [MainThread]: 
13:36:20.326358 [info ] [MainThread]: [32mCompleted successfully[0m
13:36:20.326625 [info ] [MainThread]: 
13:36:20.326824 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
13:36:20.327093 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10568d9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10567beb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107c15af0>]}


============================== 2022-05-13 13:36:25.414263 | b3c81fb8-37ec-4c6e-8891-24bfc41b5c24 ==============================
13:36:25.414263 [info ] [MainThread]: Running with dbt=1.0.1
13:36:25.414627 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, store_failures=False, indirect_selection='eager', threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.test.TestTask'>, which='test', rpc_method='test')
13:36:25.414772 [debug] [MainThread]: Tracking: tracking
13:36:25.415007 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c035b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c03eb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c03ca0>]}
13:36:25.458105 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
13:36:25.458271 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
13:36:25.461412 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b3c81fb8-37ec-4c6e-8891-24bfc41b5c24', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108bcd100>]}
13:36:25.464960 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b3c81fb8-37ec-4c6e-8891-24bfc41b5c24', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d2cc10>]}
13:36:25.465155 [info ] [MainThread]: Found 7 models, 13 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
13:36:25.466366 [info ] [MainThread]: 
13:36:25.466639 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:36:25.467304 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
13:36:25.473582 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
13:36:25.473703 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
13:36:25.473775 [debug] [ThreadPool]: Opening a new connection, currently in state init
13:36:26.189272 [debug] [ThreadPool]: SQL status: SUCCESS 7 in 0.72 seconds
13:36:26.191870 [debug] [ThreadPool]: On list_analytics_dbt: Close
13:36:26.410102 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
13:36:26.410678 [info ] [MainThread]: 
13:36:26.414620 [debug] [Thread-1  ]: Began running node test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
13:36:26.414891 [info ] [Thread-1  ]: 1 of 13 START test accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE [RUN]
13:36:26.415427 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
13:36:26.415601 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
13:36:26.415757 [debug] [Thread-1  ]: Compiling test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
13:36:26.430251 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
13:36:26.430896 [debug] [Thread-1  ]: finished collecting timing info
13:36:26.431036 [debug] [Thread-1  ]: Began executing node test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
13:36:26.443303 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
13:36:26.444181 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
13:36:26.444286 [debug] [Thread-1  ]: On test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        c_mktsegment as value_field,
        count(*) as n_records

    from analytics.dbt.playing_with_tests
    group by c_mktsegment

)

select *
from all_values
where value_field not in (
    'BUILDING','AUTOMOBILE','MACHINERY','HOUSEHOLD','FURNITURE'
)



      
    ) dbt_internal_test
13:36:26.444376 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:36:27.093933 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.65 seconds
13:36:27.098031 [debug] [Thread-1  ]: finished collecting timing info
13:36:27.098481 [debug] [Thread-1  ]: On test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3: Close
13:36:27.298480 [info ] [Thread-1  ]: 1 of 13 PASS accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE [[32mPASS[0m in 0.88s]
13:36:27.303250 [debug] [Thread-1  ]: Finished running node test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
13:36:27.303561 [debug] [Thread-1  ]: Began running node test.learn_dbt.assert_accbal_less_than_100m
13:36:27.304025 [info ] [Thread-1  ]: 2 of 13 START test assert_accbal_less_than_100m................................. [RUN]
13:36:27.304932 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.assert_accbal_less_than_100m"
13:36:27.306011 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.assert_accbal_less_than_100m
13:36:27.306306 [debug] [Thread-1  ]: Compiling test.learn_dbt.assert_accbal_less_than_100m
13:36:27.309524 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.assert_accbal_less_than_100m"
13:36:27.310226 [debug] [Thread-1  ]: finished collecting timing info
13:36:27.310395 [debug] [Thread-1  ]: Began executing node test.learn_dbt.assert_accbal_less_than_100m
13:36:27.312396 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.assert_accbal_less_than_100m"
13:36:27.313302 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.assert_accbal_less_than_100m"
13:36:27.313440 [debug] [Thread-1  ]: On test.learn_dbt.assert_accbal_less_than_100m: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.assert_accbal_less_than_100m"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      select sum(c_acctbal) as sum
from analytics.dbt.playing_with_tests
having sum > 100000000
      
    ) dbt_internal_test
13:36:27.313575 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:36:27.955184 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.64 seconds
13:36:27.957711 [debug] [Thread-1  ]: finished collecting timing info
13:36:27.958024 [debug] [Thread-1  ]: On test.learn_dbt.assert_accbal_less_than_100m: Close
13:36:28.289965 [error] [Thread-1  ]: 2 of 13 FAIL 1 assert_accbal_less_than_100m..................................... [[31mFAIL 1[0m in 0.99s]
13:36:28.290697 [debug] [Thread-1  ]: Finished running node test.learn_dbt.assert_accbal_less_than_100m
13:36:28.290966 [debug] [Thread-1  ]: Began running node test.learn_dbt.assert_under_10_percent_null
13:36:28.291284 [info ] [Thread-1  ]: 3 of 13 START test assert_under_10_percent_null................................. [RUN]
13:36:28.291921 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.assert_under_10_percent_null"
13:36:28.292133 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.assert_under_10_percent_null
13:36:28.292328 [debug] [Thread-1  ]: Compiling test.learn_dbt.assert_under_10_percent_null
13:36:28.295302 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.assert_under_10_percent_null"
13:36:28.296048 [debug] [Thread-1  ]: finished collecting timing info
13:36:28.296237 [debug] [Thread-1  ]: Began executing node test.learn_dbt.assert_under_10_percent_null
13:36:28.298674 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.assert_under_10_percent_null"
13:36:28.300003 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.assert_under_10_percent_null"
13:36:28.300187 [debug] [Thread-1  ]: On test.learn_dbt.assert_under_10_percent_null: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.assert_under_10_percent_null"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      select sum (case when id is null then 1 else 0 end) / count(*) as total_nulls
from analytics.dbt.first_model
having sum (case when id is null then 1 else 0 end) / count(*) > .4
      
    ) dbt_internal_test
13:36:28.300347 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:36:29.381661 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.08 seconds
13:36:29.386787 [debug] [Thread-1  ]: finished collecting timing info
13:36:29.387199 [debug] [Thread-1  ]: On test.learn_dbt.assert_under_10_percent_null: Close
13:36:29.644274 [info ] [Thread-1  ]: 3 of 13 PASS assert_under_10_percent_null....................................... [[32mPASS[0m in 1.35s]
13:36:29.645164 [debug] [Thread-1  ]: Finished running node test.learn_dbt.assert_under_10_percent_null
13:36:29.645642 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
13:36:29.646047 [info ] [Thread-1  ]: 4 of 13 START test not_null_my_second_dbt_model_id.............................. [RUN]
13:36:29.646693 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"
13:36:29.646904 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
13:36:29.647124 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
13:36:29.655355 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"
13:36:29.656191 [debug] [Thread-1  ]: finished collecting timing info
13:36:29.656371 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
13:36:29.658291 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"
13:36:29.659361 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"
13:36:29.659523 [debug] [Thread-1  ]: On test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.my_second_dbt_model
where id is null



      
    ) dbt_internal_test
13:36:29.659656 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:36:30.464061 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.8 seconds
13:36:30.472532 [debug] [Thread-1  ]: finished collecting timing info
13:36:30.472916 [debug] [Thread-1  ]: On test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778: Close
13:36:30.924523 [error] [Thread-1  ]: 4 of 13 FAIL 1 not_null_my_second_dbt_model_id.................................. [[31mFAIL 1[0m in 1.28s]
13:36:30.925193 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
13:36:30.925447 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4
13:36:30.925772 [info ] [Thread-1  ]: 5 of 13 START test not_null_playing_with_tests_c_custkey........................ [RUN]
13:36:30.926405 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4"
13:36:30.926630 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4
13:36:30.926838 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4
13:36:30.931541 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4"
13:36:30.932392 [debug] [Thread-1  ]: finished collecting timing info
13:36:30.932582 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4
13:36:30.934902 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4"
13:36:30.936009 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4"
13:36:30.936262 [debug] [Thread-1  ]: On test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.playing_with_tests
where c_custkey is null



      
    ) dbt_internal_test
13:36:30.936431 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:36:32.054640 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.12 seconds
13:36:32.059095 [debug] [Thread-1  ]: finished collecting timing info
13:36:32.059672 [debug] [Thread-1  ]: On test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4: Close
13:36:32.453033 [info ] [Thread-1  ]: 5 of 13 PASS not_null_playing_with_tests_c_custkey.............................. [[32mPASS[0m in 1.53s]
13:36:32.453752 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4
13:36:32.454001 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
13:36:32.454202 [info ] [Thread-1  ]: 6 of 13 START test not_null_snowflake_cumulative_sales_o_orderdate.............. [RUN]
13:36:32.454953 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
13:36:32.455177 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
13:36:32.455375 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
13:36:32.460346 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
13:36:32.460988 [debug] [Thread-1  ]: finished collecting timing info
13:36:32.461166 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
13:36:32.463371 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
13:36:32.464330 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
13:36:32.464515 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.snowflake_cumulative_sales
where o_orderdate is null



      
    ) dbt_internal_test
13:36:32.464822 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:36:33.354086 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.89 seconds
13:36:33.356438 [debug] [Thread-1  ]: finished collecting timing info
13:36:33.356777 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856: Close
13:36:33.544153 [info ] [Thread-1  ]: 6 of 13 PASS not_null_snowflake_cumulative_sales_o_orderdate.................... [[32mPASS[0m in 1.09s]
13:36:33.544796 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
13:36:33.545057 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
13:36:33.545266 [info ] [Thread-1  ]: 7 of 13 START test not_null_snowflake_customer_purchases_c_custkey.............. [RUN]
13:36:33.545985 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
13:36:33.546237 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
13:36:33.546443 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
13:36:33.551571 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
13:36:33.552483 [debug] [Thread-1  ]: finished collecting timing info
13:36:33.552677 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
13:36:33.555021 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
13:36:33.556069 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
13:36:33.556310 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.snowflake_customer_purchases
where c_custkey is null



      
    ) dbt_internal_test
13:36:33.556455 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:36:34.408810 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.85 seconds
13:36:34.411983 [debug] [Thread-1  ]: finished collecting timing info
13:36:34.412411 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502: Close
13:36:34.579199 [info ] [Thread-1  ]: 7 of 13 PASS not_null_snowflake_customer_purchases_c_custkey.................... [[32mPASS[0m in 1.03s]
13:36:34.579978 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
13:36:34.580250 [debug] [Thread-1  ]: Began running node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
13:36:34.580579 [info ] [Thread-1  ]: 8 of 13 START test relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ [RUN]
13:36:34.581228 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
13:36:34.581441 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
13:36:34.581644 [debug] [Thread-1  ]: Compiling test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
13:36:34.592393 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
13:36:34.593203 [debug] [Thread-1  ]: finished collecting timing info
13:36:34.593368 [debug] [Thread-1  ]: Began executing node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
13:36:34.596007 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
13:36:34.597108 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
13:36:34.597236 [debug] [Thread-1  ]: On test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select id as from_field
    from analytics.dbt.my_second_dbt_model
    where id is not null
),

parent as (
    select id as to_field
    from analytics.dbt.first_model
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
13:36:34.597349 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:36:36.800159 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.2 seconds
13:36:36.803226 [debug] [Thread-1  ]: finished collecting timing info
13:36:36.803641 [debug] [Thread-1  ]: On test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: Close
13:36:37.214629 [info ] [Thread-1  ]: 8 of 13 PASS relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.. [[32mPASS[0m in 2.63s]
13:36:37.215555 [debug] [Thread-1  ]: Finished running node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
13:36:37.215856 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
13:36:37.216142 [info ] [Thread-1  ]: 9 of 13 START test unique_my_first_dbt_model_id................................. [RUN]
13:36:37.216705 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
13:36:37.216886 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
13:36:37.217053 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
13:36:37.224348 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
13:36:37.225027 [debug] [Thread-1  ]: finished collecting timing info
13:36:37.225192 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
13:36:37.226858 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
13:36:37.227845 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
13:36:37.228034 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.first_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
13:36:37.228153 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:36:37.954048 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.73 seconds
13:36:37.956833 [debug] [Thread-1  ]: finished collecting timing info
13:36:37.957169 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_first_dbt_model_id.16e066b321: Close
13:36:38.156332 [info ] [Thread-1  ]: 9 of 13 PASS unique_my_first_dbt_model_id....................................... [[32mPASS[0m in 0.94s]
13:36:38.156678 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
13:36:38.156810 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:36:38.156962 [info ] [Thread-1  ]: 10 of 13 START test unique_my_second_dbt_model_id............................... [RUN]
13:36:38.157237 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
13:36:38.157337 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:36:38.157428 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:36:38.159968 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
13:36:38.160404 [debug] [Thread-1  ]: finished collecting timing info
13:36:38.160497 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:36:38.161658 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
13:36:38.162266 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
13:36:38.162356 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.my_second_dbt_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
13:36:38.162433 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:36:38.871213 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.71 seconds
13:36:38.874808 [debug] [Thread-1  ]: finished collecting timing info
13:36:38.875358 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493: Close
13:36:39.084376 [info ] [Thread-1  ]: 10 of 13 PASS unique_my_second_dbt_model_id..................................... [[32mPASS[0m in 0.93s]
13:36:39.084998 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:36:39.085239 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550
13:36:39.085543 [info ] [Thread-1  ]: 11 of 13 START test unique_playing_with_tests_c_custkey......................... [RUN]
13:36:39.086098 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550"
13:36:39.086277 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550
13:36:39.086447 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550
13:36:39.091117 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550"
13:36:39.091805 [debug] [Thread-1  ]: finished collecting timing info
13:36:39.091985 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550
13:36:39.094265 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550"
13:36:39.095369 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550"
13:36:39.095604 [debug] [Thread-1  ]: On test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    c_custkey as unique_field,
    count(*) as n_records

from analytics.dbt.playing_with_tests
where c_custkey is not null
group by c_custkey
having count(*) > 1



      
    ) dbt_internal_test
13:36:39.095882 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:36:39.869788 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.77 seconds
13:36:39.872671 [debug] [Thread-1  ]: finished collecting timing info
13:36:39.873053 [debug] [Thread-1  ]: On test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550: Close
13:36:40.208083 [info ] [Thread-1  ]: 11 of 13 PASS unique_playing_with_tests_c_custkey............................... [[32mPASS[0m in 1.12s]
13:36:40.208742 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550
13:36:40.209087 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
13:36:40.209671 [info ] [Thread-1  ]: 12 of 13 START test unique_snowflake_cumulative_sales_o_orderdate............... [RUN]
13:36:40.210615 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
13:36:40.214203 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
13:36:40.214492 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
13:36:40.224815 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
13:36:40.225276 [debug] [Thread-1  ]: finished collecting timing info
13:36:40.225379 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
13:36:40.226613 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
13:36:40.227251 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
13:36:40.227338 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    o_orderdate as unique_field,
    count(*) as n_records

from analytics.dbt.snowflake_cumulative_sales
where o_orderdate is not null
group by o_orderdate
having count(*) > 1



      
    ) dbt_internal_test
13:36:40.227418 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:36:41.290648 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.06 seconds
13:36:41.293272 [debug] [Thread-1  ]: finished collecting timing info
13:36:41.293546 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed: Close
13:36:41.475328 [info ] [Thread-1  ]: 12 of 13 PASS unique_snowflake_cumulative_sales_o_orderdate..................... [[32mPASS[0m in 1.27s]
13:36:41.475635 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
13:36:41.475908 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
13:36:41.476117 [info ] [Thread-1  ]: 13 of 13 START test unique_snowflake_customer_purchases_c_custkey............... [RUN]
13:36:41.476433 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
13:36:41.476531 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
13:36:41.476621 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
13:36:41.479229 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
13:36:41.479729 [debug] [Thread-1  ]: finished collecting timing info
13:36:41.479864 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
13:36:41.481399 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
13:36:41.482248 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
13:36:41.482371 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    c_custkey as unique_field,
    count(*) as n_records

from analytics.dbt.snowflake_customer_purchases
where c_custkey is not null
group by c_custkey
having count(*) > 1



      
    ) dbt_internal_test
13:36:41.482479 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:36:42.608758 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.13 seconds
13:36:42.611942 [debug] [Thread-1  ]: finished collecting timing info
13:36:42.612362 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f: Close
13:36:42.954066 [info ] [Thread-1  ]: 13 of 13 PASS unique_snowflake_customer_purchases_c_custkey..................... [[32mPASS[0m in 1.48s]
13:36:42.954759 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
13:36:42.957131 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:36:42.959784 [info ] [MainThread]: 
13:36:42.960377 [info ] [MainThread]: Finished running 13 tests in 17.49s.
13:36:42.962276 [debug] [MainThread]: Connection 'master' was properly closed.
13:36:42.962491 [debug] [MainThread]: Connection 'test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f' was properly closed.
13:36:42.972687 [info ] [MainThread]: 
13:36:42.972948 [info ] [MainThread]: [31mCompleted with 2 errors and 0 warnings:[0m
13:36:42.973143 [info ] [MainThread]: 
13:36:42.973311 [error] [MainThread]: [31mFailure in test assert_accbal_less_than_100m (tests/assert_accbal_less_than_100m.sql)[0m
13:36:42.973503 [error] [MainThread]:   Got 1 result, configured to fail if != 0
13:36:42.973669 [info ] [MainThread]: 
13:36:42.973830 [info ] [MainThread]:   compiled SQL at target/compiled/learn_dbt/tests/assert_accbal_less_than_100m.sql
13:36:42.973999 [info ] [MainThread]: 
13:36:42.974158 [error] [MainThread]: [31mFailure in test not_null_my_second_dbt_model_id (models/example/schema.yml)[0m
13:36:42.974321 [error] [MainThread]:   Got 1 result, configured to fail if != 0
13:36:42.974477 [info ] [MainThread]: 
13:36:42.974631 [info ] [MainThread]:   compiled SQL at target/compiled/learn_dbt/models/example/schema.yml/not_null_my_second_dbt_model_id.sql
13:36:42.974806 [info ] [MainThread]: 
13:36:42.974962 [info ] [MainThread]: Done. PASS=11 WARN=0 ERROR=2 SKIP=0 TOTAL=13
13:36:42.975205 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108d5b0a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079eb580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b0bb550>]}


============================== 2022-05-16 12:03:05.570429 | 8e6273ec-b6f3-44db-9654-d210cdb3b580 ==============================
12:03:05.570429 [info ] [MainThread]: Running with dbt=1.0.1
12:03:05.570961 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['example'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
12:03:05.571128 [debug] [MainThread]: Tracking: tracking
12:03:05.571347 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11274fe20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11274f8e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11274feb0>]}
12:03:05.620459 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
12:03:05.620592 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
12:03:05.623784 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8e6273ec-b6f3-44db-9654-d210cdb3b580', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112719130>]}
12:03:05.627700 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8e6273ec-b6f3-44db-9654-d210cdb3b580', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11286ba90>]}
12:03:05.627843 [info ] [MainThread]: Found 7 models, 13 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
12:03:05.628636 [info ] [MainThread]: 
12:03:05.628846 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:03:05.629309 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
12:03:05.635161 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
12:03:05.635250 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
12:03:05.635324 [debug] [ThreadPool]: Opening a new connection, currently in state init
12:03:06.736389 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.1 seconds
12:03:06.739011 [debug] [ThreadPool]: On list_analytics: Close
12:03:06.922243 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
12:03:06.931128 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
12:03:06.931356 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
12:03:06.931517 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:03:07.495342 [debug] [ThreadPool]: SQL status: SUCCESS 7 in 0.56 seconds
12:03:07.498916 [debug] [ThreadPool]: On list_analytics_dbt: Close
12:03:07.719728 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
12:03:07.720166 [info ] [MainThread]: 
12:03:07.724992 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
12:03:07.725497 [info ] [Thread-1  ]: 1 of 7 START incremental model dbt.dates........................................ [RUN]
12:03:07.725779 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
12:03:07.725873 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
12:03:07.725969 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
12:03:07.731608 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
12:03:07.732767 [debug] [Thread-1  ]: finished collecting timing info
12:03:07.732929 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
12:03:07.761578 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:03:07.761797 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
12:03:07.761899 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:03:10.888675 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 3.13 seconds
12:03:10.901875 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:03:10.902266 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
12:03:11.052022 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.15 seconds
12:03:11.058983 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:03:11.059290 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
12:03:11.210681 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.15 seconds
12:03:11.220736 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:03:11.221002 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
12:03:11.370965 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.15 seconds
12:03:11.396875 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
12:03:11.399353 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:03:11.399485 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
12:03:11.532118 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.13 seconds
12:03:11.533448 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:03:11.533859 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
12:03:12.332856 [debug] [Thread-1  ]: SQL status: SUCCESS 3 in 0.8 seconds
12:03:12.334064 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:03:12.334272 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
12:03:12.590310 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.26 seconds
12:03:12.603540 [debug] [Thread-1  ]: finished collecting timing info
12:03:12.603795 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
12:03:12.798399 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8e6273ec-b6f3-44db-9654-d210cdb3b580', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104b11d30>]}
12:03:12.799314 [info ] [Thread-1  ]: 1 of 7 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 5.07s]
12:03:12.799768 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
12:03:12.800018 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
12:03:12.800451 [info ] [Thread-1  ]: 2 of 7 START incremental model dbt.incremental_time............................. [RUN]
12:03:12.801104 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
12:03:12.801317 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
12:03:12.801528 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
12:03:12.805520 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
12:03:12.807527 [debug] [Thread-1  ]: finished collecting timing info
12:03:12.807733 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
12:03:12.811190 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:03:12.811419 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
12:03:12.811549 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:03:14.861281 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.05 seconds
12:03:14.866533 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:03:14.866889 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
12:03:14.991690 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.12 seconds
12:03:14.997085 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:03:14.997305 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
12:03:15.118300 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.12 seconds
12:03:15.123205 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:03:15.123459 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
12:03:15.254944 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.13 seconds
12:03:15.260130 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
12:03:15.262502 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:03:15.262674 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
12:03:15.407096 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.14 seconds
12:03:15.408158 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:03:15.408378 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
12:03:16.554095 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 1.15 seconds
12:03:16.554546 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:03:16.554722 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
12:03:16.736015 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.18 seconds
12:03:16.740048 [debug] [Thread-1  ]: finished collecting timing info
12:03:16.740429 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
12:03:16.927332 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8e6273ec-b6f3-44db-9654-d210cdb3b580', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112c3f4f0>]}
12:03:16.928161 [info ] [Thread-1  ]: 2 of 7 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 4.13s]
12:03:16.928617 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
12:03:16.928866 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
12:03:16.929140 [info ] [Thread-1  ]: 3 of 7 START table model dbt.first_model........................................ [RUN]
12:03:16.929958 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
12:03:16.930220 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
12:03:16.930399 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
12:03:16.934353 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
12:03:16.935014 [debug] [Thread-1  ]: finished collecting timing info
12:03:16.935184 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
12:03:16.943922 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
12:03:16.945020 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
12:03:16.945155 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id

)

select * 
from source_data


/*
select *, True as first_variable
from source_data
where id >= 1
*/
      );
12:03:16.945272 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:03:18.783785 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.84 seconds
12:03:18.787567 [debug] [Thread-1  ]: finished collecting timing info
12:03:18.788010 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
12:03:18.955367 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8e6273ec-b6f3-44db-9654-d210cdb3b580', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112c3fb20>]}
12:03:18.955692 [info ] [Thread-1  ]: 3 of 7 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 2.03s]
12:03:18.955886 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
12:03:18.955995 [debug] [Thread-1  ]: Began running node model.learn_dbt.playing_with_tests
12:03:18.956216 [info ] [Thread-1  ]: 4 of 7 START table model dbt.playing_with_tests................................. [RUN]
12:03:18.956459 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.playing_with_tests"
12:03:18.956540 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.playing_with_tests
12:03:18.956619 [debug] [Thread-1  ]: Compiling model.learn_dbt.playing_with_tests
12:03:18.957415 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.playing_with_tests"
12:03:18.957900 [debug] [Thread-1  ]: finished collecting timing info
12:03:18.957993 [debug] [Thread-1  ]: Began executing node model.learn_dbt.playing_with_tests
12:03:18.959355 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.playing_with_tests"
12:03:18.959874 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
12:03:18.959962 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */


      create or replace transient table analytics.dbt.playing_with_tests  as
      (select * 
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER"
      );
12:03:18.960036 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:03:20.705721 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.75 seconds
12:03:20.709430 [debug] [Thread-1  ]: finished collecting timing info
12:03:20.709812 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: Close
12:03:20.920724 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8e6273ec-b6f3-44db-9654-d210cdb3b580', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114e9f610>]}
12:03:20.921471 [info ] [Thread-1  ]: 4 of 7 OK created table model dbt.playing_with_tests............................ [[32mSUCCESS 1[0m in 1.96s]
12:03:20.921918 [debug] [Thread-1  ]: Finished running node model.learn_dbt.playing_with_tests
12:03:20.922161 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
12:03:20.922421 [info ] [Thread-1  ]: 5 of 7 START table model dbt.snowflake_cumulative_sales......................... [RUN]
12:03:20.923097 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
12:03:20.923329 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
12:03:20.923784 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
12:03:20.925675 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
12:03:20.929215 [debug] [Thread-1  ]: finished collecting timing info
12:03:20.929451 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
12:03:20.933638 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
12:03:20.934695 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
12:03:20.934836 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
12:03:20.934963 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:03:22.404249 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.47 seconds
12:03:22.407203 [debug] [Thread-1  ]: finished collecting timing info
12:03:22.407535 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
12:03:22.623167 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8e6273ec-b6f3-44db-9654-d210cdb3b580', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112c3f0d0>]}
12:03:22.623501 [info ] [Thread-1  ]: 5 of 7 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 1.70s]
12:03:22.623885 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
12:03:22.624210 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
12:03:22.624482 [info ] [Thread-1  ]: 6 of 7 START table model dbt.snowflake_customer_purchases....................... [RUN]
12:03:22.624932 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
12:03:22.625048 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
12:03:22.625150 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
12:03:22.625989 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
12:03:22.626717 [debug] [Thread-1  ]: finished collecting timing info
12:03:22.626852 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
12:03:22.629214 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
12:03:22.630508 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
12:03:22.630687 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
12:03:22.630834 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:03:24.629478 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.0 seconds
12:03:24.632533 [debug] [Thread-1  ]: finished collecting timing info
12:03:24.632853 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
12:03:24.857074 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8e6273ec-b6f3-44db-9654-d210cdb3b580', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114e6a430>]}
12:03:24.857805 [info ] [Thread-1  ]: 6 of 7 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.23s]
12:03:24.858251 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
12:03:24.858499 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
12:03:24.858905 [info ] [Thread-1  ]: 7 of 7 START table model dbt.my_second_dbt_model................................ [RUN]
12:03:24.859538 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
12:03:24.859749 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
12:03:24.860113 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
12:03:24.863682 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
12:03:24.864470 [debug] [Thread-1  ]: finished collecting timing info
12:03:24.864648 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
12:03:24.867191 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
12:03:24.868045 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
12:03:24.868194 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
/*
union all
select 7 as id, True as first_variable
*/
      );
12:03:24.868319 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:03:26.359748 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.49 seconds
12:03:26.363410 [debug] [Thread-1  ]: finished collecting timing info
12:03:26.363849 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
12:03:26.546155 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8e6273ec-b6f3-44db-9654-d210cdb3b580', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114e33430>]}
12:03:26.546778 [info ] [Thread-1  ]: 7 of 7 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.69s]
12:03:26.547076 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
12:03:26.548060 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:03:26.548421 [info ] [MainThread]: 
12:03:26.548620 [info ] [MainThread]: Finished running 2 incremental models, 5 table models in 20.92s.
12:03:26.548785 [debug] [MainThread]: Connection 'master' was properly closed.
12:03:26.548877 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
12:03:26.554813 [info ] [MainThread]: 
12:03:26.555083 [info ] [MainThread]: [32mCompleted successfully[0m
12:03:26.555301 [info ] [MainThread]: 
12:03:26.555468 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
12:03:26.555708 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107becc10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11286b400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112d2fbb0>]}


============================== 2022-05-16 12:03:36.395805 | ec5ce9e7-519f-4010-b3fa-2e3186a56152 ==============================
12:03:36.395805 [info ] [MainThread]: Running with dbt=1.0.1
12:03:36.396183 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['dates'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
12:03:36.396348 [debug] [MainThread]: Tracking: tracking
12:03:36.396584 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11308ae20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11308aa90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11308ad30>]}
12:03:36.444659 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
12:03:36.444818 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
12:03:36.448283 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ec5ce9e7-519f-4010-b3fa-2e3186a56152', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1131a10d0>]}
12:03:36.451689 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ec5ce9e7-519f-4010-b3fa-2e3186a56152', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111ad61f0>]}
12:03:36.451823 [info ] [MainThread]: Found 7 models, 13 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
12:03:36.452517 [info ] [MainThread]: 
12:03:36.452721 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:03:36.453059 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
12:03:36.459073 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
12:03:36.459175 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
12:03:36.459242 [debug] [ThreadPool]: Opening a new connection, currently in state init
12:03:37.266443 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.81 seconds
12:03:37.268821 [debug] [ThreadPool]: On list_analytics: Close
12:03:37.443609 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
12:03:37.451444 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
12:03:37.451702 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
12:03:37.451818 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:03:38.187297 [debug] [ThreadPool]: SQL status: SUCCESS 7 in 0.74 seconds
12:03:38.191137 [debug] [ThreadPool]: On list_analytics_dbt: Close
12:03:38.372190 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
12:03:38.372867 [info ] [MainThread]: 
12:03:38.379334 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
12:03:38.379782 [info ] [Thread-1  ]: 1 of 1 START incremental model dbt.dates........................................ [RUN]
12:03:38.380706 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
12:03:38.380893 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
12:03:38.381083 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
12:03:38.389554 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
12:03:38.390163 [debug] [Thread-1  ]: finished collecting timing info
12:03:38.390305 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
12:03:38.418666 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:03:38.418891 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
12:03:38.418980 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:03:39.604768 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.19 seconds
12:03:39.618782 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:03:39.619117 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
12:03:39.756533 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.14 seconds
12:03:39.763549 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:03:39.763766 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
12:03:39.876875 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.11 seconds
12:03:39.891865 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:03:39.892222 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
12:03:40.008904 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.12 seconds
12:03:40.036348 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
12:03:40.038869 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:03:40.039015 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
12:03:40.168713 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.13 seconds
12:03:40.169776 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:03:40.170061 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
12:03:40.599276 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.43 seconds
12:03:40.600037 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:03:40.600277 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
12:03:40.801047 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.2 seconds
12:03:40.815595 [debug] [Thread-1  ]: finished collecting timing info
12:03:40.816020 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
12:03:40.994931 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ec5ce9e7-519f-4010-b3fa-2e3186a56152', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113516970>]}
12:03:40.995789 [info ] [Thread-1  ]: 1 of 1 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 2.61s]
12:03:40.996262 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
12:03:40.997617 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:03:40.997925 [info ] [MainThread]: 
12:03:40.998125 [info ] [MainThread]: Finished running 1 incremental model in 4.55s.
12:03:40.998308 [debug] [MainThread]: Connection 'master' was properly closed.
12:03:40.998405 [debug] [MainThread]: Connection 'model.learn_dbt.dates' was properly closed.
12:03:41.003879 [info ] [MainThread]: 
12:03:41.004207 [info ] [MainThread]: [32mCompleted successfully[0m
12:03:41.004458 [info ] [MainThread]: 
12:03:41.004651 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
12:03:41.004909 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1131d01f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1131c51f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11340f160>]}


============================== 2022-05-16 12:04:07.878110 | 82d4afbb-56c8-4d5c-8f6f-f886996fc7d7 ==============================
12:04:07.878110 [info ] [MainThread]: Running with dbt=1.0.1
12:04:07.878484 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['example.dates'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
12:04:07.878612 [debug] [MainThread]: Tracking: tracking
12:04:07.878839 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108207e80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1082074f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1082079d0>]}
12:04:07.926226 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
12:04:07.926357 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
12:04:07.929522 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '82d4afbb-56c8-4d5c-8f6f-f886996fc7d7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1081d10d0>]}
12:04:07.933047 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '82d4afbb-56c8-4d5c-8f6f-f886996fc7d7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105f614f0>]}
12:04:07.933183 [info ] [MainThread]: Found 7 models, 13 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
12:04:07.933847 [info ] [MainThread]: 
12:04:07.934059 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:04:07.934398 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
12:04:07.940500 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
12:04:07.940600 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
12:04:07.940666 [debug] [ThreadPool]: Opening a new connection, currently in state init
12:04:08.767554 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.83 seconds
12:04:08.770157 [debug] [ThreadPool]: On list_analytics: Close
12:04:08.959390 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
12:04:08.968613 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
12:04:08.968843 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
12:04:08.969184 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:04:09.843914 [debug] [ThreadPool]: SQL status: SUCCESS 7 in 0.87 seconds
12:04:09.847034 [debug] [ThreadPool]: On list_analytics_dbt: Close
12:04:10.033178 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
12:04:10.033840 [info ] [MainThread]: 
12:04:10.039527 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
12:04:10.039940 [info ] [Thread-1  ]: 1 of 1 START incremental model dbt.dates........................................ [RUN]
12:04:10.040853 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
12:04:10.041046 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
12:04:10.041241 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
12:04:10.050337 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
12:04:10.050876 [debug] [Thread-1  ]: finished collecting timing info
12:04:10.051017 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
12:04:10.079059 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:04:10.079260 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
12:04:10.079348 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:04:11.032993 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.95 seconds
12:04:11.044601 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:04:11.044929 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
12:04:11.167332 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.12 seconds
12:04:11.175213 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:04:11.175526 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
12:04:11.284652 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.11 seconds
12:04:11.295249 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:04:11.295477 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
12:04:11.396076 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.1 seconds
12:04:11.419486 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
12:04:11.422212 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:04:11.422352 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
12:04:11.595092 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.17 seconds
12:04:11.596436 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:04:11.596783 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
12:04:11.921616 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.32 seconds
12:04:11.922213 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:04:11.922416 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
12:04:12.125761 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.2 seconds
12:04:12.137167 [debug] [Thread-1  ]: finished collecting timing info
12:04:12.137496 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
12:04:12.315590 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82d4afbb-56c8-4d5c-8f6f-f886996fc7d7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1086a9790>]}
12:04:12.316440 [info ] [Thread-1  ]: 1 of 1 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 2.28s]
12:04:12.316905 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
12:04:12.318269 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:04:12.318785 [info ] [MainThread]: 
12:04:12.319134 [info ] [MainThread]: Finished running 1 incremental model in 4.38s.
12:04:12.319439 [debug] [MainThread]: Connection 'master' was properly closed.
12:04:12.319610 [debug] [MainThread]: Connection 'model.learn_dbt.dates' was properly closed.
12:04:12.326175 [info ] [MainThread]: 
12:04:12.326457 [info ] [MainThread]: [32mCompleted successfully[0m
12:04:12.326703 [info ] [MainThread]: 
12:04:12.326898 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
12:04:12.327166 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1083691f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10859a820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a4390a0>]}


============================== 2022-05-16 12:04:55.021116 | cf087061-08ff-49d3-a340-f7076d7a1825 ==============================
12:04:55.021116 [info ] [MainThread]: Running with dbt=1.0.1
12:04:55.021608 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['example.dates', 'example.my_first_dbt_model'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
12:04:55.021735 [debug] [MainThread]: Tracking: tracking
12:04:55.021966 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1058e27f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1058e2ca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1058e2d00>]}
12:04:55.070637 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
12:04:55.070771 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
12:04:55.074024 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cf087061-08ff-49d3-a340-f7076d7a1825', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1058cd220>]}
12:04:55.077489 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cf087061-08ff-49d3-a340-f7076d7a1825', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103d56100>]}
12:04:55.077621 [info ] [MainThread]: Found 7 models, 13 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
12:04:55.078346 [info ] [MainThread]: 
12:04:55.078545 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:04:55.078900 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
12:04:55.085012 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
12:04:55.085133 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
12:04:55.085199 [debug] [ThreadPool]: Opening a new connection, currently in state init
12:04:55.873724 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.79 seconds
12:04:55.876355 [debug] [ThreadPool]: On list_analytics: Close
12:04:56.054657 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
12:04:56.062970 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
12:04:56.063197 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
12:04:56.063353 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:04:56.865268 [debug] [ThreadPool]: SQL status: SUCCESS 7 in 0.8 seconds
12:04:56.867598 [debug] [ThreadPool]: On list_analytics_dbt: Close
12:04:57.049951 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
12:04:57.050574 [info ] [MainThread]: 
12:04:57.054704 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
12:04:57.055052 [info ] [Thread-1  ]: 1 of 2 START incremental model dbt.dates........................................ [RUN]
12:04:57.055899 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
12:04:57.056073 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
12:04:57.056232 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
12:04:57.065743 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
12:04:57.066348 [debug] [Thread-1  ]: finished collecting timing info
12:04:57.066481 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
12:04:57.095745 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:04:57.095962 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
12:04:57.096049 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:04:57.961676 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.87 seconds
12:04:57.975060 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:04:57.975418 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
12:04:58.108127 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.13 seconds
12:04:58.115847 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:04:58.116191 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
12:04:58.242695 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.13 seconds
12:04:58.256399 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:04:58.256721 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
12:04:58.429965 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.17 seconds
12:04:58.455037 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
12:04:58.457380 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:04:58.457570 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
12:04:58.583906 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.13 seconds
12:04:58.585007 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:04:58.585278 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
12:04:59.032910 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.45 seconds
12:04:59.034206 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:04:59.034499 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
12:04:59.209568 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.17 seconds
12:04:59.221755 [debug] [Thread-1  ]: finished collecting timing info
12:04:59.221977 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
12:04:59.404926 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cf087061-08ff-49d3-a340-f7076d7a1825', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105fb3070>]}
12:04:59.405651 [info ] [Thread-1  ]: 1 of 2 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 2.35s]
12:04:59.406006 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
12:04:59.406196 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
12:04:59.406514 [info ] [Thread-1  ]: 2 of 2 START table model dbt.first_model........................................ [RUN]
12:04:59.406991 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
12:04:59.407150 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
12:04:59.407305 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
12:04:59.410556 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
12:04:59.411358 [debug] [Thread-1  ]: finished collecting timing info
12:04:59.411513 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
12:04:59.420254 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
12:04:59.421389 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
12:04:59.421568 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id

)

select * 
from source_data


/*
select *, True as first_variable
from source_data
where id >= 1
*/
      );
12:04:59.421700 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:05:00.868446 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.45 seconds
12:05:00.871500 [debug] [Thread-1  ]: finished collecting timing info
12:05:00.871839 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
12:05:01.065618 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cf087061-08ff-49d3-a340-f7076d7a1825', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d92550>]}
12:05:01.066427 [info ] [Thread-1  ]: 2 of 2 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 1.66s]
12:05:01.067014 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
12:05:01.068424 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:05:01.068872 [info ] [MainThread]: 
12:05:01.069159 [info ] [MainThread]: Finished running 1 incremental model, 1 table model in 5.99s.
12:05:01.069429 [debug] [MainThread]: Connection 'master' was properly closed.
12:05:01.069566 [debug] [MainThread]: Connection 'model.learn_dbt.my_first_dbt_model' was properly closed.
12:05:01.077680 [info ] [MainThread]: 
12:05:01.078107 [info ] [MainThread]: [32mCompleted successfully[0m
12:05:01.078458 [info ] [MainThread]: 
12:05:01.078667 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
12:05:01.078995 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103970190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103d56340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106a5a670>]}


============================== 2022-05-16 12:10:00.532691 | c51c4908-74d6-4adf-9a99-99e60c89b6a0 ==============================
12:10:00.532691 [info ] [MainThread]: Running with dbt=1.0.1
12:10:00.533205 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['new'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
12:10:00.533335 [debug] [MainThread]: Tracking: tracking
12:10:00.533571 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108fd3730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108fd3af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108fd3640>]}
12:10:00.582152 [debug] [MainThread]: Partial parsing enabled: 1 files deleted, 2 files added, 2 files changed.
12:10:00.582393 [debug] [MainThread]: Partial parsing: added file: learn_dbt://models/new/schema.yml
12:10:00.582496 [debug] [MainThread]: Partial parsing: added file: learn_dbt://models/new/dates.sql
12:10:00.582658 [debug] [MainThread]: Partial parsing: update schema file: learn_dbt://models/example/schema.yml
12:10:00.582730 [debug] [MainThread]: Partial parsing: deleted file: learn_dbt://models/example/dates.sql
12:10:00.582848 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/my_first_dbt_model.sql
12:10:00.588413 [debug] [MainThread]: 1603: static parser failed on new/dates.sql
12:10:00.596400 [debug] [MainThread]: 1602: parser fallback to jinja rendering on new/dates.sql
12:10:00.597565 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
12:10:00.599700 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
12:10:00.599790 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'experimental_parser', 'label': 'c51c4908-74d6-4adf-9a99-99e60c89b6a0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10912f490>]}
12:10:00.612901 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c51c4908-74d6-4adf-9a99-99e60c89b6a0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1091760d0>]}
12:10:00.616130 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c51c4908-74d6-4adf-9a99-99e60c89b6a0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10906b580>]}
12:10:00.616257 [info ] [MainThread]: Found 7 models, 13 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
12:10:00.616892 [info ] [MainThread]: 
12:10:00.617095 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:10:00.617398 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
12:10:00.623222 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
12:10:00.623349 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
12:10:00.623417 [debug] [ThreadPool]: Opening a new connection, currently in state init
12:10:01.507413 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.88 seconds
12:10:01.508898 [debug] [ThreadPool]: On list_analytics: Close
12:10:01.688811 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
12:10:01.697371 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
12:10:01.697591 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
12:10:01.697752 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:10:02.201417 [debug] [ThreadPool]: SQL status: SUCCESS 7 in 0.5 seconds
12:10:02.204956 [debug] [ThreadPool]: On list_analytics_dbt: Close
12:10:02.362689 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
12:10:02.363203 [info ] [MainThread]: 
12:10:02.368726 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
12:10:02.369125 [info ] [Thread-1  ]: 1 of 1 START incremental model dbt.dates........................................ [RUN]
12:10:02.370157 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
12:10:02.370492 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
12:10:02.370685 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
12:10:02.376183 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
12:10:02.376806 [debug] [Thread-1  ]: finished collecting timing info
12:10:02.376957 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
12:10:02.406730 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:10:02.406919 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
12:10:02.407009 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:10:04.090971 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.68 seconds
12:10:04.102904 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:10:04.103189 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
12:10:04.228753 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.13 seconds
12:10:04.235152 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:10:04.235385 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
12:10:04.337258 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.1 seconds
12:10:04.350030 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:10:04.350286 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
12:10:04.597897 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.25 seconds
12:10:04.622337 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
12:10:04.624761 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:10:04.624888 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
12:10:04.759366 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.13 seconds
12:10:04.760946 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:10:04.761152 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
12:10:05.398784 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.64 seconds
12:10:05.400230 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:10:05.400643 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
12:10:05.720342 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.32 seconds
12:10:05.732909 [debug] [Thread-1  ]: finished collecting timing info
12:10:05.733166 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
12:10:05.916386 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c51c4908-74d6-4adf-9a99-99e60c89b6a0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c0558e0>]}
12:10:05.917662 [info ] [Thread-1  ]: 1 of 1 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 3.55s]
12:10:05.918201 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
12:10:05.919648 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:10:05.920116 [info ] [MainThread]: 
12:10:05.920395 [info ] [MainThread]: Finished running 1 incremental model in 5.30s.
12:10:05.920635 [debug] [MainThread]: Connection 'master' was properly closed.
12:10:05.920767 [debug] [MainThread]: Connection 'model.learn_dbt.dates' was properly closed.
12:10:05.927132 [info ] [MainThread]: 
12:10:05.927392 [info ] [MainThread]: [32mCompleted successfully[0m
12:10:05.927634 [info ] [MainThread]: 
12:10:05.927826 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
12:10:05.928090 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c0513d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10906b220>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10956c190>]}


============================== 2022-05-16 14:30:10.604700 | c05cc144-e036-4fdb-81ce-b918852e500e ==============================
14:30:10.604700 [info ] [MainThread]: Running with dbt=1.0.1
14:30:10.605361 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
14:30:10.605508 [debug] [MainThread]: Tracking: tracking
14:30:10.605733 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106eef0a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106eefb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106eef3a0>]}
14:30:10.641747 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
14:30:10.641997 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'c05cc144-e036-4fdb-81ce-b918852e500e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ee65e0>]}
14:30:10.659140 [debug] [MainThread]: Parsing macros/catalog.sql
14:30:10.660309 [debug] [MainThread]: Parsing macros/adapters.sql
14:30:10.680042 [debug] [MainThread]: Parsing macros/materializations/merge.sql
14:30:10.681904 [debug] [MainThread]: Parsing macros/materializations/seed.sql
14:30:10.684298 [debug] [MainThread]: Parsing macros/materializations/view.sql
14:30:10.684906 [debug] [MainThread]: Parsing macros/materializations/table.sql
14:30:10.686312 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
14:30:10.690247 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
14:30:10.690663 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
14:30:10.692348 [debug] [MainThread]: Parsing macros/materializations/configs.sql
14:30:10.693349 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
14:30:10.694085 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
14:30:10.701885 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
14:30:10.707369 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
14:30:10.713098 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
14:30:10.715182 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
14:30:10.715988 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
14:30:10.716779 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
14:30:10.718753 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
14:30:10.724199 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
14:30:10.724978 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
14:30:10.729922 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
14:30:10.737718 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
14:30:10.741468 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
14:30:10.742820 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
14:30:10.746722 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
14:30:10.747465 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
14:30:10.748742 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
14:30:10.749765 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
14:30:10.752758 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
14:30:10.760792 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
14:30:10.761454 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
14:30:10.762546 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
14:30:10.763232 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
14:30:10.763641 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
14:30:10.763888 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
14:30:10.764205 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
14:30:10.764885 [debug] [MainThread]: Parsing macros/etc/statement.sql
14:30:10.766927 [debug] [MainThread]: Parsing macros/etc/datetime.sql
14:30:10.770849 [debug] [MainThread]: Parsing macros/adapters/schema.sql
14:30:10.771805 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
14:30:10.772970 [debug] [MainThread]: Parsing macros/adapters/relation.sql
14:30:10.777490 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
14:30:10.778759 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
14:30:10.780732 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
14:30:10.784252 [debug] [MainThread]: Parsing macros/adapters/columns.sql
14:30:10.788840 [debug] [MainThread]: Parsing tests/generic/builtin.sql
14:30:10.879066 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
14:30:10.885913 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
14:30:10.886461 [debug] [MainThread]: 1699: static parser successfully parsed example/playing_with_tests.sql
14:30:10.887547 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_cumulative_sales.sql
14:30:10.888557 [debug] [MainThread]: 1603: static parser failed on example/my_second_dbt_model.sql
14:30:10.890150 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_second_dbt_model.sql
14:30:10.890594 [debug] [MainThread]: 1603: static parser failed on example/incremental_time.sql
14:30:10.893859 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_time.sql
14:30:10.894304 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
14:30:10.895252 [debug] [MainThread]: 1603: static parser failed on new/dates.sql
14:30:10.896853 [debug] [MainThread]: 1602: parser fallback to jinja rendering on new/dates.sql
14:30:10.953200 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c05cc144-e036-4fdb-81ce-b918852e500e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f9e4c0>]}
14:30:10.956694 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c05cc144-e036-4fdb-81ce-b918852e500e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ea5bb0>]}
14:30:10.956825 [info ] [MainThread]: Found 7 models, 12 tests, 0 snapshots, 0 analyses, 179 macros, 3 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
14:30:10.957643 [info ] [MainThread]: 
14:30:10.957853 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:30:10.958300 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
14:30:10.964066 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
14:30:10.964164 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
14:30:10.964238 [debug] [ThreadPool]: Opening a new connection, currently in state init
14:30:11.803038 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.84 seconds
14:30:11.805394 [debug] [ThreadPool]: On list_analytics: Close
14:30:11.994150 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
14:30:12.002426 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
14:30:12.002703 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
14:30:12.002840 [debug] [ThreadPool]: Opening a new connection, currently in state closed
14:30:12.647328 [debug] [ThreadPool]: SQL status: SUCCESS 7 in 0.64 seconds
14:30:12.650194 [debug] [ThreadPool]: On list_analytics_dbt: Close
14:30:12.817712 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
14:30:12.818315 [info ] [MainThread]: 
14:30:12.823666 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
14:30:12.824540 [info ] [Thread-1  ]: 1 of 7 START incremental model dbt.dates........................................ [RUN]
14:30:12.825114 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
14:30:12.825284 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
14:30:12.825451 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
14:30:12.831394 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
14:30:12.832989 [debug] [Thread-1  ]: finished collecting timing info
14:30:12.833178 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
14:30:12.864080 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
14:30:12.865371 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
14:30:12.865469 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:30:15.160839 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.3 seconds
14:30:15.175070 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
14:30:15.175461 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
14:30:15.305804 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.13 seconds
14:30:15.312827 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
14:30:15.313236 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
14:30:15.457627 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.14 seconds
14:30:15.470506 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
14:30:15.470927 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
14:30:15.606050 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.13 seconds
14:30:15.631548 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
14:30:15.633742 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
14:30:15.633877 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
14:30:15.915047 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.28 seconds
14:30:15.915789 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
14:30:15.916003 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
14:30:16.215105 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.3 seconds
14:30:16.215642 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
14:30:16.215823 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
14:30:16.411218 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.19 seconds
14:30:16.424873 [debug] [Thread-1  ]: finished collecting timing info
14:30:16.425354 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
14:30:16.609177 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c05cc144-e036-4fdb-81ce-b918852e500e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1091487c0>]}
14:30:16.610083 [info ] [Thread-1  ]: 1 of 7 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 3.78s]
14:30:16.610603 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
14:30:16.610818 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
14:30:16.611186 [info ] [Thread-1  ]: 2 of 7 START incremental model dbt.incremental_time............................. [RUN]
14:30:16.611728 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
14:30:16.611906 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
14:30:16.612088 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
14:30:16.615585 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
14:30:16.619284 [debug] [Thread-1  ]: finished collecting timing info
14:30:16.619521 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
14:30:16.623225 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:30:16.623470 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
14:30:16.623616 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:30:18.458311 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.83 seconds
14:30:18.465163 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:30:18.465577 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
14:30:18.602977 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.14 seconds
14:30:18.609259 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:30:18.609644 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
14:30:18.754479 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.14 seconds
14:30:18.760797 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:30:18.761146 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
14:30:18.943690 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.18 seconds
14:30:18.947569 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
14:30:18.950832 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:30:18.951075 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
14:30:19.128251 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.18 seconds
14:30:19.131050 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:30:19.131375 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
14:30:20.565096 [debug] [Thread-1  ]: SQL status: SUCCESS 3250 in 1.43 seconds
14:30:20.565720 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:30:20.565901 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
14:30:20.807615 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.24 seconds
14:30:20.810778 [debug] [Thread-1  ]: finished collecting timing info
14:30:20.811129 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
14:30:21.134764 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c05cc144-e036-4fdb-81ce-b918852e500e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1091c0850>]}
14:30:21.136080 [info ] [Thread-1  ]: 2 of 7 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 4.52s]
14:30:21.136760 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
14:30:21.137029 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
14:30:21.137449 [info ] [Thread-1  ]: 3 of 7 START view model dbt.first_model......................................... [RUN]
14:30:21.138129 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
14:30:21.138358 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
14:30:21.138576 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
14:30:21.144963 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
14:30:21.147542 [debug] [Thread-1  ]: finished collecting timing info
14:30:21.147831 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
14:30:21.164254 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
14:30:21.165942 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
14:30:21.166165 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */

  create or replace  view analytics.dbt.first_model 
  
   as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id

)

select * 
from source_data


/*
select *, True as first_variable
from source_data
where id >= 1
*/
  );
14:30:21.166286 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:30:21.825170 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.66 seconds
14:30:21.828644 [debug] [Thread-1  ]: finished collecting timing info
14:30:21.829001 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
14:30:22.167383 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c05cc144-e036-4fdb-81ce-b918852e500e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107014700>]}
14:30:22.167943 [info ] [Thread-1  ]: 3 of 7 OK created view model dbt.first_model.................................... [[32mSUCCESS 1[0m in 1.03s]
14:30:22.168292 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
14:30:22.168489 [debug] [Thread-1  ]: Began running node model.learn_dbt.playing_with_tests
14:30:22.168831 [info ] [Thread-1  ]: 4 of 7 START table model dbt.playing_with_tests................................. [RUN]
14:30:22.169456 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.playing_with_tests"
14:30:22.169649 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.playing_with_tests
14:30:22.169813 [debug] [Thread-1  ]: Compiling model.learn_dbt.playing_with_tests
14:30:22.171385 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.playing_with_tests"
14:30:22.173198 [debug] [Thread-1  ]: finished collecting timing info
14:30:22.173426 [debug] [Thread-1  ]: Began executing node model.learn_dbt.playing_with_tests
14:30:22.183218 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.playing_with_tests"
14:30:22.184661 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
14:30:22.184806 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */


      create or replace transient table analytics.dbt.playing_with_tests  as
      (select * 
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER"
      );
14:30:22.184922 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:30:24.302390 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.12 seconds
14:30:24.310518 [debug] [Thread-1  ]: finished collecting timing info
14:30:24.310952 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: Close
14:30:24.576206 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c05cc144-e036-4fdb-81ce-b918852e500e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109302730>]}
14:30:24.577179 [info ] [Thread-1  ]: 4 of 7 OK created table model dbt.playing_with_tests............................ [[32mSUCCESS 1[0m in 2.41s]
14:30:24.577676 [debug] [Thread-1  ]: Finished running node model.learn_dbt.playing_with_tests
14:30:24.577912 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
14:30:24.578370 [info ] [Thread-1  ]: 5 of 7 START table model dbt.snowflake_cumulative_sales......................... [RUN]
14:30:24.579133 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
14:30:24.579363 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
14:30:24.579582 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
14:30:24.581366 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
14:30:24.583535 [debug] [Thread-1  ]: finished collecting timing info
14:30:24.583795 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
14:30:24.586511 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
14:30:24.587853 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
14:30:24.588042 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
14:30:24.588178 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:30:26.574366 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.99 seconds
14:30:26.579063 [debug] [Thread-1  ]: finished collecting timing info
14:30:26.579470 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
14:30:26.842041 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c05cc144-e036-4fdb-81ce-b918852e500e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1091aa760>]}
14:30:26.842931 [info ] [Thread-1  ]: 5 of 7 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 2.26s]
14:30:26.843439 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
14:30:26.844021 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
14:30:26.844494 [info ] [Thread-1  ]: 6 of 7 START table model dbt.snowflake_customer_purchases....................... [RUN]
14:30:26.845253 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
14:30:26.845493 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
14:30:26.845672 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
14:30:26.847307 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
14:30:26.848738 [debug] [Thread-1  ]: finished collecting timing info
14:30:26.849138 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
14:30:26.851920 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
14:30:26.853718 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
14:30:26.853907 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
14:30:26.854060 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:30:28.494586 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.64 seconds
14:30:28.498239 [debug] [Thread-1  ]: finished collecting timing info
14:30:28.498658 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
14:30:28.650054 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c05cc144-e036-4fdb-81ce-b918852e500e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1072c6880>]}
14:30:28.650923 [info ] [Thread-1  ]: 6 of 7 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 1.80s]
14:30:28.651428 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
14:30:28.651804 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
14:30:28.652428 [info ] [Thread-1  ]: 7 of 7 START table model dbt.my_second_dbt_model................................ [RUN]
14:30:28.653059 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
14:30:28.653262 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
14:30:28.653457 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
14:30:28.656841 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
14:30:28.657630 [debug] [Thread-1  ]: finished collecting timing info
14:30:28.657811 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
14:30:28.660838 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
14:30:28.661957 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
14:30:28.662135 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
/*
union all
select 7 as id, True as first_variable
*/
      );
14:30:28.662469 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:30:30.104338 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.44 seconds
14:30:30.109205 [debug] [Thread-1  ]: finished collecting timing info
14:30:30.109644 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
14:30:30.283674 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c05cc144-e036-4fdb-81ce-b918852e500e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1093008b0>]}
14:30:30.284345 [info ] [Thread-1  ]: 7 of 7 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.63s]
14:30:30.284783 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
14:30:30.286105 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:30:30.286392 [info ] [MainThread]: 
14:30:30.286718 [info ] [MainThread]: Running 3 on-run-end hooks
14:30:30.287044 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-0
14:30:30.288621 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-0"
14:30:30.290565 [info ] [MainThread]: 1 of 3 START hook: learn_dbt.on-run-end.0....................................... [RUN]
14:30:30.291118 [debug] [MainThread]: Using snowflake connection "master"
14:30:30.291277 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analytics
14:30:30.291414 [debug] [MainThread]: Opening a new connection, currently in state init
14:30:31.155688 [debug] [MainThread]: Snowflake adapter: Snowflake query id: 01a44e66-3201-9e2f-0000-00012052b099
14:30:31.156084 [debug] [MainThread]: Snowflake adapter: Snowflake error: 002003 (02000): SQL compilation error:
Role 'ANALYTICS' does not exist or not authorized.
14:30:31.156387 [info ] [MainThread]: Database error while running on-run-end
14:30:31.156764 [debug] [MainThread]: On master: Close
14:30:31.331338 [debug] [MainThread]: Connection 'master' was properly closed.
14:30:31.331861 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
14:30:31.332257 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f6f040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109184040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1070ec6d0>]}


============================== 2022-05-16 14:31:16.140150 | 3de10183-14ad-4a0f-8ab8-07e419a8ec42 ==============================
14:31:16.140150 [info ] [MainThread]: Running with dbt=1.0.1
14:31:16.142170 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
14:31:16.142424 [debug] [MainThread]: Tracking: tracking
14:31:16.142857 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11934f2b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11934fb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11934f9a0>]}
14:31:16.179469 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
14:31:16.179722 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '3de10183-14ad-4a0f-8ab8-07e419a8ec42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x118848dc0>]}
14:31:16.194539 [debug] [MainThread]: Parsing macros/catalog.sql
14:31:16.195796 [debug] [MainThread]: Parsing macros/adapters.sql
14:31:16.216831 [debug] [MainThread]: Parsing macros/materializations/merge.sql
14:31:16.218815 [debug] [MainThread]: Parsing macros/materializations/seed.sql
14:31:16.221274 [debug] [MainThread]: Parsing macros/materializations/view.sql
14:31:16.221889 [debug] [MainThread]: Parsing macros/materializations/table.sql
14:31:16.223342 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
14:31:16.227596 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
14:31:16.228150 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
14:31:16.230071 [debug] [MainThread]: Parsing macros/materializations/configs.sql
14:31:16.231182 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
14:31:16.231980 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
14:31:16.240319 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
14:31:16.246322 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
14:31:16.252213 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
14:31:16.254289 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
14:31:16.255116 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
14:31:16.255941 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
14:31:16.257999 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
14:31:16.263462 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
14:31:16.264138 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
14:31:16.268970 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
14:31:16.277122 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
14:31:16.281173 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
14:31:16.282515 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
14:31:16.286292 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
14:31:16.287057 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
14:31:16.288355 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
14:31:16.289403 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
14:31:16.292221 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
14:31:16.300080 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
14:31:16.300742 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
14:31:16.301910 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
14:31:16.302612 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
14:31:16.303018 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
14:31:16.303247 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
14:31:16.303545 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
14:31:16.304144 [debug] [MainThread]: Parsing macros/etc/statement.sql
14:31:16.306136 [debug] [MainThread]: Parsing macros/etc/datetime.sql
14:31:16.310519 [debug] [MainThread]: Parsing macros/adapters/schema.sql
14:31:16.311604 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
14:31:16.312869 [debug] [MainThread]: Parsing macros/adapters/relation.sql
14:31:16.317307 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
14:31:16.318619 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
14:31:16.320611 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
14:31:16.323891 [debug] [MainThread]: Parsing macros/adapters/columns.sql
14:31:16.328459 [debug] [MainThread]: Parsing tests/generic/builtin.sql
14:31:16.420830 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
14:31:16.427222 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
14:31:16.427702 [debug] [MainThread]: 1699: static parser successfully parsed example/playing_with_tests.sql
14:31:16.428784 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_cumulative_sales.sql
14:31:16.429781 [debug] [MainThread]: 1603: static parser failed on example/my_second_dbt_model.sql
14:31:16.431381 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_second_dbt_model.sql
14:31:16.431834 [debug] [MainThread]: 1603: static parser failed on example/incremental_time.sql
14:31:16.435223 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_time.sql
14:31:16.435671 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
14:31:16.436624 [debug] [MainThread]: 1603: static parser failed on new/dates.sql
14:31:16.438232 [debug] [MainThread]: 1602: parser fallback to jinja rendering on new/dates.sql
14:31:16.492172 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3de10183-14ad-4a0f-8ab8-07e419a8ec42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1194d3070>]}
14:31:16.495304 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3de10183-14ad-4a0f-8ab8-07e419a8ec42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1194d3280>]}
14:31:16.495427 [info ] [MainThread]: Found 7 models, 12 tests, 0 snapshots, 0 analyses, 179 macros, 3 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
14:31:16.496216 [info ] [MainThread]: 
14:31:16.496419 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:31:16.496846 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
14:31:16.502931 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
14:31:16.503052 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
14:31:16.503124 [debug] [ThreadPool]: Opening a new connection, currently in state init
14:31:17.659224 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.16 seconds
14:31:17.661412 [debug] [ThreadPool]: On list_analytics: Close
14:31:17.849581 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
14:31:17.858093 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
14:31:17.858313 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
14:31:17.858471 [debug] [ThreadPool]: Opening a new connection, currently in state closed
14:31:18.433588 [debug] [ThreadPool]: SQL status: SUCCESS 7 in 0.58 seconds
14:31:18.435615 [debug] [ThreadPool]: On list_analytics_dbt: Close
14:31:18.709282 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
14:31:18.709970 [info ] [MainThread]: 
14:31:18.715011 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
14:31:18.715813 [info ] [Thread-1  ]: 1 of 7 START incremental model dbt.dates........................................ [RUN]
14:31:18.716375 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
14:31:18.716556 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
14:31:18.716722 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
14:31:18.723268 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
14:31:18.724159 [debug] [Thread-1  ]: finished collecting timing info
14:31:18.724332 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
14:31:18.755169 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
14:31:18.755407 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
14:31:18.755497 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:31:19.758909 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.0 seconds
14:31:19.773169 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
14:31:19.773578 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
14:31:19.891134 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.12 seconds
14:31:19.898378 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
14:31:19.898630 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
14:31:19.999291 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.1 seconds
14:31:20.012645 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
14:31:20.012956 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
14:31:20.146058 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.13 seconds
14:31:20.173378 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
14:31:20.177560 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
14:31:20.177737 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
14:31:20.317257 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.14 seconds
14:31:20.317976 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
14:31:20.318193 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
14:31:20.801001 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.48 seconds
14:31:20.801653 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
14:31:20.801941 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
14:31:20.994437 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.19 seconds
14:31:21.009015 [debug] [Thread-1  ]: finished collecting timing info
14:31:21.009445 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
14:31:21.197160 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3de10183-14ad-4a0f-8ab8-07e419a8ec42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11949d970>]}
14:31:21.197716 [info ] [Thread-1  ]: 1 of 7 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 2.48s]
14:31:21.198109 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
14:31:21.198325 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
14:31:21.198659 [info ] [Thread-1  ]: 2 of 7 START incremental model dbt.incremental_time............................. [RUN]
14:31:21.199190 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
14:31:21.199435 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
14:31:21.199780 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
14:31:21.203732 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
14:31:21.204577 [debug] [Thread-1  ]: finished collecting timing info
14:31:21.204761 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
14:31:21.208466 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:31:21.208735 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
14:31:21.208951 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:31:22.736227 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.53 seconds
14:31:22.742321 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:31:22.742752 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
14:31:23.616548 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.87 seconds
14:31:23.620888 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:31:23.621213 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
14:31:23.726176 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
14:31:23.734048 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:31:23.734471 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
14:31:24.145330 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.41 seconds
14:31:24.150462 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
14:31:24.152927 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:31:24.153122 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
14:31:24.668617 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.52 seconds
14:31:24.669219 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:31:24.669437 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
14:31:25.558443 [debug] [Thread-1  ]: SQL status: SUCCESS 64 in 0.89 seconds
14:31:25.559416 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:31:25.559620 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
14:31:26.275243 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.72 seconds
14:31:26.285444 [debug] [Thread-1  ]: finished collecting timing info
14:31:26.286130 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
14:31:26.708604 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3de10183-14ad-4a0f-8ab8-07e419a8ec42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1199d0910>]}
14:31:26.709274 [info ] [Thread-1  ]: 2 of 7 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 5.51s]
14:31:26.709598 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
14:31:26.709827 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
14:31:26.710253 [info ] [Thread-1  ]: 3 of 7 START view model dbt.first_model......................................... [RUN]
14:31:26.711181 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
14:31:26.711434 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
14:31:26.711635 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
14:31:26.715557 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
14:31:26.716094 [debug] [Thread-1  ]: finished collecting timing info
14:31:26.716241 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
14:31:26.733515 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
14:31:26.734587 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
14:31:26.734713 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */

  create or replace  view analytics.dbt.first_model 
  
   as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id

)

select * 
from source_data


/*
select *, True as first_variable
from source_data
where id >= 1
*/
  );
14:31:26.734819 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:31:27.821428 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.09 seconds
14:31:27.828630 [debug] [Thread-1  ]: finished collecting timing info
14:31:27.830455 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
14:31:28.341349 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3de10183-14ad-4a0f-8ab8-07e419a8ec42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1194896a0>]}
14:31:28.342392 [info ] [Thread-1  ]: 3 of 7 OK created view model dbt.first_model.................................... [[32mSUCCESS 1[0m in 1.63s]
14:31:28.342925 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
14:31:28.343201 [debug] [Thread-1  ]: Began running node model.learn_dbt.playing_with_tests
14:31:28.343945 [info ] [Thread-1  ]: 4 of 7 START table model dbt.playing_with_tests................................. [RUN]
14:31:28.344772 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.playing_with_tests"
14:31:28.344988 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.playing_with_tests
14:31:28.345185 [debug] [Thread-1  ]: Compiling model.learn_dbt.playing_with_tests
14:31:28.346869 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.playing_with_tests"
14:31:28.347716 [debug] [Thread-1  ]: finished collecting timing info
14:31:28.347882 [debug] [Thread-1  ]: Began executing node model.learn_dbt.playing_with_tests
14:31:28.357714 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.playing_with_tests"
14:31:28.359018 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
14:31:28.359230 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */


      create or replace transient table analytics.dbt.playing_with_tests  as
      (select * 
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER"
      );
14:31:28.359470 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:31:30.433142 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.07 seconds
14:31:30.436349 [debug] [Thread-1  ]: finished collecting timing info
14:31:30.436735 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: Close
14:31:30.765662 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3de10183-14ad-4a0f-8ab8-07e419a8ec42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119b2a160>]}
14:31:30.766398 [info ] [Thread-1  ]: 4 of 7 OK created table model dbt.playing_with_tests............................ [[32mSUCCESS 1[0m in 2.42s]
14:31:30.766880 [debug] [Thread-1  ]: Finished running node model.learn_dbt.playing_with_tests
14:31:30.768642 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
14:31:30.769475 [info ] [Thread-1  ]: 5 of 7 START table model dbt.snowflake_cumulative_sales......................... [RUN]
14:31:30.770052 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
14:31:30.770146 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
14:31:30.770224 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
14:31:30.770936 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
14:31:30.771262 [debug] [Thread-1  ]: finished collecting timing info
14:31:30.771339 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
14:31:30.772477 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
14:31:30.772953 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
14:31:30.773027 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
14:31:30.773090 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:31:33.387214 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.61 seconds
14:31:33.391055 [debug] [Thread-1  ]: finished collecting timing info
14:31:33.391486 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
14:31:33.565395 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3de10183-14ad-4a0f-8ab8-07e419a8ec42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119bb3430>]}
14:31:33.566114 [info ] [Thread-1  ]: 5 of 7 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 2.80s]
14:31:33.566521 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
14:31:33.566969 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
14:31:33.567572 [info ] [Thread-1  ]: 6 of 7 START table model dbt.snowflake_customer_purchases....................... [RUN]
14:31:33.568205 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
14:31:33.568397 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
14:31:33.568576 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
14:31:33.570287 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
14:31:33.571112 [debug] [Thread-1  ]: finished collecting timing info
14:31:33.571292 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
14:31:33.609777 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
14:31:33.610721 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
14:31:33.610847 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
14:31:33.610999 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:31:35.310138 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.7 seconds
14:31:35.315653 [debug] [Thread-1  ]: finished collecting timing info
14:31:35.316304 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
14:31:35.654256 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3de10183-14ad-4a0f-8ab8-07e419a8ec42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119bc7a30>]}
14:31:35.655375 [info ] [Thread-1  ]: 6 of 7 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.09s]
14:31:35.656079 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
14:31:35.656401 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
14:31:35.656858 [info ] [Thread-1  ]: 7 of 7 START table model dbt.my_second_dbt_model................................ [RUN]
14:31:35.657524 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
14:31:35.657748 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
14:31:35.657948 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
14:31:35.661428 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
14:31:35.662359 [debug] [Thread-1  ]: finished collecting timing info
14:31:35.662582 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
14:31:35.665255 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
14:31:35.666126 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
14:31:35.666295 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
/*
union all
select 7 as id, True as first_variable
*/
      );
14:31:35.666443 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:31:37.209549 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.54 seconds
14:31:37.213119 [debug] [Thread-1  ]: finished collecting timing info
14:31:37.213661 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
14:31:37.409309 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3de10183-14ad-4a0f-8ab8-07e419a8ec42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119bb7310>]}
14:31:37.410181 [info ] [Thread-1  ]: 7 of 7 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.75s]
14:31:37.410666 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
14:31:37.412599 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:31:37.412950 [info ] [MainThread]: 
14:31:37.413301 [info ] [MainThread]: Running 3 on-run-end hooks
14:31:37.413644 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-0
14:31:37.415187 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-0"
14:31:37.416781 [info ] [MainThread]: 1 of 3 START hook: learn_dbt.on-run-end.0....................................... [RUN]
14:31:37.417306 [debug] [MainThread]: Using snowflake connection "master"
14:31:37.417463 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
14:31:37.417602 [debug] [MainThread]: Opening a new connection, currently in state init
14:31:38.192501 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.77 seconds
14:31:38.194488 [info ] [MainThread]: 1 of 3 OK hook: learn_dbt.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.78s]
14:31:38.195065 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-1
14:31:38.196739 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-1"
14:31:38.197868 [info ] [MainThread]: 2 of 3 START hook: learn_dbt.on-run-end.1....................................... [RUN]
14:31:38.198568 [debug] [MainThread]: Using snowflake connection "master"
14:31:38.198761 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
14:31:38.367945 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.17 seconds
14:31:38.370711 [info ] [MainThread]: 2 of 3 OK hook: learn_dbt.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.17s]
14:31:38.371463 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-2
14:31:38.374433 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-2"
14:31:38.375621 [info ] [MainThread]: 3 of 3 START hook: learn_dbt.on-run-end.2....................................... [RUN]
14:31:38.376298 [debug] [MainThread]: Using snowflake connection "master"
14:31:38.376496 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
14:31:38.784605 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.41 seconds
14:31:38.787017 [info ] [MainThread]: 3 of 3 OK hook: learn_dbt.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.41s]
14:31:38.787616 [info ] [MainThread]: 
14:31:38.788185 [debug] [MainThread]: On master: Close
14:31:39.098326 [info ] [MainThread]: 
14:31:39.098880 [info ] [MainThread]: Finished running 2 incremental models, 1 view model, 4 table models, 3 hooks in 22.60s.
14:31:39.099214 [debug] [MainThread]: Connection 'master' was properly closed.
14:31:39.099391 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
14:31:39.109054 [info ] [MainThread]: 
14:31:39.109387 [info ] [MainThread]: [32mCompleted successfully[0m
14:31:39.109669 [info ] [MainThread]: 
14:31:39.109977 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
14:31:39.110314 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1199d05e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1199d0be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119499610>]}


============================== 2022-05-16 14:46:59.285824 | 963d30f2-1219-4047-8129-eaebb64daff7 ==============================
14:46:59.285824 [info ] [MainThread]: Running with dbt=1.0.1
14:46:59.286359 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
14:46:59.286490 [debug] [MainThread]: Tracking: tracking
14:46:59.286759 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107bcae20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107bcaa90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107bcad30>]}
14:46:59.322902 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
14:46:59.323226 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '963d30f2-1219-4047-8129-eaebb64daff7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107bcad60>]}
14:46:59.339268 [debug] [MainThread]: Parsing macros/catalog.sql
14:46:59.340502 [debug] [MainThread]: Parsing macros/adapters.sql
14:46:59.360044 [debug] [MainThread]: Parsing macros/materializations/merge.sql
14:46:59.361833 [debug] [MainThread]: Parsing macros/materializations/seed.sql
14:46:59.364224 [debug] [MainThread]: Parsing macros/materializations/view.sql
14:46:59.364807 [debug] [MainThread]: Parsing macros/materializations/table.sql
14:46:59.366208 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
14:46:59.370140 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
14:46:59.370553 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
14:46:59.372246 [debug] [MainThread]: Parsing macros/materializations/configs.sql
14:46:59.373262 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
14:46:59.373999 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
14:46:59.381711 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
14:46:59.387200 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
14:46:59.392973 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
14:46:59.395008 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
14:46:59.395798 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
14:46:59.396595 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
14:46:59.398761 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
14:46:59.404417 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
14:46:59.405149 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
14:46:59.410015 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
14:46:59.417667 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
14:46:59.421294 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
14:46:59.422555 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
14:46:59.426051 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
14:46:59.426623 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
14:46:59.427840 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
14:46:59.428835 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
14:46:59.431589 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
14:46:59.439631 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
14:46:59.440341 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
14:46:59.441435 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
14:46:59.442120 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
14:46:59.442521 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
14:46:59.442752 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
14:46:59.443050 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
14:46:59.443650 [debug] [MainThread]: Parsing macros/etc/statement.sql
14:46:59.445623 [debug] [MainThread]: Parsing macros/etc/datetime.sql
14:46:59.449680 [debug] [MainThread]: Parsing macros/adapters/schema.sql
14:46:59.450615 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
14:46:59.451781 [debug] [MainThread]: Parsing macros/adapters/relation.sql
14:46:59.456197 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
14:46:59.457502 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
14:46:59.459474 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
14:46:59.462758 [debug] [MainThread]: Parsing macros/adapters/columns.sql
14:46:59.467245 [debug] [MainThread]: Parsing tests/generic/builtin.sql
14:46:59.560274 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
14:46:59.567013 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
14:46:59.567653 [debug] [MainThread]: 1699: static parser successfully parsed example/playing_with_tests.sql
14:46:59.569714 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_cumulative_sales.sql
14:46:59.572045 [debug] [MainThread]: 1603: static parser failed on example/my_second_dbt_model.sql
14:46:59.574076 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_second_dbt_model.sql
14:46:59.574643 [debug] [MainThread]: 1603: static parser failed on example/incremental_time.sql
14:46:59.578357 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_time.sql
14:46:59.578891 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
14:46:59.581013 [debug] [MainThread]: 1603: static parser failed on new/dates.sql
14:46:59.582616 [debug] [MainThread]: 1602: parser fallback to jinja rendering on new/dates.sql
14:46:59.632838 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '963d30f2-1219-4047-8129-eaebb64daff7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d24f40>]}
14:46:59.636391 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '963d30f2-1219-4047-8129-eaebb64daff7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107c72f70>]}
14:46:59.636543 [info ] [MainThread]: Found 7 models, 12 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
14:46:59.637347 [info ] [MainThread]: 
14:46:59.637568 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:46:59.638031 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
14:46:59.643882 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
14:46:59.643982 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
14:46:59.644045 [debug] [ThreadPool]: Opening a new connection, currently in state init
14:47:00.458138 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.81 seconds
14:47:00.460520 [debug] [ThreadPool]: On list_analytics: Close
14:47:00.698413 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
14:47:00.706474 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
14:47:00.706759 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
14:47:00.706925 [debug] [ThreadPool]: Opening a new connection, currently in state closed
14:47:01.352516 [debug] [ThreadPool]: SQL status: SUCCESS 7 in 0.65 seconds
14:47:01.355835 [debug] [ThreadPool]: On list_analytics_dbt: Close
14:47:01.516584 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
14:47:01.517365 [info ] [MainThread]: 
14:47:01.522903 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
14:47:01.523725 [info ] [Thread-1  ]: 1 of 7 START incremental model dbt.dates........................................ [RUN]
14:47:01.524243 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
14:47:01.524413 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
14:47:01.524588 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
14:47:01.530490 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
14:47:01.531957 [debug] [Thread-1  ]: finished collecting timing info
14:47:01.532138 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
14:47:01.562167 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
14:47:01.562400 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
14:47:01.562492 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:47:03.545936 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.98 seconds
14:47:03.559993 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
14:47:03.560298 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
14:47:03.679588 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.12 seconds
14:47:03.687620 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
14:47:03.687941 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
14:47:03.839747 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.15 seconds
14:47:03.853146 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
14:47:03.853463 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
14:47:04.263948 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.41 seconds
14:47:04.290737 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
14:47:04.292421 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
14:47:04.292521 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
14:47:04.500146 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.21 seconds
14:47:04.501221 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
14:47:04.501447 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
14:47:05.543703 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 1.04 seconds
14:47:05.544786 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
14:47:05.545010 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
14:47:05.774825 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.23 seconds
14:47:05.789915 [debug] [Thread-1  ]: finished collecting timing info
14:47:05.790218 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
14:47:06.087942 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '963d30f2-1219-4047-8129-eaebb64daff7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113128550>]}
14:47:06.088648 [info ] [Thread-1  ]: 1 of 7 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 4.56s]
14:47:06.089091 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
14:47:06.089358 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
14:47:06.089767 [info ] [Thread-1  ]: 2 of 7 START incremental model dbt.incremental_time............................. [RUN]
14:47:06.090340 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
14:47:06.090529 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
14:47:06.090730 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
14:47:06.094463 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
14:47:06.097112 [debug] [Thread-1  ]: finished collecting timing info
14:47:06.097369 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
14:47:06.101452 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:47:06.101665 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
14:47:06.101810 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:47:08.145518 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.04 seconds
14:47:08.151537 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:47:08.151976 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
14:47:08.278291 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.13 seconds
14:47:08.285953 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:47:08.286239 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
14:47:08.390635 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
14:47:08.396500 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:47:08.396883 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
14:47:08.500575 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
14:47:08.506521 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
14:47:08.509864 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:47:08.510081 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
14:47:08.687444 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.18 seconds
14:47:08.688877 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:47:08.689205 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
14:47:09.382506 [debug] [Thread-1  ]: SQL status: SUCCESS 945 in 0.69 seconds
14:47:09.383483 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:47:09.383854 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
14:47:09.738936 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.35 seconds
14:47:09.744670 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:47:09.744865 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

        grant select on all views in schema  to role analyst
14:47:09.873213 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a44e77-3201-9e2f-0000-00012052b11d
14:47:09.873665 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 1 at position 37 unexpected 'to'.
14:47:09.874006 [debug] [Thread-1  ]: finished collecting timing info
14:47:09.874233 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
14:47:10.131402 [debug] [Thread-1  ]: Database Error in model incremental_time (models/example/incremental_time.sql)
  001003 (42000): SQL compilation error:
  syntax error line 1 at position 37 unexpected 'to'.
  compiled SQL at target/run/learn_dbt/models/example/incremental_time.sql
14:47:10.132009 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '963d30f2-1219-4047-8129-eaebb64daff7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100e6700>]}
14:47:10.132709 [error] [Thread-1  ]: 2 of 7 ERROR creating incremental model dbt.incremental_time.................... [[31mERROR[0m in 4.04s]
14:47:10.133289 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
14:47:10.133635 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
14:47:10.134351 [info ] [Thread-1  ]: 3 of 7 START view model dbt.first_model......................................... [RUN]
14:47:10.135025 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
14:47:10.135248 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
14:47:10.135442 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
14:47:10.140717 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
14:47:10.142847 [debug] [Thread-1  ]: finished collecting timing info
14:47:10.143144 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
14:47:10.160144 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
14:47:10.161117 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
14:47:10.161242 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */

  create or replace  view analytics.dbt.first_model 
  
   as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id

)

select * 
from source_data


/*
select *, True as first_variable
from source_data
where id >= 1
*/
  );
14:47:10.161348 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:47:10.787546 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.63 seconds
14:47:10.792174 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
14:47:10.792464 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */

        grant select on all views in schema  to role analyst
14:47:10.897603 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a44e77-3201-9e2f-0000-00012052b121
14:47:10.898103 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 1 at position 37 unexpected 'to'.
14:47:10.898524 [debug] [Thread-1  ]: finished collecting timing info
14:47:10.898775 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
14:47:11.081825 [debug] [Thread-1  ]: Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  001003 (42000): SQL compilation error:
  syntax error line 1 at position 37 unexpected 'to'.
  compiled SQL at target/run/learn_dbt/models/example/my_first_dbt_model.sql
14:47:11.083119 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '963d30f2-1219-4047-8129-eaebb64daff7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100c6b50>]}
14:47:11.083826 [error] [Thread-1  ]: 3 of 7 ERROR creating view model dbt.first_model................................ [[31mERROR[0m in 0.95s]
14:47:11.084569 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
14:47:11.084874 [debug] [Thread-1  ]: Began running node model.learn_dbt.playing_with_tests
14:47:11.085498 [info ] [Thread-1  ]: 4 of 7 START table model dbt.playing_with_tests................................. [RUN]
14:47:11.086426 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.playing_with_tests"
14:47:11.086643 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.playing_with_tests
14:47:11.086841 [debug] [Thread-1  ]: Compiling model.learn_dbt.playing_with_tests
14:47:11.088618 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.playing_with_tests"
14:47:11.089374 [debug] [Thread-1  ]: finished collecting timing info
14:47:11.089556 [debug] [Thread-1  ]: Began executing node model.learn_dbt.playing_with_tests
14:47:11.099237 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.playing_with_tests"
14:47:11.100462 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
14:47:11.100604 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */


      create or replace transient table analytics.dbt.playing_with_tests  as
      (select * 
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER"
      );
14:47:11.100725 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:47:13.274409 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.17 seconds
14:47:13.279671 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
14:47:13.279969 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */

        grant select on all views in schema  to role analyst
14:47:13.390891 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a44e77-3201-9e4e-0000-00012052a28d
14:47:13.391886 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 1 at position 37 unexpected 'to'.
14:47:13.392454 [debug] [Thread-1  ]: finished collecting timing info
14:47:13.392928 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: Close
14:47:13.587452 [debug] [Thread-1  ]: Database Error in model playing_with_tests (models/example/playing_with_tests.sql)
  001003 (42000): SQL compilation error:
  syntax error line 1 at position 37 unexpected 'to'.
  compiled SQL at target/run/learn_dbt/models/example/playing_with_tests.sql
14:47:13.588085 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '963d30f2-1219-4047-8129-eaebb64daff7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1133be880>]}
14:47:13.588596 [error] [Thread-1  ]: 4 of 7 ERROR creating table model dbt.playing_with_tests........................ [[31mERROR[0m in 2.50s]
14:47:13.589022 [debug] [Thread-1  ]: Finished running node model.learn_dbt.playing_with_tests
14:47:13.589257 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
14:47:13.589695 [info ] [Thread-1  ]: 5 of 7 START table model dbt.snowflake_cumulative_sales......................... [RUN]
14:47:13.590364 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
14:47:13.590607 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
14:47:13.590822 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
14:47:13.592758 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
14:47:13.594502 [debug] [Thread-1  ]: finished collecting timing info
14:47:13.594734 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
14:47:13.597563 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
14:47:13.598745 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
14:47:13.598941 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
14:47:13.599075 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:47:15.553385 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.95 seconds
14:47:15.558430 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
14:47:15.558838 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */

        grant select on all views in schema  to role analyst
14:47:15.742357 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a44e77-3201-9e4e-0000-00012052a291
14:47:15.742739 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 1 at position 37 unexpected 'to'.
14:47:15.743078 [debug] [Thread-1  ]: finished collecting timing info
14:47:15.743299 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
14:47:16.030227 [debug] [Thread-1  ]: Database Error in model snowflake_cumulative_sales (models/example/snowflake_cumulative_sales.sql)
  001003 (42000): SQL compilation error:
  syntax error line 1 at position 37 unexpected 'to'.
  compiled SQL at target/run/learn_dbt/models/example/snowflake_cumulative_sales.sql
14:47:16.031138 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '963d30f2-1219-4047-8129-eaebb64daff7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11314cac0>]}
14:47:16.031884 [error] [Thread-1  ]: 5 of 7 ERROR creating table model dbt.snowflake_cumulative_sales................ [[31mERROR[0m in 2.44s]
14:47:16.032600 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
14:47:16.033003 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
14:47:16.033355 [info ] [Thread-1  ]: 6 of 7 START table model dbt.snowflake_customer_purchases....................... [RUN]
14:47:16.034308 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
14:47:16.034565 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
14:47:16.034784 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
14:47:16.036505 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
14:47:16.038774 [debug] [Thread-1  ]: finished collecting timing info
14:47:16.039082 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
14:47:16.074049 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
14:47:16.075351 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
14:47:16.075526 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
14:47:16.075615 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:47:17.778357 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.7 seconds
14:47:17.783761 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
14:47:17.783957 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */

        grant select on all views in schema  to role analyst
14:47:17.902407 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a44e77-3201-9e4e-0000-00012052a299
14:47:17.902896 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 1 at position 37 unexpected 'to'.
14:47:17.903314 [debug] [Thread-1  ]: finished collecting timing info
14:47:17.903578 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
14:47:18.234302 [debug] [Thread-1  ]: Database Error in model snowflake_customer_purchases (models/example/snowflake_customer_purchases.sql)
  001003 (42000): SQL compilation error:
  syntax error line 1 at position 37 unexpected 'to'.
  compiled SQL at target/run/learn_dbt/models/example/snowflake_customer_purchases.sql
14:47:18.235155 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '963d30f2-1219-4047-8129-eaebb64daff7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1131b98b0>]}
14:47:18.235768 [error] [Thread-1  ]: 6 of 7 ERROR creating table model dbt.snowflake_customer_purchases.............. [[31mERROR[0m in 2.20s]
14:47:18.236139 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
14:47:18.236340 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
14:47:18.236656 [info ] [Thread-1  ]: 7 of 7 SKIP relation dbt.my_second_dbt_model.................................... [[33mSKIP[0m]
14:47:18.237080 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
14:47:18.238389 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:47:18.238851 [info ] [MainThread]: 
14:47:18.239144 [info ] [MainThread]: Finished running 2 incremental models, 1 view model, 4 table models in 18.60s.
14:47:18.239391 [debug] [MainThread]: Connection 'master' was properly closed.
14:47:18.239523 [debug] [MainThread]: Connection 'model.learn_dbt.snowflake_customer_purchases' was properly closed.
14:47:18.247627 [info ] [MainThread]: 
14:47:18.247939 [info ] [MainThread]: [31mCompleted with 5 errors and 0 warnings:[0m
14:47:18.248189 [info ] [MainThread]: 
14:47:18.248390 [error] [MainThread]: [33mDatabase Error in model incremental_time (models/example/incremental_time.sql)[0m
14:47:18.248591 [error] [MainThread]:   001003 (42000): SQL compilation error:
14:47:18.248781 [error] [MainThread]:   syntax error line 1 at position 37 unexpected 'to'.
14:47:18.248968 [error] [MainThread]:   compiled SQL at target/run/learn_dbt/models/example/incremental_time.sql
14:47:18.249158 [info ] [MainThread]: 
14:47:18.249346 [error] [MainThread]: [33mDatabase Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)[0m
14:47:18.249540 [error] [MainThread]:   001003 (42000): SQL compilation error:
14:47:18.249723 [error] [MainThread]:   syntax error line 1 at position 37 unexpected 'to'.
14:47:18.249910 [error] [MainThread]:   compiled SQL at target/run/learn_dbt/models/example/my_first_dbt_model.sql
14:47:18.250093 [info ] [MainThread]: 
14:47:18.250277 [error] [MainThread]: [33mDatabase Error in model playing_with_tests (models/example/playing_with_tests.sql)[0m
14:47:18.250457 [error] [MainThread]:   001003 (42000): SQL compilation error:
14:47:18.250784 [error] [MainThread]:   syntax error line 1 at position 37 unexpected 'to'.
14:47:18.251027 [error] [MainThread]:   compiled SQL at target/run/learn_dbt/models/example/playing_with_tests.sql
14:47:18.251254 [info ] [MainThread]: 
14:47:18.251473 [error] [MainThread]: [33mDatabase Error in model snowflake_cumulative_sales (models/example/snowflake_cumulative_sales.sql)[0m
14:47:18.251653 [error] [MainThread]:   001003 (42000): SQL compilation error:
14:47:18.251820 [error] [MainThread]:   syntax error line 1 at position 37 unexpected 'to'.
14:47:18.251980 [error] [MainThread]:   compiled SQL at target/run/learn_dbt/models/example/snowflake_cumulative_sales.sql
14:47:18.252144 [info ] [MainThread]: 
14:47:18.252310 [error] [MainThread]: [33mDatabase Error in model snowflake_customer_purchases (models/example/snowflake_customer_purchases.sql)[0m
14:47:18.252478 [error] [MainThread]:   001003 (42000): SQL compilation error:
14:47:18.252635 [error] [MainThread]:   syntax error line 1 at position 37 unexpected 'to'.
14:47:18.252795 [error] [MainThread]:   compiled SQL at target/run/learn_dbt/models/example/snowflake_customer_purchases.sql
14:47:18.252967 [info ] [MainThread]: 
14:47:18.253135 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=5 SKIP=1 TOTAL=7
14:47:18.253378 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100cbb20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100cb7c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110134520>]}


============================== 2022-05-16 14:48:38.617356 | 1cb406b0-e717-49ff-82ee-b9b0bd50b72e ==============================
14:48:38.617356 [info ] [MainThread]: Running with dbt=1.0.1
14:48:38.617909 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
14:48:38.618040 [debug] [MainThread]: Tracking: tracking
14:48:38.618251 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ca2190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ca20a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ca2b20>]}
14:48:38.666502 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
14:48:38.666649 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
14:48:38.670066 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1cb406b0-e717-49ff-82ee-b9b0bd50b72e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106de30d0>]}
14:48:38.673532 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1cb406b0-e717-49ff-82ee-b9b0bd50b72e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d15e20>]}
14:48:38.673668 [info ] [MainThread]: Found 7 models, 12 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
14:48:38.674520 [info ] [MainThread]: 
14:48:38.674765 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:48:38.675400 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
14:48:38.681579 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
14:48:38.681677 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
14:48:38.681744 [debug] [ThreadPool]: Opening a new connection, currently in state init
14:48:39.660451 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.98 seconds
14:48:39.662946 [debug] [ThreadPool]: On list_analytics: Close
14:48:40.054478 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
14:48:40.063213 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
14:48:40.063530 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
14:48:40.063706 [debug] [ThreadPool]: Opening a new connection, currently in state closed
14:48:40.959518 [debug] [ThreadPool]: SQL status: SUCCESS 7 in 0.9 seconds
14:48:40.963970 [debug] [ThreadPool]: On list_analytics_dbt: Close
14:48:41.126010 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
14:48:41.126670 [info ] [MainThread]: 
14:48:41.131893 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
14:48:41.132714 [info ] [Thread-1  ]: 1 of 7 START incremental model dbt.dates........................................ [RUN]
14:48:41.133313 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
14:48:41.133492 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
14:48:41.133667 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
14:48:41.143488 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
14:48:41.144093 [debug] [Thread-1  ]: finished collecting timing info
14:48:41.144240 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
14:48:41.173099 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
14:48:41.173311 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
14:48:41.173402 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:48:42.889975 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.72 seconds
14:48:42.906881 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
14:48:42.907218 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
14:48:43.159190 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.25 seconds
14:48:43.168578 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
14:48:43.168929 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
14:48:43.284426 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.12 seconds
14:48:43.299775 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
14:48:43.300188 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
14:48:43.453092 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.15 seconds
14:48:43.478927 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
14:48:43.482168 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
14:48:43.482317 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
14:48:43.612780 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.13 seconds
14:48:43.613776 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
14:48:43.614121 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
14:48:44.230070 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.62 seconds
14:48:44.231141 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
14:48:44.231471 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
14:48:44.404650 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.17 seconds
14:48:44.412454 [debug] [Thread-1  ]: finished collecting timing info
14:48:44.412829 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
14:48:44.668030 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1cb406b0-e717-49ff-82ee-b9b0bd50b72e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106dd17c0>]}
14:48:44.668873 [info ] [Thread-1  ]: 1 of 7 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 3.53s]
14:48:44.669502 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
14:48:44.669917 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
14:48:44.670516 [info ] [Thread-1  ]: 2 of 7 START incremental model dbt.incremental_time............................. [RUN]
14:48:44.671186 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
14:48:44.671394 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
14:48:44.671589 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
14:48:44.675191 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
14:48:44.675803 [debug] [Thread-1  ]: finished collecting timing info
14:48:44.675978 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
14:48:44.679630 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:48:44.679784 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
14:48:44.679912 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:48:46.231600 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.55 seconds
14:48:46.238197 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:48:46.238650 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
14:48:46.342907 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
14:48:46.349095 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:48:46.349491 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
14:48:46.443558 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.09 seconds
14:48:46.453080 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:48:46.453389 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
14:48:46.598060 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.14 seconds
14:48:46.603945 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
14:48:46.606206 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:48:46.606472 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
14:48:46.720127 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.11 seconds
14:48:46.720695 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:48:46.720884 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
14:48:47.740259 [debug] [Thread-1  ]: SQL status: SUCCESS 99 in 1.02 seconds
14:48:47.740851 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:48:47.741553 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
14:48:48.305730 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.56 seconds
14:48:48.310206 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:48:48.310495 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

        grant select on all views in schema  to role analyst
14:48:48.420140 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a44e78-3201-9e4e-0000-00012052a2b5
14:48:48.420515 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 1 at position 37 unexpected 'to'.
14:48:48.420893 [debug] [Thread-1  ]: finished collecting timing info
14:48:48.421128 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
14:48:48.694548 [debug] [Thread-1  ]: Database Error in model incremental_time (models/example/incremental_time.sql)
  001003 (42000): SQL compilation error:
  syntax error line 1 at position 37 unexpected 'to'.
  compiled SQL at target/run/learn_dbt/models/example/incremental_time.sql
14:48:48.695165 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1cb406b0-e717-49ff-82ee-b9b0bd50b72e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a15a1f0>]}
14:48:48.695649 [error] [Thread-1  ]: 2 of 7 ERROR creating incremental model dbt.incremental_time.................... [[31mERROR[0m in 4.02s]
14:48:48.696402 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
14:48:48.696697 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
14:48:48.697040 [info ] [Thread-1  ]: 3 of 7 START view model dbt.first_model......................................... [RUN]
14:48:48.697998 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
14:48:48.698274 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
14:48:48.698515 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
14:48:48.703604 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
14:48:48.704407 [debug] [Thread-1  ]: finished collecting timing info
14:48:48.704603 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
14:48:48.722173 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
14:48:48.723007 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
14:48:48.723134 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */

  create or replace  view analytics.dbt.first_model 
  
   as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id

)

select * 
from source_data


/*
select *, True as first_variable
from source_data
where id >= 1
*/
  );
14:48:48.723236 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:48:49.740759 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.02 seconds
14:48:49.748752 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
14:48:49.749088 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */

        grant select on all views in schema  to role analyst
14:48:49.875346 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a44e78-3201-9e4e-0000-00012052a2bd
14:48:49.875963 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 1 at position 37 unexpected 'to'.
14:48:49.876341 [debug] [Thread-1  ]: finished collecting timing info
14:48:49.877154 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
14:48:50.055609 [debug] [Thread-1  ]: Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  001003 (42000): SQL compilation error:
  syntax error line 1 at position 37 unexpected 'to'.
  compiled SQL at target/run/learn_dbt/models/example/my_first_dbt_model.sql
14:48:50.056312 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1cb406b0-e717-49ff-82ee-b9b0bd50b72e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a0bc670>]}
14:48:50.056786 [error] [Thread-1  ]: 3 of 7 ERROR creating view model dbt.first_model................................ [[31mERROR[0m in 1.36s]
14:48:50.057161 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
14:48:50.057354 [debug] [Thread-1  ]: Began running node model.learn_dbt.playing_with_tests
14:48:50.057746 [info ] [Thread-1  ]: 4 of 7 START table model dbt.playing_with_tests................................. [RUN]
14:48:50.058385 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.playing_with_tests"
14:48:50.058615 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.playing_with_tests
14:48:50.058810 [debug] [Thread-1  ]: Compiling model.learn_dbt.playing_with_tests
14:48:50.060267 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.playing_with_tests"
14:48:50.061002 [debug] [Thread-1  ]: finished collecting timing info
14:48:50.061180 [debug] [Thread-1  ]: Began executing node model.learn_dbt.playing_with_tests
14:48:50.071364 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.playing_with_tests"
14:48:50.072396 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
14:48:50.072563 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */


      create or replace transient table analytics.dbt.playing_with_tests  as
      (select * 
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER"
      );
14:48:50.072696 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:48:52.907233 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.83 seconds
14:48:52.915313 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
14:48:52.915628 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */

        grant select on all views in schema  to role analyst
14:48:53.032392 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a44e78-3201-9e2f-0000-00012052b151
14:48:53.032766 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 1 at position 37 unexpected 'to'.
14:48:53.033131 [debug] [Thread-1  ]: finished collecting timing info
14:48:53.033388 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: Close
14:48:53.238583 [debug] [Thread-1  ]: Database Error in model playing_with_tests (models/example/playing_with_tests.sql)
  001003 (42000): SQL compilation error:
  syntax error line 1 at position 37 unexpected 'to'.
  compiled SQL at target/run/learn_dbt/models/example/playing_with_tests.sql
14:48:53.239115 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1cb406b0-e717-49ff-82ee-b9b0bd50b72e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a24bf10>]}
14:48:53.239574 [error] [Thread-1  ]: 4 of 7 ERROR creating table model dbt.playing_with_tests........................ [[31mERROR[0m in 3.18s]
14:48:53.239983 [debug] [Thread-1  ]: Finished running node model.learn_dbt.playing_with_tests
14:48:53.240223 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
14:48:53.240750 [info ] [Thread-1  ]: 5 of 7 START table model dbt.snowflake_cumulative_sales......................... [RUN]
14:48:53.241576 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
14:48:53.241799 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
14:48:53.242008 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
14:48:53.243692 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
14:48:53.244552 [debug] [Thread-1  ]: finished collecting timing info
14:48:53.244726 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
14:48:53.247330 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
14:48:53.248581 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
14:48:53.248752 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
14:48:53.248886 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:48:55.096950 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.85 seconds
14:48:55.100767 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
14:48:55.101036 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */

        grant select on all views in schema  to role analyst
14:48:55.201392 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a44e78-3201-9e2f-0000-00012052b155
14:48:55.203871 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 1 at position 37 unexpected 'to'.
14:48:55.204609 [debug] [Thread-1  ]: finished collecting timing info
14:48:55.204875 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
14:48:55.393945 [debug] [Thread-1  ]: Database Error in model snowflake_cumulative_sales (models/example/snowflake_cumulative_sales.sql)
  001003 (42000): SQL compilation error:
  syntax error line 1 at position 37 unexpected 'to'.
  compiled SQL at target/run/learn_dbt/models/example/snowflake_cumulative_sales.sql
14:48:55.395021 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1cb406b0-e717-49ff-82ee-b9b0bd50b72e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a0cdd60>]}
14:48:55.395614 [error] [Thread-1  ]: 5 of 7 ERROR creating table model dbt.snowflake_cumulative_sales................ [[31mERROR[0m in 2.15s]
14:48:55.396076 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
14:48:55.396328 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
14:48:55.396822 [info ] [Thread-1  ]: 6 of 7 START table model dbt.snowflake_customer_purchases....................... [RUN]
14:48:55.397526 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
14:48:55.397758 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
14:48:55.397974 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
14:48:55.399940 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
14:48:55.400746 [debug] [Thread-1  ]: finished collecting timing info
14:48:55.400962 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
14:48:55.404008 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
14:48:55.405403 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
14:48:55.405594 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
14:48:55.405747 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:48:57.297753 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.89 seconds
14:48:57.302763 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
14:48:57.303067 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */

        grant select on all views in schema  to role analyst
14:48:57.429091 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a44e78-3201-9e4e-0000-00012052a2c9
14:48:57.429937 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 1 at position 37 unexpected 'to'.
14:48:57.430622 [debug] [Thread-1  ]: finished collecting timing info
14:48:57.430968 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
14:48:57.737055 [debug] [Thread-1  ]: Database Error in model snowflake_customer_purchases (models/example/snowflake_customer_purchases.sql)
  001003 (42000): SQL compilation error:
  syntax error line 1 at position 37 unexpected 'to'.
  compiled SQL at target/run/learn_dbt/models/example/snowflake_customer_purchases.sql
14:48:57.737745 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1cb406b0-e717-49ff-82ee-b9b0bd50b72e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108241c40>]}
14:48:57.738431 [error] [Thread-1  ]: 6 of 7 ERROR creating table model dbt.snowflake_customer_purchases.............. [[31mERROR[0m in 2.34s]
14:48:57.738845 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
14:48:57.739160 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
14:48:57.739464 [info ] [Thread-1  ]: 7 of 7 SKIP relation dbt.my_second_dbt_model.................................... [[33mSKIP[0m]
14:48:57.740351 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
14:48:57.741562 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:48:57.742049 [info ] [MainThread]: 
14:48:57.742349 [info ] [MainThread]: Finished running 2 incremental models, 1 view model, 4 table models in 19.07s.
14:48:57.742613 [debug] [MainThread]: Connection 'master' was properly closed.
14:48:57.742758 [debug] [MainThread]: Connection 'model.learn_dbt.snowflake_customer_purchases' was properly closed.
14:48:57.750454 [info ] [MainThread]: 
14:48:57.750805 [info ] [MainThread]: [31mCompleted with 5 errors and 0 warnings:[0m
14:48:57.751092 [info ] [MainThread]: 
14:48:57.751323 [error] [MainThread]: [33mDatabase Error in model incremental_time (models/example/incremental_time.sql)[0m
14:48:57.751541 [error] [MainThread]:   001003 (42000): SQL compilation error:
14:48:57.751731 [error] [MainThread]:   syntax error line 1 at position 37 unexpected 'to'.
14:48:57.751917 [error] [MainThread]:   compiled SQL at target/run/learn_dbt/models/example/incremental_time.sql
14:48:57.752106 [info ] [MainThread]: 
14:48:57.752296 [error] [MainThread]: [33mDatabase Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)[0m
14:48:57.752474 [error] [MainThread]:   001003 (42000): SQL compilation error:
14:48:57.752654 [error] [MainThread]:   syntax error line 1 at position 37 unexpected 'to'.
14:48:57.752832 [error] [MainThread]:   compiled SQL at target/run/learn_dbt/models/example/my_first_dbt_model.sql
14:48:57.753014 [info ] [MainThread]: 
14:48:57.753202 [error] [MainThread]: [33mDatabase Error in model playing_with_tests (models/example/playing_with_tests.sql)[0m
14:48:57.753383 [error] [MainThread]:   001003 (42000): SQL compilation error:
14:48:57.753559 [error] [MainThread]:   syntax error line 1 at position 37 unexpected 'to'.
14:48:57.753735 [error] [MainThread]:   compiled SQL at target/run/learn_dbt/models/example/playing_with_tests.sql
14:48:57.753917 [info ] [MainThread]: 
14:48:57.754099 [error] [MainThread]: [33mDatabase Error in model snowflake_cumulative_sales (models/example/snowflake_cumulative_sales.sql)[0m
14:48:57.754280 [error] [MainThread]:   001003 (42000): SQL compilation error:
14:48:57.754458 [error] [MainThread]:   syntax error line 1 at position 37 unexpected 'to'.
14:48:57.754634 [error] [MainThread]:   compiled SQL at target/run/learn_dbt/models/example/snowflake_cumulative_sales.sql
14:48:57.754814 [info ] [MainThread]: 
14:48:57.754993 [error] [MainThread]: [33mDatabase Error in model snowflake_customer_purchases (models/example/snowflake_customer_purchases.sql)[0m
14:48:57.755176 [error] [MainThread]:   001003 (42000): SQL compilation error:
14:48:57.755351 [error] [MainThread]:   syntax error line 1 at position 37 unexpected 'to'.
14:48:57.755526 [error] [MainThread]:   compiled SQL at target/run/learn_dbt/models/example/snowflake_customer_purchases.sql
14:48:57.755716 [info ] [MainThread]: 
14:48:57.755900 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=5 SKIP=1 TOTAL=7
14:48:57.756175 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1058a9fa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106dca190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a27fa30>]}


============================== 2022-05-16 14:49:57.554990 | 028b74bb-5435-40dd-8cca-3f99c4162237 ==============================
14:49:57.554990 [info ] [MainThread]: Running with dbt=1.0.1
14:49:57.555515 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
14:49:57.555639 [debug] [MainThread]: Tracking: tracking
14:49:57.555896 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120033af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120033760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120033b20>]}
14:49:57.590083 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
14:49:57.590317 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '028b74bb-5435-40dd-8cca-3f99c4162237', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12002ca90>]}
14:49:57.604313 [debug] [MainThread]: Parsing macros/catalog.sql
14:49:57.605459 [debug] [MainThread]: Parsing macros/adapters.sql
14:49:57.625379 [debug] [MainThread]: Parsing macros/materializations/merge.sql
14:49:57.627236 [debug] [MainThread]: Parsing macros/materializations/seed.sql
14:49:57.629625 [debug] [MainThread]: Parsing macros/materializations/view.sql
14:49:57.630216 [debug] [MainThread]: Parsing macros/materializations/table.sql
14:49:57.631694 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
14:49:57.636115 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
14:49:57.636686 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
14:49:57.638436 [debug] [MainThread]: Parsing macros/materializations/configs.sql
14:49:57.639476 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
14:49:57.640232 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
14:49:57.648478 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
14:49:57.654301 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
14:49:57.660162 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
14:49:57.662244 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
14:49:57.663055 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
14:49:57.663855 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
14:49:57.665838 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
14:49:57.671507 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
14:49:57.672322 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
14:49:57.677149 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
14:49:57.684830 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
14:49:57.688461 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
14:49:57.689821 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
14:49:57.693305 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
14:49:57.693891 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
14:49:57.695113 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
14:49:57.696105 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
14:49:57.698885 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
14:49:57.706906 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
14:49:57.707601 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
14:49:57.708723 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
14:49:57.709413 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
14:49:57.709814 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
14:49:57.710055 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
14:49:57.710358 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
14:49:57.710977 [debug] [MainThread]: Parsing macros/etc/statement.sql
14:49:57.712983 [debug] [MainThread]: Parsing macros/etc/datetime.sql
14:49:57.717051 [debug] [MainThread]: Parsing macros/adapters/schema.sql
14:49:57.718023 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
14:49:57.719195 [debug] [MainThread]: Parsing macros/adapters/relation.sql
14:49:57.723904 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
14:49:57.725195 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
14:49:57.727143 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
14:49:57.730447 [debug] [MainThread]: Parsing macros/adapters/columns.sql
14:49:57.735039 [debug] [MainThread]: Parsing tests/generic/builtin.sql
14:49:57.825657 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
14:49:57.832277 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
14:49:57.832989 [debug] [MainThread]: 1699: static parser successfully parsed example/playing_with_tests.sql
14:49:57.834076 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_cumulative_sales.sql
14:49:57.835112 [debug] [MainThread]: 1603: static parser failed on example/my_second_dbt_model.sql
14:49:57.836878 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_second_dbt_model.sql
14:49:57.837335 [debug] [MainThread]: 1603: static parser failed on example/incremental_time.sql
14:49:57.840945 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_time.sql
14:49:57.841440 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
14:49:57.842406 [debug] [MainThread]: 1603: static parser failed on new/dates.sql
14:49:57.844108 [debug] [MainThread]: 1602: parser fallback to jinja rendering on new/dates.sql
14:49:57.891054 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '028b74bb-5435-40dd-8cca-3f99c4162237', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120017e50>]}
14:49:57.894280 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '028b74bb-5435-40dd-8cca-3f99c4162237', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120142910>]}
14:49:57.894406 [info ] [MainThread]: Found 7 models, 12 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
14:49:57.895189 [info ] [MainThread]: 
14:49:57.895391 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:49:57.895825 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
14:49:57.901583 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
14:49:57.901678 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
14:49:57.901739 [debug] [ThreadPool]: Opening a new connection, currently in state init
14:49:58.699906 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.8 seconds
14:49:58.702507 [debug] [ThreadPool]: On list_analytics: Close
14:49:58.950180 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
14:49:58.959046 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
14:49:58.959353 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
14:49:58.959517 [debug] [ThreadPool]: Opening a new connection, currently in state closed
14:49:59.599970 [debug] [ThreadPool]: SQL status: SUCCESS 7 in 0.64 seconds
14:49:59.602452 [debug] [ThreadPool]: On list_analytics_dbt: Close
14:49:59.806597 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
14:49:59.807885 [info ] [MainThread]: 
14:49:59.814129 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
14:49:59.815036 [info ] [Thread-1  ]: 1 of 7 START incremental model dbt.dates........................................ [RUN]
14:49:59.815577 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
14:49:59.815752 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
14:49:59.815923 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
14:49:59.821540 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
14:49:59.822137 [debug] [Thread-1  ]: finished collecting timing info
14:49:59.822291 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
14:49:59.853644 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
14:49:59.853807 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
14:49:59.853896 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:50:01.923268 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.07 seconds
14:50:01.936287 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
14:50:01.936604 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
14:50:02.089321 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.15 seconds
14:50:02.096695 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
14:50:02.097075 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
14:50:02.195690 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.1 seconds
14:50:02.208729 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
14:50:02.209136 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
14:50:02.363853 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.15 seconds
14:50:02.391706 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
14:50:02.394199 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
14:50:02.394393 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
14:50:02.555842 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.16 seconds
14:50:02.556655 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
14:50:02.556861 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
14:50:03.288044 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.73 seconds
14:50:03.288600 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
14:50:03.288787 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
14:50:03.519346 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.23 seconds
14:50:03.535245 [debug] [Thread-1  ]: finished collecting timing info
14:50:03.535562 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
14:50:03.796459 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '028b74bb-5435-40dd-8cca-3f99c4162237', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12013c400>]}
14:50:03.797331 [info ] [Thread-1  ]: 1 of 7 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 3.98s]
14:50:03.797809 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
14:50:03.798060 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
14:50:03.798551 [info ] [Thread-1  ]: 2 of 7 START incremental model dbt.incremental_time............................. [RUN]
14:50:03.799322 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
14:50:03.799536 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
14:50:03.799750 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
14:50:03.803480 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
14:50:03.804055 [debug] [Thread-1  ]: finished collecting timing info
14:50:03.804218 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
14:50:03.807668 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:50:03.807821 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
14:50:03.807950 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:50:05.507395 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.7 seconds
14:50:05.513437 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:50:05.513860 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
14:50:05.652495 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.14 seconds
14:50:05.658969 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:50:05.659378 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
14:50:05.890381 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.23 seconds
14:50:05.898041 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:50:05.898393 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
14:50:05.996895 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
14:50:06.002426 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
14:50:06.004739 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:50:06.005029 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
14:50:06.127016 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.12 seconds
14:50:06.127645 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:50:06.127827 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
14:50:06.939182 [debug] [Thread-1  ]: SQL status: SUCCESS 79 in 0.81 seconds
14:50:06.940091 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:50:06.940482 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
14:50:07.219169 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.28 seconds
14:50:07.223823 [debug] [Thread-1  ]: finished collecting timing info
14:50:07.224355 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
14:50:07.505305 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '028b74bb-5435-40dd-8cca-3f99c4162237', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12270ea30>]}
14:50:07.506156 [info ] [Thread-1  ]: 2 of 7 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 3.71s]
14:50:07.506612 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
14:50:07.506855 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
14:50:07.507273 [info ] [Thread-1  ]: 3 of 7 START view model dbt.first_model......................................... [RUN]
14:50:07.507986 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
14:50:07.508206 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
14:50:07.508404 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
14:50:07.512182 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
14:50:07.513136 [debug] [Thread-1  ]: finished collecting timing info
14:50:07.513321 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
14:50:07.530816 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
14:50:07.531846 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
14:50:07.531969 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */

  create or replace  view analytics.dbt.first_model 
  
   as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id

)

select * 
from source_data


/*
select *, True as first_variable
from source_data
where id >= 1
*/
  );
14:50:07.532068 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:50:08.200291 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.67 seconds
14:50:08.202952 [debug] [Thread-1  ]: finished collecting timing info
14:50:08.203198 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
14:50:08.384633 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '028b74bb-5435-40dd-8cca-3f99c4162237', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12278fc10>]}
14:50:08.385346 [info ] [Thread-1  ]: 3 of 7 OK created view model dbt.first_model.................................... [[32mSUCCESS 1[0m in 0.88s]
14:50:08.385775 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
14:50:08.386014 [debug] [Thread-1  ]: Began running node model.learn_dbt.playing_with_tests
14:50:08.386498 [info ] [Thread-1  ]: 4 of 7 START table model dbt.playing_with_tests................................. [RUN]
14:50:08.387469 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.playing_with_tests"
14:50:08.387710 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.playing_with_tests
14:50:08.387896 [debug] [Thread-1  ]: Compiling model.learn_dbt.playing_with_tests
14:50:08.389361 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.playing_with_tests"
14:50:08.389978 [debug] [Thread-1  ]: finished collecting timing info
14:50:08.390163 [debug] [Thread-1  ]: Began executing node model.learn_dbt.playing_with_tests
14:50:08.400010 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.playing_with_tests"
14:50:08.401199 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
14:50:08.401472 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */


      create or replace transient table analytics.dbt.playing_with_tests  as
      (select * 
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER"
      );
14:50:08.401622 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:50:10.321378 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.92 seconds
14:50:10.324131 [debug] [Thread-1  ]: finished collecting timing info
14:50:10.324506 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: Close
14:50:10.577298 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '028b74bb-5435-40dd-8cca-3f99c4162237', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122785dc0>]}
14:50:10.577951 [info ] [Thread-1  ]: 4 of 7 OK created table model dbt.playing_with_tests............................ [[32mSUCCESS 1[0m in 2.19s]
14:50:10.578224 [debug] [Thread-1  ]: Finished running node model.learn_dbt.playing_with_tests
14:50:10.578336 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
14:50:10.578522 [info ] [Thread-1  ]: 5 of 7 START table model dbt.snowflake_cumulative_sales......................... [RUN]
14:50:10.578799 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
14:50:10.578888 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
14:50:10.578970 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
14:50:10.579725 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
14:50:10.580380 [debug] [Thread-1  ]: finished collecting timing info
14:50:10.580581 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
14:50:10.583217 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
14:50:10.584263 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
14:50:10.584436 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
14:50:10.584579 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:50:12.251947 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.67 seconds
14:50:12.255578 [debug] [Thread-1  ]: finished collecting timing info
14:50:12.256060 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
14:50:12.914715 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '028b74bb-5435-40dd-8cca-3f99c4162237', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12272cb80>]}
14:50:12.915565 [info ] [Thread-1  ]: 5 of 7 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 2.34s]
14:50:12.916057 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
14:50:12.916319 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
14:50:12.917014 [info ] [Thread-1  ]: 6 of 7 START table model dbt.snowflake_customer_purchases....................... [RUN]
14:50:12.917815 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
14:50:12.918158 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
14:50:12.918459 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
14:50:12.920231 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
14:50:12.920956 [debug] [Thread-1  ]: finished collecting timing info
14:50:12.921133 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
14:50:12.923542 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
14:50:12.924635 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
14:50:12.924793 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
14:50:12.924934 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:50:15.047444 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.12 seconds
14:50:15.049009 [debug] [Thread-1  ]: finished collecting timing info
14:50:15.049181 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
14:50:15.328168 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '028b74bb-5435-40dd-8cca-3f99c4162237', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1207c5160>]}
14:50:15.329011 [info ] [Thread-1  ]: 6 of 7 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.41s]
14:50:15.329496 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
14:50:15.329739 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
14:50:15.330156 [info ] [Thread-1  ]: 7 of 7 START table model dbt.my_second_dbt_model................................ [RUN]
14:50:15.330702 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
14:50:15.330843 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
14:50:15.330983 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
14:50:15.333666 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
14:50:15.336111 [debug] [Thread-1  ]: finished collecting timing info
14:50:15.336395 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
14:50:15.368768 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
14:50:15.369619 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
14:50:15.369728 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
/*
union all
select 7 as id, True as first_variable
*/
      );
14:50:15.369819 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:50:16.379179 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.01 seconds
14:50:16.381470 [debug] [Thread-1  ]: finished collecting timing info
14:50:16.381720 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
14:50:16.549277 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '028b74bb-5435-40dd-8cca-3f99c4162237', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12276c400>]}
14:50:16.550420 [info ] [Thread-1  ]: 7 of 7 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.22s]
14:50:16.550941 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
14:50:16.552681 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:50:16.553302 [info ] [MainThread]: 
14:50:16.553613 [info ] [MainThread]: Finished running 2 incremental models, 1 view model, 4 table models in 18.66s.
14:50:16.553868 [debug] [MainThread]: Connection 'master' was properly closed.
14:50:16.554009 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
14:50:16.560766 [info ] [MainThread]: 
14:50:16.561079 [info ] [MainThread]: [32mCompleted successfully[0m
14:50:16.561348 [info ] [MainThread]: 
14:50:16.561542 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
14:50:16.561833 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12013cd00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12013e2e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122740e80>]}


============================== 2022-05-16 14:50:40.657616 | 39ddb7bb-0bb0-49df-b912-9de4cd67bb4c ==============================
14:50:40.657616 [info ] [MainThread]: Running with dbt=1.0.1
14:50:40.658265 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
14:50:40.658482 [debug] [MainThread]: Tracking: tracking
14:50:40.658721 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110773e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1107738e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110773a00>]}
14:50:40.693619 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
14:50:40.693862 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '39ddb7bb-0bb0-49df-b912-9de4cd67bb4c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11077a550>]}
14:50:40.708411 [debug] [MainThread]: Parsing macros/catalog.sql
14:50:40.709592 [debug] [MainThread]: Parsing macros/adapters.sql
14:50:40.729680 [debug] [MainThread]: Parsing macros/materializations/merge.sql
14:50:40.731564 [debug] [MainThread]: Parsing macros/materializations/seed.sql
14:50:40.734017 [debug] [MainThread]: Parsing macros/materializations/view.sql
14:50:40.734611 [debug] [MainThread]: Parsing macros/materializations/table.sql
14:50:40.736022 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
14:50:40.740292 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
14:50:40.740791 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
14:50:40.742560 [debug] [MainThread]: Parsing macros/materializations/configs.sql
14:50:40.743615 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
14:50:40.744376 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
14:50:40.752496 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
14:50:40.758247 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
14:50:40.764099 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
14:50:40.766156 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
14:50:40.766958 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
14:50:40.767752 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
14:50:40.769723 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
14:50:40.775245 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
14:50:40.775959 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
14:50:40.780842 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
14:50:40.788606 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
14:50:40.792409 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
14:50:40.793738 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
14:50:40.797271 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
14:50:40.797850 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
14:50:40.799084 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
14:50:40.800124 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
14:50:40.802901 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
14:50:40.810935 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
14:50:40.811624 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
14:50:40.812726 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
14:50:40.813429 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
14:50:40.813842 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
14:50:40.814079 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
14:50:40.814377 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
14:50:40.814978 [debug] [MainThread]: Parsing macros/etc/statement.sql
14:50:40.816992 [debug] [MainThread]: Parsing macros/etc/datetime.sql
14:50:40.821279 [debug] [MainThread]: Parsing macros/adapters/schema.sql
14:50:40.822329 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
14:50:40.823510 [debug] [MainThread]: Parsing macros/adapters/relation.sql
14:50:40.828284 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
14:50:40.829749 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
14:50:40.831822 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
14:50:40.835177 [debug] [MainThread]: Parsing macros/adapters/columns.sql
14:50:40.839714 [debug] [MainThread]: Parsing tests/generic/builtin.sql
14:50:40.930280 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
14:50:40.937697 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
14:50:40.938402 [debug] [MainThread]: 1699: static parser successfully parsed example/playing_with_tests.sql
14:50:40.940574 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_cumulative_sales.sql
14:50:40.942458 [debug] [MainThread]: 1603: static parser failed on example/my_second_dbt_model.sql
14:50:40.944281 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_second_dbt_model.sql
14:50:40.944811 [debug] [MainThread]: 1603: static parser failed on example/incremental_time.sql
14:50:40.948437 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_time.sql
14:50:40.948973 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
14:50:40.950959 [debug] [MainThread]: 1603: static parser failed on new/dates.sql
14:50:40.953111 [debug] [MainThread]: 1602: parser fallback to jinja rendering on new/dates.sql
14:50:41.000440 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '39ddb7bb-0bb0-49df-b912-9de4cd67bb4c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110911f10>]}
14:50:41.003796 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '39ddb7bb-0bb0-49df-b912-9de4cd67bb4c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110911e20>]}
14:50:41.003934 [info ] [MainThread]: Found 7 models, 12 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
14:50:41.004717 [info ] [MainThread]: 
14:50:41.004941 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:50:41.005524 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
14:50:41.011540 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
14:50:41.011651 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
14:50:41.011717 [debug] [ThreadPool]: Opening a new connection, currently in state init
14:50:41.938683 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.93 seconds
14:50:41.939612 [debug] [ThreadPool]: On list_analytics: Close
14:50:42.102159 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
14:50:42.111405 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
14:50:42.111733 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
14:50:42.111876 [debug] [ThreadPool]: Opening a new connection, currently in state closed
14:50:42.982971 [debug] [ThreadPool]: SQL status: SUCCESS 7 in 0.87 seconds
14:50:42.987197 [debug] [ThreadPool]: On list_analytics_dbt: Close
14:50:43.220852 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
14:50:43.221436 [info ] [MainThread]: 
14:50:43.226858 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
14:50:43.227734 [info ] [Thread-1  ]: 1 of 7 START incremental model dbt.dates........................................ [RUN]
14:50:43.228319 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
14:50:43.228501 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
14:50:43.228685 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
14:50:43.234789 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
14:50:43.235402 [debug] [Thread-1  ]: finished collecting timing info
14:50:43.235564 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
14:50:43.265630 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
14:50:43.265832 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
14:50:43.265920 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:50:44.352434 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.09 seconds
14:50:44.365855 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
14:50:44.366172 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
14:50:44.498417 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.13 seconds
14:50:44.507581 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
14:50:44.507963 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
14:50:44.689195 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.18 seconds
14:50:44.701050 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
14:50:44.701326 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
14:50:44.802741 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.1 seconds
14:50:44.827421 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
14:50:44.829732 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
14:50:44.829863 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
14:50:44.969735 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.14 seconds
14:50:44.971144 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
14:50:44.971382 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
14:50:45.307337 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.34 seconds
14:50:45.307910 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
14:50:45.308185 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
14:50:45.506198 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.2 seconds
14:50:45.520345 [debug] [Thread-1  ]: finished collecting timing info
14:50:45.520801 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
14:50:46.301934 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '39ddb7bb-0bb0-49df-b912-9de4cd67bb4c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1107ea610>]}
14:50:46.302599 [info ] [Thread-1  ]: 1 of 7 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 3.07s]
14:50:46.303047 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
14:50:46.303259 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
14:50:46.303688 [info ] [Thread-1  ]: 2 of 7 START incremental model dbt.incremental_time............................. [RUN]
14:50:46.304356 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
14:50:46.304538 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
14:50:46.304722 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
14:50:46.308110 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
14:50:46.308945 [debug] [Thread-1  ]: finished collecting timing info
14:50:46.309127 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
14:50:46.312874 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:50:46.313052 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
14:50:46.313187 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:50:47.959818 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.65 seconds
14:50:47.965704 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:50:47.984560 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
14:50:48.113504 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.13 seconds
14:50:48.118740 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:50:48.119143 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
14:50:48.232090 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.11 seconds
14:50:48.238199 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:50:48.238538 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
14:50:48.360546 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.12 seconds
14:50:48.365976 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
14:50:48.368635 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:50:48.368972 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
14:50:48.554406 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.19 seconds
14:50:48.555606 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:50:48.556005 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
14:50:50.460691 [debug] [Thread-1  ]: SQL status: SUCCESS 42 in 1.9 seconds
14:50:50.461824 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:50:50.462072 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
14:50:51.027455 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.57 seconds
14:50:51.032314 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:50:51.032621 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

        grant usage on schema  to role analyst
14:50:51.157791 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a44e7a-3201-9e2f-0000-00012052b1a9
14:50:51.158207 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 002003 (42S02): SQL compilation error:
Table 'SCHEMA' does not exist or not authorized.
14:50:51.158573 [debug] [Thread-1  ]: finished collecting timing info
14:50:51.158808 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
14:50:51.619284 [debug] [Thread-1  ]: Database Error in model incremental_time (models/example/incremental_time.sql)
  002003 (42S02): SQL compilation error:
  Table 'SCHEMA' does not exist or not authorized.
  compiled SQL at target/run/learn_dbt/models/example/incremental_time.sql
14:50:51.619915 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '39ddb7bb-0bb0-49df-b912-9de4cd67bb4c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110b63520>]}
14:50:51.620454 [error] [Thread-1  ]: 2 of 7 ERROR creating incremental model dbt.incremental_time.................... [[31mERROR[0m in 5.32s]
14:50:51.620900 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
14:50:51.621137 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
14:50:51.621407 [info ] [Thread-1  ]: 3 of 7 START view model dbt.first_model......................................... [RUN]
14:50:51.622361 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
14:50:51.622638 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
14:50:51.622850 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
14:50:51.626782 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
14:50:51.627522 [debug] [Thread-1  ]: finished collecting timing info
14:50:51.627713 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
14:50:51.646452 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
14:50:51.647425 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
14:50:51.647552 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */

  create or replace  view analytics.dbt.first_model 
  
   as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id

)

select * 
from source_data


/*
select *, True as first_variable
from source_data
where id >= 1
*/
  );
14:50:51.647656 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:50:52.647076 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.0 seconds
14:50:52.649442 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
14:50:52.649661 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */

        grant usage on schema  to role analyst
14:50:53.073960 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a44e7a-3201-9e4e-0000-00012052a315
14:50:53.074696 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 002003 (42S02): SQL compilation error:
Table 'SCHEMA' does not exist or not authorized.
14:50:53.075057 [debug] [Thread-1  ]: finished collecting timing info
14:50:53.075287 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
14:50:53.268831 [debug] [Thread-1  ]: Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  002003 (42S02): SQL compilation error:
  Table 'SCHEMA' does not exist or not authorized.
  compiled SQL at target/run/learn_dbt/models/example/my_first_dbt_model.sql
14:50:53.269489 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '39ddb7bb-0bb0-49df-b912-9de4cd67bb4c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112ca03d0>]}
14:50:53.270149 [error] [Thread-1  ]: 3 of 7 ERROR creating view model dbt.first_model................................ [[31mERROR[0m in 1.65s]
14:50:53.270731 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
14:50:53.270992 [debug] [Thread-1  ]: Began running node model.learn_dbt.playing_with_tests
14:50:53.271615 [info ] [Thread-1  ]: 4 of 7 START table model dbt.playing_with_tests................................. [RUN]
14:50:53.272340 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.playing_with_tests"
14:50:53.272559 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.playing_with_tests
14:50:53.272750 [debug] [Thread-1  ]: Compiling model.learn_dbt.playing_with_tests
14:50:53.274556 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.playing_with_tests"
14:50:53.275372 [debug] [Thread-1  ]: finished collecting timing info
14:50:53.275579 [debug] [Thread-1  ]: Began executing node model.learn_dbt.playing_with_tests
14:50:53.285752 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.playing_with_tests"
14:50:53.286777 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
14:50:53.286939 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */


      create or replace transient table analytics.dbt.playing_with_tests  as
      (select * 
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER"
      );
14:50:53.287067 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:50:55.580930 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.29 seconds
14:50:55.585484 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
14:50:55.585723 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */

        grant usage on schema  to role analyst
14:50:55.707557 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a44e7a-3201-9e4e-0000-00012052a319
14:50:55.708041 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 002003 (42S02): SQL compilation error:
Table 'SCHEMA' does not exist or not authorized.
14:50:55.708455 [debug] [Thread-1  ]: finished collecting timing info
14:50:55.708708 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: Close
14:50:55.873957 [debug] [Thread-1  ]: Database Error in model playing_with_tests (models/example/playing_with_tests.sql)
  002003 (42S02): SQL compilation error:
  Table 'SCHEMA' does not exist or not authorized.
  compiled SQL at target/run/learn_dbt/models/example/playing_with_tests.sql
14:50:55.875094 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '39ddb7bb-0bb0-49df-b912-9de4cd67bb4c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112d927c0>]}
14:50:55.875752 [error] [Thread-1  ]: 4 of 7 ERROR creating table model dbt.playing_with_tests........................ [[31mERROR[0m in 2.60s]
14:50:55.876341 [debug] [Thread-1  ]: Finished running node model.learn_dbt.playing_with_tests
14:50:55.876601 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
14:50:55.877218 [info ] [Thread-1  ]: 5 of 7 START table model dbt.snowflake_cumulative_sales......................... [RUN]
14:50:55.878006 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
14:50:55.878234 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
14:50:55.878450 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
14:50:55.880032 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
14:50:55.880605 [debug] [Thread-1  ]: finished collecting timing info
14:50:55.880777 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
14:50:55.883402 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
14:50:55.884453 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
14:50:55.884622 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
14:50:55.884774 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:50:57.269881 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.39 seconds
14:50:57.272948 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
14:50:57.273223 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */

        grant usage on schema  to role analyst
14:50:57.393806 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a44e7a-3201-9e4e-0000-00012052a321
14:50:57.394267 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 002003 (42S02): SQL compilation error:
Table 'SCHEMA' does not exist or not authorized.
14:50:57.394642 [debug] [Thread-1  ]: finished collecting timing info
14:50:57.394861 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
14:50:57.553237 [debug] [Thread-1  ]: Database Error in model snowflake_cumulative_sales (models/example/snowflake_cumulative_sales.sql)
  002003 (42S02): SQL compilation error:
  Table 'SCHEMA' does not exist or not authorized.
  compiled SQL at target/run/learn_dbt/models/example/snowflake_cumulative_sales.sql
14:50:57.554285 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '39ddb7bb-0bb0-49df-b912-9de4cd67bb4c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112d92730>]}
14:50:57.554927 [error] [Thread-1  ]: 5 of 7 ERROR creating table model dbt.snowflake_cumulative_sales................ [[31mERROR[0m in 1.68s]
14:50:57.555331 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
14:50:57.555905 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
14:50:57.556315 [info ] [Thread-1  ]: 6 of 7 START table model dbt.snowflake_customer_purchases....................... [RUN]
14:50:57.556958 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
14:50:57.557172 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
14:50:57.557534 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
14:50:57.559381 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
14:50:57.560210 [debug] [Thread-1  ]: finished collecting timing info
14:50:57.560429 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
14:50:57.563908 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
14:50:57.565423 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
14:50:57.565675 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
14:50:57.565925 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:50:58.982236 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.42 seconds
14:50:58.985254 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
14:50:58.985548 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */

        grant usage on schema  to role analyst
14:50:59.185212 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a44e7a-3201-9e4e-0000-00012052a329
14:50:59.185563 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 002003 (42S02): SQL compilation error:
Table 'SCHEMA' does not exist or not authorized.
14:50:59.185933 [debug] [Thread-1  ]: finished collecting timing info
14:50:59.186189 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
14:50:59.521918 [debug] [Thread-1  ]: Database Error in model snowflake_customer_purchases (models/example/snowflake_customer_purchases.sql)
  002003 (42S02): SQL compilation error:
  Table 'SCHEMA' does not exist or not authorized.
  compiled SQL at target/run/learn_dbt/models/example/snowflake_customer_purchases.sql
14:50:59.522566 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '39ddb7bb-0bb0-49df-b912-9de4cd67bb4c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112c87d60>]}
14:50:59.522977 [error] [Thread-1  ]: 6 of 7 ERROR creating table model dbt.snowflake_customer_purchases.............. [[31mERROR[0m in 1.97s]
14:50:59.523311 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
14:50:59.523494 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
14:50:59.523794 [info ] [Thread-1  ]: 7 of 7 SKIP relation dbt.my_second_dbt_model.................................... [[33mSKIP[0m]
14:50:59.524139 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
14:50:59.525272 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:50:59.525848 [info ] [MainThread]: 
14:50:59.526125 [info ] [MainThread]: Finished running 2 incremental models, 1 view model, 4 table models in 18.52s.
14:50:59.526350 [debug] [MainThread]: Connection 'master' was properly closed.
14:50:59.526465 [debug] [MainThread]: Connection 'model.learn_dbt.snowflake_customer_purchases' was properly closed.
14:50:59.532139 [info ] [MainThread]: 
14:50:59.532352 [info ] [MainThread]: [31mCompleted with 5 errors and 0 warnings:[0m
14:50:59.532534 [info ] [MainThread]: 
14:50:59.532685 [error] [MainThread]: [33mDatabase Error in model incremental_time (models/example/incremental_time.sql)[0m
14:50:59.532866 [error] [MainThread]:   002003 (42S02): SQL compilation error:
14:50:59.533048 [error] [MainThread]:   Table 'SCHEMA' does not exist or not authorized.
14:50:59.533235 [error] [MainThread]:   compiled SQL at target/run/learn_dbt/models/example/incremental_time.sql
14:50:59.533429 [info ] [MainThread]: 
14:50:59.533620 [error] [MainThread]: [33mDatabase Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)[0m
14:50:59.533807 [error] [MainThread]:   002003 (42S02): SQL compilation error:
14:50:59.533992 [error] [MainThread]:   Table 'SCHEMA' does not exist or not authorized.
14:50:59.534167 [error] [MainThread]:   compiled SQL at target/run/learn_dbt/models/example/my_first_dbt_model.sql
14:50:59.534349 [info ] [MainThread]: 
14:50:59.534531 [error] [MainThread]: [33mDatabase Error in model playing_with_tests (models/example/playing_with_tests.sql)[0m
14:50:59.534721 [error] [MainThread]:   002003 (42S02): SQL compilation error:
14:50:59.534906 [error] [MainThread]:   Table 'SCHEMA' does not exist or not authorized.
14:50:59.535086 [error] [MainThread]:   compiled SQL at target/run/learn_dbt/models/example/playing_with_tests.sql
14:50:59.535272 [info ] [MainThread]: 
14:50:59.535453 [error] [MainThread]: [33mDatabase Error in model snowflake_cumulative_sales (models/example/snowflake_cumulative_sales.sql)[0m
14:50:59.535634 [error] [MainThread]:   002003 (42S02): SQL compilation error:
14:50:59.535813 [error] [MainThread]:   Table 'SCHEMA' does not exist or not authorized.
14:50:59.535988 [error] [MainThread]:   compiled SQL at target/run/learn_dbt/models/example/snowflake_cumulative_sales.sql
14:50:59.536171 [info ] [MainThread]: 
14:50:59.536353 [error] [MainThread]: [33mDatabase Error in model snowflake_customer_purchases (models/example/snowflake_customer_purchases.sql)[0m
14:50:59.536533 [error] [MainThread]:   002003 (42S02): SQL compilation error:
14:50:59.536709 [error] [MainThread]:   Table 'SCHEMA' does not exist or not authorized.
14:50:59.536885 [error] [MainThread]:   compiled SQL at target/run/learn_dbt/models/example/snowflake_customer_purchases.sql
14:50:59.537093 [info ] [MainThread]: 
14:50:59.537279 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=5 SKIP=1 TOTAL=7
14:50:59.537550 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110ccf2e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110ccfe80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110cbd130>]}


============================== 2022-05-16 14:52:27.000748 | d055399c-5080-4392-a0d6-76bbc00da9e0 ==============================
14:52:27.000748 [info ] [MainThread]: Running with dbt=1.0.1
14:52:27.001449 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
14:52:27.001624 [debug] [MainThread]: Tracking: tracking
14:52:27.001892 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106183e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1061838e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106183eb0>]}
14:52:27.036540 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
14:52:27.036781 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'd055399c-5080-4392-a0d6-76bbc00da9e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10618a280>]}
14:52:27.051239 [debug] [MainThread]: Parsing macros/catalog.sql
14:52:27.052431 [debug] [MainThread]: Parsing macros/adapters.sql
14:52:27.072047 [debug] [MainThread]: Parsing macros/materializations/merge.sql
14:52:27.073985 [debug] [MainThread]: Parsing macros/materializations/seed.sql
14:52:27.076408 [debug] [MainThread]: Parsing macros/materializations/view.sql
14:52:27.077002 [debug] [MainThread]: Parsing macros/materializations/table.sql
14:52:27.078398 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
14:52:27.082372 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
14:52:27.082939 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
14:52:27.085106 [debug] [MainThread]: Parsing macros/materializations/configs.sql
14:52:27.086277 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
14:52:27.087040 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
14:52:27.095262 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
14:52:27.100865 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
14:52:27.106638 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
14:52:27.108671 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
14:52:27.109474 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
14:52:27.110264 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
14:52:27.112330 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
14:52:27.118050 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
14:52:27.118800 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
14:52:27.123864 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
14:52:27.131678 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
14:52:27.135332 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
14:52:27.136608 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
14:52:27.140184 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
14:52:27.140908 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
14:52:27.142225 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
14:52:27.143255 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
14:52:27.146045 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
14:52:27.153916 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
14:52:27.154576 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
14:52:27.155683 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
14:52:27.156405 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
14:52:27.156820 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
14:52:27.157062 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
14:52:27.157388 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
14:52:27.158031 [debug] [MainThread]: Parsing macros/etc/statement.sql
14:52:27.160033 [debug] [MainThread]: Parsing macros/etc/datetime.sql
14:52:27.163980 [debug] [MainThread]: Parsing macros/adapters/schema.sql
14:52:27.164911 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
14:52:27.166352 [debug] [MainThread]: Parsing macros/adapters/relation.sql
14:52:27.171131 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
14:52:27.172422 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
14:52:27.174373 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
14:52:27.178067 [debug] [MainThread]: Parsing macros/adapters/columns.sql
14:52:27.182798 [debug] [MainThread]: Parsing tests/generic/builtin.sql
14:52:27.276065 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
14:52:27.283104 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
14:52:27.283794 [debug] [MainThread]: 1699: static parser successfully parsed example/playing_with_tests.sql
14:52:27.285663 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_cumulative_sales.sql
14:52:27.287706 [debug] [MainThread]: 1603: static parser failed on example/my_second_dbt_model.sql
14:52:27.289823 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_second_dbt_model.sql
14:52:27.290383 [debug] [MainThread]: 1603: static parser failed on example/incremental_time.sql
14:52:27.294179 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_time.sql
14:52:27.294721 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
14:52:27.296461 [debug] [MainThread]: 1603: static parser failed on new/dates.sql
14:52:27.298551 [debug] [MainThread]: 1602: parser fallback to jinja rendering on new/dates.sql
14:52:27.346717 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd055399c-5080-4392-a0d6-76bbc00da9e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1061fcb20>]}
14:52:27.350027 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd055399c-5080-4392-a0d6-76bbc00da9e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1061fca30>]}
14:52:27.350160 [info ] [MainThread]: Found 7 models, 12 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
14:52:27.350933 [info ] [MainThread]: 
14:52:27.351147 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:52:27.351601 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
14:52:27.357767 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
14:52:27.357917 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
14:52:27.357987 [debug] [ThreadPool]: Opening a new connection, currently in state init
14:52:28.161728 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.8 seconds
14:52:28.165097 [debug] [ThreadPool]: On list_analytics: Close
14:52:28.364086 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
14:52:28.374788 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
14:52:28.375094 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
14:52:28.375269 [debug] [ThreadPool]: Opening a new connection, currently in state closed
14:52:28.911760 [debug] [ThreadPool]: SQL status: SUCCESS 7 in 0.54 seconds
14:52:28.915223 [debug] [ThreadPool]: On list_analytics_dbt: Close
14:52:29.084866 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
14:52:29.085414 [info ] [MainThread]: 
14:52:29.090157 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
14:52:29.090945 [info ] [Thread-1  ]: 1 of 7 START incremental model dbt.dates........................................ [RUN]
14:52:29.091510 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
14:52:29.091690 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
14:52:29.091854 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
14:52:29.097802 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
14:52:29.098856 [debug] [Thread-1  ]: finished collecting timing info
14:52:29.099084 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
14:52:29.130776 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
14:52:29.130986 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
14:52:29.131076 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:52:30.693407 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.56 seconds
14:52:30.702573 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
14:52:30.702823 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
14:52:30.854690 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.15 seconds
14:52:30.860062 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
14:52:30.860305 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
14:52:30.980873 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.12 seconds
14:52:30.992976 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
14:52:30.993326 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
14:52:31.088145 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.09 seconds
14:52:31.114534 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
14:52:31.117094 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
14:52:31.117223 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
14:52:31.243866 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.12 seconds
14:52:31.247519 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
14:52:31.247960 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
14:52:31.534886 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.29 seconds
14:52:31.535505 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
14:52:31.535705 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
14:52:31.682020 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.15 seconds
14:52:31.698182 [debug] [Thread-1  ]: finished collecting timing info
14:52:31.698687 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
14:52:31.926284 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd055399c-5080-4392-a0d6-76bbc00da9e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106679520>]}
14:52:31.927090 [info ] [Thread-1  ]: 1 of 7 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 2.83s]
14:52:31.927888 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
14:52:31.928344 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
14:52:31.928722 [info ] [Thread-1  ]: 2 of 7 START incremental model dbt.incremental_time............................. [RUN]
14:52:31.929373 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
14:52:31.929735 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
14:52:31.929945 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
14:52:31.934135 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
14:52:31.935909 [debug] [Thread-1  ]: finished collecting timing info
14:52:31.936190 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
14:52:31.940262 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:52:31.940480 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
14:52:31.940611 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:52:33.372494 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.43 seconds
14:52:33.377532 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:52:33.377872 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
14:52:33.489129 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.11 seconds
14:52:33.494420 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:52:33.494728 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
14:52:33.695907 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.2 seconds
14:52:33.700963 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:52:33.701354 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
14:52:33.809059 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.11 seconds
14:52:33.814209 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
14:52:33.816800 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:52:33.817009 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
14:52:33.936478 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.12 seconds
14:52:33.937589 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:52:33.938118 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
14:52:34.520488 [debug] [Thread-1  ]: SQL status: SUCCESS 106 in 0.58 seconds
14:52:34.520988 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:52:34.521169 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
14:52:34.805911 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.28 seconds
14:52:34.814721 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:52:34.814834 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

        grant usage on schema dbt to role analyst
14:52:34.943060 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.13 seconds
14:52:34.946249 [debug] [Thread-1  ]: finished collecting timing info
14:52:34.946678 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
14:52:35.125252 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd055399c-5080-4392-a0d6-76bbc00da9e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1066933a0>]}
14:52:35.126172 [info ] [Thread-1  ]: 2 of 7 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 3.20s]
14:52:35.126722 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
14:52:35.126992 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
14:52:35.127438 [info ] [Thread-1  ]: 3 of 7 START view model dbt.first_model......................................... [RUN]
14:52:35.128124 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
14:52:35.128367 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
14:52:35.128629 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
14:52:35.132511 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
14:52:35.133241 [debug] [Thread-1  ]: finished collecting timing info
14:52:35.133558 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
14:52:35.153021 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
14:52:35.154343 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
14:52:35.154548 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */

  create or replace  view analytics.dbt.first_model 
  
   as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id

)

select * 
from source_data


/*
select *, True as first_variable
from source_data
where id >= 1
*/
  );
14:52:35.154658 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:52:35.750049 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.6 seconds
14:52:35.754223 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
14:52:35.754524 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */

        grant usage on schema dbt to role analyst
14:52:35.848359 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.09 seconds
14:52:35.850148 [debug] [Thread-1  ]: finished collecting timing info
14:52:35.850415 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
14:52:36.062469 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd055399c-5080-4392-a0d6-76bbc00da9e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109864670>]}
14:52:36.063395 [info ] [Thread-1  ]: 3 of 7 OK created view model dbt.first_model.................................... [[32mSUCCESS 1[0m in 0.93s]
14:52:36.063876 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
14:52:36.064074 [debug] [Thread-1  ]: Began running node model.learn_dbt.playing_with_tests
14:52:36.064418 [info ] [Thread-1  ]: 4 of 7 START table model dbt.playing_with_tests................................. [RUN]
14:52:36.064729 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.playing_with_tests"
14:52:36.064839 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.playing_with_tests
14:52:36.064931 [debug] [Thread-1  ]: Compiling model.learn_dbt.playing_with_tests
14:52:36.065791 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.playing_with_tests"
14:52:36.066401 [debug] [Thread-1  ]: finished collecting timing info
14:52:36.066608 [debug] [Thread-1  ]: Began executing node model.learn_dbt.playing_with_tests
14:52:36.077229 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.playing_with_tests"
14:52:36.078319 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
14:52:36.078467 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */


      create or replace transient table analytics.dbt.playing_with_tests  as
      (select * 
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER"
      );
14:52:36.078598 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:52:37.939522 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.86 seconds
14:52:37.944742 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
14:52:37.945031 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */

        grant usage on schema dbt to role analyst
14:52:38.034818 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.09 seconds
14:52:38.037992 [debug] [Thread-1  ]: finished collecting timing info
14:52:38.038421 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: Close
14:52:38.231786 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd055399c-5080-4392-a0d6-76bbc00da9e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109830730>]}
14:52:38.232826 [info ] [Thread-1  ]: 4 of 7 OK created table model dbt.playing_with_tests............................ [[32mSUCCESS 1[0m in 2.17s]
14:52:38.233366 [debug] [Thread-1  ]: Finished running node model.learn_dbt.playing_with_tests
14:52:38.233616 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
14:52:38.234179 [info ] [Thread-1  ]: 5 of 7 START table model dbt.snowflake_cumulative_sales......................... [RUN]
14:52:38.234860 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
14:52:38.235079 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
14:52:38.235340 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
14:52:38.237206 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
14:52:38.237954 [debug] [Thread-1  ]: finished collecting timing info
14:52:38.238164 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
14:52:38.241093 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
14:52:38.242314 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
14:52:38.242501 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
14:52:38.242656 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:52:39.804074 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.56 seconds
14:52:39.808648 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
14:52:39.808966 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */

        grant usage on schema dbt to role analyst
14:52:39.904841 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.1 seconds
14:52:39.908876 [debug] [Thread-1  ]: finished collecting timing info
14:52:39.909272 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
14:52:40.066749 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd055399c-5080-4392-a0d6-76bbc00da9e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1064936a0>]}
14:52:40.067364 [info ] [Thread-1  ]: 5 of 7 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 1.83s]
14:52:40.067954 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
14:52:40.068305 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
14:52:40.068762 [info ] [Thread-1  ]: 6 of 7 START table model dbt.snowflake_customer_purchases....................... [RUN]
14:52:40.069542 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
14:52:40.069755 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
14:52:40.069931 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
14:52:40.071495 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
14:52:40.073411 [debug] [Thread-1  ]: finished collecting timing info
14:52:40.073671 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
14:52:40.077278 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
14:52:40.079071 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
14:52:40.079241 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
14:52:40.079376 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:52:41.769936 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.69 seconds
14:52:41.772808 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
14:52:41.773006 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */

        grant usage on schema dbt to role analyst
14:52:41.922642 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.15 seconds
14:52:41.925636 [debug] [Thread-1  ]: finished collecting timing info
14:52:41.926044 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
14:52:42.107617 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd055399c-5080-4392-a0d6-76bbc00da9e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10988f7f0>]}
14:52:42.107885 [info ] [Thread-1  ]: 6 of 7 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.04s]
14:52:42.108048 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
14:52:42.108152 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
14:52:42.108347 [info ] [Thread-1  ]: 7 of 7 START table model dbt.my_second_dbt_model................................ [RUN]
14:52:42.108671 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
14:52:42.108758 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
14:52:42.108835 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
14:52:42.110307 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
14:52:42.110624 [debug] [Thread-1  ]: finished collecting timing info
14:52:42.110698 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
14:52:42.111547 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
14:52:42.111926 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
14:52:42.112002 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
/*
union all
select 7 as id, True as first_variable
*/
      );
14:52:42.112066 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:52:43.101407 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.99 seconds
14:52:43.106069 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
14:52:43.110631 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */

        grant usage on schema dbt to role analyst
14:52:43.254256 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.14 seconds
14:52:43.258342 [debug] [Thread-1  ]: finished collecting timing info
14:52:43.258887 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
14:52:43.446832 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd055399c-5080-4392-a0d6-76bbc00da9e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109871490>]}
14:52:43.448530 [info ] [Thread-1  ]: 7 of 7 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.34s]
14:52:43.450791 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
14:52:43.468955 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:52:43.469433 [info ] [MainThread]: 
14:52:43.469617 [info ] [MainThread]: Finished running 2 incremental models, 1 view model, 4 table models in 16.12s.
14:52:43.469771 [debug] [MainThread]: Connection 'master' was properly closed.
14:52:43.469850 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
14:52:43.475451 [info ] [MainThread]: 
14:52:43.475703 [info ] [MainThread]: [32mCompleted successfully[0m
14:52:43.475889 [info ] [MainThread]: 
14:52:43.476034 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
14:52:43.476245 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10620a5b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1061fc4f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106750e80>]}


============================== 2022-05-16 14:53:33.628845 | 33eebe00-9d9f-4fca-8465-cac96e7c614e ==============================
14:53:33.628845 [info ] [MainThread]: Running with dbt=1.0.1
14:53:33.629201 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
14:53:33.629342 [debug] [MainThread]: Tracking: tracking
14:53:33.629577 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1104ab250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1104abb80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1104ab910>]}
14:53:33.662478 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
14:53:33.662709 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '33eebe00-9d9f-4fca-8465-cac96e7c614e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1104a2e80>]}
14:53:33.678986 [debug] [MainThread]: Parsing macros/catalog.sql
14:53:33.680220 [debug] [MainThread]: Parsing macros/adapters.sql
14:53:33.700090 [debug] [MainThread]: Parsing macros/materializations/merge.sql
14:53:33.701943 [debug] [MainThread]: Parsing macros/materializations/seed.sql
14:53:33.704489 [debug] [MainThread]: Parsing macros/materializations/view.sql
14:53:33.705170 [debug] [MainThread]: Parsing macros/materializations/table.sql
14:53:33.706651 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
14:53:33.710658 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
14:53:33.711097 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
14:53:33.712827 [debug] [MainThread]: Parsing macros/materializations/configs.sql
14:53:33.713858 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
14:53:33.714610 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
14:53:33.722354 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
14:53:33.727998 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
14:53:33.733765 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
14:53:33.735803 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
14:53:33.736603 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
14:53:33.737394 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
14:53:33.739487 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
14:53:33.745139 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
14:53:33.745864 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
14:53:33.750982 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
14:53:33.758970 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
14:53:33.762689 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
14:53:33.763981 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
14:53:33.767473 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
14:53:33.768058 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
14:53:33.769275 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
14:53:33.770275 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
14:53:33.773069 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
14:53:33.781106 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
14:53:33.781780 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
14:53:33.782881 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
14:53:33.783573 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
14:53:33.783970 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
14:53:33.784203 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
14:53:33.784507 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
14:53:33.785112 [debug] [MainThread]: Parsing macros/etc/statement.sql
14:53:33.787099 [debug] [MainThread]: Parsing macros/etc/datetime.sql
14:53:33.791040 [debug] [MainThread]: Parsing macros/adapters/schema.sql
14:53:33.792058 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
14:53:33.793293 [debug] [MainThread]: Parsing macros/adapters/relation.sql
14:53:33.797880 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
14:53:33.799169 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
14:53:33.801113 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
14:53:33.804406 [debug] [MainThread]: Parsing macros/adapters/columns.sql
14:53:33.808896 [debug] [MainThread]: Parsing tests/generic/builtin.sql
14:53:33.898603 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
14:53:33.905178 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
14:53:33.905954 [debug] [MainThread]: 1699: static parser successfully parsed example/playing_with_tests.sql
14:53:33.908037 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_cumulative_sales.sql
14:53:33.909952 [debug] [MainThread]: 1603: static parser failed on example/my_second_dbt_model.sql
14:53:33.911795 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_second_dbt_model.sql
14:53:33.912326 [debug] [MainThread]: 1603: static parser failed on example/incremental_time.sql
14:53:33.915975 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_time.sql
14:53:33.916536 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
14:53:33.918289 [debug] [MainThread]: 1603: static parser failed on new/dates.sql
14:53:33.920298 [debug] [MainThread]: 1602: parser fallback to jinja rendering on new/dates.sql
14:53:33.969083 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '33eebe00-9d9f-4fca-8465-cac96e7c614e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111a7df10>]}
14:53:33.972249 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '33eebe00-9d9f-4fca-8465-cac96e7c614e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111a7ddc0>]}
14:53:33.972404 [info ] [MainThread]: Found 7 models, 12 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
14:53:33.973249 [info ] [MainThread]: 
14:53:33.973495 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:53:33.974070 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
14:53:33.980666 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
14:53:33.980827 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
14:53:33.980899 [debug] [ThreadPool]: Opening a new connection, currently in state init
14:53:34.767470 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.79 seconds
14:53:34.769779 [debug] [ThreadPool]: On list_analytics: Close
14:53:34.923543 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
14:53:34.932923 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
14:53:34.933255 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
14:53:34.933420 [debug] [ThreadPool]: Opening a new connection, currently in state closed
14:53:35.446583 [debug] [ThreadPool]: SQL status: SUCCESS 7 in 0.51 seconds
14:53:35.448354 [debug] [ThreadPool]: On list_analytics_dbt: Close
14:53:35.618510 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
14:53:35.619076 [info ] [MainThread]: 
14:53:35.624454 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
14:53:35.625339 [info ] [Thread-1  ]: 1 of 7 START incremental model dbt.dates........................................ [RUN]
14:53:35.625941 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
14:53:35.626120 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
14:53:35.626292 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
14:53:35.631886 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
14:53:35.632899 [debug] [Thread-1  ]: finished collecting timing info
14:53:35.633166 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
14:53:35.663267 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
14:53:35.663518 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
14:53:35.663613 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:53:36.563293 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.9 seconds
14:53:36.583090 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
14:53:36.583482 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
14:53:36.692861 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.11 seconds
14:53:36.710393 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
14:53:36.711250 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
14:53:36.807017 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.1 seconds
14:53:36.827491 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
14:53:36.827963 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
14:53:36.937005 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.11 seconds
14:53:36.974749 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
14:53:36.979190 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
14:53:36.979498 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
14:53:37.121179 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.14 seconds
14:53:37.123824 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
14:53:37.124131 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
14:53:37.786924 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.66 seconds
14:53:37.787168 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
14:53:37.787253 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
14:53:37.979037 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.19 seconds
14:53:38.003803 [debug] [Thread-1  ]: finished collecting timing info
14:53:38.004219 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
14:53:38.259127 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '33eebe00-9d9f-4fca-8465-cac96e7c614e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111ebf670>]}
14:53:38.260450 [info ] [Thread-1  ]: 1 of 7 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 2.63s]
14:53:38.260883 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
14:53:38.261132 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
14:53:38.261596 [info ] [Thread-1  ]: 2 of 7 START incremental model dbt.incremental_time............................. [RUN]
14:53:38.262683 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
14:53:38.263105 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
14:53:38.263602 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
14:53:38.276917 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
14:53:38.279692 [debug] [Thread-1  ]: finished collecting timing info
14:53:38.279922 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
14:53:38.282720 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:53:38.282873 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
14:53:38.282979 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:53:39.515228 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.23 seconds
14:53:39.520450 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:53:39.520835 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
14:53:39.639381 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.12 seconds
14:53:39.648472 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:53:39.649596 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
14:53:39.753992 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
14:53:39.763350 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:53:39.763918 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
14:53:39.878143 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.11 seconds
14:53:39.884579 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
14:53:39.888542 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:53:39.888908 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
14:53:40.024439 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.14 seconds
14:53:40.024895 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:53:40.025060 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
14:53:40.731630 [debug] [Thread-1  ]: SQL status: SUCCESS 66 in 0.71 seconds
14:53:40.733612 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:53:40.734083 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
14:53:41.060631 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.33 seconds
14:53:41.072657 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:53:41.073242 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

        grant select on all views in schema dbt to role analyst
14:53:41.193903 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.12 seconds
14:53:41.197838 [debug] [Thread-1  ]: finished collecting timing info
14:53:41.198659 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
14:53:41.373523 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '33eebe00-9d9f-4fca-8465-cac96e7c614e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111e24f10>]}
14:53:41.374583 [info ] [Thread-1  ]: 2 of 7 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 3.11s]
14:53:41.375009 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
14:53:41.375259 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
14:53:41.375526 [info ] [Thread-1  ]: 3 of 7 START view model dbt.first_model......................................... [RUN]
14:53:41.376316 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
14:53:41.376876 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
14:53:41.377315 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
14:53:41.392717 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
14:53:41.393748 [debug] [Thread-1  ]: finished collecting timing info
14:53:41.393887 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
14:53:41.409838 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
14:53:41.411564 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
14:53:41.411814 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */

  create or replace  view analytics.dbt.first_model 
  
   as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id

)

select * 
from source_data


/*
select *, True as first_variable
from source_data
where id >= 1
*/
  );
14:53:41.411954 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:53:42.224527 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.81 seconds
14:53:42.228435 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
14:53:42.228687 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */

        grant select on all views in schema dbt to role analyst
14:53:42.365078 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.14 seconds
14:53:42.367682 [debug] [Thread-1  ]: finished collecting timing info
14:53:42.368109 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
14:53:42.525294 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '33eebe00-9d9f-4fca-8465-cac96e7c614e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113d2d730>]}
14:53:42.526737 [info ] [Thread-1  ]: 3 of 7 OK created view model dbt.first_model.................................... [[32mSUCCESS 1[0m in 1.15s]
14:53:42.527289 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
14:53:42.527700 [debug] [Thread-1  ]: Began running node model.learn_dbt.playing_with_tests
14:53:42.528311 [info ] [Thread-1  ]: 4 of 7 START table model dbt.playing_with_tests................................. [RUN]
14:53:42.535895 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.playing_with_tests"
14:53:42.536899 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.playing_with_tests
14:53:42.537223 [debug] [Thread-1  ]: Compiling model.learn_dbt.playing_with_tests
14:53:42.538380 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.playing_with_tests"
14:53:42.538820 [debug] [Thread-1  ]: finished collecting timing info
14:53:42.538920 [debug] [Thread-1  ]: Began executing node model.learn_dbt.playing_with_tests
14:53:42.550650 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.playing_with_tests"
14:53:42.551359 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
14:53:42.551590 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */


      create or replace transient table analytics.dbt.playing_with_tests  as
      (select * 
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER"
      );
14:53:42.551784 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:53:43.969872 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.42 seconds
14:53:43.978074 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
14:53:43.978421 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */

        grant select on all views in schema dbt to role analyst
14:53:44.093196 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.11 seconds
14:53:44.095538 [debug] [Thread-1  ]: finished collecting timing info
14:53:44.096113 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: Close
14:53:44.260731 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '33eebe00-9d9f-4fca-8465-cac96e7c614e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113d88af0>]}
14:53:44.261548 [info ] [Thread-1  ]: 4 of 7 OK created table model dbt.playing_with_tests............................ [[32mSUCCESS 1[0m in 1.73s]
14:53:44.261973 [debug] [Thread-1  ]: Finished running node model.learn_dbt.playing_with_tests
14:53:44.262281 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
14:53:44.262676 [info ] [Thread-1  ]: 5 of 7 START table model dbt.snowflake_cumulative_sales......................... [RUN]
14:53:44.263384 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
14:53:44.263791 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
14:53:44.264106 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
14:53:44.275147 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
14:53:44.277124 [debug] [Thread-1  ]: finished collecting timing info
14:53:44.277339 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
14:53:44.279103 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
14:53:44.279745 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
14:53:44.279848 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
14:53:44.279957 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:53:45.572128 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.29 seconds
14:53:45.576746 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
14:53:45.577215 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */

        grant select on all views in schema dbt to role analyst
14:53:45.697896 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.12 seconds
14:53:45.704072 [debug] [Thread-1  ]: finished collecting timing info
14:53:45.704489 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
14:53:45.862153 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '33eebe00-9d9f-4fca-8465-cac96e7c614e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113d4cac0>]}
14:53:45.862983 [info ] [Thread-1  ]: 5 of 7 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 1.60s]
14:53:45.863448 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
14:53:45.863690 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
14:53:45.863971 [info ] [Thread-1  ]: 6 of 7 START table model dbt.snowflake_customer_purchases....................... [RUN]
14:53:45.864605 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
14:53:45.864894 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
14:53:45.872673 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
14:53:45.875945 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
14:53:45.876566 [debug] [Thread-1  ]: finished collecting timing info
14:53:45.876731 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
14:53:45.878476 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
14:53:45.879421 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
14:53:45.879566 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
14:53:45.879639 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:53:47.723007 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.84 seconds
14:53:47.728337 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
14:53:47.728750 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */

        grant select on all views in schema dbt to role analyst
14:53:47.838931 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.11 seconds
14:53:47.841952 [debug] [Thread-1  ]: finished collecting timing info
14:53:47.842506 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
14:53:48.022788 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '33eebe00-9d9f-4fca-8465-cac96e7c614e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111e05850>]}
14:53:48.025003 [info ] [Thread-1  ]: 6 of 7 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.16s]
14:53:48.025694 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
14:53:48.026021 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
14:53:48.026429 [info ] [Thread-1  ]: 7 of 7 START table model dbt.my_second_dbt_model................................ [RUN]
14:53:48.027249 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
14:53:48.027686 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
14:53:48.028098 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
14:53:48.042560 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
14:53:48.044282 [debug] [Thread-1  ]: finished collecting timing info
14:53:48.044466 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
14:53:48.045942 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
14:53:48.046578 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
14:53:48.046677 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
/*
union all
select 7 as id, True as first_variable
*/
      );
14:53:48.046764 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:53:49.009005 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.96 seconds
14:53:49.013785 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
14:53:49.014065 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */

        grant select on all views in schema dbt to role analyst
14:53:49.144980 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.13 seconds
14:53:49.147774 [debug] [Thread-1  ]: finished collecting timing info
14:53:49.148227 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
14:53:49.340370 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '33eebe00-9d9f-4fca-8465-cac96e7c614e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111df9b80>]}
14:53:49.341110 [info ] [Thread-1  ]: 7 of 7 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.31s]
14:53:49.341619 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
14:53:49.344102 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:53:49.344964 [info ] [MainThread]: 
14:53:49.345579 [info ] [MainThread]: Finished running 2 incremental models, 1 view model, 4 table models in 15.37s.
14:53:49.346438 [debug] [MainThread]: Connection 'master' was properly closed.
14:53:49.351085 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
14:53:49.359433 [info ] [MainThread]: 
14:53:49.359737 [info ] [MainThread]: [32mCompleted successfully[0m
14:53:49.359967 [info ] [MainThread]: 
14:53:49.360232 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
14:53:49.360551 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111e1e040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111ad1a00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113dd96a0>]}


============================== 2022-05-16 14:54:22.477020 | 1ea0f2df-2a19-4250-a7f4-0d225eb19877 ==============================
14:54:22.477020 [info ] [MainThread]: Running with dbt=1.0.1
14:54:22.477637 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
14:54:22.477832 [debug] [MainThread]: Tracking: tracking
14:54:22.478054 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x118f4fe80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x118f4f4f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x118f4f9d0>]}
14:54:22.512818 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
14:54:22.513084 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '1ea0f2df-2a19-4250-a7f4-0d225eb19877', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x118347070>]}
14:54:22.527673 [debug] [MainThread]: Parsing macros/catalog.sql
14:54:22.528968 [debug] [MainThread]: Parsing macros/adapters.sql
14:54:22.549340 [debug] [MainThread]: Parsing macros/materializations/merge.sql
14:54:22.551462 [debug] [MainThread]: Parsing macros/materializations/seed.sql
14:54:22.554045 [debug] [MainThread]: Parsing macros/materializations/view.sql
14:54:22.554695 [debug] [MainThread]: Parsing macros/materializations/table.sql
14:54:22.556305 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
14:54:22.560376 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
14:54:22.560815 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
14:54:22.562528 [debug] [MainThread]: Parsing macros/materializations/configs.sql
14:54:22.563542 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
14:54:22.564285 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
14:54:22.572315 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
14:54:22.578032 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
14:54:22.584123 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
14:54:22.586305 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
14:54:22.587252 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
14:54:22.588350 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
14:54:22.590683 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
14:54:22.596158 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
14:54:22.596849 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
14:54:22.601715 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
14:54:22.609405 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
14:54:22.613027 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
14:54:22.614278 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
14:54:22.617773 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
14:54:22.618345 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
14:54:22.619556 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
14:54:22.620544 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
14:54:22.623626 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
14:54:22.631843 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
14:54:22.632646 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
14:54:22.633795 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
14:54:22.634498 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
14:54:22.634901 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
14:54:22.635145 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
14:54:22.635468 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
14:54:22.636126 [debug] [MainThread]: Parsing macros/etc/statement.sql
14:54:22.638138 [debug] [MainThread]: Parsing macros/etc/datetime.sql
14:54:22.642063 [debug] [MainThread]: Parsing macros/adapters/schema.sql
14:54:22.642992 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
14:54:22.644146 [debug] [MainThread]: Parsing macros/adapters/relation.sql
14:54:22.648816 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
14:54:22.650127 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
14:54:22.652087 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
14:54:22.656060 [debug] [MainThread]: Parsing macros/adapters/columns.sql
14:54:22.660894 [debug] [MainThread]: Parsing tests/generic/builtin.sql
14:54:22.754286 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
14:54:22.761589 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
14:54:22.762498 [debug] [MainThread]: 1699: static parser successfully parsed example/playing_with_tests.sql
14:54:22.764520 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_cumulative_sales.sql
14:54:22.766431 [debug] [MainThread]: 1603: static parser failed on example/my_second_dbt_model.sql
14:54:22.768494 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_second_dbt_model.sql
14:54:22.769144 [debug] [MainThread]: 1603: static parser failed on example/incremental_time.sql
14:54:22.773264 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_time.sql
14:54:22.773899 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
14:54:22.775826 [debug] [MainThread]: 1603: static parser failed on new/dates.sql
14:54:22.777901 [debug] [MainThread]: 1602: parser fallback to jinja rendering on new/dates.sql
14:54:22.825662 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1ea0f2df-2a19-4250-a7f4-0d225eb19877', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x118fe4ca0>]}
14:54:22.829079 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1ea0f2df-2a19-4250-a7f4-0d225eb19877', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x118fe41f0>]}
14:54:22.829223 [info ] [MainThread]: Found 7 models, 12 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
14:54:22.830022 [info ] [MainThread]: 
14:54:22.830240 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:54:22.830712 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
14:54:22.836614 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
14:54:22.836729 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
14:54:22.836793 [debug] [ThreadPool]: Opening a new connection, currently in state init
14:54:23.608080 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.77 seconds
14:54:23.611088 [debug] [ThreadPool]: On list_analytics: Close
14:54:23.836847 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
14:54:23.846857 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
14:54:23.847413 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
14:54:23.847680 [debug] [ThreadPool]: Opening a new connection, currently in state closed
14:54:24.573455 [debug] [ThreadPool]: SQL status: SUCCESS 7 in 0.73 seconds
14:54:24.576712 [debug] [ThreadPool]: On list_analytics_dbt: Close
14:54:24.758343 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
14:54:24.759055 [info ] [MainThread]: 
14:54:24.764880 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
14:54:24.765692 [info ] [Thread-1  ]: 1 of 7 START incremental model dbt.dates........................................ [RUN]
14:54:24.766243 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
14:54:24.766418 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
14:54:24.766586 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
14:54:24.771287 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
14:54:24.771797 [debug] [Thread-1  ]: finished collecting timing info
14:54:24.771911 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
14:54:24.804182 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
14:54:24.804405 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
14:54:24.804491 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:54:25.630678 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.83 seconds
14:54:25.648667 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
14:54:25.648911 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
14:54:25.853544 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.2 seconds
14:54:25.862511 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
14:54:25.862853 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
14:54:25.973160 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.11 seconds
14:54:25.984646 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
14:54:25.984957 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
14:54:26.105801 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.12 seconds
14:54:26.128393 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
14:54:26.130968 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
14:54:26.131114 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
14:54:26.303055 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.17 seconds
14:54:26.304646 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
14:54:26.304930 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
14:54:26.731131 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.43 seconds
14:54:26.732681 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
14:54:26.732954 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
14:54:26.910027 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.18 seconds
14:54:26.923858 [debug] [Thread-1  ]: finished collecting timing info
14:54:26.924152 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
14:54:27.170589 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1ea0f2df-2a19-4250-a7f4-0d225eb19877', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11906bb20>]}
14:54:27.171483 [info ] [Thread-1  ]: 1 of 7 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 2.40s]
14:54:27.171866 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
14:54:27.172064 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
14:54:27.172381 [info ] [Thread-1  ]: 2 of 7 START incremental model dbt.incremental_time............................. [RUN]
14:54:27.173177 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
14:54:27.173469 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
14:54:27.173683 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
14:54:27.176988 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
14:54:27.177970 [debug] [Thread-1  ]: finished collecting timing info
14:54:27.178268 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
14:54:27.182100 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:54:27.182275 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
14:54:27.182406 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:54:28.361769 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.18 seconds
14:54:28.367141 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:54:28.367493 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
14:54:28.479097 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.11 seconds
14:54:28.484996 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:54:28.485352 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
14:54:28.591578 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.11 seconds
14:54:28.596384 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:54:28.596737 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
14:54:28.702945 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.11 seconds
14:54:28.706844 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
14:54:28.709345 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:54:28.709584 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
14:54:28.834518 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.12 seconds
14:54:28.837649 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:54:28.838072 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
14:54:29.503657 [debug] [Thread-1  ]: SQL status: SUCCESS 49 in 0.67 seconds
14:54:29.504263 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:54:29.504444 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
14:54:29.727733 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.22 seconds
14:54:29.729954 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
14:54:29.730058 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

        grant select on analytics.dbt.incremental_time to role analyst
14:54:29.826712 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.1 seconds
14:54:29.829056 [debug] [Thread-1  ]: finished collecting timing info
14:54:29.829197 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
14:54:30.003952 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1ea0f2df-2a19-4250-a7f4-0d225eb19877', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1193a4a00>]}
14:54:30.004630 [info ] [Thread-1  ]: 2 of 7 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 2.83s]
14:54:30.005081 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
14:54:30.005332 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
14:54:30.005986 [info ] [Thread-1  ]: 3 of 7 START view model dbt.first_model......................................... [RUN]
14:54:30.006700 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
14:54:30.006926 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
14:54:30.007127 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
14:54:30.011360 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
14:54:30.013684 [debug] [Thread-1  ]: finished collecting timing info
14:54:30.013996 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
14:54:30.032623 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
14:54:30.033619 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
14:54:30.033747 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */

  create or replace  view analytics.dbt.first_model 
  
   as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id

)

select * 
from source_data


/*
select *, True as first_variable
from source_data
where id >= 1
*/
  );
14:54:30.033850 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:54:30.634849 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.6 seconds
14:54:30.638585 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
14:54:30.638815 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */

        grant select on analytics.dbt.first_model to role analyst
14:54:30.755694 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.12 seconds
14:54:30.758649 [debug] [Thread-1  ]: finished collecting timing info
14:54:30.758825 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
14:54:30.919082 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1ea0f2df-2a19-4250-a7f4-0d225eb19877', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b4a9070>]}
14:54:30.919580 [info ] [Thread-1  ]: 3 of 7 OK created view model dbt.first_model.................................... [[32mSUCCESS 1[0m in 0.91s]
14:54:30.919807 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
14:54:30.919925 [debug] [Thread-1  ]: Began running node model.learn_dbt.playing_with_tests
14:54:30.920214 [info ] [Thread-1  ]: 4 of 7 START table model dbt.playing_with_tests................................. [RUN]
14:54:30.920543 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.playing_with_tests"
14:54:30.920643 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.playing_with_tests
14:54:30.920741 [debug] [Thread-1  ]: Compiling model.learn_dbt.playing_with_tests
14:54:30.922156 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.playing_with_tests"
14:54:30.923928 [debug] [Thread-1  ]: finished collecting timing info
14:54:30.924150 [debug] [Thread-1  ]: Began executing node model.learn_dbt.playing_with_tests
14:54:30.933616 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.playing_with_tests"
14:54:30.934623 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
14:54:30.934793 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */


      create or replace transient table analytics.dbt.playing_with_tests  as
      (select * 
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER"
      );
14:54:30.934930 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:54:32.431529 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.5 seconds
14:54:32.436984 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
14:54:32.437299 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */

        grant select on analytics.dbt.playing_with_tests to role analyst
14:54:32.566578 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.13 seconds
14:54:32.569833 [debug] [Thread-1  ]: finished collecting timing info
14:54:32.570148 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: Close
14:54:32.743012 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1ea0f2df-2a19-4250-a7f4-0d225eb19877', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1193a5040>]}
14:54:32.744095 [info ] [Thread-1  ]: 4 of 7 OK created table model dbt.playing_with_tests............................ [[32mSUCCESS 1[0m in 1.82s]
14:54:32.744479 [debug] [Thread-1  ]: Finished running node model.learn_dbt.playing_with_tests
14:54:32.744651 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
14:54:32.745022 [info ] [Thread-1  ]: 5 of 7 START table model dbt.snowflake_cumulative_sales......................... [RUN]
14:54:32.745579 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
14:54:32.745736 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
14:54:32.745886 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
14:54:32.747521 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
14:54:32.748330 [debug] [Thread-1  ]: finished collecting timing info
14:54:32.748488 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
14:54:32.750885 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
14:54:32.751976 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
14:54:32.752229 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
14:54:32.752410 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:54:33.995120 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.24 seconds
14:54:33.997682 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
14:54:33.997769 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */

        grant select on analytics.dbt.snowflake_cumulative_sales to role analyst
14:54:34.114562 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.12 seconds
14:54:34.119139 [debug] [Thread-1  ]: finished collecting timing info
14:54:34.119577 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
14:54:34.283763 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1ea0f2df-2a19-4250-a7f4-0d225eb19877', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b4089a0>]}
14:54:34.285078 [info ] [Thread-1  ]: 5 of 7 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 1.54s]
14:54:34.285743 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
14:54:34.285995 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
14:54:34.286456 [info ] [Thread-1  ]: 6 of 7 START table model dbt.snowflake_customer_purchases....................... [RUN]
14:54:34.287022 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
14:54:34.287197 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
14:54:34.287360 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
14:54:34.288897 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
14:54:34.289584 [debug] [Thread-1  ]: finished collecting timing info
14:54:34.289760 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
14:54:34.293115 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
14:54:34.294403 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
14:54:34.294592 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
14:54:34.294742 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:54:36.053652 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.76 seconds
14:54:36.060328 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
14:54:36.060617 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */

        grant select on analytics.dbt.snowflake_customer_purchases to role analyst
14:54:36.190392 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.13 seconds
14:54:36.193386 [debug] [Thread-1  ]: finished collecting timing info
14:54:36.193904 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
14:54:36.359831 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1ea0f2df-2a19-4250-a7f4-0d225eb19877', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b40ed90>]}
14:54:36.361359 [info ] [Thread-1  ]: 6 of 7 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.07s]
14:54:36.361913 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
14:54:36.362160 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
14:54:36.362557 [info ] [Thread-1  ]: 7 of 7 START table model dbt.my_second_dbt_model................................ [RUN]
14:54:36.363240 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
14:54:36.363460 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
14:54:36.363655 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
14:54:36.367717 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
14:54:36.369709 [debug] [Thread-1  ]: finished collecting timing info
14:54:36.369921 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
14:54:36.372394 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
14:54:36.373509 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
14:54:36.373668 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
/*
union all
select 7 as id, True as first_variable
*/
      );
14:54:36.373805 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
14:54:37.618306 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.24 seconds
14:54:37.622939 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
14:54:37.623237 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */

        grant select on analytics.dbt.my_second_dbt_model to role analyst
14:54:37.739110 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.12 seconds
14:54:37.742063 [debug] [Thread-1  ]: finished collecting timing info
14:54:37.742551 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
14:54:37.917121 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1ea0f2df-2a19-4250-a7f4-0d225eb19877', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b40ec40>]}
14:54:37.918017 [info ] [Thread-1  ]: 7 of 7 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.55s]
14:54:37.918646 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
14:54:37.920204 [debug] [MainThread]: Acquiring new snowflake connection "master"
14:54:37.920857 [info ] [MainThread]: 
14:54:37.921246 [info ] [MainThread]: Finished running 2 incremental models, 1 view model, 4 table models in 15.09s.
14:54:37.921558 [debug] [MainThread]: Connection 'master' was properly closed.
14:54:37.921898 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
14:54:37.929719 [info ] [MainThread]: 
14:54:37.930109 [info ] [MainThread]: [32mCompleted successfully[0m
14:54:37.930380 [info ] [MainThread]: 
14:54:37.930580 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
14:54:37.930874 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1193a65e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1193a6fa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b40e2e0>]}


============================== 2022-05-16 15:00:05.449742 | c4effbce-ea3e-4622-95e8-a0913f7b6db3 ==============================
15:00:05.449742 [info ] [MainThread]: Running with dbt=1.0.1
15:00:05.450558 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
15:00:05.450761 [debug] [MainThread]: Tracking: tracking
15:00:05.451567 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104fcb520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104fcb100>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104fcb280>]}
15:00:05.488661 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
15:00:05.488883 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'c4effbce-ea3e-4622-95e8-a0913f7b6db3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10451bcd0>]}
15:00:05.504704 [debug] [MainThread]: Parsing macros/catalog.sql
15:00:05.506004 [debug] [MainThread]: Parsing macros/adapters.sql
15:00:05.526855 [debug] [MainThread]: Parsing macros/materializations/merge.sql
15:00:05.528780 [debug] [MainThread]: Parsing macros/materializations/seed.sql
15:00:05.531197 [debug] [MainThread]: Parsing macros/materializations/view.sql
15:00:05.531817 [debug] [MainThread]: Parsing macros/materializations/table.sql
15:00:05.533228 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
15:00:05.537222 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
15:00:05.537723 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
15:00:05.539522 [debug] [MainThread]: Parsing macros/materializations/configs.sql
15:00:05.540554 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
15:00:05.541303 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
15:00:05.549279 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
15:00:05.554822 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
15:00:05.560706 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
15:00:05.562914 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
15:00:05.563728 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
15:00:05.564530 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
15:00:05.566501 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
15:00:05.572393 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
15:00:05.573247 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
15:00:05.578144 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
15:00:05.586233 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
15:00:05.589939 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
15:00:05.591221 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
15:00:05.594742 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
15:00:05.595496 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
15:00:05.596852 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
15:00:05.597872 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
15:00:05.600708 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
15:00:05.609121 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
15:00:05.609911 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
15:00:05.611038 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
15:00:05.611729 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
15:00:05.612126 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
15:00:05.612386 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
15:00:05.612692 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
15:00:05.613295 [debug] [MainThread]: Parsing macros/etc/statement.sql
15:00:05.615297 [debug] [MainThread]: Parsing macros/etc/datetime.sql
15:00:05.619234 [debug] [MainThread]: Parsing macros/adapters/schema.sql
15:00:05.620164 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
15:00:05.621330 [debug] [MainThread]: Parsing macros/adapters/relation.sql
15:00:05.626104 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
15:00:05.627415 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
15:00:05.629359 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
15:00:05.632676 [debug] [MainThread]: Parsing macros/adapters/columns.sql
15:00:05.637151 [debug] [MainThread]: Parsing tests/generic/builtin.sql
15:00:05.729599 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
15:00:05.736087 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
15:00:05.736581 [debug] [MainThread]: 1699: static parser successfully parsed example/playing_with_tests.sql
15:00:05.737663 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_cumulative_sales.sql
15:00:05.738645 [debug] [MainThread]: 1603: static parser failed on example/my_second_dbt_model.sql
15:00:05.740171 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_second_dbt_model.sql
15:00:05.740637 [debug] [MainThread]: 1603: static parser failed on example/incremental_time.sql
15:00:05.744186 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_time.sql
15:00:05.744693 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
15:00:05.745655 [debug] [MainThread]: 1603: static parser failed on new/dates.sql
15:00:05.747313 [debug] [MainThread]: 1602: parser fallback to jinja rendering on new/dates.sql
15:00:05.803937 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c4effbce-ea3e-4622-95e8-a0913f7b6db3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105209d60>]}
15:00:05.807263 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c4effbce-ea3e-4622-95e8-a0913f7b6db3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1050c7970>]}
15:00:05.807397 [info ] [MainThread]: Found 7 models, 12 tests, 0 snapshots, 0 analyses, 179 macros, 4 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
15:00:05.808387 [info ] [MainThread]: 
15:00:05.808680 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:00:05.809270 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
15:00:05.815599 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
15:00:05.815750 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
15:00:05.815814 [debug] [ThreadPool]: Opening a new connection, currently in state init
15:00:06.693712 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.88 seconds
15:00:06.696403 [debug] [ThreadPool]: On list_analytics: Close
15:00:06.905726 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
15:00:06.913847 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
15:00:06.914170 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
15:00:06.914335 [debug] [ThreadPool]: Opening a new connection, currently in state closed
15:00:07.445095 [debug] [ThreadPool]: SQL status: SUCCESS 7 in 0.53 seconds
15:00:07.449038 [debug] [ThreadPool]: On list_analytics_dbt: Close
15:00:07.618654 [info ] [MainThread]: 
15:00:07.619192 [info ] [MainThread]: Running 1 on-run-start hook
15:00:07.619599 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-start-0
15:00:07.621609 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-start-0"
15:00:07.624890 [info ] [MainThread]: 1 of 1 START hook: learn_dbt.on-run-start.0..................................... [RUN]
15:00:07.625520 [debug] [MainThread]: Using snowflake connection "master"
15:00:07.625683 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
15:00:07.625823 [debug] [MainThread]: Opening a new connection, currently in state init
15:00:08.556675 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.93 seconds
15:00:08.559395 [info ] [MainThread]: 1 of 1 OK hook: learn_dbt.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.93s]
15:00:08.559807 [info ] [MainThread]: 
15:00:08.559994 [debug] [MainThread]: On master: Close
15:00:08.746134 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
15:00:08.746753 [info ] [MainThread]: 
15:00:08.753282 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
15:00:08.753741 [info ] [Thread-1  ]: 1 of 7 START incremental model dbt.dates........................................ [RUN]
15:00:08.754826 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
15:00:08.755125 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
15:00:08.755300 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
15:00:08.761390 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
15:00:08.762911 [debug] [Thread-1  ]: finished collecting timing info
15:00:08.763161 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
15:00:08.792536 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
15:00:08.792744 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
15:00:08.792836 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:00:11.307306 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.51 seconds
15:00:11.317358 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
15:00:11.317673 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
15:00:11.474286 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.16 seconds
15:00:11.480985 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
15:00:11.481273 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
15:00:11.624923 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.14 seconds
15:00:11.634224 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
15:00:11.634473 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
15:00:11.743607 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.11 seconds
15:00:11.769548 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
15:00:11.773811 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
15:00:11.774003 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
15:00:11.907991 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.13 seconds
15:00:11.912768 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
15:00:11.913259 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
15:00:12.536527 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.62 seconds
15:00:12.537271 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
15:00:12.537460 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
15:00:13.102936 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.57 seconds
15:00:13.117511 [debug] [Thread-1  ]: finished collecting timing info
15:00:13.117904 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
15:00:13.303093 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c4effbce-ea3e-4622-95e8-a0913f7b6db3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1055f9550>]}
15:00:13.303892 [info ] [Thread-1  ]: 1 of 7 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 4.55s]
15:00:13.304388 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
15:00:13.304648 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
15:00:13.305071 [info ] [Thread-1  ]: 2 of 7 START incremental model dbt.incremental_time............................. [RUN]
15:00:13.305628 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
15:00:13.305820 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
15:00:13.306001 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
15:00:13.308711 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
15:00:13.311390 [debug] [Thread-1  ]: finished collecting timing info
15:00:13.311711 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
15:00:13.315599 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
15:00:13.315805 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
15:00:13.315948 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:00:15.198801 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.88 seconds
15:00:15.204651 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
15:00:15.205026 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
15:00:15.316757 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.11 seconds
15:00:15.323189 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
15:00:15.323519 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
15:00:15.425191 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
15:00:15.431280 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
15:00:15.431621 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
15:00:15.552949 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.12 seconds
15:00:15.557857 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
15:00:15.561357 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
15:00:15.561591 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
15:00:15.721544 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.16 seconds
15:00:15.722274 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
15:00:15.722475 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
15:00:16.531799 [debug] [Thread-1  ]: SQL status: SUCCESS 346 in 0.81 seconds
15:00:16.532947 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
15:00:16.533180 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
15:00:16.923739 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.39 seconds
15:00:16.927101 [debug] [Thread-1  ]: finished collecting timing info
15:00:16.927621 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
15:00:17.108415 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c4effbce-ea3e-4622-95e8-a0913f7b6db3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10753f040>]}
15:00:17.109166 [info ] [Thread-1  ]: 2 of 7 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 3.80s]
15:00:17.109661 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
15:00:17.110092 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
15:00:17.110623 [info ] [Thread-1  ]: 3 of 7 START view model dbt.first_model......................................... [RUN]
15:00:17.111324 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
15:00:17.111549 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
15:00:17.111750 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
15:00:17.115975 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
15:00:17.117678 [debug] [Thread-1  ]: finished collecting timing info
15:00:17.117869 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
15:00:17.135928 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
15:00:17.136919 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
15:00:17.137049 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */

  create or replace  view analytics.dbt.first_model 
  
   as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id

)

select * 
from source_data


/*
select *, True as first_variable
from source_data
where id >= 1
*/
  );
15:00:17.137154 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:00:18.066786 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.93 seconds
15:00:18.069401 [debug] [Thread-1  ]: finished collecting timing info
15:00:18.069911 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
15:00:18.347174 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c4effbce-ea3e-4622-95e8-a0913f7b6db3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075a0970>]}
15:00:18.348462 [info ] [Thread-1  ]: 3 of 7 OK created view model dbt.first_model.................................... [[32mSUCCESS 1[0m in 1.24s]
15:00:18.349006 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
15:00:18.349275 [debug] [Thread-1  ]: Began running node model.learn_dbt.playing_with_tests
15:00:18.349574 [info ] [Thread-1  ]: 4 of 7 START table model dbt.playing_with_tests................................. [RUN]
15:00:18.350374 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.playing_with_tests"
15:00:18.350737 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.playing_with_tests
15:00:18.351020 [debug] [Thread-1  ]: Compiling model.learn_dbt.playing_with_tests
15:00:18.352258 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.playing_with_tests"
15:00:18.354478 [debug] [Thread-1  ]: finished collecting timing info
15:00:18.354728 [debug] [Thread-1  ]: Began executing node model.learn_dbt.playing_with_tests
15:00:18.364454 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.playing_with_tests"
15:00:18.365352 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
15:00:18.365531 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */


      create or replace transient table analytics.dbt.playing_with_tests  as
      (select * 
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER"
      );
15:00:18.365651 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:00:20.301167 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.94 seconds
15:00:20.306288 [debug] [Thread-1  ]: finished collecting timing info
15:00:20.306696 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: Close
15:00:20.834238 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c4effbce-ea3e-4622-95e8-a0913f7b6db3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10753fa90>]}
15:00:20.835173 [info ] [Thread-1  ]: 4 of 7 OK created table model dbt.playing_with_tests............................ [[32mSUCCESS 1[0m in 2.48s]
15:00:20.835857 [debug] [Thread-1  ]: Finished running node model.learn_dbt.playing_with_tests
15:00:20.836133 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
15:00:20.836626 [info ] [Thread-1  ]: 5 of 7 START table model dbt.snowflake_cumulative_sales......................... [RUN]
15:00:20.837474 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
15:00:20.837769 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
15:00:20.838002 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
15:00:20.839895 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
15:00:20.841532 [debug] [Thread-1  ]: finished collecting timing info
15:00:20.841888 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
15:00:20.844635 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
15:00:20.846127 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
15:00:20.846374 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
15:00:20.846520 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:00:23.802286 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.96 seconds
15:00:23.806245 [debug] [Thread-1  ]: finished collecting timing info
15:00:23.806613 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
15:00:24.089166 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c4effbce-ea3e-4622-95e8-a0913f7b6db3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10753f1c0>]}
15:00:24.089710 [info ] [Thread-1  ]: 5 of 7 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 3.25s]
15:00:24.090088 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
15:00:24.090314 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
15:00:24.090556 [info ] [Thread-1  ]: 6 of 7 START table model dbt.snowflake_customer_purchases....................... [RUN]
15:00:24.091305 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
15:00:24.091521 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
15:00:24.091692 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
15:00:24.093114 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
15:00:24.095551 [debug] [Thread-1  ]: finished collecting timing info
15:00:24.095875 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
15:00:24.098835 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
15:00:24.100380 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
15:00:24.100587 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
15:00:24.100822 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:00:25.943345 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.84 seconds
15:00:25.947516 [debug] [Thread-1  ]: finished collecting timing info
15:00:25.947944 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
15:00:26.128135 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c4effbce-ea3e-4622-95e8-a0913f7b6db3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110842fa0>]}
15:00:26.128817 [info ] [Thread-1  ]: 6 of 7 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.04s]
15:00:26.129326 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
15:00:26.129572 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
15:00:26.129889 [info ] [Thread-1  ]: 7 of 7 START table model dbt.my_second_dbt_model................................ [RUN]
15:00:26.130517 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
15:00:26.130711 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
15:00:26.130892 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
15:00:26.134275 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
15:00:26.136178 [debug] [Thread-1  ]: finished collecting timing info
15:00:26.136382 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
15:00:26.139054 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
15:00:26.140033 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
15:00:26.140357 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
/*
union all
select 7 as id, True as first_variable
*/
      );
15:00:26.140576 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:00:27.926725 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.79 seconds
15:00:27.929603 [debug] [Thread-1  ]: finished collecting timing info
15:00:27.930062 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
15:00:28.128319 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c4effbce-ea3e-4622-95e8-a0913f7b6db3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1055ad640>]}
15:00:28.128806 [info ] [Thread-1  ]: 7 of 7 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 2.00s]
15:00:28.129276 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
15:00:28.130684 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:00:28.130985 [info ] [MainThread]: 
15:00:28.131305 [info ] [MainThread]: Running 3 on-run-end hooks
15:00:28.131639 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-0
15:00:28.133503 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-0"
15:00:28.136690 [info ] [MainThread]: 1 of 3 START hook: learn_dbt.on-run-end.0....................................... [RUN]
15:00:28.137363 [debug] [MainThread]: Using snowflake connection "master"
15:00:28.137548 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
15:00:28.137703 [debug] [MainThread]: Opening a new connection, currently in state closed
15:00:28.706725 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.57 seconds
15:00:28.708784 [info ] [MainThread]: 1 of 3 OK hook: learn_dbt.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.57s]
15:00:28.709442 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-1
15:00:28.711191 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-1"
15:00:28.713605 [info ] [MainThread]: 2 of 3 START hook: learn_dbt.on-run-end.1....................................... [RUN]
15:00:28.714369 [debug] [MainThread]: Using snowflake connection "master"
15:00:28.714547 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
15:00:29.129184 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.41 seconds
15:00:29.131451 [info ] [MainThread]: 2 of 3 OK hook: learn_dbt.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.42s]
15:00:29.132100 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-2
15:00:29.134190 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-2"
15:00:29.136685 [info ] [MainThread]: 3 of 3 START hook: learn_dbt.on-run-end.2....................................... [RUN]
15:00:29.137369 [debug] [MainThread]: Using snowflake connection "master"
15:00:29.137545 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
15:00:29.380184 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.24 seconds
15:00:29.384291 [info ] [MainThread]: 3 of 3 OK hook: learn_dbt.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.25s]
15:00:29.385159 [info ] [MainThread]: 
15:00:29.385876 [debug] [MainThread]: On master: Close
15:00:29.578771 [info ] [MainThread]: 
15:00:29.579358 [info ] [MainThread]: Finished running 2 incremental models, 1 view model, 4 table models, 4 hooks in 23.77s.
15:00:29.579730 [debug] [MainThread]: Connection 'master' was properly closed.
15:00:29.579913 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
15:00:29.588410 [info ] [MainThread]: 
15:00:29.588756 [info ] [MainThread]: [32mCompleted successfully[0m
15:00:29.589350 [info ] [MainThread]: 
15:00:29.589625 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
15:00:29.589980 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104fa68b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105639ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075dcfa0>]}


============================== 2022-05-16 15:05:43.584653 | 5387b42c-3425-4d83-ae24-b916ffcf3ff9 ==============================
15:05:43.584653 [info ] [MainThread]: Running with dbt=1.0.1
15:05:43.585304 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
15:05:43.585415 [debug] [MainThread]: Tracking: tracking
15:05:43.585638 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104883850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1048831c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104883ee0>]}
15:05:43.620675 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
15:05:43.620886 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '5387b42c-3425-4d83-ae24-b916ffcf3ff9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1048895b0>]}
15:05:43.636675 [debug] [MainThread]: Parsing macros/catalog.sql
15:05:43.637838 [debug] [MainThread]: Parsing macros/adapters.sql
15:05:43.657525 [debug] [MainThread]: Parsing macros/materializations/merge.sql
15:05:43.659330 [debug] [MainThread]: Parsing macros/materializations/seed.sql
15:05:43.661732 [debug] [MainThread]: Parsing macros/materializations/view.sql
15:05:43.662535 [debug] [MainThread]: Parsing macros/materializations/table.sql
15:05:43.664106 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
15:05:43.668134 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
15:05:43.668572 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
15:05:43.670314 [debug] [MainThread]: Parsing macros/materializations/configs.sql
15:05:43.671325 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
15:05:43.672270 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
15:05:43.680436 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
15:05:43.686037 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
15:05:43.691843 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
15:05:43.693913 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
15:05:43.694778 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
15:05:43.695592 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
15:05:43.697581 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
15:05:43.702948 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
15:05:43.703625 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
15:05:43.708457 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
15:05:43.716365 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
15:05:43.720027 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
15:05:43.721311 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
15:05:43.724811 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
15:05:43.725381 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
15:05:43.726591 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
15:05:43.727596 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
15:05:43.730553 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
15:05:43.738544 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
15:05:43.739226 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
15:05:43.740327 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
15:05:43.741027 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
15:05:43.741428 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
15:05:43.741661 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
15:05:43.741963 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
15:05:43.742568 [debug] [MainThread]: Parsing macros/etc/statement.sql
15:05:43.744587 [debug] [MainThread]: Parsing macros/etc/datetime.sql
15:05:43.748820 [debug] [MainThread]: Parsing macros/adapters/schema.sql
15:05:43.749774 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
15:05:43.750951 [debug] [MainThread]: Parsing macros/adapters/relation.sql
15:05:43.755305 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
15:05:43.756580 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
15:05:43.758558 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
15:05:43.762020 [debug] [MainThread]: Parsing macros/adapters/columns.sql
15:05:43.766784 [debug] [MainThread]: Parsing tests/generic/builtin.sql
15:05:43.860338 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
15:05:43.867523 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
15:05:43.868224 [debug] [MainThread]: 1699: static parser successfully parsed example/playing_with_tests.sql
15:05:43.870188 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_cumulative_sales.sql
15:05:43.873096 [debug] [MainThread]: 1603: static parser failed on example/my_second_dbt_model.sql
15:05:43.874990 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_second_dbt_model.sql
15:05:43.875527 [debug] [MainThread]: 1603: static parser failed on example/incremental_time.sql
15:05:43.879144 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_time.sql
15:05:43.879750 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
15:05:43.881929 [debug] [MainThread]: 1603: static parser failed on new/dates.sql
15:05:43.883543 [debug] [MainThread]: 1602: parser fallback to jinja rendering on new/dates.sql
15:05:43.938642 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5387b42c-3425-4d83-ae24-b916ffcf3ff9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10490f280>]}
15:05:43.941964 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5387b42c-3425-4d83-ae24-b916ffcf3ff9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104901ee0>]}
15:05:43.942094 [info ] [MainThread]: Found 7 models, 12 tests, 0 snapshots, 0 analyses, 179 macros, 4 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
15:05:43.942929 [info ] [MainThread]: 
15:05:43.943136 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:05:43.943621 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
15:05:43.949611 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
15:05:43.949742 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
15:05:43.949810 [debug] [ThreadPool]: Opening a new connection, currently in state init
15:05:44.732172 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.78 seconds
15:05:44.734826 [debug] [ThreadPool]: On list_analytics: Close
15:05:44.940376 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
15:05:44.946370 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
15:05:44.946656 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
15:05:44.946816 [debug] [ThreadPool]: Opening a new connection, currently in state closed
15:05:45.748486 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 0.8 seconds
15:05:45.751504 [debug] [ThreadPool]: On list_analytics_dbt: Close
15:05:45.937030 [info ] [MainThread]: 
15:05:45.937670 [info ] [MainThread]: Running 1 on-run-start hook
15:05:45.938344 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-start-0
15:05:45.939953 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-start-0"
15:05:45.941746 [info ] [MainThread]: 1 of 1 START hook: learn_dbt.on-run-start.0..................................... [RUN]
15:05:45.942335 [debug] [MainThread]: Using snowflake connection "master"
15:05:45.942496 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
15:05:45.942634 [debug] [MainThread]: Opening a new connection, currently in state init
15:05:46.496187 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.55 seconds
15:05:46.497658 [info ] [MainThread]: 1 of 1 OK hook: learn_dbt.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.56s]
15:05:46.498085 [info ] [MainThread]: 
15:05:46.498473 [debug] [MainThread]: On master: Close
15:05:47.066781 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
15:05:47.067598 [info ] [MainThread]: 
15:05:47.073078 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
15:05:47.073588 [info ] [Thread-1  ]: 1 of 7 START incremental model dbt.dates........................................ [RUN]
15:05:47.075782 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
15:05:47.076096 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
15:05:47.076282 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
15:05:47.079606 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
15:05:47.080559 [debug] [Thread-1  ]: finished collecting timing info
15:05:47.080812 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
15:05:47.112325 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
15:05:47.112564 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
15:05:47.112658 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:05:48.562111 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.45 seconds
15:05:48.574869 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
15:05:48.575266 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
15:05:48.693500 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.12 seconds
15:05:48.701136 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
15:05:48.701541 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
15:05:48.830152 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.13 seconds
15:05:48.836218 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
15:05:48.836483 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
15:05:48.945456 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.11 seconds
15:05:48.971823 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
15:05:48.975829 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
15:05:48.976019 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
15:05:49.094826 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.12 seconds
15:05:49.095665 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
15:05:49.095857 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
15:05:49.653564 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.56 seconds
15:05:49.654101 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
15:05:49.654250 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
15:05:49.830936 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.18 seconds
15:05:49.845460 [debug] [Thread-1  ]: finished collecting timing info
15:05:49.845765 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
15:05:50.020202 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5387b42c-3425-4d83-ae24-b916ffcf3ff9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104ddc7c0>]}
15:05:50.020919 [info ] [Thread-1  ]: 1 of 7 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 2.95s]
15:05:50.021271 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
15:05:50.021455 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
15:05:50.021826 [info ] [Thread-1  ]: 2 of 7 START incremental model dbt.incremental_time............................. [RUN]
15:05:50.022234 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
15:05:50.022387 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
15:05:50.022534 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
15:05:50.026049 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
15:05:50.028340 [debug] [Thread-1  ]: finished collecting timing info
15:05:50.028562 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
15:05:50.034175 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
15:05:50.034386 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

        insert into dbt.audit (model, state, time values ('incremental_time', 'starting model deployment', current_timestamp)
15:05:50.034531 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:05:50.872935 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a44e89-3201-9e2f-0000-00012052b2a9
15:05:50.873472 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 1 at position 42 unexpected 'values'.
15:05:50.873898 [debug] [Thread-1  ]: finished collecting timing info
15:05:50.874153 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
15:05:51.068027 [debug] [Thread-1  ]: Database Error in model incremental_time (models/example/incremental_time.sql)
  001003 (42000): SQL compilation error:
  syntax error line 1 at position 42 unexpected 'values'.
15:05:51.068836 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5387b42c-3425-4d83-ae24-b916ffcf3ff9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106d936d0>]}
15:05:51.069572 [error] [Thread-1  ]: 2 of 7 ERROR creating incremental model dbt.incremental_time.................... [[31mERROR[0m in 1.05s]
15:05:51.070044 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
15:05:51.070289 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
15:05:51.070787 [info ] [Thread-1  ]: 3 of 7 START view model dbt.first_model......................................... [RUN]
15:05:51.071536 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
15:05:51.071764 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
15:05:51.071991 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
15:05:51.076521 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
15:05:51.077251 [debug] [Thread-1  ]: finished collecting timing info
15:05:51.077441 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
15:05:51.088898 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
15:05:51.089128 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */

        insert into dbt.audit (model, state, time values ('first_model', 'starting model deployment', current_timestamp)
15:05:51.089263 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:05:51.660025 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a44e89-3201-9e2f-0000-00012052b2ad
15:05:51.660458 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 1 at position 42 unexpected 'values'.
15:05:51.660845 [debug] [Thread-1  ]: finished collecting timing info
15:05:51.661084 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
15:05:51.846868 [debug] [Thread-1  ]: Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  001003 (42000): SQL compilation error:
  syntax error line 1 at position 42 unexpected 'values'.
15:05:51.848117 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5387b42c-3425-4d83-ae24-b916ffcf3ff9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106d95af0>]}
15:05:51.848349 [error] [Thread-1  ]: 3 of 7 ERROR creating view model dbt.first_model................................ [[31mERROR[0m in 0.78s]
15:05:51.848522 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
15:05:51.848623 [debug] [Thread-1  ]: Began running node model.learn_dbt.playing_with_tests
15:05:51.848722 [info ] [Thread-1  ]: 4 of 7 START table model dbt.playing_with_tests................................. [RUN]
15:05:51.848934 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.playing_with_tests"
15:05:51.849002 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.playing_with_tests
15:05:51.849072 [debug] [Thread-1  ]: Compiling model.learn_dbt.playing_with_tests
15:05:51.849759 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.playing_with_tests"
15:05:51.850373 [debug] [Thread-1  ]: finished collecting timing info
15:05:51.850479 [debug] [Thread-1  ]: Began executing node model.learn_dbt.playing_with_tests
15:05:51.859729 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
15:05:51.859992 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */

        insert into dbt.audit (model, state, time values ('playing_with_tests', 'starting model deployment', current_timestamp)
15:05:51.860129 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:05:52.381256 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a44e89-3201-9e2f-0000-00012052b2b1
15:05:52.381738 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 1 at position 42 unexpected 'values'.
15:05:52.382189 [debug] [Thread-1  ]: finished collecting timing info
15:05:52.382491 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: Close
15:05:52.548730 [debug] [Thread-1  ]: Database Error in model playing_with_tests (models/example/playing_with_tests.sql)
  001003 (42000): SQL compilation error:
  syntax error line 1 at position 42 unexpected 'values'.
15:05:52.549093 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5387b42c-3425-4d83-ae24-b916ffcf3ff9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e97400>]}
15:05:52.549360 [error] [Thread-1  ]: 4 of 7 ERROR creating table model dbt.playing_with_tests........................ [[31mERROR[0m in 0.70s]
15:05:52.549581 [debug] [Thread-1  ]: Finished running node model.learn_dbt.playing_with_tests
15:05:52.549701 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
15:05:52.549943 [info ] [Thread-1  ]: 5 of 7 START table model dbt.snowflake_cumulative_sales......................... [RUN]
15:05:52.550282 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
15:05:52.550401 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
15:05:52.550522 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
15:05:52.552509 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
15:05:52.554574 [debug] [Thread-1  ]: finished collecting timing info
15:05:52.554777 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
15:05:52.559635 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
15:05:52.559880 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */

        insert into dbt.audit (model, state, time values ('snowflake_cumulative_sales', 'starting model deployment', current_timestamp)
15:05:52.560037 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:05:53.077516 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a44e89-3201-9e4e-0000-00012052a449
15:05:53.078565 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 1 at position 42 unexpected 'values'.
15:05:53.079240 [debug] [Thread-1  ]: finished collecting timing info
15:05:53.079508 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
15:05:53.278749 [debug] [Thread-1  ]: Database Error in model snowflake_cumulative_sales (models/example/snowflake_cumulative_sales.sql)
  001003 (42000): SQL compilation error:
  syntax error line 1 at position 42 unexpected 'values'.
15:05:53.279303 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5387b42c-3425-4d83-ae24-b916ffcf3ff9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104d577c0>]}
15:05:53.279824 [error] [Thread-1  ]: 5 of 7 ERROR creating table model dbt.snowflake_cumulative_sales................ [[31mERROR[0m in 0.73s]
15:05:53.280274 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
15:05:53.280530 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
15:05:53.280963 [info ] [Thread-1  ]: 6 of 7 START table model dbt.snowflake_customer_purchases....................... [RUN]
15:05:53.281495 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
15:05:53.281694 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
15:05:53.281884 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
15:05:53.283599 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
15:05:53.286402 [debug] [Thread-1  ]: finished collecting timing info
15:05:53.286592 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
15:05:53.290720 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
15:05:53.290944 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */

        insert into dbt.audit (model, state, time values ('snowflake_customer_purchases', 'starting model deployment', current_timestamp)
15:05:53.291082 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:05:53.791594 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a44e89-3201-9e4e-0000-00012052a44d
15:05:53.792176 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 1 at position 42 unexpected 'values'.
15:05:53.792547 [debug] [Thread-1  ]: finished collecting timing info
15:05:53.792773 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
15:05:53.949724 [debug] [Thread-1  ]: Database Error in model snowflake_customer_purchases (models/example/snowflake_customer_purchases.sql)
  001003 (42000): SQL compilation error:
  syntax error line 1 at position 42 unexpected 'values'.
15:05:53.950562 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5387b42c-3425-4d83-ae24-b916ffcf3ff9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104d89b80>]}
15:05:53.951151 [error] [Thread-1  ]: 6 of 7 ERROR creating table model dbt.snowflake_customer_purchases.............. [[31mERROR[0m in 0.67s]
15:05:53.951625 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
15:05:53.951886 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
15:05:53.952298 [info ] [Thread-1  ]: 7 of 7 SKIP relation dbt.my_second_dbt_model.................................... [[33mSKIP[0m]
15:05:53.952788 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
15:05:53.954281 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:05:53.954586 [info ] [MainThread]: 
15:05:53.954910 [info ] [MainThread]: Running 3 on-run-end hooks
15:05:53.955240 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-0
15:05:53.956806 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-0"
15:05:53.959746 [info ] [MainThread]: 1 of 3 START hook: learn_dbt.on-run-end.0....................................... [RUN]
15:05:53.960334 [debug] [MainThread]: Using snowflake connection "master"
15:05:53.960499 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
15:05:53.960642 [debug] [MainThread]: Opening a new connection, currently in state closed
15:05:54.503131 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.54 seconds
15:05:54.504487 [info ] [MainThread]: 1 of 3 OK hook: learn_dbt.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.54s]
15:05:54.504901 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-1
15:05:54.506574 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-1"
15:05:54.509312 [info ] [MainThread]: 2 of 3 START hook: learn_dbt.on-run-end.1....................................... [RUN]
15:05:54.510074 [debug] [MainThread]: Using snowflake connection "master"
15:05:54.510282 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
15:05:54.642764 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.13 seconds
15:05:54.644730 [info ] [MainThread]: 2 of 3 OK hook: learn_dbt.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.13s]
15:05:54.645622 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-2
15:05:54.647750 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-2"
15:05:54.649770 [info ] [MainThread]: 3 of 3 START hook: learn_dbt.on-run-end.2....................................... [RUN]
15:05:54.650515 [debug] [MainThread]: Using snowflake connection "master"
15:05:54.650727 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
15:05:54.764714 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.11 seconds
15:05:54.765503 [info ] [MainThread]: 3 of 3 OK hook: learn_dbt.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.12s]
15:05:54.765741 [info ] [MainThread]: 
15:05:54.765926 [debug] [MainThread]: On master: Close
15:05:54.934307 [info ] [MainThread]: 
15:05:54.935037 [info ] [MainThread]: Finished running 2 incremental models, 1 view model, 4 table models, 4 hooks in 10.99s.
15:05:54.935379 [debug] [MainThread]: Connection 'master' was properly closed.
15:05:54.935558 [debug] [MainThread]: Connection 'model.learn_dbt.snowflake_customer_purchases' was properly closed.
15:05:54.980569 [info ] [MainThread]: 
15:05:54.980808 [info ] [MainThread]: [31mCompleted with 5 errors and 0 warnings:[0m
15:05:54.980965 [info ] [MainThread]: 
15:05:54.981091 [error] [MainThread]: [33mDatabase Error in model incremental_time (models/example/incremental_time.sql)[0m
15:05:54.981216 [error] [MainThread]:   001003 (42000): SQL compilation error:
15:05:54.981330 [error] [MainThread]:   syntax error line 1 at position 42 unexpected 'values'.
15:05:54.981445 [info ] [MainThread]: 
15:05:54.981558 [error] [MainThread]: [33mDatabase Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)[0m
15:05:54.981672 [error] [MainThread]:   001003 (42000): SQL compilation error:
15:05:54.981782 [error] [MainThread]:   syntax error line 1 at position 42 unexpected 'values'.
15:05:54.981894 [info ] [MainThread]: 
15:05:54.982007 [error] [MainThread]: [33mDatabase Error in model playing_with_tests (models/example/playing_with_tests.sql)[0m
15:05:54.982119 [error] [MainThread]:   001003 (42000): SQL compilation error:
15:05:54.982229 [error] [MainThread]:   syntax error line 1 at position 42 unexpected 'values'.
15:05:54.982340 [info ] [MainThread]: 
15:05:54.982451 [error] [MainThread]: [33mDatabase Error in model snowflake_cumulative_sales (models/example/snowflake_cumulative_sales.sql)[0m
15:05:54.982562 [error] [MainThread]:   001003 (42000): SQL compilation error:
15:05:54.982676 [error] [MainThread]:   syntax error line 1 at position 42 unexpected 'values'.
15:05:54.982792 [info ] [MainThread]: 
15:05:54.982907 [error] [MainThread]: [33mDatabase Error in model snowflake_customer_purchases (models/example/snowflake_customer_purchases.sql)[0m
15:05:54.983020 [error] [MainThread]:   001003 (42000): SQL compilation error:
15:05:54.983131 [error] [MainThread]:   syntax error line 1 at position 42 unexpected 'values'.
15:05:54.983248 [info ] [MainThread]: 
15:05:54.983370 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=5 SKIP=1 TOTAL=7
15:05:54.983549 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104cf5dc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104da2af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106d75820>]}


============================== 2022-05-16 15:07:55.572565 | 422092f8-24e8-4cb8-aec5-d850f9f423dc ==============================
15:07:55.572565 [info ] [MainThread]: Running with dbt=1.0.1
15:07:55.573141 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
15:07:55.573266 [debug] [MainThread]: Tracking: tracking
15:07:55.573493 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10632b4c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10632b460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10632b8b0>]}
15:07:55.607351 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
15:07:55.607564 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '422092f8-24e8-4cb8-aec5-d850f9f423dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1063308e0>]}
15:07:55.623952 [debug] [MainThread]: Parsing macros/catalog.sql
15:07:55.625135 [debug] [MainThread]: Parsing macros/adapters.sql
15:07:55.644552 [debug] [MainThread]: Parsing macros/materializations/merge.sql
15:07:55.646328 [debug] [MainThread]: Parsing macros/materializations/seed.sql
15:07:55.648708 [debug] [MainThread]: Parsing macros/materializations/view.sql
15:07:55.649295 [debug] [MainThread]: Parsing macros/materializations/table.sql
15:07:55.650706 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
15:07:55.654692 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
15:07:55.655115 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
15:07:55.656814 [debug] [MainThread]: Parsing macros/materializations/configs.sql
15:07:55.657815 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
15:07:55.658548 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
15:07:55.666601 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
15:07:55.672192 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
15:07:55.677940 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
15:07:55.680072 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
15:07:55.680965 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
15:07:55.681781 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
15:07:55.683822 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
15:07:55.689194 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
15:07:55.689878 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
15:07:55.694675 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
15:07:55.702504 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
15:07:55.706146 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
15:07:55.707408 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
15:07:55.710904 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
15:07:55.711504 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
15:07:55.712856 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
15:07:55.713882 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
15:07:55.716713 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
15:07:55.724553 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
15:07:55.725208 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
15:07:55.726304 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
15:07:55.727201 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
15:07:55.727747 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
15:07:55.728016 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
15:07:55.728338 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
15:07:55.728987 [debug] [MainThread]: Parsing macros/etc/statement.sql
15:07:55.731036 [debug] [MainThread]: Parsing macros/etc/datetime.sql
15:07:55.735259 [debug] [MainThread]: Parsing macros/adapters/schema.sql
15:07:55.736221 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
15:07:55.737664 [debug] [MainThread]: Parsing macros/adapters/relation.sql
15:07:55.742243 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
15:07:55.743547 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
15:07:55.745511 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
15:07:55.749010 [debug] [MainThread]: Parsing macros/adapters/columns.sql
15:07:55.753589 [debug] [MainThread]: Parsing tests/generic/builtin.sql
15:07:55.845385 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
15:07:55.852379 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
15:07:55.853072 [debug] [MainThread]: 1699: static parser successfully parsed example/playing_with_tests.sql
15:07:55.855045 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_cumulative_sales.sql
15:07:55.856902 [debug] [MainThread]: 1603: static parser failed on example/my_second_dbt_model.sql
15:07:55.858712 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_second_dbt_model.sql
15:07:55.859241 [debug] [MainThread]: 1603: static parser failed on example/incremental_time.sql
15:07:55.862806 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_time.sql
15:07:55.863330 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
15:07:55.865424 [debug] [MainThread]: 1603: static parser failed on new/dates.sql
15:07:55.867024 [debug] [MainThread]: 1602: parser fallback to jinja rendering on new/dates.sql
15:07:55.921927 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '422092f8-24e8-4cb8-aec5-d850f9f423dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1063b72b0>]}
15:07:55.925141 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '422092f8-24e8-4cb8-aec5-d850f9f423dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1063b4160>]}
15:07:55.925267 [info ] [MainThread]: Found 7 models, 12 tests, 0 snapshots, 0 analyses, 179 macros, 4 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
15:07:55.926102 [info ] [MainThread]: 
15:07:55.926330 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:07:55.926808 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
15:07:55.932859 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
15:07:55.933043 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
15:07:55.933118 [debug] [ThreadPool]: Opening a new connection, currently in state init
15:07:57.097259 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.16 seconds
15:07:57.099802 [debug] [ThreadPool]: On list_analytics: Close
15:07:57.576073 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
15:07:57.584827 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
15:07:57.585141 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
15:07:57.585314 [debug] [ThreadPool]: Opening a new connection, currently in state closed
15:07:59.268903 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 1.68 seconds
15:07:59.273250 [debug] [ThreadPool]: On list_analytics_dbt: Close
15:07:59.793863 [info ] [MainThread]: 
15:07:59.794438 [info ] [MainThread]: Running 1 on-run-start hook
15:07:59.794829 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-start-0
15:07:59.796643 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-start-0"
15:07:59.799899 [info ] [MainThread]: 1 of 1 START hook: learn_dbt.on-run-start.0..................................... [RUN]
15:07:59.800480 [debug] [MainThread]: Using snowflake connection "master"
15:07:59.800634 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
15:07:59.800772 [debug] [MainThread]: Opening a new connection, currently in state init
15:08:00.645954 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.85 seconds
15:08:00.648072 [info ] [MainThread]: 1 of 1 OK hook: learn_dbt.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.85s]
15:08:00.648631 [info ] [MainThread]: 
15:08:00.649062 [debug] [MainThread]: On master: Close
15:08:00.861497 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
15:08:00.862079 [info ] [MainThread]: 
15:08:00.865393 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
15:08:00.865594 [info ] [Thread-1  ]: 1 of 7 START incremental model dbt.dates........................................ [RUN]
15:08:00.866570 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
15:08:00.866682 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
15:08:00.866765 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
15:08:00.869482 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
15:08:00.870250 [debug] [Thread-1  ]: finished collecting timing info
15:08:00.870353 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
15:08:00.891523 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
15:08:00.891680 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
15:08:00.891749 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:08:03.266882 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.38 seconds
15:08:03.280611 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
15:08:03.280933 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
15:08:03.399324 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.12 seconds
15:08:03.406995 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
15:08:03.407326 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
15:08:03.507620 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.1 seconds
15:08:03.519543 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
15:08:03.519843 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
15:08:03.794997 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.27 seconds
15:08:03.821596 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
15:08:03.825378 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
15:08:03.825572 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
15:08:03.937757 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.11 seconds
15:08:03.939099 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
15:08:03.939383 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
15:08:04.316145 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.38 seconds
15:08:04.316815 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
15:08:04.317041 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
15:08:04.523194 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.21 seconds
15:08:04.536367 [debug] [Thread-1  ]: finished collecting timing info
15:08:04.536898 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
15:08:04.842773 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '422092f8-24e8-4cb8-aec5-d850f9f423dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106896100>]}
15:08:04.843467 [info ] [Thread-1  ]: 1 of 7 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 3.98s]
15:08:04.843924 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
15:08:04.844209 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
15:08:04.844677 [info ] [Thread-1  ]: 2 of 7 START incremental model dbt.incremental_time............................. [RUN]
15:08:04.845550 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
15:08:04.845787 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
15:08:04.845993 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
15:08:04.849722 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
15:08:04.851753 [debug] [Thread-1  ]: finished collecting timing info
15:08:04.852055 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
15:08:04.857105 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
15:08:04.857275 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

        insert into dbt.audit (model, state, time) values ('incremental_time', 'starting model deployment', current_timestamp)
15:08:04.857408 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:08:06.282809 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.43 seconds
15:08:06.287256 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
15:08:06.287646 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
15:08:07.158179 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.87 seconds
15:08:07.162502 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
15:08:07.162729 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
15:08:07.333367 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.17 seconds
15:08:07.339326 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
15:08:07.339668 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
15:08:07.445319 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.11 seconds
15:08:07.447868 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
15:08:07.448076 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
15:08:07.548424 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
15:08:07.554205 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
15:08:07.558372 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
15:08:07.558702 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
15:08:07.704193 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.15 seconds
15:08:07.705938 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
15:08:07.706949 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
15:08:08.412619 [debug] [Thread-1  ]: SQL status: SUCCESS 473 in 0.71 seconds
15:08:08.413153 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
15:08:08.413339 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
15:08:08.712071 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.3 seconds
15:08:08.715059 [debug] [Thread-1  ]: finished collecting timing info
15:08:08.715521 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
15:08:09.037380 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '422092f8-24e8-4cb8-aec5-d850f9f423dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106872490>]}
15:08:09.039610 [info ] [Thread-1  ]: 2 of 7 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 4.19s]
15:08:09.040273 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
15:08:09.043130 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
15:08:09.043630 [info ] [Thread-1  ]: 3 of 7 START view model dbt.first_model......................................... [RUN]
15:08:09.043915 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
15:08:09.044000 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
15:08:09.044079 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
15:08:09.045833 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
15:08:09.046213 [debug] [Thread-1  ]: finished collecting timing info
15:08:09.046293 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
15:08:09.052064 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
15:08:09.052197 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('first_model', 'starting model deployment', current_timestamp)
15:08:09.052264 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:08:10.747177 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.69 seconds
15:08:10.760963 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
15:08:10.762205 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
15:08:10.762369 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */

  create or replace  view analytics.dbt.first_model 
  
   as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id

)

select * 
from source_data


/*
select *, True as first_variable
from source_data
where id >= 1
*/
  );
15:08:10.951268 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.19 seconds
15:08:10.954770 [debug] [Thread-1  ]: finished collecting timing info
15:08:10.955118 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
15:08:11.222185 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '422092f8-24e8-4cb8-aec5-d850f9f423dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068729d0>]}
15:08:11.223058 [info ] [Thread-1  ]: 3 of 7 OK created view model dbt.first_model.................................... [[32mSUCCESS 1[0m in 2.18s]
15:08:11.223529 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
15:08:11.223793 [debug] [Thread-1  ]: Began running node model.learn_dbt.playing_with_tests
15:08:11.224545 [info ] [Thread-1  ]: 4 of 7 START table model dbt.playing_with_tests................................. [RUN]
15:08:11.225469 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.playing_with_tests"
15:08:11.225775 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.playing_with_tests
15:08:11.225985 [debug] [Thread-1  ]: Compiling model.learn_dbt.playing_with_tests
15:08:11.227933 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.playing_with_tests"
15:08:11.228658 [debug] [Thread-1  ]: finished collecting timing info
15:08:11.228833 [debug] [Thread-1  ]: Began executing node model.learn_dbt.playing_with_tests
15:08:11.239919 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
15:08:11.240095 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */

        insert into dbt.audit (model, state, time) values ('playing_with_tests', 'starting model deployment', current_timestamp)
15:08:11.240221 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:08:12.312034 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.07 seconds
15:08:12.316278 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.playing_with_tests"
15:08:12.317452 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
15:08:12.317651 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */


      create or replace transient table analytics.dbt.playing_with_tests  as
      (select * 
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER"
      );
15:08:13.626634 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.31 seconds
15:08:13.630587 [debug] [Thread-1  ]: finished collecting timing info
15:08:13.630791 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: Close
15:08:13.823151 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '422092f8-24e8-4cb8-aec5-d850f9f423dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1098954f0>]}
15:08:13.823931 [info ] [Thread-1  ]: 4 of 7 OK created table model dbt.playing_with_tests............................ [[32mSUCCESS 1[0m in 2.60s]
15:08:13.824593 [debug] [Thread-1  ]: Finished running node model.learn_dbt.playing_with_tests
15:08:13.824975 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
15:08:13.825430 [info ] [Thread-1  ]: 5 of 7 START table model dbt.snowflake_cumulative_sales......................... [RUN]
15:08:13.826074 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
15:08:13.826290 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
15:08:13.826487 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
15:08:13.828161 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
15:08:13.828789 [debug] [Thread-1  ]: finished collecting timing info
15:08:13.828996 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
15:08:13.833095 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
15:08:13.833336 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */

        insert into dbt.audit (model, state, time) values ('snowflake_cumulative_sales', 'starting model deployment', current_timestamp)
15:08:13.833498 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:08:15.145178 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.31 seconds
15:08:15.147637 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
15:08:15.149006 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
15:08:15.149222 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
15:08:15.963882 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.81 seconds
15:08:15.966862 [debug] [Thread-1  ]: finished collecting timing info
15:08:15.967282 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
15:08:16.120939 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '422092f8-24e8-4cb8-aec5-d850f9f423dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1086cb490>]}
15:08:16.121688 [info ] [Thread-1  ]: 5 of 7 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 2.29s]
15:08:16.122144 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
15:08:16.122394 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
15:08:16.122925 [info ] [Thread-1  ]: 6 of 7 START table model dbt.snowflake_customer_purchases....................... [RUN]
15:08:16.123691 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
15:08:16.123920 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
15:08:16.124130 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
15:08:16.125959 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
15:08:16.126587 [debug] [Thread-1  ]: finished collecting timing info
15:08:16.126756 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
15:08:16.130629 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
15:08:16.130893 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */

        insert into dbt.audit (model, state, time) values ('snowflake_customer_purchases', 'starting model deployment', current_timestamp)
15:08:16.131052 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:08:17.105213 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.97 seconds
15:08:17.108282 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
15:08:17.111164 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
15:08:17.111489 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
15:08:18.630795 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.52 seconds
15:08:18.634717 [debug] [Thread-1  ]: finished collecting timing info
15:08:18.635162 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
15:08:18.872012 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '422092f8-24e8-4cb8-aec5-d850f9f423dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109846250>]}
15:08:18.872993 [info ] [Thread-1  ]: 6 of 7 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.75s]
15:08:18.873481 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
15:08:18.873747 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
15:08:18.874367 [info ] [Thread-1  ]: 7 of 7 START table model dbt.my_second_dbt_model................................ [RUN]
15:08:18.875157 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
15:08:18.875385 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
15:08:18.875584 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
15:08:18.878846 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
15:08:18.880968 [debug] [Thread-1  ]: finished collecting timing info
15:08:18.881296 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
15:08:18.885516 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
15:08:18.885697 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('my_second_dbt_model', 'starting model deployment', current_timestamp)
15:08:18.885837 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:08:19.962870 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.08 seconds
15:08:19.965847 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
15:08:19.968979 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
15:08:19.969214 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
/*
union all
select 7 as id, True as first_variable
*/
      );
15:08:20.576270 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.61 seconds
15:08:20.579286 [debug] [Thread-1  ]: finished collecting timing info
15:08:20.579689 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
15:08:20.778817 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '422092f8-24e8-4cb8-aec5-d850f9f423dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1086e72e0>]}
15:08:20.779599 [info ] [Thread-1  ]: 7 of 7 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.90s]
15:08:20.780102 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
15:08:20.781677 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:08:20.782059 [info ] [MainThread]: 
15:08:20.782424 [info ] [MainThread]: Running 3 on-run-end hooks
15:08:20.782772 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-0
15:08:20.784519 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-0"
15:08:20.785639 [info ] [MainThread]: 1 of 3 START hook: learn_dbt.on-run-end.0....................................... [RUN]
15:08:20.786213 [debug] [MainThread]: Using snowflake connection "master"
15:08:20.786370 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
15:08:20.786513 [debug] [MainThread]: Opening a new connection, currently in state closed
15:08:21.430032 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.64 seconds
15:08:21.431748 [info ] [MainThread]: 1 of 3 OK hook: learn_dbt.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.65s]
15:08:21.432262 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-1
15:08:21.434273 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-1"
15:08:21.435447 [info ] [MainThread]: 2 of 3 START hook: learn_dbt.on-run-end.1....................................... [RUN]
15:08:21.436134 [debug] [MainThread]: Using snowflake connection "master"
15:08:21.436337 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
15:08:21.620635 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.18 seconds
15:08:21.622970 [info ] [MainThread]: 2 of 3 OK hook: learn_dbt.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.19s]
15:08:21.623264 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-2
15:08:21.624244 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-2"
15:08:21.624943 [info ] [MainThread]: 3 of 3 START hook: learn_dbt.on-run-end.2....................................... [RUN]
15:08:21.625241 [debug] [MainThread]: Using snowflake connection "master"
15:08:21.625320 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
15:08:21.770729 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.15 seconds
15:08:21.772895 [info ] [MainThread]: 3 of 3 OK hook: learn_dbt.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.15s]
15:08:21.773193 [info ] [MainThread]: 
15:08:21.773356 [debug] [MainThread]: On master: Close
15:08:22.058645 [info ] [MainThread]: 
15:08:22.059239 [info ] [MainThread]: Finished running 2 incremental models, 1 view model, 4 table models, 4 hooks in 26.13s.
15:08:22.059567 [debug] [MainThread]: Connection 'master' was properly closed.
15:08:22.059742 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
15:08:22.067626 [info ] [MainThread]: 
15:08:22.068052 [info ] [MainThread]: [32mCompleted successfully[0m
15:08:22.068357 [info ] [MainThread]: 
15:08:22.068598 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
15:08:22.068893 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106872e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106405880>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1086cba90>]}


============================== 2022-05-16 15:12:37.951192 | 5d71d778-9638-4193-a72b-d9482fd92d60 ==============================
15:12:37.951192 [info ] [MainThread]: Running with dbt=1.0.1
15:12:37.951713 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
15:12:37.951827 [debug] [MainThread]: Tracking: tracking
15:12:37.952033 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10498fbb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10498f610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10498ffa0>]}
15:12:37.986595 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
15:12:37.986819 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '5d71d778-9638-4193-a72b-d9482fd92d60', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10496f520>]}
15:12:38.000663 [debug] [MainThread]: Parsing macros/catalog.sql
15:12:38.001838 [debug] [MainThread]: Parsing macros/adapters.sql
15:12:38.021749 [debug] [MainThread]: Parsing macros/materializations/merge.sql
15:12:38.023584 [debug] [MainThread]: Parsing macros/materializations/seed.sql
15:12:38.025952 [debug] [MainThread]: Parsing macros/materializations/view.sql
15:12:38.026540 [debug] [MainThread]: Parsing macros/materializations/table.sql
15:12:38.027935 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
15:12:38.032225 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
15:12:38.032770 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
15:12:38.034580 [debug] [MainThread]: Parsing macros/materializations/configs.sql
15:12:38.035623 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
15:12:38.036390 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
15:12:38.044447 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
15:12:38.050241 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
15:12:38.056081 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
15:12:38.058119 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
15:12:38.058909 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
15:12:38.059703 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
15:12:38.061853 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
15:12:38.067296 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
15:12:38.068013 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
15:12:38.073091 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
15:12:38.080925 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
15:12:38.084839 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
15:12:38.086148 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
15:12:38.089687 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
15:12:38.090263 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
15:12:38.091478 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
15:12:38.092469 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
15:12:38.095220 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
15:12:38.103172 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
15:12:38.103850 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
15:12:38.104953 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
15:12:38.105642 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
15:12:38.106043 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
15:12:38.106275 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
15:12:38.106572 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
15:12:38.107194 [debug] [MainThread]: Parsing macros/etc/statement.sql
15:12:38.109235 [debug] [MainThread]: Parsing macros/etc/datetime.sql
15:12:38.113412 [debug] [MainThread]: Parsing macros/adapters/schema.sql
15:12:38.114400 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
15:12:38.115606 [debug] [MainThread]: Parsing macros/adapters/relation.sql
15:12:38.119963 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
15:12:38.121239 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
15:12:38.123186 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
15:12:38.126485 [debug] [MainThread]: Parsing macros/adapters/columns.sql
15:12:38.131096 [debug] [MainThread]: Parsing tests/generic/builtin.sql
15:12:38.224856 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
15:12:38.232188 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
15:12:38.233027 [debug] [MainThread]: 1699: static parser successfully parsed example/playing_with_tests.sql
15:12:38.235357 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_cumulative_sales.sql
15:12:38.237605 [debug] [MainThread]: 1603: static parser failed on example/my_second_dbt_model.sql
15:12:38.239884 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_second_dbt_model.sql
15:12:38.240472 [debug] [MainThread]: 1603: static parser failed on example/incremental_time.sql
15:12:38.244485 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_time.sql
15:12:38.245057 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
15:12:38.247570 [debug] [MainThread]: 1603: static parser failed on new/dates.sql
15:12:38.249127 [debug] [MainThread]: 1602: parser fallback to jinja rendering on new/dates.sql
15:12:38.303840 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5d71d778-9638-4193-a72b-d9482fd92d60', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c674c0>]}
15:12:38.307623 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5d71d778-9638-4193-a72b-d9482fd92d60', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c67250>]}
15:12:38.307756 [info ] [MainThread]: Found 7 models, 12 tests, 0 snapshots, 0 analyses, 179 macros, 4 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
15:12:38.308576 [info ] [MainThread]: 
15:12:38.308787 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:12:38.309267 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
15:12:38.315233 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
15:12:38.315338 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
15:12:38.315409 [debug] [ThreadPool]: Opening a new connection, currently in state init
15:12:39.571476 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.26 seconds
15:12:39.574154 [debug] [ThreadPool]: On list_analytics: Close
15:12:40.036095 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
15:12:40.042297 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
15:12:40.042553 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
15:12:40.042717 [debug] [ThreadPool]: Opening a new connection, currently in state closed
15:12:41.013547 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 0.97 seconds
15:12:41.016487 [debug] [ThreadPool]: On list_analytics_dbt: Close
15:12:41.334390 [info ] [MainThread]: 
15:12:41.335074 [info ] [MainThread]: Running 1 on-run-start hook
15:12:41.335460 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-start-0
15:12:41.337077 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-start-0"
15:12:41.339069 [info ] [MainThread]: 1 of 1 START hook: learn_dbt.on-run-start.0..................................... [RUN]
15:12:41.339734 [debug] [MainThread]: Using snowflake connection "master"
15:12:41.339919 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
15:12:41.340082 [debug] [MainThread]: Opening a new connection, currently in state init
15:12:42.058448 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.72 seconds
15:12:42.060412 [info ] [MainThread]: 1 of 1 OK hook: learn_dbt.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.72s]
15:12:42.060990 [info ] [MainThread]: 
15:12:42.061652 [debug] [MainThread]: On master: Close
15:12:42.252711 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
15:12:42.253438 [info ] [MainThread]: 
15:12:42.258742 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
15:12:42.259196 [info ] [Thread-1  ]: 1 of 7 START incremental model dbt.dates........................................ [RUN]
15:12:42.260116 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
15:12:42.260298 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
15:12:42.260473 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
15:12:42.266370 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
15:12:42.267054 [debug] [Thread-1  ]: finished collecting timing info
15:12:42.267224 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
15:12:42.298373 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
15:12:42.298560 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
15:12:42.298646 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:12:44.975218 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.68 seconds
15:12:44.988961 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
15:12:44.989298 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
15:12:45.858783 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.87 seconds
15:12:45.866060 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
15:12:45.866363 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
15:12:45.961159 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.09 seconds
15:12:45.973994 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
15:12:45.974344 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
15:12:46.090714 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.12 seconds
15:12:46.117475 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
15:12:46.120359 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
15:12:46.120583 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
15:12:46.253876 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.13 seconds
15:12:46.255158 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
15:12:46.255565 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
15:12:47.098342 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.84 seconds
15:12:47.099293 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
15:12:47.099585 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
15:12:47.300034 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.2 seconds
15:12:47.311109 [debug] [Thread-1  ]: finished collecting timing info
15:12:47.311451 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
15:12:47.559065 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5d71d778-9638-4193-a72b-d9482fd92d60', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c67520>]}
15:12:47.560649 [info ] [Thread-1  ]: 1 of 7 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 5.30s]
15:12:47.561063 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
15:12:47.561238 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
15:12:47.561532 [info ] [Thread-1  ]: 2 of 7 START incremental model dbt.incremental_time............................. [RUN]
15:12:47.561990 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
15:12:47.562131 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
15:12:47.562281 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
15:12:47.566596 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
15:12:47.567261 [debug] [Thread-1  ]: finished collecting timing info
15:12:47.567442 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
15:12:47.571406 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
15:12:47.571761 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

        insert into dbt.audit (model, state, time) values ('incremental_time', 'starting model deployment', current_timestamp)
15:12:47.571990 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:12:48.519743 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.95 seconds
15:12:48.521793 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
15:12:48.521958 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
15:12:49.508069 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.99 seconds
15:12:49.515720 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
15:12:49.516129 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
15:12:49.654046 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.14 seconds
15:12:49.658618 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
15:12:49.658864 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
15:12:49.801579 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.14 seconds
15:12:49.805117 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
15:12:49.805310 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
15:12:50.054983 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.25 seconds
15:12:50.058788 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
15:12:50.060706 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
15:12:50.060893 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
15:12:50.221977 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.16 seconds
15:12:50.222940 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
15:12:50.223163 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
15:12:50.913424 [debug] [Thread-1  ]: SQL status: SUCCESS 282 in 0.69 seconds
15:12:50.914059 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
15:12:50.914248 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
15:12:51.512514 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.6 seconds
15:12:51.517462 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
15:12:51.517787 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

        insert into dbt.audit (model, state, time) values ('incremental_time', 'ending model deployment', current_timestamp)
15:12:51.973540 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.46 seconds
15:12:51.978344 [debug] [Thread-1  ]: finished collecting timing info
15:12:51.978766 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
15:12:52.268110 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5d71d778-9638-4193-a72b-d9482fd92d60', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1062da0a0>]}
15:12:52.269071 [info ] [Thread-1  ]: 2 of 7 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 4.71s]
15:12:52.269681 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
15:12:52.270188 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
15:12:52.270811 [info ] [Thread-1  ]: 3 of 7 START view model dbt.first_model......................................... [RUN]
15:12:52.271535 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
15:12:52.271767 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
15:12:52.271980 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
15:12:52.276579 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
15:12:52.277395 [debug] [Thread-1  ]: finished collecting timing info
15:12:52.277592 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
15:12:52.289515 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
15:12:52.289747 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('first_model', 'starting model deployment', current_timestamp)
15:12:52.289873 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:12:53.219922 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.93 seconds
15:12:53.234632 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
15:12:53.236179 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
15:12:53.236342 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */

  create or replace  view analytics.dbt.first_model 
  
   as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id

)

select * 
from source_data


/*
select *, True as first_variable
from source_data
where id >= 1
*/
  );
15:12:53.475525 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.24 seconds
15:12:53.480007 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
15:12:53.480359 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('first_model', 'ending model deployment', current_timestamp)
15:12:53.941621 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.46 seconds
15:12:53.945260 [debug] [Thread-1  ]: finished collecting timing info
15:12:53.945652 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
15:12:54.249929 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5d71d778-9638-4193-a72b-d9482fd92d60', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106437d30>]}
15:12:54.251138 [info ] [Thread-1  ]: 3 of 7 OK created view model dbt.first_model.................................... [[32mSUCCESS 1[0m in 1.98s]
15:12:54.251496 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
15:12:54.251627 [debug] [Thread-1  ]: Began running node model.learn_dbt.playing_with_tests
15:12:54.251776 [info ] [Thread-1  ]: 4 of 7 START table model dbt.playing_with_tests................................. [RUN]
15:12:54.252092 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.playing_with_tests"
15:12:54.252278 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.playing_with_tests
15:12:54.252512 [debug] [Thread-1  ]: Compiling model.learn_dbt.playing_with_tests
15:12:54.295287 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.playing_with_tests"
15:12:54.295899 [debug] [Thread-1  ]: finished collecting timing info
15:12:54.296002 [debug] [Thread-1  ]: Began executing node model.learn_dbt.playing_with_tests
15:12:54.301784 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
15:12:54.301885 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */

        insert into dbt.audit (model, state, time) values ('playing_with_tests', 'starting model deployment', current_timestamp)
15:12:54.301974 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:12:55.337487 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.04 seconds
15:12:55.341404 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.playing_with_tests"
15:12:55.343244 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
15:12:55.343685 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */


      create or replace transient table analytics.dbt.playing_with_tests  as
      (select * 
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER"
      );
15:12:57.394623 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.05 seconds
15:12:57.398753 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
15:12:57.399018 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */

        insert into dbt.audit (model, state, time) values ('playing_with_tests', 'ending model deployment', current_timestamp)
15:12:57.887127 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.49 seconds
15:12:57.889785 [debug] [Thread-1  ]: finished collecting timing info
15:12:57.890100 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: Close
15:12:58.254236 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5d71d778-9638-4193-a72b-d9482fd92d60', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106411dc0>]}
15:12:58.254997 [info ] [Thread-1  ]: 4 of 7 OK created table model dbt.playing_with_tests............................ [[32mSUCCESS 1[0m in 4.00s]
15:12:58.255499 [debug] [Thread-1  ]: Finished running node model.learn_dbt.playing_with_tests
15:12:58.255697 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
15:12:58.256033 [info ] [Thread-1  ]: 5 of 7 START table model dbt.snowflake_cumulative_sales......................... [RUN]
15:12:58.256535 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
15:12:58.256697 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
15:12:58.256902 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
15:12:58.259392 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
15:12:58.260403 [debug] [Thread-1  ]: finished collecting timing info
15:12:58.260640 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
15:12:58.264330 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
15:12:58.264531 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */

        insert into dbt.audit (model, state, time) values ('snowflake_cumulative_sales', 'starting model deployment', current_timestamp)
15:12:58.264692 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:12:59.923914 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.66 seconds
15:12:59.926066 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
15:12:59.927342 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
15:12:59.927519 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
15:13:00.843521 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.92 seconds
15:13:00.846699 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
15:13:00.846799 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */

        insert into dbt.audit (model, state, time) values ('snowflake_cumulative_sales', 'ending model deployment', current_timestamp)
15:13:01.586413 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.74 seconds
15:13:01.589465 [debug] [Thread-1  ]: finished collecting timing info
15:13:01.589893 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
15:13:01.768593 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5d71d778-9638-4193-a72b-d9482fd92d60', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104a17a30>]}
15:13:01.769933 [info ] [Thread-1  ]: 5 of 7 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 3.51s]
15:13:01.770661 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
15:13:01.770967 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
15:13:01.771305 [info ] [Thread-1  ]: 6 of 7 START table model dbt.snowflake_customer_purchases....................... [RUN]
15:13:01.771790 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
15:13:01.771941 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
15:13:01.772100 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
15:13:01.773809 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
15:13:01.774390 [debug] [Thread-1  ]: finished collecting timing info
15:13:01.774534 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
15:13:01.776733 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
15:13:01.776888 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */

        insert into dbt.audit (model, state, time) values ('snowflake_customer_purchases', 'starting model deployment', current_timestamp)
15:13:01.776969 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:13:03.203160 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.43 seconds
15:13:03.206047 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
15:13:03.207704 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
15:13:03.207934 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
15:13:05.359041 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.15 seconds
15:13:05.363267 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
15:13:05.363555 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */

        insert into dbt.audit (model, state, time) values ('snowflake_customer_purchases', 'ending model deployment', current_timestamp)
15:13:05.809429 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.45 seconds
15:13:05.812189 [debug] [Thread-1  ]: finished collecting timing info
15:13:05.812598 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
15:13:06.177552 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5d71d778-9638-4193-a72b-d9482fd92d60', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104a8b160>]}
15:13:06.178164 [info ] [Thread-1  ]: 6 of 7 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 4.41s]
15:13:06.178620 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
15:13:06.178898 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
15:13:06.179383 [info ] [Thread-1  ]: 7 of 7 START table model dbt.my_second_dbt_model................................ [RUN]
15:13:06.180088 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
15:13:06.180282 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
15:13:06.180468 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
15:13:06.183710 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
15:13:06.184534 [debug] [Thread-1  ]: finished collecting timing info
15:13:06.184709 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
15:13:06.187954 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
15:13:06.188131 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('my_second_dbt_model', 'starting model deployment', current_timestamp)
15:13:06.188280 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:13:07.106374 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.92 seconds
15:13:07.109612 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
15:13:07.111119 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
15:13:07.111459 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
/*
union all
select 7 as id, True as first_variable
*/
      );
15:13:07.907652 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.8 seconds
15:13:07.912023 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
15:13:07.912305 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('my_second_dbt_model', 'ending model deployment', current_timestamp)
15:13:08.526955 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.61 seconds
15:13:08.530097 [debug] [Thread-1  ]: finished collecting timing info
15:13:08.530619 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
15:13:08.742004 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5d71d778-9638-4193-a72b-d9482fd92d60', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104a13520>]}
15:13:08.742789 [info ] [Thread-1  ]: 7 of 7 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 2.56s]
15:13:08.743258 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
15:13:08.744823 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:13:08.745064 [info ] [MainThread]: 
15:13:08.745321 [info ] [MainThread]: Running 3 on-run-end hooks
15:13:08.745583 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-0
15:13:08.746879 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-0"
15:13:08.747722 [info ] [MainThread]: 1 of 3 START hook: learn_dbt.on-run-end.0....................................... [RUN]
15:13:08.748203 [debug] [MainThread]: Using snowflake connection "master"
15:13:08.748355 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
15:13:08.748492 [debug] [MainThread]: Opening a new connection, currently in state closed
15:13:09.582751 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.83 seconds
15:13:09.585649 [info ] [MainThread]: 1 of 3 OK hook: learn_dbt.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.84s]
15:13:09.586421 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-1
15:13:09.588439 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-1"
15:13:09.589706 [info ] [MainThread]: 2 of 3 START hook: learn_dbt.on-run-end.1....................................... [RUN]
15:13:09.590416 [debug] [MainThread]: Using snowflake connection "master"
15:13:09.590614 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
15:13:09.988189 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.4 seconds
15:13:09.992985 [info ] [MainThread]: 2 of 3 OK hook: learn_dbt.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.40s]
15:13:09.993630 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-2
15:13:09.995999 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-2"
15:13:09.996789 [info ] [MainThread]: 3 of 3 START hook: learn_dbt.on-run-end.2....................................... [RUN]
15:13:09.997118 [debug] [MainThread]: Using snowflake connection "master"
15:13:09.997213 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
15:13:10.149030 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.15 seconds
15:13:10.150625 [info ] [MainThread]: 3 of 3 OK hook: learn_dbt.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.15s]
15:13:10.151219 [info ] [MainThread]: 
15:13:10.151755 [debug] [MainThread]: On master: Close
15:13:10.599179 [info ] [MainThread]: 
15:13:10.599892 [info ] [MainThread]: Finished running 2 incremental models, 1 view model, 4 table models, 4 hooks in 32.29s.
15:13:10.600565 [debug] [MainThread]: Connection 'master' was properly closed.
15:13:10.600798 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
15:13:10.609529 [info ] [MainThread]: 
15:13:10.609915 [info ] [MainThread]: [32mCompleted successfully[0m
15:13:10.610243 [info ] [MainThread]: 
15:13:10.610482 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
15:13:10.610832 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1060b26a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1060b2c70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10623f2b0>]}


============================== 2022-05-16 15:16:37.785397 | d8abc254-f1a4-4d79-874d-b91477758729 ==============================
15:16:37.785397 [info ] [MainThread]: Running with dbt=1.0.1
15:16:37.786298 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
15:16:37.786461 [debug] [MainThread]: Tracking: tracking
15:16:37.786742 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1206434c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120643c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1206438b0>]}
15:16:37.833795 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
15:16:37.834193 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/my_first_dbt_model.sql
15:16:37.841435 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
15:16:37.849532 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
15:16:37.863968 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd8abc254-f1a4-4d79-874d-b91477758729', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1207c30d0>]}
15:16:37.868017 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd8abc254-f1a4-4d79-874d-b91477758729', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12074eb50>]}
15:16:37.868227 [info ] [MainThread]: Found 7 models, 12 tests, 0 snapshots, 0 analyses, 179 macros, 4 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
15:16:37.869254 [info ] [MainThread]: 
15:16:37.869508 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:16:37.870013 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
15:16:37.876424 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
15:16:37.876566 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
15:16:37.876638 [debug] [ThreadPool]: Opening a new connection, currently in state init
15:16:38.733676 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.86 seconds
15:16:38.735313 [debug] [ThreadPool]: On list_analytics: Close
15:16:38.948545 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
15:16:38.952956 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
15:16:38.953117 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
15:16:38.953193 [debug] [ThreadPool]: Opening a new connection, currently in state closed
15:16:39.755884 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 0.8 seconds
15:16:39.760020 [debug] [ThreadPool]: On list_analytics_dbt: Close
15:16:39.999653 [info ] [MainThread]: 
15:16:40.000490 [info ] [MainThread]: Running 1 on-run-start hook
15:16:40.001229 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-start-0
15:16:40.004305 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-start-0"
15:16:40.015291 [info ] [MainThread]: 1 of 1 START hook: learn_dbt.on-run-start.0..................................... [RUN]
15:16:40.016172 [debug] [MainThread]: Using snowflake connection "master"
15:16:40.016385 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
15:16:40.016582 [debug] [MainThread]: Opening a new connection, currently in state init
15:16:40.654541 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.64 seconds
15:16:40.657258 [info ] [MainThread]: 1 of 1 OK hook: learn_dbt.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.64s]
15:16:40.657910 [info ] [MainThread]: 
15:16:40.658459 [debug] [MainThread]: On master: Close
15:16:40.848440 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
15:16:40.849304 [info ] [MainThread]: 
15:16:40.857431 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
15:16:40.858041 [info ] [Thread-1  ]: 1 of 7 START incremental model dbt.dates........................................ [RUN]
15:16:40.859188 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
15:16:40.859430 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
15:16:40.859623 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
15:16:40.881842 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
15:16:40.882594 [debug] [Thread-1  ]: finished collecting timing info
15:16:40.882796 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
15:16:40.919397 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
15:16:40.919620 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
15:16:40.919722 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:16:42.413076 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.49 seconds
15:16:42.430177 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
15:16:42.430650 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
15:16:42.557374 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.13 seconds
15:16:42.570326 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
15:16:42.570761 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
15:16:42.745547 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.17 seconds
15:16:42.766916 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
15:16:42.767299 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
15:16:42.868545 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.1 seconds
15:16:42.905015 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
15:16:42.907954 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
15:16:42.908139 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
15:16:43.138796 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.23 seconds
15:16:43.139624 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
15:16:43.139850 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
15:16:43.433933 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.29 seconds
15:16:43.434716 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
15:16:43.435276 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
15:16:43.608901 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.17 seconds
15:16:43.626713 [debug] [Thread-1  ]: finished collecting timing info
15:16:43.627167 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
15:16:43.994690 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd8abc254-f1a4-4d79-874d-b91477758729', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120b82220>]}
15:16:43.995517 [info ] [Thread-1  ]: 1 of 7 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 3.14s]
15:16:43.996008 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
15:16:43.996256 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
15:16:43.996557 [info ] [Thread-1  ]: 2 of 7 START incremental model dbt.incremental_time............................. [RUN]
15:16:44.000265 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
15:16:44.000676 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
15:16:44.001016 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
15:16:44.012935 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
15:16:44.013634 [debug] [Thread-1  ]: finished collecting timing info
15:16:44.013801 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
15:16:44.017678 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
15:16:44.017993 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

        insert into dbt.audit (model, state, time) values ('incremental_time', 'starting model deployment', current_timestamp)
15:16:44.018159 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:16:44.941331 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.92 seconds
15:16:44.944409 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
15:16:44.944898 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
15:16:46.445854 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.5 seconds
15:16:46.450644 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
15:16:46.450983 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
15:16:46.619998 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.17 seconds
15:16:46.631137 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
15:16:46.631639 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
15:16:46.939700 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.31 seconds
15:16:46.948628 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
15:16:46.949334 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
15:16:47.060277 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.11 seconds
15:16:47.065883 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
15:16:47.068408 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
15:16:47.068609 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
15:16:47.192384 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.12 seconds
15:16:47.193083 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
15:16:47.193587 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
15:16:47.991827 [debug] [Thread-1  ]: SQL status: SUCCESS 237 in 0.8 seconds
15:16:47.992840 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
15:16:47.993140 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
15:16:48.628145 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.63 seconds
15:16:48.632906 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
15:16:48.633347 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

        insert into dbt.audit (model, state, time) values ('incremental_time', 'ending model deployment', current_timestamp)
15:16:49.112839 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.48 seconds
15:16:49.115802 [debug] [Thread-1  ]: finished collecting timing info
15:16:49.116364 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
15:16:49.311947 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd8abc254-f1a4-4d79-874d-b91477758729', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120a4a400>]}
15:16:49.313014 [info ] [Thread-1  ]: 2 of 7 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 5.31s]
15:16:49.313625 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
15:16:49.314206 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
15:16:49.314669 [info ] [Thread-1  ]: 3 of 7 START view model dbt.first_model......................................... [RUN]
15:16:49.315557 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
15:16:49.315892 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
15:16:49.316288 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
15:16:49.330203 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
15:16:49.331622 [debug] [Thread-1  ]: finished collecting timing info
15:16:49.331717 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
15:16:49.338293 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
15:16:49.338404 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('first_model', 'starting model deployment', current_timestamp)
15:16:49.338493 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:16:50.801007 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.46 seconds
15:16:50.822267 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
15:16:50.831598 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
15:16:50.831993 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */

  create or replace  view analytics.dbt.first_model 
  
   as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id, 'CA' as state, '2020-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select null as id, 'CT' as state, '2020-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select 3 as id, 'VT' as state, '2020-01-01 00:00:00.000'::timestamp as updated_at

)

select * 
from source_data


/*
select *, True as first_variable
from source_data
where id >= 1
*/
  );
15:16:51.137970 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.31 seconds
15:16:51.146613 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
15:16:51.147563 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('first_model', 'ending model deployment', current_timestamp)
15:16:51.599236 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.45 seconds
15:16:51.602064 [debug] [Thread-1  ]: finished collecting timing info
15:16:51.602387 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
15:16:51.800617 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd8abc254-f1a4-4d79-874d-b91477758729', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x124513790>]}
15:16:51.801527 [info ] [Thread-1  ]: 3 of 7 OK created view model dbt.first_model.................................... [[32mSUCCESS 1[0m in 2.49s]
15:16:51.802059 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
15:16:51.802396 [debug] [Thread-1  ]: Began running node model.learn_dbt.playing_with_tests
15:16:51.802834 [info ] [Thread-1  ]: 4 of 7 START table model dbt.playing_with_tests................................. [RUN]
15:16:51.803928 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.playing_with_tests"
15:16:51.804417 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.playing_with_tests
15:16:51.804834 [debug] [Thread-1  ]: Compiling model.learn_dbt.playing_with_tests
15:16:51.814697 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.playing_with_tests"
15:16:51.816195 [debug] [Thread-1  ]: finished collecting timing info
15:16:51.816411 [debug] [Thread-1  ]: Began executing node model.learn_dbt.playing_with_tests
15:16:51.828491 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
15:16:51.828747 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */

        insert into dbt.audit (model, state, time) values ('playing_with_tests', 'starting model deployment', current_timestamp)
15:16:51.828918 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:16:53.315416 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.49 seconds
15:16:53.318141 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.playing_with_tests"
15:16:53.319619 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
15:16:53.319861 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */


      create or replace transient table analytics.dbt.playing_with_tests  as
      (select * 
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER"
      );
15:16:54.905712 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.59 seconds
15:16:54.913216 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
15:16:54.913629 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */

        insert into dbt.audit (model, state, time) values ('playing_with_tests', 'ending model deployment', current_timestamp)
15:16:55.329083 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.42 seconds
15:16:55.332877 [debug] [Thread-1  ]: finished collecting timing info
15:16:55.333596 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: Close
15:16:55.514164 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd8abc254-f1a4-4d79-874d-b91477758729', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x124552640>]}
15:16:55.515175 [info ] [Thread-1  ]: 4 of 7 OK created table model dbt.playing_with_tests............................ [[32mSUCCESS 1[0m in 3.71s]
15:16:55.515581 [debug] [Thread-1  ]: Finished running node model.learn_dbt.playing_with_tests
15:16:55.515835 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
15:16:55.516096 [info ] [Thread-1  ]: 5 of 7 START table model dbt.snowflake_cumulative_sales......................... [RUN]
15:16:55.516971 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
15:16:55.517237 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
15:16:55.517857 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
15:16:55.521472 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
15:16:55.524624 [debug] [Thread-1  ]: finished collecting timing info
15:16:55.525743 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
15:16:55.534767 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
15:16:55.534997 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */

        insert into dbt.audit (model, state, time) values ('snowflake_cumulative_sales', 'starting model deployment', current_timestamp)
15:16:55.535091 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:16:56.835475 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.3 seconds
15:16:56.838968 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
15:16:56.841851 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
15:16:56.842268 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
15:16:57.679847 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.84 seconds
15:16:57.689539 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
15:16:57.689997 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */

        insert into dbt.audit (model, state, time) values ('snowflake_cumulative_sales', 'ending model deployment', current_timestamp)
15:16:58.290852 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.6 seconds
15:16:58.295400 [debug] [Thread-1  ]: finished collecting timing info
15:16:58.295901 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
15:16:58.605034 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd8abc254-f1a4-4d79-874d-b91477758729', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12454eb80>]}
15:16:58.610074 [info ] [Thread-1  ]: 5 of 7 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 3.09s]
15:16:58.611353 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
15:16:58.611826 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
15:16:58.612453 [info ] [Thread-1  ]: 6 of 7 START table model dbt.snowflake_customer_purchases....................... [RUN]
15:16:58.618096 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
15:16:58.618670 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
15:16:58.618991 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
15:16:58.621374 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
15:16:58.622114 [debug] [Thread-1  ]: finished collecting timing info
15:16:58.622328 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
15:16:58.626411 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
15:16:58.626651 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */

        insert into dbt.audit (model, state, time) values ('snowflake_customer_purchases', 'starting model deployment', current_timestamp)
15:16:58.626844 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:16:59.559800 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.93 seconds
15:16:59.563003 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
15:16:59.565127 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
15:16:59.566217 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
15:17:00.608763 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.04 seconds
15:17:00.614930 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
15:17:00.615334 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */

        insert into dbt.audit (model, state, time) values ('snowflake_customer_purchases', 'ending model deployment', current_timestamp)
15:17:01.092597 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.48 seconds
15:17:01.095053 [debug] [Thread-1  ]: finished collecting timing info
15:17:01.095317 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
15:17:01.263303 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd8abc254-f1a4-4d79-874d-b91477758729', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120bba040>]}
15:17:01.264097 [info ] [Thread-1  ]: 6 of 7 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.65s]
15:17:01.264983 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
15:17:01.266024 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
15:17:01.271879 [info ] [Thread-1  ]: 7 of 7 START table model dbt.my_second_dbt_model................................ [RUN]
15:17:01.273637 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
15:17:01.275263 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
15:17:01.286194 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
15:17:01.291588 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
15:17:01.293176 [debug] [Thread-1  ]: finished collecting timing info
15:17:01.293322 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
15:17:01.295358 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
15:17:01.295532 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('my_second_dbt_model', 'starting model deployment', current_timestamp)
15:17:01.295632 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:17:02.426037 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.13 seconds
15:17:02.428886 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
15:17:02.431668 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
15:17:02.432428 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
/*
union all
select 7 as id, True as first_variable
*/
      );
15:17:03.452237 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.02 seconds
15:17:03.461823 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
15:17:03.462273 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('my_second_dbt_model', 'ending model deployment', current_timestamp)
15:17:03.963227 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.5 seconds
15:17:03.969753 [debug] [Thread-1  ]: finished collecting timing info
15:17:03.970847 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
15:17:04.226039 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd8abc254-f1a4-4d79-874d-b91477758729', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120b84790>]}
15:17:04.226896 [info ] [Thread-1  ]: 7 of 7 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 2.95s]
15:17:04.227311 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
15:17:04.230899 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:17:04.231409 [info ] [MainThread]: 
15:17:04.233565 [info ] [MainThread]: Running 3 on-run-end hooks
15:17:04.238608 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-0
15:17:04.241986 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-0"
15:17:04.243574 [info ] [MainThread]: 1 of 3 START hook: learn_dbt.on-run-end.0....................................... [RUN]
15:17:04.244492 [debug] [MainThread]: Using snowflake connection "master"
15:17:04.244759 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
15:17:04.244988 [debug] [MainThread]: Opening a new connection, currently in state closed
15:17:04.980155 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.74 seconds
15:17:04.982556 [info ] [MainThread]: 1 of 3 OK hook: learn_dbt.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.74s]
15:17:04.983062 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-1
15:17:04.985727 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-1"
15:17:04.995784 [info ] [MainThread]: 2 of 3 START hook: learn_dbt.on-run-end.1....................................... [RUN]
15:17:04.996209 [debug] [MainThread]: Using snowflake connection "master"
15:17:04.996302 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
15:17:05.161163 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.16 seconds
15:17:05.162885 [info ] [MainThread]: 2 of 3 OK hook: learn_dbt.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.17s]
15:17:05.163477 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-2
15:17:05.165692 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-2"
15:17:05.166889 [info ] [MainThread]: 3 of 3 START hook: learn_dbt.on-run-end.2....................................... [RUN]
15:17:05.167548 [debug] [MainThread]: Using snowflake connection "master"
15:17:05.167746 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
15:17:05.342736 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.17 seconds
15:17:05.346032 [info ] [MainThread]: 3 of 3 OK hook: learn_dbt.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.18s]
15:17:05.347182 [info ] [MainThread]: 
15:17:05.348763 [debug] [MainThread]: On master: Close
15:17:05.508849 [info ] [MainThread]: 
15:17:05.509114 [info ] [MainThread]: Finished running 2 incremental models, 1 view model, 4 table models, 4 hooks in 27.64s.
15:17:05.509233 [debug] [MainThread]: Connection 'master' was properly closed.
15:17:05.509294 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
15:17:05.512345 [info ] [MainThread]: 
15:17:05.512485 [info ] [MainThread]: [32mCompleted successfully[0m
15:17:05.512860 [info ] [MainThread]: 
15:17:05.513085 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
15:17:05.513317 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120b84820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120b84bb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x124528430>]}


============================== 2022-05-16 15:18:32.507472 | 8daba672-4025-435e-a871-cf8714c78ff3 ==============================
15:18:32.507472 [info ] [MainThread]: Running with dbt=1.0.1
15:18:32.508210 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
15:18:32.508365 [debug] [MainThread]: Tracking: tracking
15:18:32.508589 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108fb3520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108fb3b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108fb3250>]}
15:18:32.552003 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
15:18:32.552477 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/my_first_dbt_model.sql
15:18:32.564547 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
15:18:32.572270 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
15:18:32.585972 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8daba672-4025-435e-a871-cf8714c78ff3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1092310d0>]}
15:18:32.589463 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8daba672-4025-435e-a871-cf8714c78ff3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107ff5340>]}
15:18:32.589596 [info ] [MainThread]: Found 7 models, 12 tests, 0 snapshots, 0 analyses, 179 macros, 4 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
15:18:32.590466 [info ] [MainThread]: 
15:18:32.590675 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:18:32.591136 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
15:18:32.597043 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
15:18:32.597179 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
15:18:32.597248 [debug] [ThreadPool]: Opening a new connection, currently in state init
15:18:33.600282 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.0 seconds
15:18:33.602481 [debug] [ThreadPool]: On list_analytics: Close
15:18:33.894041 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
15:18:33.902623 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
15:18:33.902881 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
15:18:33.903050 [debug] [ThreadPool]: Opening a new connection, currently in state closed
15:18:34.941587 [debug] [ThreadPool]: SQL status: SUCCESS 7 in 1.04 seconds
15:18:34.944379 [debug] [ThreadPool]: On list_analytics_dbt: Close
15:18:35.117126 [info ] [MainThread]: 
15:18:35.117437 [info ] [MainThread]: Running 1 on-run-start hook
15:18:35.117612 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-start-0
15:18:35.118589 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-start-0"
15:18:35.120722 [info ] [MainThread]: 1 of 1 START hook: learn_dbt.on-run-start.0..................................... [RUN]
15:18:35.121385 [debug] [MainThread]: Using snowflake connection "master"
15:18:35.121547 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
15:18:35.121689 [debug] [MainThread]: Opening a new connection, currently in state init
15:18:36.095231 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.97 seconds
15:18:36.097641 [info ] [MainThread]: 1 of 1 OK hook: learn_dbt.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.98s]
15:18:36.098220 [info ] [MainThread]: 
15:18:36.099264 [debug] [MainThread]: On master: Close
15:18:36.275596 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
15:18:36.276358 [info ] [MainThread]: 
15:18:36.282104 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
15:18:36.282399 [info ] [Thread-1  ]: 1 of 7 START incremental model dbt.dates........................................ [RUN]
15:18:36.283054 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
15:18:36.283180 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
15:18:36.283292 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
15:18:36.292037 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
15:18:36.293007 [debug] [Thread-1  ]: finished collecting timing info
15:18:36.293262 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
15:18:36.324155 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
15:18:36.324344 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
15:18:36.324433 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:18:37.897984 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.57 seconds
15:18:37.910095 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
15:18:37.910524 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
15:18:38.082699 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.17 seconds
15:18:38.087236 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
15:18:38.087385 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
15:18:38.529237 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.44 seconds
15:18:38.541926 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
15:18:38.542249 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
15:18:38.664501 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.12 seconds
15:18:38.689953 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
15:18:38.692428 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
15:18:38.692583 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
15:18:38.839131 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.15 seconds
15:18:38.840467 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
15:18:38.840724 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
15:18:39.753922 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.91 seconds
15:18:39.755064 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
15:18:39.755291 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
15:18:39.944927 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.19 seconds
15:18:39.958674 [debug] [Thread-1  ]: finished collecting timing info
15:18:39.959220 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
15:18:40.345955 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8daba672-4025-435e-a871-cf8714c78ff3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a83c2e0>]}
15:18:40.346388 [info ] [Thread-1  ]: 1 of 7 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 4.06s]
15:18:40.346666 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
15:18:40.346818 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
15:18:40.347072 [info ] [Thread-1  ]: 2 of 7 START incremental model dbt.incremental_time............................. [RUN]
15:18:40.347484 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
15:18:40.347605 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
15:18:40.347718 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
15:18:40.350536 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
15:18:40.352745 [debug] [Thread-1  ]: finished collecting timing info
15:18:40.352877 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
15:18:40.356271 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
15:18:40.356497 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

        insert into dbt.audit (model, state, time) values ('incremental_time', 'starting model deployment', current_timestamp)
15:18:40.356665 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:18:41.622414 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.27 seconds
15:18:41.625706 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
15:18:41.626079 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
15:18:42.434918 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.81 seconds
15:18:42.439170 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
15:18:42.439319 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
15:18:42.560019 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.12 seconds
15:18:42.565898 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
15:18:42.566288 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
15:18:42.671543 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.11 seconds
15:18:42.677376 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
15:18:42.677776 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
15:18:42.802354 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.12 seconds
15:18:42.807309 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
15:18:42.809922 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
15:18:42.810248 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
15:18:42.941451 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.13 seconds
15:18:42.942497 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
15:18:42.942812 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
15:18:43.543088 [debug] [Thread-1  ]: SQL status: SUCCESS 116 in 0.6 seconds
15:18:43.543510 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
15:18:43.543711 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
15:18:43.790843 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.25 seconds
15:18:43.796834 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
15:18:43.797125 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

        insert into dbt.audit (model, state, time) values ('incremental_time', 'ending model deployment', current_timestamp)
15:18:44.375272 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.58 seconds
15:18:44.377884 [debug] [Thread-1  ]: finished collecting timing info
15:18:44.378247 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
15:18:44.607129 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8daba672-4025-435e-a871-cf8714c78ff3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109627f10>]}
15:18:44.608111 [info ] [Thread-1  ]: 2 of 7 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 4.26s]
15:18:44.608448 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
15:18:44.608553 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
15:18:44.608678 [info ] [Thread-1  ]: 3 of 7 START table model dbt.first_model........................................ [RUN]
15:18:44.608929 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
15:18:44.609098 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
15:18:44.609284 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
15:18:44.611384 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
15:18:44.613436 [debug] [Thread-1  ]: finished collecting timing info
15:18:44.613666 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
15:18:44.623488 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
15:18:44.623661 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('first_model', 'starting model deployment', current_timestamp)
15:18:44.623780 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:18:45.559850 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.94 seconds
15:18:45.562310 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
15:18:45.564365 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
15:18:45.564598 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id, 'CA' as state, '2020-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select null as id, 'CT' as state, '2020-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select 3 as id, 'VT' as state, '2020-01-01 00:00:00.000'::timestamp as updated_at

)

select * 
from source_data


/*
select *, True as first_variable
from source_data
where id >= 1
*/
      );
15:18:46.180610 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.62 seconds
15:18:46.187180 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
15:18:46.187479 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('first_model', 'ending model deployment', current_timestamp)
15:18:46.625263 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.44 seconds
15:18:46.627630 [debug] [Thread-1  ]: finished collecting timing info
15:18:46.627892 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
15:18:46.868141 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8daba672-4025-435e-a871-cf8714c78ff3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a8883d0>]}
15:18:46.869574 [info ] [Thread-1  ]: 3 of 7 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 2.26s]
15:18:46.870141 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
15:18:46.870385 [debug] [Thread-1  ]: Began running node model.learn_dbt.playing_with_tests
15:18:46.870647 [info ] [Thread-1  ]: 4 of 7 START table model dbt.playing_with_tests................................. [RUN]
15:18:46.871344 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.playing_with_tests"
15:18:46.871787 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.playing_with_tests
15:18:46.872091 [debug] [Thread-1  ]: Compiling model.learn_dbt.playing_with_tests
15:18:46.874491 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.playing_with_tests"
15:18:46.875241 [debug] [Thread-1  ]: finished collecting timing info
15:18:46.875423 [debug] [Thread-1  ]: Began executing node model.learn_dbt.playing_with_tests
15:18:46.878567 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
15:18:46.878738 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */

        insert into dbt.audit (model, state, time) values ('playing_with_tests', 'starting model deployment', current_timestamp)
15:18:46.879031 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:18:48.251064 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.37 seconds
15:18:48.257946 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.playing_with_tests"
15:18:48.259949 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
15:18:48.260149 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */


      create or replace transient table analytics.dbt.playing_with_tests  as
      (select * 
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER"
      );
15:18:49.732020 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.47 seconds
15:18:49.737534 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
15:18:49.737818 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */

        insert into dbt.audit (model, state, time) values ('playing_with_tests', 'ending model deployment', current_timestamp)
15:18:50.220821 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.48 seconds
15:18:50.224561 [debug] [Thread-1  ]: finished collecting timing info
15:18:50.224992 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: Close
15:18:50.732503 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8daba672-4025-435e-a871-cf8714c78ff3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a8f9af0>]}
15:18:50.733253 [info ] [Thread-1  ]: 4 of 7 OK created table model dbt.playing_with_tests............................ [[32mSUCCESS 1[0m in 3.86s]
15:18:50.733712 [debug] [Thread-1  ]: Finished running node model.learn_dbt.playing_with_tests
15:18:50.733965 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
15:18:50.734250 [info ] [Thread-1  ]: 5 of 7 START table model dbt.snowflake_cumulative_sales......................... [RUN]
15:18:50.734990 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
15:18:50.735251 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
15:18:50.735474 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
15:18:50.737908 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
15:18:50.740086 [debug] [Thread-1  ]: finished collecting timing info
15:18:50.740294 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
15:18:50.743889 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
15:18:50.744128 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */

        insert into dbt.audit (model, state, time) values ('snowflake_cumulative_sales', 'starting model deployment', current_timestamp)
15:18:50.744248 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:18:51.790150 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.05 seconds
15:18:51.797163 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
15:18:51.797986 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
15:18:51.798068 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
15:18:52.772545 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.97 seconds
15:18:52.777720 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
15:18:52.778037 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */

        insert into dbt.audit (model, state, time) values ('snowflake_cumulative_sales', 'ending model deployment', current_timestamp)
15:18:53.213740 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.44 seconds
15:18:53.215814 [debug] [Thread-1  ]: finished collecting timing info
15:18:53.216011 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
15:18:53.418549 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8daba672-4025-435e-a871-cf8714c78ff3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a8f4310>]}
15:18:53.419397 [info ] [Thread-1  ]: 5 of 7 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 2.68s]
15:18:53.419866 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
15:18:53.420411 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
15:18:53.420913 [info ] [Thread-1  ]: 6 of 7 START table model dbt.snowflake_customer_purchases....................... [RUN]
15:18:53.421659 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
15:18:53.421899 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
15:18:53.422109 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
15:18:53.424574 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
15:18:53.425280 [debug] [Thread-1  ]: finished collecting timing info
15:18:53.425597 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
15:18:53.429115 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
15:18:53.429288 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */

        insert into dbt.audit (model, state, time) values ('snowflake_customer_purchases', 'starting model deployment', current_timestamp)
15:18:53.429419 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:18:54.335311 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.91 seconds
15:18:54.338785 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
15:18:54.340781 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
15:18:54.341027 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
15:18:56.090474 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.75 seconds
15:18:56.097079 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
15:18:56.097360 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */

        insert into dbt.audit (model, state, time) values ('snowflake_customer_purchases', 'ending model deployment', current_timestamp)
15:18:56.689315 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.59 seconds
15:18:56.694465 [debug] [Thread-1  ]: finished collecting timing info
15:18:56.694817 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
15:18:56.960017 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8daba672-4025-435e-a871-cf8714c78ff3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1096ba2e0>]}
15:18:56.961339 [info ] [Thread-1  ]: 6 of 7 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 3.54s]
15:18:56.961911 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
15:18:56.962372 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
15:18:56.962887 [info ] [Thread-1  ]: 7 of 7 START table model dbt.my_second_dbt_model................................ [RUN]
15:18:56.963634 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
15:18:56.963866 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
15:18:56.964057 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
15:18:56.967871 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
15:18:56.968629 [debug] [Thread-1  ]: finished collecting timing info
15:18:56.968815 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
15:18:56.972268 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
15:18:56.972470 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('my_second_dbt_model', 'starting model deployment', current_timestamp)
15:18:56.972627 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:18:58.453430 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.48 seconds
15:18:58.456006 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
15:18:58.457504 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
15:18:58.457750 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
/*
union all
select 7 as id, True as first_variable
*/
      );
15:18:59.261850 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.8 seconds
15:18:59.266085 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
15:18:59.266374 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('my_second_dbt_model', 'ending model deployment', current_timestamp)
15:18:59.877963 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.61 seconds
15:18:59.886891 [debug] [Thread-1  ]: finished collecting timing info
15:18:59.887317 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
15:19:00.312676 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8daba672-4025-435e-a871-cf8714c78ff3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a9037c0>]}
15:19:00.313336 [info ] [Thread-1  ]: 7 of 7 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 3.35s]
15:19:00.313774 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
15:19:00.315078 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:19:00.315412 [info ] [MainThread]: 
15:19:00.315736 [info ] [MainThread]: Running 3 on-run-end hooks
15:19:00.316069 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-0
15:19:00.317909 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-0"
15:19:00.320298 [info ] [MainThread]: 1 of 3 START hook: learn_dbt.on-run-end.0....................................... [RUN]
15:19:00.320806 [debug] [MainThread]: Using snowflake connection "master"
15:19:00.320956 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
15:19:00.321092 [debug] [MainThread]: Opening a new connection, currently in state closed
15:19:00.965943 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.64 seconds
15:19:00.969482 [info ] [MainThread]: 1 of 3 OK hook: learn_dbt.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.65s]
15:19:00.970202 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-1
15:19:00.972176 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-1"
15:19:00.973582 [info ] [MainThread]: 2 of 3 START hook: learn_dbt.on-run-end.1....................................... [RUN]
15:19:00.974329 [debug] [MainThread]: Using snowflake connection "master"
15:19:00.974536 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
15:19:01.158712 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.18 seconds
15:19:01.161050 [info ] [MainThread]: 2 of 3 OK hook: learn_dbt.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.19s]
15:19:01.161678 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-2
15:19:01.163873 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-2"
15:19:01.166231 [info ] [MainThread]: 3 of 3 START hook: learn_dbt.on-run-end.2....................................... [RUN]
15:19:01.166841 [debug] [MainThread]: Using snowflake connection "master"
15:19:01.167010 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
15:19:01.289269 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.12 seconds
15:19:01.290802 [info ] [MainThread]: 3 of 3 OK hook: learn_dbt.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.12s]
15:19:01.291259 [info ] [MainThread]: 
15:19:01.291655 [debug] [MainThread]: On master: Close
15:19:01.546141 [info ] [MainThread]: 
15:19:01.546710 [info ] [MainThread]: Finished running 2 incremental models, 5 table models, 4 hooks in 28.96s.
15:19:01.547049 [debug] [MainThread]: Connection 'master' was properly closed.
15:19:01.547354 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
15:19:01.554854 [info ] [MainThread]: 
15:19:01.555031 [info ] [MainThread]: [32mCompleted successfully[0m
15:19:01.555193 [info ] [MainThread]: 
15:19:01.555300 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
15:19:01.555455 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10929bc40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109601640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a8e2d30>]}


============================== 2022-05-16 15:27:05.777120 | 9c23209b-e16c-438c-9bae-6d7beb0d856a ==============================
15:27:05.777120 [info ] [MainThread]: Running with dbt=1.0.1
15:27:05.777621 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.snapshot.SnapshotTask'>, which='snapshot', rpc_method='snapshot')
15:27:05.777754 [debug] [MainThread]: Tracking: tracking
15:27:05.777985 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1051531c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105153dc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105153c10>]}
15:27:05.824310 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
15:27:05.824591 [debug] [MainThread]: Partial parsing: added file: learn_dbt://snapshots/first_model_snapshot.sql
15:27:05.843129 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9c23209b-e16c-438c-9bae-6d7beb0d856a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1051077f0>]}
15:27:05.846850 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9c23209b-e16c-438c-9bae-6d7beb0d856a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x100fe9580>]}
15:27:05.847035 [info ] [MainThread]: Found 7 models, 12 tests, 1 snapshot, 0 analyses, 179 macros, 4 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
15:27:05.847764 [info ] [MainThread]: 
15:27:05.847964 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:27:05.848289 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
15:27:05.854414 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
15:27:05.854561 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
15:27:05.854627 [debug] [ThreadPool]: Opening a new connection, currently in state init
15:27:06.824213 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.97 seconds
15:27:06.825678 [debug] [ThreadPool]: On list_analytics: Close
15:27:07.014944 [debug] [ThreadPool]: Acquiring new snowflake connection "create_analytics_snaphots"
15:27:07.015643 [debug] [ThreadPool]: Acquiring new snowflake connection "create_analytics_snaphots"
15:27:07.015963 [debug] [ThreadPool]: Creating schema "_ReferenceKey(database='analytics', schema='snaphots', identifier=None)"
15:27:07.021868 [debug] [ThreadPool]: Using snowflake connection "create_analytics_snaphots"
15:27:07.022101 [debug] [ThreadPool]: On create_analytics_snaphots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "create_analytics_snaphots"} */
create schema if not exists analytics.snaphots
15:27:07.022193 [debug] [ThreadPool]: Opening a new connection, currently in state closed
15:27:07.663723 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.64 seconds
15:27:07.665757 [debug] [ThreadPool]: On create_analytics_snaphots: Close
15:27:07.843407 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snaphots"
15:27:07.850593 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snaphots"
15:27:07.850797 [debug] [ThreadPool]: On list_analytics_snaphots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snaphots"} */

    show terse objects in analytics.snaphots
15:27:07.850874 [debug] [ThreadPool]: Opening a new connection, currently in state closed
15:27:08.710383 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 0.86 seconds
15:27:08.718074 [debug] [ThreadPool]: On list_analytics_snaphots: Close
15:27:08.905432 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
15:27:08.907880 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
15:27:08.908079 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
15:27:08.908249 [debug] [ThreadPool]: Opening a new connection, currently in state closed
15:27:09.861685 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 0.95 seconds
15:27:09.867858 [debug] [ThreadPool]: On list_analytics_dbt: Close
15:27:10.051103 [info ] [MainThread]: 
15:27:10.051808 [info ] [MainThread]: Running 1 on-run-start hook
15:27:10.052166 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-start-0
15:27:10.052900 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-start-0"
15:27:10.056113 [info ] [MainThread]: 1 of 1 START hook: learn_dbt.on-run-start.0..................................... [RUN]
15:27:10.056883 [debug] [MainThread]: Using snowflake connection "master"
15:27:10.057080 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
15:27:10.057228 [debug] [MainThread]: Opening a new connection, currently in state init
15:27:10.805992 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.75 seconds
15:27:10.808243 [info ] [MainThread]: 1 of 1 OK hook: learn_dbt.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.75s]
15:27:10.808677 [info ] [MainThread]: 
15:27:10.809109 [debug] [MainThread]: On master: Close
15:27:10.999151 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
15:27:10.999871 [info ] [MainThread]: 
15:27:11.005228 [debug] [Thread-1  ]: Began running node snapshot.learn_dbt.first_model_snapshot
15:27:11.005625 [info ] [Thread-1  ]: 1 of 1 START snapshot snaphots.first_model_snapshot............................. [RUN]
15:27:11.006156 [debug] [Thread-1  ]: Acquiring new snowflake connection "snapshot.learn_dbt.first_model_snapshot"
15:27:11.006340 [debug] [Thread-1  ]: Began compiling node snapshot.learn_dbt.first_model_snapshot
15:27:11.006503 [debug] [Thread-1  ]: Compiling snapshot.learn_dbt.first_model_snapshot
15:27:11.010307 [debug] [Thread-1  ]: finished collecting timing info
15:27:11.010525 [debug] [Thread-1  ]: Began executing node snapshot.learn_dbt.first_model_snapshot
15:27:11.033120 [debug] [Thread-1  ]: Using snowflake connection "snapshot.learn_dbt.first_model_snapshot"
15:27:11.033344 [debug] [Thread-1  ]: On snapshot.learn_dbt.first_model_snapshot: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "snapshot.learn_dbt.first_model_snapshot"} */
select count(*)
        from analytics.INFORMATION_SCHEMA.schemata
        where upper(schema_name) = upper('snaphots')
            and upper(catalog_name) = upper('analytics')
15:27:11.033451 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:27:12.924926 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.89 seconds
15:27:12.962598 [debug] [Thread-1  ]: Writing runtime SQL for node "snapshot.learn_dbt.first_model_snapshot"
15:27:12.964076 [debug] [Thread-1  ]: Using snowflake connection "snapshot.learn_dbt.first_model_snapshot"
15:27:12.964198 [debug] [Thread-1  ]: On snapshot.learn_dbt.first_model_snapshot: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "snapshot.learn_dbt.first_model_snapshot"} */

      

      create or replace transient table analytics.snaphots.first_model_snapshot  as
      (

    select *,
        md5(coalesce(cast(id as varchar ), '')
         || '|' || coalesce(cast(updated_at as varchar ), '')
        ) as dbt_scd_id,
        updated_at as dbt_updated_at,
        updated_at as dbt_valid_from,
        nullif(updated_at, updated_at) as dbt_valid_to
    from (
        
    



    select * from analytics.dbt.first_model

    ) sbq



      );
15:27:13.680862 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.72 seconds
15:27:13.699694 [debug] [Thread-1  ]: finished collecting timing info
15:27:13.700126 [debug] [Thread-1  ]: On snapshot.learn_dbt.first_model_snapshot: Close
15:27:14.049213 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9c23209b-e16c-438c-9bae-6d7beb0d856a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106a26dc0>]}
15:27:14.050298 [info ] [Thread-1  ]: 1 of 1 OK snapshotted snaphots.first_model_snapshot............................. [[32mSUCCESS 1[0m in 3.04s]
15:27:14.050695 [debug] [Thread-1  ]: Finished running node snapshot.learn_dbt.first_model_snapshot
15:27:14.051617 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:27:14.051875 [info ] [MainThread]: 
15:27:14.052067 [info ] [MainThread]: Running 3 on-run-end hooks
15:27:14.052264 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-0
15:27:14.053310 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-0"
15:27:14.056032 [info ] [MainThread]: 1 of 3 START hook: learn_dbt.on-run-end.0....................................... [RUN]
15:27:14.056531 [debug] [MainThread]: Using snowflake connection "master"
15:27:14.056671 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
15:27:14.056803 [debug] [MainThread]: Opening a new connection, currently in state closed
15:27:14.709344 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.65 seconds
15:27:14.711008 [info ] [MainThread]: 1 of 3 OK hook: learn_dbt.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.65s]
15:27:14.711692 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-1
15:27:14.713359 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-1"
15:27:14.714361 [info ] [MainThread]: 2 of 3 START hook: learn_dbt.on-run-end.1....................................... [RUN]
15:27:14.715049 [debug] [MainThread]: Using snowflake connection "master"
15:27:14.715252 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
15:27:15.007057 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.29 seconds
15:27:15.008599 [info ] [MainThread]: 2 of 3 OK hook: learn_dbt.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.29s]
15:27:15.009399 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-2
15:27:15.011659 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-2"
15:27:15.014067 [info ] [MainThread]: 3 of 3 START hook: learn_dbt.on-run-end.2....................................... [RUN]
15:27:15.014577 [debug] [MainThread]: Using snowflake connection "master"
15:27:15.014704 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
15:27:15.140803 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.13 seconds
15:27:15.142714 [info ] [MainThread]: 3 of 3 OK hook: learn_dbt.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.13s]
15:27:15.143313 [info ] [MainThread]: 
15:27:15.144137 [debug] [MainThread]: On master: Close
15:27:15.393625 [info ] [MainThread]: 
15:27:15.394068 [info ] [MainThread]: Finished running 1 snapshot, 4 hooks in 9.55s.
15:27:15.394309 [debug] [MainThread]: Connection 'master' was properly closed.
15:27:15.394435 [debug] [MainThread]: Connection 'snapshot.learn_dbt.first_model_snapshot' was properly closed.
15:27:15.401651 [info ] [MainThread]: 
15:27:15.402035 [info ] [MainThread]: [32mCompleted successfully[0m
15:27:15.402330 [info ] [MainThread]: 
15:27:15.402566 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
15:27:15.402899 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1087f0400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1087f02e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1087f0f70>]}


============================== 2022-05-16 15:28:37.337047 | f7412e6c-993b-4354-b42f-77ab178b6819 ==============================
15:28:37.337047 [info ] [MainThread]: Running with dbt=1.0.1
15:28:37.337596 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['my'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
15:28:37.337736 [debug] [MainThread]: Tracking: tracking
15:28:37.337963 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106763970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106763d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067639d0>]}
15:28:37.384016 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
15:28:37.384339 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/my_first_dbt_model.sql
15:28:37.392576 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
15:28:37.401048 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
15:28:37.414372 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f7412e6c-993b-4354-b42f-77ab178b6819', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068fc0d0>]}
15:28:37.417734 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f7412e6c-993b-4354-b42f-77ab178b6819', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105268ee0>]}
15:28:37.417870 [info ] [MainThread]: Found 7 models, 12 tests, 1 snapshot, 0 analyses, 179 macros, 4 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
15:28:37.418200 [warn ] [MainThread]: The selection criterion 'my' does not match any nodes
15:28:37.418652 [info ] [MainThread]: 
15:28:37.418764 [warn ] [MainThread]: [[33mWARNING[0m]: Nothing to do. Try checking your model configs and model specification args
15:28:37.421425 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10524bfd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10525c0d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105b24a00>]}


============================== 2022-05-16 15:28:53.525099 | bb672ab1-be2d-45e4-9285-75a55b4fcda0 ==============================
15:28:53.525099 [info ] [MainThread]: Running with dbt=1.0.1
15:28:53.525630 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['my_first_dbt_model'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
15:28:53.525786 [debug] [MainThread]: Tracking: tracking
15:28:53.526005 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105077070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1050771c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105077490>]}
15:28:53.571182 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
15:28:53.571338 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
15:28:53.575078 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'bb672ab1-be2d-45e4-9285-75a55b4fcda0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1050350d0>]}
15:28:53.579170 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'bb672ab1-be2d-45e4-9285-75a55b4fcda0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103749910>]}
15:28:53.579425 [info ] [MainThread]: Found 7 models, 12 tests, 1 snapshot, 0 analyses, 179 macros, 4 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
15:28:53.580131 [info ] [MainThread]: 
15:28:53.580348 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:28:53.580647 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
15:28:53.587082 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
15:28:53.587211 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
15:28:53.587286 [debug] [ThreadPool]: Opening a new connection, currently in state init
15:28:54.340294 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 0.75 seconds
15:28:54.343371 [debug] [ThreadPool]: On list_analytics: Close
15:28:54.692866 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snaphots"
15:28:54.702107 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snaphots"
15:28:54.702460 [debug] [ThreadPool]: On list_analytics_snaphots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snaphots"} */

    show terse objects in analytics.snaphots
15:28:54.702736 [debug] [ThreadPool]: Opening a new connection, currently in state closed
15:28:55.657441 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.95 seconds
15:28:55.661014 [debug] [ThreadPool]: On list_analytics_snaphots: Close
15:28:55.874015 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
15:28:55.877012 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
15:28:55.877242 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
15:28:55.877378 [debug] [ThreadPool]: Opening a new connection, currently in state closed
15:28:56.429874 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 0.55 seconds
15:28:56.433130 [debug] [ThreadPool]: On list_analytics_dbt: Close
15:28:56.710803 [info ] [MainThread]: 
15:28:56.711444 [info ] [MainThread]: Running 1 on-run-start hook
15:28:56.712052 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-start-0
15:28:56.712867 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-start-0"
15:28:56.714734 [info ] [MainThread]: 1 of 1 START hook: learn_dbt.on-run-start.0..................................... [RUN]
15:28:56.715118 [debug] [MainThread]: Using snowflake connection "master"
15:28:56.715213 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
15:28:56.715288 [debug] [MainThread]: Opening a new connection, currently in state init
15:28:57.566568 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.85 seconds
15:28:57.568710 [info ] [MainThread]: 1 of 1 OK hook: learn_dbt.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.85s]
15:28:57.569121 [info ] [MainThread]: 
15:28:57.569581 [debug] [MainThread]: On master: Close
15:28:57.846675 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
15:28:57.847358 [info ] [MainThread]: 
15:28:57.852704 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
15:28:57.853089 [info ] [Thread-1  ]: 1 of 1 START table model dbt.first_model........................................ [RUN]
15:28:57.853613 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
15:28:57.853781 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
15:28:57.853952 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
15:28:57.857060 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
15:28:57.857864 [debug] [Thread-1  ]: finished collecting timing info
15:28:57.857960 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
15:28:57.872681 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
15:28:57.872858 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('first_model', 'starting model deployment', current_timestamp)
15:28:57.872959 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:28:59.296025 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.42 seconds
15:28:59.307078 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
15:28:59.309459 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
15:28:59.309681 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id, 'NY' as state, '2020-02-01 00:01:00.000'::timestamp as updated_at
    union all
    select null as id, 'CT' as state, '2020-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select 3 as id, 'VT' as state, '2020-01-01 00:00:00.000'::timestamp as updated_at

)

select * 
from source_data


/*
select *, True as first_variable
from source_data
where id >= 1
*/
      );
15:29:00.545415 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.24 seconds
15:29:00.549712 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
15:29:00.549891 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('first_model', 'ending model deployment', current_timestamp)
15:29:01.388761 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.84 seconds
15:29:01.402543 [debug] [Thread-1  ]: finished collecting timing info
15:29:01.402866 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
15:29:01.577322 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bb672ab1-be2d-45e4-9285-75a55b4fcda0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1051e5e80>]}
15:29:01.578074 [info ] [Thread-1  ]: 1 of 1 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 3.72s]
15:29:01.578492 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
15:29:01.579918 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:29:01.580290 [info ] [MainThread]: 
15:29:01.580461 [info ] [MainThread]: Running 3 on-run-end hooks
15:29:01.580628 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-0
15:29:01.581458 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-0"
15:29:01.583112 [info ] [MainThread]: 1 of 3 START hook: learn_dbt.on-run-end.0....................................... [RUN]
15:29:01.583490 [debug] [MainThread]: Using snowflake connection "master"
15:29:01.583588 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
15:29:01.583667 [debug] [MainThread]: Opening a new connection, currently in state closed
15:29:02.346070 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.76 seconds
15:29:02.347692 [info ] [MainThread]: 1 of 3 OK hook: learn_dbt.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.76s]
15:29:02.348337 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-1
15:29:02.350087 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-1"
15:29:02.351238 [info ] [MainThread]: 2 of 3 START hook: learn_dbt.on-run-end.1....................................... [RUN]
15:29:02.351909 [debug] [MainThread]: Using snowflake connection "master"
15:29:02.352126 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
15:29:02.507487 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.16 seconds
15:29:02.508816 [info ] [MainThread]: 2 of 3 OK hook: learn_dbt.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.16s]
15:29:02.509097 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-2
15:29:02.509991 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-2"
15:29:02.510605 [info ] [MainThread]: 3 of 3 START hook: learn_dbt.on-run-end.2....................................... [RUN]
15:29:02.511281 [debug] [MainThread]: Using snowflake connection "master"
15:29:02.511479 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
15:29:02.623742 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.11 seconds
15:29:02.624472 [info ] [MainThread]: 3 of 3 OK hook: learn_dbt.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.11s]
15:29:02.624716 [info ] [MainThread]: 
15:29:02.624910 [debug] [MainThread]: On master: Close
15:29:03.003135 [info ] [MainThread]: 
15:29:03.003866 [info ] [MainThread]: Finished running 1 table model, 4 hooks in 9.42s.
15:29:03.004211 [debug] [MainThread]: Connection 'master' was properly closed.
15:29:03.004390 [debug] [MainThread]: Connection 'model.learn_dbt.my_first_dbt_model' was properly closed.
15:29:03.011828 [info ] [MainThread]: 
15:29:03.012158 [info ] [MainThread]: [32mCompleted successfully[0m
15:29:03.012441 [info ] [MainThread]: 
15:29:03.012675 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
15:29:03.013027 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1055bd640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105412370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10559fac0>]}


============================== 2022-05-16 15:29:48.090676 | 71b82b94-c5b9-4c45-afb8-2717b87729bd ==============================
15:29:48.090676 [info ] [MainThread]: Running with dbt=1.0.1
15:29:48.091058 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.snapshot.SnapshotTask'>, which='snapshot', rpc_method='snapshot')
15:29:48.091261 [debug] [MainThread]: Tracking: tracking
15:29:48.091487 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068e3370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068e3be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068e39d0>]}
15:29:48.138005 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
15:29:48.138162 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
15:29:48.141632 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '71b82b94-c5b9-4c45-afb8-2717b87729bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068a20d0>]}
15:29:48.145425 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '71b82b94-c5b9-4c45-afb8-2717b87729bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053ac1f0>]}
15:29:48.145624 [info ] [MainThread]: Found 7 models, 12 tests, 1 snapshot, 0 analyses, 179 macros, 4 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
15:29:48.146368 [info ] [MainThread]: 
15:29:48.146576 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:29:48.146910 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
15:29:48.152896 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
15:29:48.153002 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
15:29:48.153067 [debug] [ThreadPool]: Opening a new connection, currently in state init
15:29:49.136540 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 0.98 seconds
15:29:49.138935 [debug] [ThreadPool]: On list_analytics: Close
15:29:49.345380 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snaphots"
15:29:49.353816 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snaphots"
15:29:49.354046 [debug] [ThreadPool]: On list_analytics_snaphots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snaphots"} */

    show terse objects in analytics.snaphots
15:29:49.354182 [debug] [ThreadPool]: Opening a new connection, currently in state closed
15:29:50.185457 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.83 seconds
15:29:50.187857 [debug] [ThreadPool]: On list_analytics_snaphots: Close
15:29:50.360379 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
15:29:50.363078 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
15:29:50.363379 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
15:29:50.363473 [debug] [ThreadPool]: Opening a new connection, currently in state closed
15:29:51.233270 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 0.87 seconds
15:29:51.235721 [debug] [ThreadPool]: On list_analytics_dbt: Close
15:29:51.407710 [info ] [MainThread]: 
15:29:51.408454 [info ] [MainThread]: Running 1 on-run-start hook
15:29:51.409010 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-start-0
15:29:51.410941 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-start-0"
15:29:51.413299 [info ] [MainThread]: 1 of 1 START hook: learn_dbt.on-run-start.0..................................... [RUN]
15:29:51.413941 [debug] [MainThread]: Using snowflake connection "master"
15:29:51.414108 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
15:29:51.414256 [debug] [MainThread]: Opening a new connection, currently in state init
15:29:52.000206 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.59 seconds
15:29:52.002134 [info ] [MainThread]: 1 of 1 OK hook: learn_dbt.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.59s]
15:29:52.002660 [info ] [MainThread]: 
15:29:52.003306 [debug] [MainThread]: On master: Close
15:29:52.280721 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
15:29:52.281663 [info ] [MainThread]: 
15:29:52.287960 [debug] [Thread-1  ]: Began running node snapshot.learn_dbt.first_model_snapshot
15:29:52.288186 [info ] [Thread-1  ]: 1 of 1 START snapshot snaphots.first_model_snapshot............................. [RUN]
15:29:52.288421 [debug] [Thread-1  ]: Acquiring new snowflake connection "snapshot.learn_dbt.first_model_snapshot"
15:29:52.288497 [debug] [Thread-1  ]: Began compiling node snapshot.learn_dbt.first_model_snapshot
15:29:52.288573 [debug] [Thread-1  ]: Compiling snapshot.learn_dbt.first_model_snapshot
15:29:52.290339 [debug] [Thread-1  ]: finished collecting timing info
15:29:52.290438 [debug] [Thread-1  ]: Began executing node snapshot.learn_dbt.first_model_snapshot
15:29:52.316964 [debug] [Thread-1  ]: Using snowflake connection "snapshot.learn_dbt.first_model_snapshot"
15:29:52.317181 [debug] [Thread-1  ]: On snapshot.learn_dbt.first_model_snapshot: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "snapshot.learn_dbt.first_model_snapshot"} */
select count(*)
        from analytics.INFORMATION_SCHEMA.schemata
        where upper(schema_name) = upper('snaphots')
            and upper(catalog_name) = upper('analytics')
15:29:52.317294 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:29:53.553237 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.24 seconds
15:29:53.580006 [debug] [Thread-1  ]: Using snowflake connection "snapshot.learn_dbt.first_model_snapshot"
15:29:53.580262 [debug] [Thread-1  ]: On snapshot.learn_dbt.first_model_snapshot: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "snapshot.learn_dbt.first_model_snapshot"} */

    describe table "ANALYTICS"."SNAPHOTS"."FIRST_MODEL_SNAPSHOT"
15:29:53.721363 [debug] [Thread-1  ]: SQL status: SUCCESS 7 in 0.14 seconds
15:29:53.753356 [debug] [Thread-1  ]: Using snowflake connection "snapshot.learn_dbt.first_model_snapshot"
15:29:53.753684 [debug] [Thread-1  ]: On snapshot.learn_dbt.first_model_snapshot: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "snapshot.learn_dbt.first_model_snapshot"} */

        

      create or replace temporary table "ANALYTICS"."SNAPHOTS"."FIRST_MODEL_SNAPSHOT__dbt_tmp"  as
      (with snapshot_query as (

        
    



    select * from analytics.dbt.first_model


    ),

    snapshotted_data as (

        select *,
            id as dbt_unique_key

        from "ANALYTICS"."SNAPHOTS"."FIRST_MODEL_SNAPSHOT"
        where dbt_valid_to is null

    ),

    insertions_source_data as (

        select
            *,
            id as dbt_unique_key,
            updated_at as dbt_updated_at,
            updated_at as dbt_valid_from,
            nullif(updated_at, updated_at) as dbt_valid_to,
            md5(coalesce(cast(id as varchar ), '')
         || '|' || coalesce(cast(updated_at as varchar ), '')
        ) as dbt_scd_id

        from snapshot_query
    ),

    updates_source_data as (

        select
            *,
            id as dbt_unique_key,
            updated_at as dbt_updated_at,
            updated_at as dbt_valid_from,
            updated_at as dbt_valid_to

        from snapshot_query
    ),

    insertions as (

        select
            'insert' as dbt_change_type,
            source_data.*

        from insertions_source_data as source_data
        left outer join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
        where snapshotted_data.dbt_unique_key is null
           or (
                snapshotted_data.dbt_unique_key is not null
            and (
                (snapshotted_data.dbt_valid_from < source_data.updated_at)
            )
        )

    ),

    updates as (

        select
            'update' as dbt_change_type,
            source_data.*,
            snapshotted_data.dbt_scd_id

        from updates_source_data as source_data
        join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
        where (
            (snapshotted_data.dbt_valid_from < source_data.updated_at)
        )
    )

    select * from insertions
    union all
    select * from updates

      );
15:29:54.569549 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.82 seconds
15:29:54.572925 [debug] [Thread-1  ]: Using snowflake connection "snapshot.learn_dbt.first_model_snapshot"
15:29:54.573175 [debug] [Thread-1  ]: On snapshot.learn_dbt.first_model_snapshot: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "snapshot.learn_dbt.first_model_snapshot"} */

    describe table "ANALYTICS"."SNAPHOTS"."FIRST_MODEL_SNAPSHOT__dbt_tmp"
15:29:54.674530 [debug] [Thread-1  ]: SQL status: SUCCESS 9 in 0.1 seconds
15:29:54.680000 [debug] [Thread-1  ]: Using snowflake connection "snapshot.learn_dbt.first_model_snapshot"
15:29:54.680358 [debug] [Thread-1  ]: On snapshot.learn_dbt.first_model_snapshot: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "snapshot.learn_dbt.first_model_snapshot"} */

    describe table "ANALYTICS"."SNAPHOTS"."FIRST_MODEL_SNAPSHOT"
15:29:54.859485 [debug] [Thread-1  ]: SQL status: SUCCESS 7 in 0.18 seconds
15:29:54.865107 [debug] [Thread-1  ]: Using snowflake connection "snapshot.learn_dbt.first_model_snapshot"
15:29:54.865491 [debug] [Thread-1  ]: On snapshot.learn_dbt.first_model_snapshot: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "snapshot.learn_dbt.first_model_snapshot"} */

    describe table "ANALYTICS"."SNAPHOTS"."FIRST_MODEL_SNAPSHOT__dbt_tmp"
15:29:54.975003 [debug] [Thread-1  ]: SQL status: SUCCESS 9 in 0.11 seconds
15:29:54.980570 [debug] [Thread-1  ]: Using snowflake connection "snapshot.learn_dbt.first_model_snapshot"
15:29:54.980995 [debug] [Thread-1  ]: On snapshot.learn_dbt.first_model_snapshot: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "snapshot.learn_dbt.first_model_snapshot"} */

    describe table "ANALYTICS"."SNAPHOTS"."FIRST_MODEL_SNAPSHOT"
15:29:55.093718 [debug] [Thread-1  ]: SQL status: SUCCESS 7 in 0.11 seconds
15:29:55.100652 [debug] [Thread-1  ]: Using snowflake connection "snapshot.learn_dbt.first_model_snapshot"
15:29:55.100866 [debug] [Thread-1  ]: On snapshot.learn_dbt.first_model_snapshot: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "snapshot.learn_dbt.first_model_snapshot"} */

    describe table "ANALYTICS"."SNAPHOTS"."FIRST_MODEL_SNAPSHOT__dbt_tmp"
15:29:55.238447 [debug] [Thread-1  ]: SQL status: SUCCESS 9 in 0.14 seconds
15:29:55.250178 [debug] [Thread-1  ]: Writing runtime SQL for node "snapshot.learn_dbt.first_model_snapshot"
15:29:55.252140 [debug] [Thread-1  ]: Using snowflake connection "snapshot.learn_dbt.first_model_snapshot"
15:29:55.252306 [debug] [Thread-1  ]: On snapshot.learn_dbt.first_model_snapshot: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "snapshot.learn_dbt.first_model_snapshot"} */

      begin;
15:29:55.435271 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.18 seconds
15:29:55.435877 [debug] [Thread-1  ]: Using snowflake connection "snapshot.learn_dbt.first_model_snapshot"
15:29:55.436072 [debug] [Thread-1  ]: On snapshot.learn_dbt.first_model_snapshot: merge into "ANALYTICS"."SNAPHOTS"."FIRST_MODEL_SNAPSHOT" as DBT_INTERNAL_DEST
    using "ANALYTICS"."SNAPHOTS"."FIRST_MODEL_SNAPSHOT__dbt_tmp" as DBT_INTERNAL_SOURCE
    on DBT_INTERNAL_SOURCE.dbt_scd_id = DBT_INTERNAL_DEST.dbt_scd_id

    when matched
     and DBT_INTERNAL_DEST.dbt_valid_to is null
     and DBT_INTERNAL_SOURCE.dbt_change_type in ('update', 'delete')
        then update
        set dbt_valid_to = DBT_INTERNAL_SOURCE.dbt_valid_to

    when not matched
     and DBT_INTERNAL_SOURCE.dbt_change_type = 'insert'
        then insert ("ID", "STATE", "UPDATED_AT", "DBT_UPDATED_AT", "DBT_VALID_FROM", "DBT_VALID_TO", "DBT_SCD_ID")
        values ("ID", "STATE", "UPDATED_AT", "DBT_UPDATED_AT", "DBT_VALID_FROM", "DBT_VALID_TO", "DBT_SCD_ID")

;
15:29:56.119943 [debug] [Thread-1  ]: SQL status: SUCCESS 2 in 0.68 seconds
15:29:56.120676 [debug] [Thread-1  ]: Using snowflake connection "snapshot.learn_dbt.first_model_snapshot"
15:29:56.120870 [debug] [Thread-1  ]: On snapshot.learn_dbt.first_model_snapshot: commit;
15:29:56.473654 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.35 seconds
15:29:56.491631 [debug] [Thread-1  ]: finished collecting timing info
15:29:56.491924 [debug] [Thread-1  ]: On snapshot.learn_dbt.first_model_snapshot: Close
15:29:56.694090 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '71b82b94-c5b9-4c45-afb8-2717b87729bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ccb6a0>]}
15:29:56.695064 [info ] [Thread-1  ]: 1 of 1 OK snapshotted snaphots.first_model_snapshot............................. [[32mSUCCESS 1[0m in 4.41s]
15:29:56.695632 [debug] [Thread-1  ]: Finished running node snapshot.learn_dbt.first_model_snapshot
15:29:56.696923 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:29:56.697216 [info ] [MainThread]: 
15:29:56.697491 [info ] [MainThread]: Running 3 on-run-end hooks
15:29:56.697780 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-0
15:29:56.699180 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-0"
15:29:56.700161 [info ] [MainThread]: 1 of 3 START hook: learn_dbt.on-run-end.0....................................... [RUN]
15:29:56.700701 [debug] [MainThread]: Using snowflake connection "master"
15:29:56.700858 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
15:29:56.701000 [debug] [MainThread]: Opening a new connection, currently in state closed
15:29:57.649687 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.95 seconds
15:29:57.662237 [info ] [MainThread]: 1 of 3 OK hook: learn_dbt.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.96s]
15:29:57.662786 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-1
15:29:57.665927 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-1"
15:29:57.667025 [info ] [MainThread]: 2 of 3 START hook: learn_dbt.on-run-end.1....................................... [RUN]
15:29:57.667494 [debug] [MainThread]: Using snowflake connection "master"
15:29:57.667622 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
15:29:57.792002 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.12 seconds
15:29:57.793942 [info ] [MainThread]: 2 of 3 OK hook: learn_dbt.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.13s]
15:29:57.794368 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-2
15:29:57.797102 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-2"
15:29:57.799669 [info ] [MainThread]: 3 of 3 START hook: learn_dbt.on-run-end.2....................................... [RUN]
15:29:57.800423 [debug] [MainThread]: Using snowflake connection "master"
15:29:57.800638 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
15:29:57.924266 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.12 seconds
15:29:57.924970 [info ] [MainThread]: 3 of 3 OK hook: learn_dbt.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.12s]
15:29:57.925210 [info ] [MainThread]: 
15:29:57.925395 [debug] [MainThread]: On master: Close
15:29:58.124909 [info ] [MainThread]: 
15:29:58.125627 [info ] [MainThread]: Finished running 1 snapshot, 4 hooks in 9.98s.
15:29:58.126127 [debug] [MainThread]: Connection 'master' was properly closed.
15:29:58.126349 [debug] [MainThread]: Connection 'snapshot.learn_dbt.first_model_snapshot' was properly closed.
15:29:58.136374 [info ] [MainThread]: 
15:29:58.136740 [info ] [MainThread]: [32mCompleted successfully[0m
15:29:58.137045 [info ] [MainThread]: 
15:29:58.137285 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
15:29:58.137609 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c9b0a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108b7f4f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108b7f8e0>]}


============================== 2022-05-16 15:43:35.417623 | 21c013d7-e8d9-41b7-842c-2cce30de6323 ==============================
15:43:35.417623 [info ] [MainThread]: Running with dbt=1.0.1
15:43:35.418207 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
15:43:35.418407 [debug] [MainThread]: Tracking: tracking
15:43:35.418644 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c97e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c978e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c97eb0>]}
15:43:35.458460 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c66a60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c667c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c66880>]}


============================== 2022-05-16 15:44:05.280819 | 1843c7b8-aa71-42f3-8439-2ea798de3d51 ==============================
15:44:05.280819 [info ] [MainThread]: Running with dbt=1.0.1
15:44:05.282179 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
15:44:05.282495 [debug] [MainThread]: Tracking: tracking
15:44:05.283053 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1104d3850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1104d31c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1104d3ee0>]}
15:44:05.332171 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
15:44:05.332476 [debug] [MainThread]: Partial parsing: update schema file: learn_dbt://models/example/schema.yml
15:44:05.332626 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/snowflake_customer_purchases.sql
15:44:05.340169 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
15:44:05.366914 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1843c7b8-aa71-42f3-8439-2ea798de3d51', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1106680d0>]}
15:44:05.370498 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1843c7b8-aa71-42f3-8439-2ea798de3d51', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1064de1c0>]}
15:44:05.370626 [info ] [MainThread]: Found 7 models, 12 tests, 1 snapshot, 0 analyses, 179 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
15:44:05.371543 [info ] [MainThread]: 
15:44:05.371764 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:44:05.372257 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
15:44:05.378960 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
15:44:05.379131 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
15:44:05.379200 [debug] [ThreadPool]: Opening a new connection, currently in state init
15:44:06.354975 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 0.98 seconds
15:44:06.357591 [debug] [ThreadPool]: On list_analytics: Close
15:44:06.573783 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
15:44:06.582407 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
15:44:06.582687 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
15:44:06.582850 [debug] [ThreadPool]: Opening a new connection, currently in state closed
15:44:07.482439 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 0.9 seconds
15:44:07.485381 [debug] [ThreadPool]: On list_analytics_dbt: Close
15:44:07.649521 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snaphots"
15:44:07.652726 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snaphots"
15:44:07.652974 [debug] [ThreadPool]: On list_analytics_snaphots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snaphots"} */

    show terse objects in analytics.snaphots
15:44:07.653154 [debug] [ThreadPool]: Opening a new connection, currently in state closed
15:44:08.396352 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.74 seconds
15:44:08.399001 [debug] [ThreadPool]: On list_analytics_snaphots: Close
15:44:08.588153 [info ] [MainThread]: 
15:44:08.588614 [info ] [MainThread]: Running 1 on-run-start hook
15:44:08.588893 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-start-0
15:44:08.589667 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-start-0"
15:44:08.591415 [info ] [MainThread]: 1 of 1 START hook: learn_dbt.on-run-start.0..................................... [RUN]
15:44:08.591709 [debug] [MainThread]: Using snowflake connection "master"
15:44:08.591779 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
15:44:08.591838 [debug] [MainThread]: Opening a new connection, currently in state init
15:44:09.331983 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.74 seconds
15:44:09.333792 [info ] [MainThread]: 1 of 1 OK hook: learn_dbt.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.74s]
15:44:09.334339 [info ] [MainThread]: 
15:44:09.334733 [debug] [MainThread]: On master: Close
15:44:09.528658 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
15:44:09.529210 [info ] [MainThread]: 
15:44:09.535162 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
15:44:09.535532 [info ] [Thread-1  ]: 1 of 7 START incremental model dbt.dates........................................ [RUN]
15:44:09.536374 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
15:44:09.536554 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
15:44:09.536729 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
15:44:09.544395 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
15:44:09.545096 [debug] [Thread-1  ]: finished collecting timing info
15:44:09.545248 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
15:44:09.575486 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
15:44:09.575669 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
15:44:09.575740 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:44:11.296503 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.72 seconds
15:44:11.325895 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
15:44:11.326364 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
15:44:11.429612 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.1 seconds
15:44:11.437086 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
15:44:11.437469 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
15:44:11.542743 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.11 seconds
15:44:11.557203 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
15:44:11.557521 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
15:44:11.676858 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.12 seconds
15:44:11.702042 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
15:44:11.704381 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
15:44:11.704528 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
15:44:11.819018 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.11 seconds
15:44:11.819726 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
15:44:11.819912 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
15:44:12.088356 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.27 seconds
15:44:12.088804 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
15:44:12.088989 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
15:44:12.298175 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.21 seconds
15:44:12.312743 [debug] [Thread-1  ]: finished collecting timing info
15:44:12.313175 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
15:44:12.587674 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1843c7b8-aa71-42f3-8439-2ea798de3d51', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111b29220>]}
15:44:12.588638 [info ] [Thread-1  ]: 1 of 7 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 3.05s]
15:44:12.589153 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
15:44:12.589427 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
15:44:12.589875 [info ] [Thread-1  ]: 2 of 7 START incremental model dbt.incremental_time............................. [RUN]
15:44:12.590632 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
15:44:12.590893 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
15:44:12.591110 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
15:44:12.595151 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
15:44:12.597944 [debug] [Thread-1  ]: finished collecting timing info
15:44:12.598200 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
15:44:12.602752 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
15:44:12.602998 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

        insert into dbt.audit (model, state, time) values ('incremental_time', 'starting model deployment', current_timestamp)
15:44:12.603171 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:44:13.651451 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.05 seconds
15:44:13.655777 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
15:44:13.656195 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
15:44:14.454709 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.8 seconds
15:44:14.460285 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
15:44:14.460622 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
15:44:14.576113 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.12 seconds
15:44:14.578822 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
15:44:14.579086 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
15:44:14.709403 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.13 seconds
15:44:14.715626 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
15:44:14.715963 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
15:44:14.811858 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
15:44:14.817443 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
15:44:14.819987 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
15:44:14.820196 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
15:44:14.947525 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.13 seconds
15:44:14.948191 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
15:44:14.948394 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
15:44:15.626126 [debug] [Thread-1  ]: SQL status: SUCCESS 1532 in 0.68 seconds
15:44:15.627057 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
15:44:15.627224 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
15:44:15.895503 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.27 seconds
15:44:15.899714 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
15:44:15.899995 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

        insert into dbt.audit (model, state, time) values ('incremental_time', 'ending model deployment', current_timestamp)
15:44:16.338032 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.44 seconds
15:44:16.340050 [debug] [Thread-1  ]: finished collecting timing info
15:44:16.340234 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
15:44:16.534171 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1843c7b8-aa71-42f3-8439-2ea798de3d51', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111a53400>]}
15:44:16.535648 [info ] [Thread-1  ]: 2 of 7 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 3.94s]
15:44:16.536386 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
15:44:16.536668 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
15:44:16.537125 [info ] [Thread-1  ]: 3 of 7 START table model dbt.first_model........................................ [RUN]
15:44:16.537870 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
15:44:16.538120 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
15:44:16.538345 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
15:44:16.542979 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
15:44:16.544978 [debug] [Thread-1  ]: finished collecting timing info
15:44:16.545161 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
15:44:16.552712 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
15:44:16.552943 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('first_model', 'starting model deployment', current_timestamp)
15:44:16.553079 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:44:17.974491 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.42 seconds
15:44:17.977166 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
15:44:17.980079 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
15:44:17.980276 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id, 'NY' as state, '2020-02-01 00:01:00.000'::timestamp as updated_at
    union all
    select null as id, 'CT' as state, '2020-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select 3 as id, 'VT' as state, '2020-01-01 00:00:00.000'::timestamp as updated_at

)

select * 
from source_data


/*
select *, True as first_variable
from source_data
where id >= 1
*/
      );
15:44:18.564043 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.58 seconds
15:44:18.565738 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
15:44:18.565848 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('first_model', 'ending model deployment', current_timestamp)
15:44:18.996404 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.43 seconds
15:44:18.999617 [debug] [Thread-1  ]: finished collecting timing info
15:44:19.000067 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
15:44:19.212897 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1843c7b8-aa71-42f3-8439-2ea798de3d51', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113c12d00>]}
15:44:19.213271 [info ] [Thread-1  ]: 3 of 7 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 2.68s]
15:44:19.213471 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
15:44:19.213579 [debug] [Thread-1  ]: Began running node model.learn_dbt.playing_with_tests
15:44:19.213680 [info ] [Thread-1  ]: 4 of 7 START table model dbt.playing_with_tests................................. [RUN]
15:44:19.213986 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.playing_with_tests"
15:44:19.214061 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.playing_with_tests
15:44:19.214252 [debug] [Thread-1  ]: Compiling model.learn_dbt.playing_with_tests
15:44:19.215250 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.playing_with_tests"
15:44:19.215593 [debug] [Thread-1  ]: finished collecting timing info
15:44:19.215672 [debug] [Thread-1  ]: Began executing node model.learn_dbt.playing_with_tests
15:44:19.218453 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
15:44:19.218625 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */

        insert into dbt.audit (model, state, time) values ('playing_with_tests', 'starting model deployment', current_timestamp)
15:44:19.218773 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:44:20.605963 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.39 seconds
15:44:20.608104 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.playing_with_tests"
15:44:20.609124 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
15:44:20.609307 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */


      create or replace transient table analytics.dbt.playing_with_tests  as
      (select * 
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER"
      );
15:44:21.999869 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.39 seconds
15:44:22.007094 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
15:44:22.007365 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */

        insert into dbt.audit (model, state, time) values ('playing_with_tests', 'ending model deployment', current_timestamp)
15:44:22.570331 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.56 seconds
15:44:22.574234 [debug] [Thread-1  ]: finished collecting timing info
15:44:22.574670 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: Close
15:44:22.753141 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1843c7b8-aa71-42f3-8439-2ea798de3d51', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113c12bb0>]}
15:44:22.753959 [info ] [Thread-1  ]: 4 of 7 OK created table model dbt.playing_with_tests............................ [[32mSUCCESS 1[0m in 3.54s]
15:44:22.754444 [debug] [Thread-1  ]: Finished running node model.learn_dbt.playing_with_tests
15:44:22.754715 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
15:44:22.755201 [info ] [Thread-1  ]: 5 of 7 START table model dbt.snowflake_cumulative_sales......................... [RUN]
15:44:22.755669 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
15:44:22.755820 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
15:44:22.755973 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
15:44:22.757951 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
15:44:22.759790 [debug] [Thread-1  ]: finished collecting timing info
15:44:22.759931 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
15:44:22.761980 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
15:44:22.762111 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */

        insert into dbt.audit (model, state, time) values ('snowflake_cumulative_sales', 'starting model deployment', current_timestamp)
15:44:22.762203 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:44:23.775250 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.01 seconds
15:44:23.776895 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
15:44:23.777818 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
15:44:23.777954 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
15:44:24.756308 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.98 seconds
15:44:24.759840 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
15:44:24.760013 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */

        insert into dbt.audit (model, state, time) values ('snowflake_cumulative_sales', 'ending model deployment', current_timestamp)
15:44:25.246817 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.49 seconds
15:44:25.250193 [debug] [Thread-1  ]: finished collecting timing info
15:44:25.250529 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
15:44:25.428430 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1843c7b8-aa71-42f3-8439-2ea798de3d51', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111a8f160>]}
15:44:25.429294 [info ] [Thread-1  ]: 5 of 7 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 2.67s]
15:44:25.429802 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
15:44:25.430061 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
15:44:25.430442 [info ] [Thread-1  ]: 6 of 7 START table model dbt.snowflake_customer_purchases....................... [RUN]
15:44:25.431001 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
15:44:25.431203 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
15:44:25.431405 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
15:44:25.435570 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
15:44:25.436451 [debug] [Thread-1  ]: finished collecting timing info
15:44:25.436635 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
15:44:25.439978 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
15:44:25.440191 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */

        insert into dbt.audit (model, state, time) values ('snowflake_customer_purchases', 'starting model deployment', current_timestamp)
15:44:25.440347 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:44:26.453043 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.01 seconds
15:44:26.455992 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
15:44:26.458578 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
15:44:26.458847 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from snowflake_sample_data.tpch_sf1.customer
left join snowflake_sample_data.tpch_sf1.orders o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
15:44:26.610925 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a44eb0-3201-9e37-0000-00012052c159
15:44:26.611306 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 000904 (42000): SQL compilation error: error line 8 at position 3
invalid identifier 'C.C_CUSTKEY'
15:44:26.611629 [debug] [Thread-1  ]: finished collecting timing info
15:44:26.611840 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
15:44:26.922976 [debug] [Thread-1  ]: Database Error in model snowflake_customer_purchases (models/example/snowflake_customer_purchases.sql)
  000904 (42000): SQL compilation error: error line 8 at position 3
  invalid identifier 'C.C_CUSTKEY'
  compiled SQL at target/run/learn_dbt/models/example/snowflake_customer_purchases.sql
15:44:26.923772 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1843c7b8-aa71-42f3-8439-2ea798de3d51', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113c2cd60>]}
15:44:26.924388 [error] [Thread-1  ]: 6 of 7 ERROR creating table model dbt.snowflake_customer_purchases.............. [[31mERROR[0m in 1.49s]
15:44:26.924889 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
15:44:26.925143 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
15:44:26.925746 [info ] [Thread-1  ]: 7 of 7 START table model dbt.my_second_dbt_model................................ [RUN]
15:44:26.926551 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
15:44:26.926791 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
15:44:26.927007 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
15:44:26.930946 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
15:44:26.931628 [debug] [Thread-1  ]: finished collecting timing info
15:44:26.931810 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
15:44:26.934880 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
15:44:26.935203 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('my_second_dbt_model', 'starting model deployment', current_timestamp)
15:44:26.935334 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:44:27.963216 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.03 seconds
15:44:27.966594 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
15:44:27.968118 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
15:44:27.968353 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
/*
union all
select 7 as id, True as first_variable
*/
      );
15:44:28.671784 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.7 seconds
15:44:28.676743 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
15:44:28.677023 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('my_second_dbt_model', 'ending model deployment', current_timestamp)
15:44:29.096821 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.42 seconds
15:44:29.100440 [debug] [Thread-1  ]: finished collecting timing info
15:44:29.100863 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
15:44:29.357093 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1843c7b8-aa71-42f3-8439-2ea798de3d51', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113c2c1f0>]}
15:44:29.357843 [info ] [Thread-1  ]: 7 of 7 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 2.43s]
15:44:29.358227 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
15:44:29.359120 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:44:29.359303 [info ] [MainThread]: 
15:44:29.359458 [info ] [MainThread]: Running 3 on-run-end hooks
15:44:29.359622 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-0
15:44:29.360388 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-0"
15:44:29.360916 [info ] [MainThread]: 1 of 3 START hook: learn_dbt.on-run-end.0....................................... [RUN]
15:44:29.361203 [debug] [MainThread]: Using snowflake connection "master"
15:44:29.361291 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
15:44:29.361368 [debug] [MainThread]: Opening a new connection, currently in state closed
15:44:30.304059 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.94 seconds
15:44:30.311604 [info ] [MainThread]: 1 of 3 OK hook: learn_dbt.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.95s]
15:44:30.312604 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-1
15:44:30.314152 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-1"
15:44:30.315177 [info ] [MainThread]: 2 of 3 START hook: learn_dbt.on-run-end.1....................................... [RUN]
15:44:30.315686 [debug] [MainThread]: Using snowflake connection "master"
15:44:30.315817 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
15:44:30.500609 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.18 seconds
15:44:30.502074 [info ] [MainThread]: 2 of 3 OK hook: learn_dbt.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.19s]
15:44:30.503281 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-2
15:44:30.505489 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-2"
15:44:30.506565 [info ] [MainThread]: 3 of 3 START hook: learn_dbt.on-run-end.2....................................... [RUN]
15:44:30.507168 [debug] [MainThread]: Using snowflake connection "master"
15:44:30.507349 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
15:44:30.625047 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.12 seconds
15:44:30.626427 [info ] [MainThread]: 3 of 3 OK hook: learn_dbt.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.12s]
15:44:30.626921 [info ] [MainThread]: 
15:44:30.627276 [debug] [MainThread]: On master: Close
15:44:30.795261 [info ] [MainThread]: 
15:44:30.795849 [info ] [MainThread]: Finished running 2 incremental models, 5 table models, 4 hooks in 25.42s.
15:44:30.796184 [debug] [MainThread]: Connection 'master' was properly closed.
15:44:30.796360 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
15:44:30.803334 [info ] [MainThread]: 
15:44:30.803635 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
15:44:30.803908 [info ] [MainThread]: 
15:44:30.804139 [error] [MainThread]: [33mDatabase Error in model snowflake_customer_purchases (models/example/snowflake_customer_purchases.sql)[0m
15:44:30.804371 [error] [MainThread]:   000904 (42000): SQL compilation error: error line 8 at position 3
15:44:30.804588 [error] [MainThread]:   invalid identifier 'C.C_CUSTKEY'
15:44:30.804798 [error] [MainThread]:   compiled SQL at target/run/learn_dbt/models/example/snowflake_customer_purchases.sql
15:44:30.805028 [info ] [MainThread]: 
15:44:30.805248 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=1 SKIP=0 TOTAL=7
15:44:30.805561 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111b04160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111b04c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113c128b0>]}


============================== 2022-05-16 15:45:32.404915 | 05a960f3-d005-49bf-becb-ca62fd357651 ==============================
15:45:32.404915 [info ] [MainThread]: Running with dbt=1.0.1
15:45:32.405427 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['snowflake_customer_purchases'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
15:45:32.405591 [debug] [MainThread]: Tracking: tracking
15:45:32.405899 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1105d3f70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1105d38e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1105d3910>]}
15:45:32.453655 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
15:45:32.453948 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/snowflake_customer_purchases.sql
15:45:32.459527 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
15:45:32.480459 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '05a960f3-d005-49bf-becb-ca62fd357651', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11076b0d0>]}
15:45:32.483953 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '05a960f3-d005-49bf-becb-ca62fd357651', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1106e4070>]}
15:45:32.484086 [info ] [MainThread]: Found 7 models, 12 tests, 1 snapshot, 0 analyses, 179 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
15:45:32.484805 [info ] [MainThread]: 
15:45:32.485011 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:45:32.485328 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
15:45:32.491186 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
15:45:32.491286 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
15:45:32.491348 [debug] [ThreadPool]: Opening a new connection, currently in state init
15:45:33.463151 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 0.97 seconds
15:45:33.466110 [debug] [ThreadPool]: On list_analytics: Close
15:45:33.625902 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
15:45:33.634716 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
15:45:33.635038 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
15:45:33.635207 [debug] [ThreadPool]: Opening a new connection, currently in state closed
15:45:34.531942 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 0.9 seconds
15:45:34.537311 [debug] [ThreadPool]: On list_analytics_dbt: Close
15:45:34.733237 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snaphots"
15:45:34.735190 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snaphots"
15:45:34.735400 [debug] [ThreadPool]: On list_analytics_snaphots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snaphots"} */

    show terse objects in analytics.snaphots
15:45:34.735554 [debug] [ThreadPool]: Opening a new connection, currently in state closed
15:45:35.422463 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.69 seconds
15:45:35.424732 [debug] [ThreadPool]: On list_analytics_snaphots: Close
15:45:35.590043 [info ] [MainThread]: 
15:45:35.590755 [info ] [MainThread]: Running 1 on-run-start hook
15:45:35.591134 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-start-0
15:45:35.592978 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-start-0"
15:45:35.594920 [info ] [MainThread]: 1 of 1 START hook: learn_dbt.on-run-start.0..................................... [RUN]
15:45:35.595495 [debug] [MainThread]: Using snowflake connection "master"
15:45:35.595645 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
15:45:35.595781 [debug] [MainThread]: Opening a new connection, currently in state init
15:45:36.363217 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.77 seconds
15:45:36.364864 [info ] [MainThread]: 1 of 1 OK hook: learn_dbt.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.77s]
15:45:36.365494 [info ] [MainThread]: 
15:45:36.365888 [debug] [MainThread]: On master: Close
15:45:36.553941 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
15:45:36.554750 [info ] [MainThread]: 
15:45:36.560471 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
15:45:36.560886 [info ] [Thread-1  ]: 1 of 1 START table model dbt.snowflake_customer_purchases....................... [RUN]
15:45:36.561591 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
15:45:36.561868 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
15:45:36.562048 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
15:45:36.565447 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
15:45:36.566197 [debug] [Thread-1  ]: finished collecting timing info
15:45:36.566367 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
15:45:36.581388 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
15:45:36.581558 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */

        insert into dbt.audit (model, state, time) values ('snowflake_customer_purchases', 'starting model deployment', current_timestamp)
15:45:36.581667 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:45:38.129990 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.55 seconds
15:45:38.143888 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
15:45:38.144885 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
15:45:38.144969 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from snowflake_sample_data.tpch_sf1.customer c
left join snowflake_sample_data.tpch_sf1.orders o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
15:45:39.662569 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.52 seconds
15:45:39.666400 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
15:45:39.666635 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */

        insert into dbt.audit (model, state, time) values ('snowflake_customer_purchases', 'ending model deployment', current_timestamp)
15:45:40.178980 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.51 seconds
15:45:40.192865 [debug] [Thread-1  ]: finished collecting timing info
15:45:40.193299 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
15:45:40.366013 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '05a960f3-d005-49bf-becb-ca62fd357651', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11161b5e0>]}
15:45:40.366638 [info ] [Thread-1  ]: 1 of 1 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 3.80s]
15:45:40.367119 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
15:45:40.368545 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:45:40.368878 [info ] [MainThread]: 
15:45:40.369225 [info ] [MainThread]: Running 3 on-run-end hooks
15:45:40.369574 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-0
15:45:40.371465 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-0"
15:45:40.372557 [info ] [MainThread]: 1 of 3 START hook: learn_dbt.on-run-end.0....................................... [RUN]
15:45:40.373095 [debug] [MainThread]: Using snowflake connection "master"
15:45:40.373255 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
15:45:40.373396 [debug] [MainThread]: Opening a new connection, currently in state closed
15:45:40.951622 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.58 seconds
15:45:40.953519 [info ] [MainThread]: 1 of 3 OK hook: learn_dbt.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.58s]
15:45:40.954051 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-1
15:45:40.955540 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-1"
15:45:40.956200 [info ] [MainThread]: 2 of 3 START hook: learn_dbt.on-run-end.1....................................... [RUN]
15:45:40.956618 [debug] [MainThread]: Using snowflake connection "master"
15:45:40.956738 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
15:45:41.216250 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.26 seconds
15:45:41.217150 [info ] [MainThread]: 2 of 3 OK hook: learn_dbt.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.26s]
15:45:41.217379 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-2
15:45:41.218591 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-2"
15:45:41.219107 [info ] [MainThread]: 3 of 3 START hook: learn_dbt.on-run-end.2....................................... [RUN]
15:45:41.219393 [debug] [MainThread]: Using snowflake connection "master"
15:45:41.219478 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
15:45:41.328537 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.11 seconds
15:45:41.329787 [info ] [MainThread]: 3 of 3 OK hook: learn_dbt.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.11s]
15:45:41.330041 [info ] [MainThread]: 
15:45:41.330235 [debug] [MainThread]: On master: Close
15:45:41.497519 [info ] [MainThread]: 
15:45:41.498101 [info ] [MainThread]: Finished running 1 table model, 4 hooks in 9.01s.
15:45:41.498438 [debug] [MainThread]: Connection 'master' was properly closed.
15:45:41.498612 [debug] [MainThread]: Connection 'model.learn_dbt.snowflake_customer_purchases' was properly closed.
15:45:41.507153 [info ] [MainThread]: 
15:45:41.507525 [info ] [MainThread]: [32mCompleted successfully[0m
15:45:41.508052 [info ] [MainThread]: 
15:45:41.508318 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
15:45:41.508647 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1106e4130>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11177bd00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1114f4a00>]}


============================== 2022-05-16 15:46:37.664103 | a6013461-642e-487e-bff3-e547fa9f05fb ==============================
15:46:37.664103 [info ] [MainThread]: Running with dbt=1.0.1
15:46:37.664463 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['snowflake_customer_purchases'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
15:46:37.664592 [debug] [MainThread]: Tracking: tracking
15:46:37.664831 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106bea160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106bea070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106bea400>]}
15:46:37.708731 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
15:46:37.709133 [debug] [MainThread]: Partial parsing: deleted source source.learn_dbt.sample.orders
15:46:37.709208 [debug] [MainThread]: Partial parsing: deleted source source.learn_dbt.sample.customer
15:46:37.709277 [debug] [MainThread]: Partial parsing: update schema file: learn_dbt://models/example/schema.yml
15:46:37.714734 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
15:46:37.735621 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106d53a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106bb6b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106bb6bb0>]}


============================== 2022-05-16 15:47:18.604725 | 0d0e68e8-02e2-4d0b-8001-061021ab22d3 ==============================
15:47:18.604725 [info ] [MainThread]: Running with dbt=1.0.1
15:47:18.605371 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['snowflake_customer_purchases'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
15:47:18.605535 [debug] [MainThread]: Tracking: tracking
15:47:18.605752 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106983e80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106983f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1069839d0>]}
15:47:18.655721 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
15:47:18.656096 [debug] [MainThread]: Partial parsing: deleted source source.learn_dbt.sample.orders
15:47:18.656172 [debug] [MainThread]: Partial parsing: deleted source source.learn_dbt.sample.customer
15:47:18.656244 [debug] [MainThread]: Partial parsing: update schema file: learn_dbt://models/example/schema.yml
15:47:18.661607 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
15:47:18.682988 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ad3c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106aa9820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106aa9880>]}


============================== 2022-05-16 15:48:27.400073 | 26845377-f750-4ee9-9c01-e682c8464a7c ==============================
15:48:27.400073 [info ] [MainThread]: Running with dbt=1.0.1
15:48:27.401026 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['snowflake_customer_purchases'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
15:48:27.401288 [debug] [MainThread]: Tracking: tracking
15:48:27.401663 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11164fbb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11164ff40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11164ffa0>]}
15:48:27.449980 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
15:48:27.450361 [debug] [MainThread]: Partial parsing: deleted source source.learn_dbt.sample.orders
15:48:27.450435 [debug] [MainThread]: Partial parsing: deleted source source.learn_dbt.sample.customer
15:48:27.450504 [debug] [MainThread]: Partial parsing: update schema file: learn_dbt://models/example/schema.yml
15:48:27.455821 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
15:48:27.484662 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '26845377-f750-4ee9-9c01-e682c8464a7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1118210d0>]}
15:48:27.488465 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '26845377-f750-4ee9-9c01-e682c8464a7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1117de640>]}
15:48:27.488597 [info ] [MainThread]: Found 7 models, 14 tests, 1 snapshot, 0 analyses, 179 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
15:48:27.489248 [info ] [MainThread]: 
15:48:27.489449 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:48:27.489785 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
15:48:27.496008 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
15:48:27.496145 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
15:48:27.496214 [debug] [ThreadPool]: Opening a new connection, currently in state init
15:48:28.449102 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 0.95 seconds
15:48:28.450801 [debug] [ThreadPool]: On list_analytics: Close
15:48:28.649989 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
15:48:28.658600 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
15:48:28.658826 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
15:48:28.658985 [debug] [ThreadPool]: Opening a new connection, currently in state closed
15:48:29.494417 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 0.84 seconds
15:48:29.497262 [debug] [ThreadPool]: On list_analytics_dbt: Close
15:48:29.693720 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snaphots"
15:48:29.696907 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snaphots"
15:48:29.697147 [debug] [ThreadPool]: On list_analytics_snaphots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snaphots"} */

    show terse objects in analytics.snaphots
15:48:29.697303 [debug] [ThreadPool]: Opening a new connection, currently in state closed
15:48:30.423671 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.73 seconds
15:48:30.427086 [debug] [ThreadPool]: On list_analytics_snaphots: Close
15:48:30.617428 [info ] [MainThread]: 
15:48:30.617936 [info ] [MainThread]: Running 1 on-run-start hook
15:48:30.618211 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-start-0
15:48:30.619453 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-start-0"
15:48:30.620988 [info ] [MainThread]: 1 of 1 START hook: learn_dbt.on-run-start.0..................................... [RUN]
15:48:30.621606 [debug] [MainThread]: Using snowflake connection "master"
15:48:30.621771 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
15:48:30.621916 [debug] [MainThread]: Opening a new connection, currently in state init
15:48:31.378163 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.76 seconds
15:48:31.381005 [info ] [MainThread]: 1 of 1 OK hook: learn_dbt.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.76s]
15:48:31.381621 [info ] [MainThread]: 
15:48:31.382119 [debug] [MainThread]: On master: Close
15:48:31.827367 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
15:48:31.828069 [info ] [MainThread]: 
15:48:31.833421 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
15:48:31.833806 [info ] [Thread-1  ]: 1 of 1 START table model dbt.snowflake_customer_purchases....................... [RUN]
15:48:31.834322 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
15:48:31.834494 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
15:48:31.834650 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
15:48:31.838108 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
15:48:31.838737 [debug] [Thread-1  ]: finished collecting timing info
15:48:31.838895 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
15:48:31.853430 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
15:48:31.853597 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */

        insert into dbt.audit (model, state, time) values ('snowflake_customer_purchases', 'starting model deployment', current_timestamp)
15:48:31.853697 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:48:33.667729 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.81 seconds
15:48:33.681524 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
15:48:33.682822 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
15:48:33.682971 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from snowflake_sample_data.tpch_sf1.customer c
left join snowflake_sample_data.tpch_sf1.orders o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
15:48:35.262289 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.58 seconds
15:48:35.268108 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
15:48:35.268428 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */

        insert into dbt.audit (model, state, time) values ('snowflake_customer_purchases', 'ending model deployment', current_timestamp)
15:48:35.859843 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.59 seconds
15:48:35.873339 [debug] [Thread-1  ]: finished collecting timing info
15:48:35.873723 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
15:48:36.040683 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '26845377-f750-4ee9-9c01-e682c8464a7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111d5c070>]}
15:48:36.041450 [info ] [Thread-1  ]: 1 of 1 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 4.21s]
15:48:36.041914 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
15:48:36.043261 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:48:36.043617 [info ] [MainThread]: 
15:48:36.043941 [info ] [MainThread]: Running 3 on-run-end hooks
15:48:36.044243 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-0
15:48:36.045857 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-0"
15:48:36.046697 [info ] [MainThread]: 1 of 3 START hook: learn_dbt.on-run-end.0....................................... [RUN]
15:48:36.047211 [debug] [MainThread]: Using snowflake connection "master"
15:48:36.047364 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
15:48:36.047500 [debug] [MainThread]: Opening a new connection, currently in state closed
15:48:36.833954 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.79 seconds
15:48:36.836438 [info ] [MainThread]: 1 of 3 OK hook: learn_dbt.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.79s]
15:48:36.837650 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-1
15:48:36.841300 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-1"
15:48:36.842528 [info ] [MainThread]: 2 of 3 START hook: learn_dbt.on-run-end.1....................................... [RUN]
15:48:36.843224 [debug] [MainThread]: Using snowflake connection "master"
15:48:36.843429 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
15:48:37.033726 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.19 seconds
15:48:37.035253 [info ] [MainThread]: 2 of 3 OK hook: learn_dbt.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.19s]
15:48:37.036038 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-2
15:48:37.038382 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-2"
15:48:37.039530 [info ] [MainThread]: 3 of 3 START hook: learn_dbt.on-run-end.2....................................... [RUN]
15:48:37.040219 [debug] [MainThread]: Using snowflake connection "master"
15:48:37.040415 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
15:48:37.141781 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.1 seconds
15:48:37.144552 [info ] [MainThread]: 3 of 3 OK hook: learn_dbt.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.10s]
15:48:37.144825 [info ] [MainThread]: 
15:48:37.145018 [debug] [MainThread]: On master: Close
15:48:37.496655 [info ] [MainThread]: 
15:48:37.497307 [info ] [MainThread]: Finished running 1 table model, 4 hooks in 10.01s.
15:48:37.497530 [debug] [MainThread]: Connection 'master' was properly closed.
15:48:37.497645 [debug] [MainThread]: Connection 'model.learn_dbt.snowflake_customer_purchases' was properly closed.
15:48:37.504114 [info ] [MainThread]: 
15:48:37.504408 [info ] [MainThread]: [32mCompleted successfully[0m
15:48:37.504692 [info ] [MainThread]: 
15:48:37.504917 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
15:48:37.505371 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1118243a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1117de310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111d8a5e0>]}


============================== 2022-05-16 15:49:06.123883 | 99eb05b1-fd25-41c5-a695-9d9e8cf904e7 ==============================
15:49:06.123883 [info ] [MainThread]: Running with dbt=1.0.1
15:49:06.124281 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, store_failures=False, indirect_selection='eager', threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.test.TestTask'>, which='test', rpc_method='test')
15:49:06.124418 [debug] [MainThread]: Tracking: tracking
15:49:06.124651 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1055995e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1055999a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1055994f0>]}
15:49:06.173292 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
15:49:06.173437 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
15:49:06.176812 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '99eb05b1-fd25-41c5-a695-9d9e8cf904e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1055730a0>]}
15:49:06.180589 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '99eb05b1-fd25-41c5-a695-9d9e8cf904e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10558bac0>]}
15:49:06.180723 [info ] [MainThread]: Found 7 models, 14 tests, 1 snapshot, 0 analyses, 179 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
15:49:06.181634 [info ] [MainThread]: 
15:49:06.181850 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:49:06.182374 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snaphots"
15:49:06.188268 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snaphots"
15:49:06.188349 [debug] [ThreadPool]: On list_analytics_snaphots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snaphots"} */

    show terse objects in analytics.snaphots
15:49:06.188411 [debug] [ThreadPool]: Opening a new connection, currently in state init
15:49:07.319338 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1.13 seconds
15:49:07.321589 [debug] [ThreadPool]: On list_analytics_snaphots: Close
15:49:07.510693 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
15:49:07.513728 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
15:49:07.513983 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
15:49:07.514178 [debug] [ThreadPool]: Opening a new connection, currently in state closed
15:49:08.405166 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 0.89 seconds
15:49:08.408051 [debug] [ThreadPool]: On list_analytics_dbt: Close
15:49:08.578551 [info ] [MainThread]: 
15:49:08.579210 [info ] [MainThread]: Running 1 on-run-start hook
15:49:08.579656 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-start-0
15:49:08.581322 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-start-0"
15:49:08.583281 [info ] [MainThread]: 1 of 1 START hook: learn_dbt.on-run-start.0..................................... [RUN]
15:49:08.583659 [debug] [MainThread]: Using snowflake connection "master"
15:49:08.583764 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
15:49:08.583857 [debug] [MainThread]: Opening a new connection, currently in state init
15:49:09.324117 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.74 seconds
15:49:09.327250 [info ] [MainThread]: 1 of 1 OK hook: learn_dbt.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.74s]
15:49:09.328095 [info ] [MainThread]: 
15:49:09.328617 [debug] [MainThread]: On master: Close
15:49:09.536081 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
15:49:09.536711 [info ] [MainThread]: 
15:49:09.541706 [debug] [Thread-1  ]: Began running node test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
15:49:09.541935 [info ] [Thread-1  ]: 1 of 14 START test accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE [RUN]
15:49:09.542330 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
15:49:09.542515 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
15:49:09.542620 [debug] [Thread-1  ]: Compiling test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
15:49:09.550911 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
15:49:09.552339 [debug] [Thread-1  ]: finished collecting timing info
15:49:09.552513 [debug] [Thread-1  ]: Began executing node test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
15:49:09.563146 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
15:49:09.564145 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
15:49:09.564270 [debug] [Thread-1  ]: On test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        c_mktsegment as value_field,
        count(*) as n_records

    from analytics.dbt.playing_with_tests
    group by c_mktsegment

)

select *
from all_values
where value_field not in (
    'BUILDING','AUTOMOBILE','MACHINERY','HOUSEHOLD','FURNITURE'
)



      
    ) dbt_internal_test
15:49:09.564371 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:49:10.474359 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.91 seconds
15:49:10.478201 [debug] [Thread-1  ]: finished collecting timing info
15:49:10.478652 [debug] [Thread-1  ]: On test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3: Close
15:49:10.644126 [info ] [Thread-1  ]: 1 of 14 PASS accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE [[32mPASS[0m in 1.10s]
15:49:10.644588 [debug] [Thread-1  ]: Finished running node test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
15:49:10.644726 [debug] [Thread-1  ]: Began running node test.learn_dbt.assert_accbal_more_than_100m
15:49:10.644824 [info ] [Thread-1  ]: 2 of 14 START test assert_accbal_more_than_100m................................. [RUN]
15:49:10.645218 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.assert_accbal_more_than_100m"
15:49:10.645331 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.assert_accbal_more_than_100m
15:49:10.645447 [debug] [Thread-1  ]: Compiling test.learn_dbt.assert_accbal_more_than_100m
15:49:10.646844 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.assert_accbal_more_than_100m"
15:49:10.647204 [debug] [Thread-1  ]: finished collecting timing info
15:49:10.647294 [debug] [Thread-1  ]: Began executing node test.learn_dbt.assert_accbal_more_than_100m
15:49:10.648442 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.assert_accbal_more_than_100m"
15:49:10.648945 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.assert_accbal_more_than_100m"
15:49:10.649041 [debug] [Thread-1  ]: On test.learn_dbt.assert_accbal_more_than_100m: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.assert_accbal_more_than_100m"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      select sum(c_acctbal) as sum
from analytics.dbt.playing_with_tests
having sum < 100000000
      
    ) dbt_internal_test
15:49:10.649124 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:49:11.643369 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.99 seconds
15:49:11.646475 [debug] [Thread-1  ]: finished collecting timing info
15:49:11.646904 [debug] [Thread-1  ]: On test.learn_dbt.assert_accbal_more_than_100m: Close
15:49:11.964661 [info ] [Thread-1  ]: 2 of 14 PASS assert_accbal_more_than_100m....................................... [[32mPASS[0m in 1.32s]
15:49:11.965467 [debug] [Thread-1  ]: Finished running node test.learn_dbt.assert_accbal_more_than_100m
15:49:11.965754 [debug] [Thread-1  ]: Began running node test.learn_dbt.assert_under_10_percent_null
15:49:11.966082 [info ] [Thread-1  ]: 3 of 14 START test assert_under_10_percent_null................................. [RUN]
15:49:11.966714 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.assert_under_10_percent_null"
15:49:11.966927 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.assert_under_10_percent_null
15:49:11.967124 [debug] [Thread-1  ]: Compiling test.learn_dbt.assert_under_10_percent_null
15:49:11.970204 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.assert_under_10_percent_null"
15:49:11.971022 [debug] [Thread-1  ]: finished collecting timing info
15:49:11.971196 [debug] [Thread-1  ]: Began executing node test.learn_dbt.assert_under_10_percent_null
15:49:11.973610 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.assert_under_10_percent_null"
15:49:11.974943 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.assert_under_10_percent_null"
15:49:11.975124 [debug] [Thread-1  ]: On test.learn_dbt.assert_under_10_percent_null: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.assert_under_10_percent_null"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      select sum (case when id is null then 1 else 0 end) / count(*) as total_nulls
from analytics.dbt.first_model
having sum (case when id is null then 1 else 0 end) / count(*) > .4
      
    ) dbt_internal_test
15:49:11.975276 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:49:12.692188 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.72 seconds
15:49:12.696725 [debug] [Thread-1  ]: finished collecting timing info
15:49:12.697157 [debug] [Thread-1  ]: On test.learn_dbt.assert_under_10_percent_null: Close
15:49:13.012963 [info ] [Thread-1  ]: 3 of 14 PASS assert_under_10_percent_null....................................... [[32mPASS[0m in 1.05s]
15:49:13.014714 [debug] [Thread-1  ]: Finished running node test.learn_dbt.assert_under_10_percent_null
15:49:13.015170 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4
15:49:13.015872 [info ] [Thread-1  ]: 4 of 14 START test not_null_playing_with_tests_c_custkey........................ [RUN]
15:49:13.016639 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4"
15:49:13.016872 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4
15:49:13.017092 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4
15:49:13.024354 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4"
15:49:13.024985 [debug] [Thread-1  ]: finished collecting timing info
15:49:13.025123 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4
15:49:13.027300 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4"
15:49:13.028454 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4"
15:49:13.028609 [debug] [Thread-1  ]: On test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.playing_with_tests
where c_custkey is null



      
    ) dbt_internal_test
15:49:13.028739 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:49:13.674313 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.65 seconds
15:49:13.677358 [debug] [Thread-1  ]: finished collecting timing info
15:49:13.677819 [debug] [Thread-1  ]: On test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4: Close
15:49:13.882529 [info ] [Thread-1  ]: 4 of 14 PASS not_null_playing_with_tests_c_custkey.............................. [[32mPASS[0m in 0.87s]
15:49:13.883336 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4
15:49:13.883607 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
15:49:13.883824 [info ] [Thread-1  ]: 5 of 14 START test not_null_snowflake_cumulative_sales_o_orderdate.............. [RUN]
15:49:13.884565 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
15:49:13.884819 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
15:49:13.885046 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
15:49:13.889317 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
15:49:13.890124 [debug] [Thread-1  ]: finished collecting timing info
15:49:13.890283 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
15:49:13.892266 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
15:49:13.893143 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
15:49:13.893280 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.snowflake_cumulative_sales
where o_orderdate is null



      
    ) dbt_internal_test
15:49:13.893404 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:49:14.726829 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.83 seconds
15:49:14.729921 [debug] [Thread-1  ]: finished collecting timing info
15:49:14.730245 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856: Close
15:49:15.111959 [info ] [Thread-1  ]: 5 of 14 PASS not_null_snowflake_cumulative_sales_o_orderdate.................... [[32mPASS[0m in 1.23s]
15:49:15.112802 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
15:49:15.113082 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
15:49:15.113469 [info ] [Thread-1  ]: 6 of 14 START test not_null_snowflake_customer_purchases_c_custkey.............. [RUN]
15:49:15.114156 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
15:49:15.114380 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
15:49:15.114599 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
15:49:15.119742 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
15:49:15.120653 [debug] [Thread-1  ]: finished collecting timing info
15:49:15.120839 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
15:49:15.123122 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
15:49:15.123784 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
15:49:15.123958 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.snowflake_customer_purchases
where c_custkey is null



      
    ) dbt_internal_test
15:49:15.124060 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:49:15.845436 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.72 seconds
15:49:15.848115 [debug] [Thread-1  ]: finished collecting timing info
15:49:15.848401 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502: Close
15:49:16.160306 [info ] [Thread-1  ]: 6 of 14 PASS not_null_snowflake_customer_purchases_c_custkey.................... [[32mPASS[0m in 1.05s]
15:49:16.161120 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
15:49:16.161406 [debug] [Thread-1  ]: Began running node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
15:49:16.161883 [info ] [Thread-1  ]: 7 of 14 START test relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ [RUN]
15:49:16.162566 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
15:49:16.162782 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
15:49:16.162981 [debug] [Thread-1  ]: Compiling test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
15:49:16.173590 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
15:49:16.174310 [debug] [Thread-1  ]: finished collecting timing info
15:49:16.174469 [debug] [Thread-1  ]: Began executing node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
15:49:16.176362 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
15:49:16.177529 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
15:49:16.177670 [debug] [Thread-1  ]: On test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select id as from_field
    from analytics.dbt.my_second_dbt_model
    where id is not null
),

parent as (
    select id as to_field
    from analytics.dbt.first_model
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
15:49:16.177783 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:49:17.991459 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.81 seconds
15:49:17.995661 [debug] [Thread-1  ]: finished collecting timing info
15:49:17.996257 [debug] [Thread-1  ]: On test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: Close
15:49:18.259598 [info ] [Thread-1  ]: 7 of 14 PASS relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.. [[32mPASS[0m in 2.10s]
15:49:18.259885 [debug] [Thread-1  ]: Finished running node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
15:49:18.259983 [debug] [Thread-1  ]: Began running node test.learn_dbt.source_not_null_sample_customer_c_custkey.96001aaec2
15:49:18.260059 [info ] [Thread-1  ]: 8 of 14 START test source_not_null_sample_customer_c_custkey.................... [RUN]
15:49:18.260249 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.source_not_null_sample_customer_c_custkey.96001aaec2"
15:49:18.260325 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.source_not_null_sample_customer_c_custkey.96001aaec2
15:49:18.260403 [debug] [Thread-1  ]: Compiling test.learn_dbt.source_not_null_sample_customer_c_custkey.96001aaec2
15:49:18.265260 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.source_not_null_sample_customer_c_custkey.96001aaec2"
15:49:18.265959 [debug] [Thread-1  ]: finished collecting timing info
15:49:18.266142 [debug] [Thread-1  ]: Began executing node test.learn_dbt.source_not_null_sample_customer_c_custkey.96001aaec2
15:49:18.267949 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.source_not_null_sample_customer_c_custkey.96001aaec2"
15:49:18.268870 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.source_not_null_sample_customer_c_custkey.96001aaec2"
15:49:18.269029 [debug] [Thread-1  ]: On test.learn_dbt.source_not_null_sample_customer_c_custkey.96001aaec2: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.source_not_null_sample_customer_c_custkey.96001aaec2"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from snowflake_sample_data.tpch_sf1.customer
where c_custkey is null



      
    ) dbt_internal_test
15:49:18.269173 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:49:19.303546 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.03 seconds
15:49:19.306686 [debug] [Thread-1  ]: finished collecting timing info
15:49:19.306997 [debug] [Thread-1  ]: On test.learn_dbt.source_not_null_sample_customer_c_custkey.96001aaec2: Close
15:49:19.495347 [info ] [Thread-1  ]: 8 of 14 PASS source_not_null_sample_customer_c_custkey.......................... [[32mPASS[0m in 1.24s]
15:49:19.496434 [debug] [Thread-1  ]: Finished running node test.learn_dbt.source_not_null_sample_customer_c_custkey.96001aaec2
15:49:19.496750 [debug] [Thread-1  ]: Began running node test.learn_dbt.source_unique_sample_customer_c_custkey.f7f30c39fd
15:49:19.497175 [info ] [Thread-1  ]: 9 of 14 START test source_unique_sample_customer_c_custkey...................... [RUN]
15:49:19.497914 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.source_unique_sample_customer_c_custkey.f7f30c39fd"
15:49:19.498144 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.source_unique_sample_customer_c_custkey.f7f30c39fd
15:49:19.498364 [debug] [Thread-1  ]: Compiling test.learn_dbt.source_unique_sample_customer_c_custkey.f7f30c39fd
15:49:19.507494 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.source_unique_sample_customer_c_custkey.f7f30c39fd"
15:49:19.508146 [debug] [Thread-1  ]: finished collecting timing info
15:49:19.508305 [debug] [Thread-1  ]: Began executing node test.learn_dbt.source_unique_sample_customer_c_custkey.f7f30c39fd
15:49:19.509869 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.source_unique_sample_customer_c_custkey.f7f30c39fd"
15:49:19.510840 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.source_unique_sample_customer_c_custkey.f7f30c39fd"
15:49:19.510978 [debug] [Thread-1  ]: On test.learn_dbt.source_unique_sample_customer_c_custkey.f7f30c39fd: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.source_unique_sample_customer_c_custkey.f7f30c39fd"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    c_custkey as unique_field,
    count(*) as n_records

from snowflake_sample_data.tpch_sf1.customer
where c_custkey is not null
group by c_custkey
having count(*) > 1



      
    ) dbt_internal_test
15:49:19.511105 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:49:20.166819 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.66 seconds
15:49:20.170355 [debug] [Thread-1  ]: finished collecting timing info
15:49:20.170764 [debug] [Thread-1  ]: On test.learn_dbt.source_unique_sample_customer_c_custkey.f7f30c39fd: Close
15:49:20.481050 [info ] [Thread-1  ]: 9 of 14 PASS source_unique_sample_customer_c_custkey............................ [[32mPASS[0m in 0.98s]
15:49:20.481835 [debug] [Thread-1  ]: Finished running node test.learn_dbt.source_unique_sample_customer_c_custkey.f7f30c39fd
15:49:20.482318 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
15:49:20.482744 [info ] [Thread-1  ]: 10 of 14 START test unique_my_first_dbt_model_id................................ [RUN]
15:49:20.483426 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
15:49:20.483645 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
15:49:20.483856 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
15:49:20.489192 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
15:49:20.491248 [debug] [Thread-1  ]: finished collecting timing info
15:49:20.491517 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
15:49:20.493902 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
15:49:20.494939 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
15:49:20.495082 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.first_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
15:49:20.495213 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:49:21.140307 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.65 seconds
15:49:21.142847 [debug] [Thread-1  ]: finished collecting timing info
15:49:21.143135 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_first_dbt_model_id.16e066b321: Close
15:49:21.401254 [info ] [Thread-1  ]: 10 of 14 PASS unique_my_first_dbt_model_id...................................... [[32mPASS[0m in 0.92s]
15:49:21.402694 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
15:49:21.403131 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
15:49:21.403534 [info ] [Thread-1  ]: 11 of 14 START test unique_my_second_dbt_model_id............................... [RUN]
15:49:21.404293 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
15:49:21.404514 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
15:49:21.404729 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
15:49:21.409947 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
15:49:21.410799 [debug] [Thread-1  ]: finished collecting timing info
15:49:21.410988 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
15:49:21.413331 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
15:49:21.414551 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
15:49:21.414699 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.my_second_dbt_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
15:49:21.414824 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:49:22.115213 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.7 seconds
15:49:22.118585 [debug] [Thread-1  ]: finished collecting timing info
15:49:22.118995 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493: Close
15:49:22.290632 [info ] [Thread-1  ]: 11 of 14 PASS unique_my_second_dbt_model_id..................................... [[32mPASS[0m in 0.89s]
15:49:22.291339 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
15:49:22.291585 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550
15:49:22.291795 [info ] [Thread-1  ]: 12 of 14 START test unique_playing_with_tests_c_custkey......................... [RUN]
15:49:22.292535 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550"
15:49:22.292784 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550
15:49:22.292967 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550
15:49:22.296976 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550"
15:49:22.297858 [debug] [Thread-1  ]: finished collecting timing info
15:49:22.298037 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550
15:49:22.300344 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550"
15:49:22.301363 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550"
15:49:22.301502 [debug] [Thread-1  ]: On test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    c_custkey as unique_field,
    count(*) as n_records

from analytics.dbt.playing_with_tests
where c_custkey is not null
group by c_custkey
having count(*) > 1



      
    ) dbt_internal_test
15:49:22.301629 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:49:23.136439 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.83 seconds
15:49:23.138807 [debug] [Thread-1  ]: finished collecting timing info
15:49:23.139046 [debug] [Thread-1  ]: On test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550: Close
15:49:23.308953 [info ] [Thread-1  ]: 12 of 14 PASS unique_playing_with_tests_c_custkey............................... [[32mPASS[0m in 1.02s]
15:49:23.309608 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550
15:49:23.309866 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
15:49:23.310070 [info ] [Thread-1  ]: 13 of 14 START test unique_snowflake_cumulative_sales_o_orderdate............... [RUN]
15:49:23.310846 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
15:49:23.311075 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
15:49:23.311270 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
15:49:23.315824 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
15:49:23.316836 [debug] [Thread-1  ]: finished collecting timing info
15:49:23.317079 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
15:49:23.319532 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
15:49:23.320700 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
15:49:23.320864 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    o_orderdate as unique_field,
    count(*) as n_records

from analytics.dbt.snowflake_cumulative_sales
where o_orderdate is not null
group by o_orderdate
having count(*) > 1



      
    ) dbt_internal_test
15:49:23.320991 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:49:24.193823 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.87 seconds
15:49:24.196210 [debug] [Thread-1  ]: finished collecting timing info
15:49:24.196599 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed: Close
15:49:24.552655 [info ] [Thread-1  ]: 13 of 14 PASS unique_snowflake_cumulative_sales_o_orderdate..................... [[32mPASS[0m in 1.24s]
15:49:24.553437 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
15:49:24.553711 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
15:49:24.554052 [info ] [Thread-1  ]: 14 of 14 START test unique_snowflake_customer_purchases_c_custkey............... [RUN]
15:49:24.554724 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
15:49:24.554953 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
15:49:24.555171 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
15:49:24.560251 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
15:49:24.561250 [debug] [Thread-1  ]: finished collecting timing info
15:49:24.561466 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
15:49:24.563679 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
15:49:24.564503 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
15:49:24.564687 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    c_custkey as unique_field,
    count(*) as n_records

from analytics.dbt.snowflake_customer_purchases
where c_custkey is not null
group by c_custkey
having count(*) > 1



      
    ) dbt_internal_test
15:49:24.564783 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:49:25.660303 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.1 seconds
15:49:25.663384 [debug] [Thread-1  ]: finished collecting timing info
15:49:25.663918 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f: Close
15:49:25.844239 [info ] [Thread-1  ]: 14 of 14 PASS unique_snowflake_customer_purchases_c_custkey..................... [[32mPASS[0m in 1.29s]
15:49:25.844997 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
15:49:25.847649 [debug] [MainThread]: Acquiring new snowflake connection "master"
15:49:25.848022 [info ] [MainThread]: 
15:49:25.848379 [info ] [MainThread]: Running 3 on-run-end hooks
15:49:25.848741 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-0
15:49:25.850651 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-0"
15:49:25.851940 [info ] [MainThread]: 1 of 3 START hook: learn_dbt.on-run-end.0....................................... [RUN]
15:49:25.852675 [debug] [MainThread]: Using snowflake connection "master"
15:49:25.852963 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
15:49:25.853121 [debug] [MainThread]: Opening a new connection, currently in state closed
15:49:26.833098 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.98 seconds
15:49:26.834576 [info ] [MainThread]: 1 of 3 OK hook: learn_dbt.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.98s]
15:49:26.835318 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-1
15:49:26.837394 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-1"
15:49:26.838769 [info ] [MainThread]: 2 of 3 START hook: learn_dbt.on-run-end.1....................................... [RUN]
15:49:26.839488 [debug] [MainThread]: Using snowflake connection "master"
15:49:26.839697 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
15:49:27.230751 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.39 seconds
15:49:27.232349 [info ] [MainThread]: 2 of 3 OK hook: learn_dbt.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.39s]
15:49:27.232714 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-2
15:49:27.233518 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-2"
15:49:27.233947 [info ] [MainThread]: 3 of 3 START hook: learn_dbt.on-run-end.2....................................... [RUN]
15:49:27.234176 [debug] [MainThread]: Using snowflake connection "master"
15:49:27.234243 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
15:49:27.370978 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.14 seconds
15:49:27.372584 [info ] [MainThread]: 3 of 3 OK hook: learn_dbt.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.14s]
15:49:27.373060 [info ] [MainThread]: 
15:49:27.373404 [debug] [MainThread]: On master: Close
15:49:27.693239 [info ] [MainThread]: 
15:49:27.693811 [info ] [MainThread]: Finished running 14 tests, 4 hooks in 21.51s.
15:49:27.694147 [debug] [MainThread]: Connection 'master' was properly closed.
15:49:27.694322 [debug] [MainThread]: Connection 'test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f' was properly closed.
15:49:27.701209 [info ] [MainThread]: 
15:49:27.701371 [info ] [MainThread]: [32mCompleted successfully[0m
15:49:27.701518 [info ] [MainThread]: 
15:49:27.701626 [info ] [MainThread]: Done. PASS=14 WARN=0 ERROR=0 SKIP=0 TOTAL=14
15:49:27.701818 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105b658e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10597da00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b72640>]}


============================== 2022-05-16 16:40:57.882292 | 69f64724-d019-4d70-97b3-434969d5fc81 ==============================
16:40:57.882292 [info ] [MainThread]: Running with dbt=1.0.1
16:40:57.882873 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['snowflake_customer_purchases'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
16:40:57.882993 [debug] [MainThread]: Tracking: tracking
16:40:57.883227 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110812850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110812760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110812400>]}
16:40:57.932256 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
16:40:57.932494 [debug] [MainThread]: Partial parsing: added file: learn_dbt://macros/group_by.sql
16:40:57.932635 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/snowflake_customer_purchases.sql
16:40:57.932706 [debug] [MainThread]: Parsing macros/group_by.sql
16:40:57.932913 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1108b4490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1108b4940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1108b49a0>]}


============================== 2022-05-16 16:41:20.937644 | ef4c206a-b3a8-46bd-aebe-f4a4ccc70a68 ==============================
16:41:20.937644 [info ] [MainThread]: Running with dbt=1.0.1
16:41:20.938064 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['snowflake_customer_purchases'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
16:41:20.938208 [debug] [MainThread]: Tracking: tracking
16:41:20.938474 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105fb32b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105fb3eb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105fb3910>]}
16:41:20.981544 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
16:41:20.981777 [debug] [MainThread]: Partial parsing: added file: learn_dbt://macros/group_by.sql
16:41:20.981924 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/snowflake_customer_purchases.sql
16:41:20.981995 [debug] [MainThread]: Parsing macros/group_by.sql
16:41:20.982193 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106018610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106018ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106018b20>]}


============================== 2022-05-16 16:42:22.582054 | 22786a25-4de0-4954-88ac-1e6296aebb5a ==============================
16:42:22.582054 [info ] [MainThread]: Running with dbt=1.0.1
16:42:22.582449 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['snowflake_customer_purchases'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
16:42:22.582562 [debug] [MainThread]: Tracking: tracking
16:42:22.582781 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a5f1c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a5ff40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a5f460>]}
16:42:22.628169 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
16:42:22.631167 [debug] [MainThread]: Partial parsing: added file: learn_dbt://macros/group_by.sql
16:42:22.631387 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/snowflake_customer_purchases.sql
16:42:22.631466 [debug] [MainThread]: Parsing macros/group_by.sql
16:42:22.631664 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b12580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b12a30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b12a90>]}


============================== 2022-05-16 16:48:23.092612 | 678e939c-640d-40f9-9d66-058a6aa23b18 ==============================
16:48:23.092612 [info ] [MainThread]: Running with dbt=1.0.1
16:48:23.096570 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['snowflake_customer_purchases'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
16:48:23.096778 [debug] [MainThread]: Tracking: tracking
16:48:23.097071 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1259a5a30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1259a5610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1259a5790>]}
16:48:23.146612 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
16:48:23.146858 [debug] [MainThread]: Partial parsing: added file: learn_dbt://macros/group_by.sql
16:48:23.147003 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/snowflake_customer_purchases.sql
16:48:23.147086 [debug] [MainThread]: Parsing macros/group_by.sql
16:48:23.147292 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x125a4d460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x125a4d910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x125a4d970>]}


============================== 2022-05-16 16:55:08.728159 | 98fb647e-1890-4595-b326-20f20aea24f9 ==============================
16:55:08.728159 [info ] [MainThread]: Running with dbt=1.0.1
16:55:08.728725 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['snowflake_customer_purchases'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
16:55:08.728885 [debug] [MainThread]: Tracking: tracking
16:55:08.729087 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10760ffa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10760f8e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10760f070>]}
16:55:08.780840 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
16:55:08.781094 [debug] [MainThread]: Partial parsing: added file: learn_dbt://macros/group_by.sql
16:55:08.781240 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/snowflake_customer_purchases.sql
16:55:08.781314 [debug] [MainThread]: Parsing macros/group_by.sql
16:55:08.789695 [debug] [MainThread]: 1603: static parser failed on example/snowflake_customer_purchases.sql
16:55:08.796263 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/snowflake_customer_purchases.sql
16:55:08.810730 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '98fb647e-1890-4595-b326-20f20aea24f9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077960d0>]}
16:55:08.814368 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '98fb647e-1890-4595-b326-20f20aea24f9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10770e220>]}
16:55:08.814495 [info ] [MainThread]: Found 7 models, 14 tests, 1 snapshot, 0 analyses, 180 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
16:55:08.815186 [info ] [MainThread]: 
16:55:08.815389 [debug] [MainThread]: Acquiring new snowflake connection "master"
16:55:08.815726 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
16:55:08.821693 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
16:55:08.821819 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
16:55:08.821885 [debug] [ThreadPool]: Opening a new connection, currently in state init
16:55:09.766096 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 0.94 seconds
16:55:09.767631 [debug] [ThreadPool]: On list_analytics: Close
16:55:10.003154 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snaphots"
16:55:10.011913 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snaphots"
16:55:10.012169 [debug] [ThreadPool]: On list_analytics_snaphots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snaphots"} */

    show terse objects in analytics.snaphots
16:55:10.012334 [debug] [ThreadPool]: Opening a new connection, currently in state closed
16:55:10.657426 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.65 seconds
16:55:10.659967 [debug] [ThreadPool]: On list_analytics_snaphots: Close
16:55:10.827660 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
16:55:10.832338 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
16:55:10.832670 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
16:55:10.832868 [debug] [ThreadPool]: Opening a new connection, currently in state closed
16:55:11.841999 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 1.01 seconds
16:55:11.845908 [debug] [ThreadPool]: On list_analytics_dbt: Close
16:55:12.098778 [info ] [MainThread]: 
16:55:12.099369 [info ] [MainThread]: Running 1 on-run-start hook
16:55:12.100007 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-start-0
16:55:12.101542 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-start-0"
16:55:12.103610 [info ] [MainThread]: 1 of 1 START hook: learn_dbt.on-run-start.0..................................... [RUN]
16:55:12.104177 [debug] [MainThread]: Using snowflake connection "master"
16:55:12.104333 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
16:55:12.104455 [debug] [MainThread]: Opening a new connection, currently in state init
16:55:12.752664 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.65 seconds
16:55:12.754966 [info ] [MainThread]: 1 of 1 OK hook: learn_dbt.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.65s]
16:55:12.755582 [info ] [MainThread]: 
16:55:12.755970 [debug] [MainThread]: On master: Close
16:55:12.944335 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
16:55:12.945068 [info ] [MainThread]: 
16:55:12.950281 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
16:55:12.950721 [info ] [Thread-1  ]: 1 of 1 START table model dbt.snowflake_customer_purchases....................... [RUN]
16:55:12.951331 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
16:55:12.951534 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
16:55:12.951758 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
16:55:12.957047 [debug] [Thread-1  ]: finished collecting timing info
16:55:12.957442 [debug] [Thread-1  ]: Compilation Error in model snowflake_customer_purchases (models/example/snowflake_customer_purchases.sql)
  'group_by' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
16:55:12.957880 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '98fb647e-1890-4595-b326-20f20aea24f9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110511af0>]}
16:55:12.958204 [error] [Thread-1  ]: 1 of 1 ERROR creating table model dbt.snowflake_customer_purchases.............. [[31mERROR[0m in 0.01s]
16:55:12.958488 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
16:55:12.959321 [debug] [MainThread]: Acquiring new snowflake connection "master"
16:55:12.959540 [info ] [MainThread]: 
16:55:12.959772 [info ] [MainThread]: Running 3 on-run-end hooks
16:55:12.959997 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-0
16:55:12.961146 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-0"
16:55:12.961870 [info ] [MainThread]: 1 of 3 START hook: learn_dbt.on-run-end.0....................................... [RUN]
16:55:12.962318 [debug] [MainThread]: Using snowflake connection "master"
16:55:12.962454 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
16:55:12.962571 [debug] [MainThread]: Opening a new connection, currently in state closed
16:55:13.524792 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.56 seconds
16:55:13.526386 [info ] [MainThread]: 1 of 3 OK hook: learn_dbt.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.56s]
16:55:13.526980 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-1
16:55:13.529295 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-1"
16:55:13.531856 [info ] [MainThread]: 2 of 3 START hook: learn_dbt.on-run-end.1....................................... [RUN]
16:55:13.532568 [debug] [MainThread]: Using snowflake connection "master"
16:55:13.532765 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
16:55:13.802074 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.27 seconds
16:55:13.806159 [info ] [MainThread]: 2 of 3 OK hook: learn_dbt.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.27s]
16:55:13.806690 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-2
16:55:13.808490 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-2"
16:55:13.809832 [info ] [MainThread]: 3 of 3 START hook: learn_dbt.on-run-end.2....................................... [RUN]
16:55:13.810396 [debug] [MainThread]: Using snowflake connection "master"
16:55:13.810679 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
16:55:13.956890 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.15 seconds
16:55:13.959526 [info ] [MainThread]: 3 of 3 OK hook: learn_dbt.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.15s]
16:55:13.960224 [info ] [MainThread]: 
16:55:13.960680 [debug] [MainThread]: On master: Close
16:55:14.193869 [info ] [MainThread]: 
16:55:14.194644 [info ] [MainThread]: Finished running 1 table model, 4 hooks in 5.38s.
16:55:14.195367 [debug] [MainThread]: Connection 'master' was properly closed.
16:55:14.195636 [debug] [MainThread]: Connection 'model.learn_dbt.snowflake_customer_purchases' was properly closed.
16:55:14.204899 [info ] [MainThread]: 
16:55:14.205268 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
16:55:14.205553 [info ] [MainThread]: 
16:55:14.205785 [error] [MainThread]: [33mCompilation Error in model snowflake_customer_purchases (models/example/snowflake_customer_purchases.sql)[0m
16:55:14.206017 [error] [MainThread]:   'group_by' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
16:55:14.206246 [info ] [MainThread]: 
16:55:14.206460 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
16:55:14.206743 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10770e340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110406910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110375250>]}


============================== 2022-05-16 16:55:43.982474 | 1ec744c0-b4b7-44f6-9d44-a51ee73292f9 ==============================
16:55:43.982474 [info ] [MainThread]: Running with dbt=1.0.1
16:55:43.983024 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['snowflake_customer_purchases'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
16:55:43.983176 [debug] [MainThread]: Tracking: tracking
16:55:43.983456 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10771f370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10771fbe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10771f9d0>]}
16:55:44.035360 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
16:55:44.035653 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://macros/group_by.sql
16:55:44.035735 [debug] [MainThread]: Parsing macros/group_by.sql
16:55:44.042011 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1ec744c0-b4b7-44f6-9d44-a51ee73292f9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1078630d0>]}
16:55:44.046220 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1ec744c0-b4b7-44f6-9d44-a51ee73292f9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077a91f0>]}
16:55:44.046385 [info ] [MainThread]: Found 7 models, 14 tests, 1 snapshot, 0 analyses, 180 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
16:55:44.047088 [info ] [MainThread]: 
16:55:44.047310 [debug] [MainThread]: Acquiring new snowflake connection "master"
16:55:44.047661 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
16:55:44.053854 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
16:55:44.053954 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
16:55:44.054020 [debug] [ThreadPool]: Opening a new connection, currently in state init
16:55:46.477047 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 2.42 seconds
16:55:46.479900 [debug] [ThreadPool]: On list_analytics: Close
16:55:46.701997 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
16:55:46.711385 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
16:55:46.711796 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
16:55:46.712150 [debug] [ThreadPool]: Opening a new connection, currently in state closed
16:55:47.355968 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 0.64 seconds
16:55:47.358153 [debug] [ThreadPool]: On list_analytics_dbt: Close
16:55:47.547391 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snaphots"
16:55:47.548812 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snaphots"
16:55:47.548937 [debug] [ThreadPool]: On list_analytics_snaphots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snaphots"} */

    show terse objects in analytics.snaphots
16:55:47.549020 [debug] [ThreadPool]: Opening a new connection, currently in state closed
16:55:48.404210 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.86 seconds
16:55:48.407343 [debug] [ThreadPool]: On list_analytics_snaphots: Close
16:55:48.595386 [info ] [MainThread]: 
16:55:48.596064 [info ] [MainThread]: Running 1 on-run-start hook
16:55:48.596448 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-start-0
16:55:48.598270 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-start-0"
16:55:48.601240 [info ] [MainThread]: 1 of 1 START hook: learn_dbt.on-run-start.0..................................... [RUN]
16:55:48.601867 [debug] [MainThread]: Using snowflake connection "master"
16:55:48.602034 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
16:55:48.602184 [debug] [MainThread]: Opening a new connection, currently in state init
16:55:49.450980 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.85 seconds
16:55:49.453834 [info ] [MainThread]: 1 of 1 OK hook: learn_dbt.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.85s]
16:55:49.454431 [info ] [MainThread]: 
16:55:49.454808 [debug] [MainThread]: On master: Close
16:55:49.640237 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
16:55:49.641350 [info ] [MainThread]: 
16:55:49.646780 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
16:55:49.647168 [info ] [Thread-1  ]: 1 of 1 START table model dbt.snowflake_customer_purchases....................... [RUN]
16:55:49.647685 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
16:55:49.647851 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
16:55:49.648003 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
16:55:49.653732 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
16:55:49.655055 [debug] [Thread-1  ]: finished collecting timing info
16:55:49.655247 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
16:55:49.669468 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
16:55:49.669665 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */

        insert into dbt.audit (model, state, time) values ('snowflake_customer_purchases', 'starting model deployment', current_timestamp)
16:55:49.669772 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:55:51.308606 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.64 seconds
16:55:51.322999 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
16:55:51.325958 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
16:55:51.326152 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from snowflake_sample_data.tpch_sf1.customer c
left join snowflake_sample_data.tpch_sf1.orders o
on c.c_custkey = o.o_custkey
group by 1,2,3
      );
16:55:52.641904 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.32 seconds
16:55:52.644517 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
16:55:52.644643 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */

        insert into dbt.audit (model, state, time) values ('snowflake_customer_purchases', 'ending model deployment', current_timestamp)
16:55:53.460396 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.82 seconds
16:55:53.474593 [debug] [Thread-1  ]: finished collecting timing info
16:55:53.475056 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
16:55:53.745274 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1ec744c0-b4b7-44f6-9d44-a51ee73292f9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107e571c0>]}
16:55:53.745916 [info ] [Thread-1  ]: 1 of 1 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 4.10s]
16:55:53.746381 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
16:55:53.747632 [debug] [MainThread]: Acquiring new snowflake connection "master"
16:55:53.747992 [info ] [MainThread]: 
16:55:53.748344 [info ] [MainThread]: Running 3 on-run-end hooks
16:55:53.748698 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-0
16:55:53.750524 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-0"
16:55:53.752746 [info ] [MainThread]: 1 of 3 START hook: learn_dbt.on-run-end.0....................................... [RUN]
16:55:53.753334 [debug] [MainThread]: Using snowflake connection "master"
16:55:53.753506 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
16:55:53.753652 [debug] [MainThread]: Opening a new connection, currently in state closed
16:55:54.235724 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.48 seconds
16:55:54.237645 [info ] [MainThread]: 1 of 3 OK hook: learn_dbt.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.48s]
16:55:54.238099 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-1
16:55:54.239310 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-1"
16:55:54.240807 [info ] [MainThread]: 2 of 3 START hook: learn_dbt.on-run-end.1....................................... [RUN]
16:55:54.241263 [debug] [MainThread]: Using snowflake connection "master"
16:55:54.241383 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
16:55:54.385931 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.14 seconds
16:55:54.388629 [info ] [MainThread]: 2 of 3 OK hook: learn_dbt.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.15s]
16:55:54.389240 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-2
16:55:54.391490 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-2"
16:55:54.392602 [info ] [MainThread]: 3 of 3 START hook: learn_dbt.on-run-end.2....................................... [RUN]
16:55:54.393325 [debug] [MainThread]: Using snowflake connection "master"
16:55:54.393551 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
16:55:54.691800 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.3 seconds
16:55:54.693805 [info ] [MainThread]: 3 of 3 OK hook: learn_dbt.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.30s]
16:55:54.694476 [info ] [MainThread]: 
16:55:54.694932 [debug] [MainThread]: On master: Close
16:55:54.891879 [info ] [MainThread]: 
16:55:54.892531 [info ] [MainThread]: Finished running 1 table model, 4 hooks in 10.84s.
16:55:54.892866 [debug] [MainThread]: Connection 'master' was properly closed.
16:55:54.893047 [debug] [MainThread]: Connection 'model.learn_dbt.snowflake_customer_purchases' was properly closed.
16:55:54.900304 [info ] [MainThread]: 
16:55:54.900646 [info ] [MainThread]: [32mCompleted successfully[0m
16:55:54.900909 [info ] [MainThread]: 
16:55:54.901106 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
16:55:54.901419 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107eeedc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107f2e670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107f72ac0>]}


============================== 2022-05-17 07:34:27.742989 | cac7c501-fad2-4c63-ae05-c2e99a602c68 ==============================
07:34:27.742989 [info ] [MainThread]: Running with dbt=1.0.1
07:34:27.743686 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
07:34:27.743822 [debug] [MainThread]: Tracking: tracking
07:34:27.744032 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1069c3610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1069c3a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1069c3310>]}
07:34:27.779449 [info ] [MainThread]: Unable to do partial parsing because profile has changed
07:34:27.779692 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'cac7c501-fad2-4c63-ae05-c2e99a602c68', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b00d90>]}
07:34:27.797995 [debug] [MainThread]: Parsing macros/group_by.sql
07:34:27.799388 [debug] [MainThread]: Parsing macros/catalog.sql
07:34:27.800419 [debug] [MainThread]: Parsing macros/adapters.sql
07:34:27.820071 [debug] [MainThread]: Parsing macros/materializations/merge.sql
07:34:27.822176 [debug] [MainThread]: Parsing macros/materializations/seed.sql
07:34:27.824820 [debug] [MainThread]: Parsing macros/materializations/view.sql
07:34:27.825469 [debug] [MainThread]: Parsing macros/materializations/table.sql
07:34:27.826911 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
07:34:27.830908 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
07:34:27.832198 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
07:34:27.833973 [debug] [MainThread]: Parsing macros/materializations/configs.sql
07:34:27.835105 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
07:34:27.835906 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
07:34:27.843788 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
07:34:27.849685 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
07:34:27.855880 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
07:34:27.858054 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
07:34:27.858880 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
07:34:27.859681 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
07:34:27.861655 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
07:34:27.867284 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
07:34:27.868096 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
07:34:27.873207 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
07:34:27.881508 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
07:34:27.885361 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
07:34:27.886694 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
07:34:27.890276 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
07:34:27.890885 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
07:34:27.892133 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
07:34:27.893217 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
07:34:27.896035 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
07:34:27.904539 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
07:34:27.905291 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
07:34:27.906412 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
07:34:27.907196 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
07:34:27.907648 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
07:34:27.907914 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
07:34:27.908236 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
07:34:27.908858 [debug] [MainThread]: Parsing macros/etc/statement.sql
07:34:27.910903 [debug] [MainThread]: Parsing macros/etc/datetime.sql
07:34:27.915084 [debug] [MainThread]: Parsing macros/adapters/schema.sql
07:34:27.916122 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
07:34:27.917340 [debug] [MainThread]: Parsing macros/adapters/relation.sql
07:34:27.921797 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
07:34:27.923425 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
07:34:27.925505 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
07:34:27.928841 [debug] [MainThread]: Parsing macros/adapters/columns.sql
07:34:27.933369 [debug] [MainThread]: Parsing tests/generic/builtin.sql
07:34:28.021827 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
07:34:28.028858 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
07:34:28.029593 [debug] [MainThread]: 1699: static parser successfully parsed example/playing_with_tests.sql
07:34:28.031719 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_cumulative_sales.sql
07:34:28.039587 [debug] [MainThread]: 1603: static parser failed on example/my_second_dbt_model.sql
07:34:28.042226 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_second_dbt_model.sql
07:34:28.042918 [debug] [MainThread]: 1603: static parser failed on example/incremental_time.sql
07:34:28.046848 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_time.sql
07:34:28.047445 [debug] [MainThread]: 1603: static parser failed on example/snowflake_customer_purchases.sql
07:34:28.050832 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/snowflake_customer_purchases.sql
07:34:28.051290 [debug] [MainThread]: 1603: static parser failed on new/dates.sql
07:34:28.052763 [debug] [MainThread]: 1602: parser fallback to jinja rendering on new/dates.sql
07:34:28.118617 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cac7c501-fad2-4c63-ae05-c2e99a602c68', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106df30d0>]}
07:34:28.122409 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cac7c501-fad2-4c63-ae05-c2e99a602c68', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10699cdc0>]}
07:34:28.122564 [info ] [MainThread]: Found 7 models, 14 tests, 1 snapshot, 0 analyses, 180 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
07:34:28.123422 [info ] [MainThread]: 
07:34:28.123645 [debug] [MainThread]: Acquiring new snowflake connection "master"
07:34:28.124106 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
07:34:28.130762 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
07:34:28.130874 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
07:34:28.130942 [debug] [ThreadPool]: Opening a new connection, currently in state init
07:34:28.961190 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 0.83 seconds
07:34:28.963764 [debug] [ThreadPool]: On list_analytics: Close
07:34:29.210796 [debug] [ThreadPool]: Acquiring new snowflake connection "create_analytics_dbt_nigel"
07:34:29.211216 [debug] [ThreadPool]: Acquiring new snowflake connection "create_analytics_dbt_nigel"
07:34:29.211440 [debug] [ThreadPool]: Creating schema "_ReferenceKey(database='analytics', schema='dbt_nigel', identifier=None)"
07:34:29.216923 [debug] [ThreadPool]: Using snowflake connection "create_analytics_dbt_nigel"
07:34:29.217084 [debug] [ThreadPool]: On create_analytics_dbt_nigel: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "create_analytics_dbt_nigel"} */
create schema if not exists analytics.dbt_nigel
07:34:29.217190 [debug] [ThreadPool]: Opening a new connection, currently in state closed
07:34:30.080076 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.86 seconds
07:34:30.080929 [debug] [ThreadPool]: On create_analytics_dbt_nigel: Close
07:34:30.244115 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt_nigel"
07:34:30.247434 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt_nigel"
07:34:30.247543 [debug] [ThreadPool]: On list_analytics_dbt_nigel: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt_nigel"} */

    show terse objects in analytics.dbt_nigel
07:34:30.247613 [debug] [ThreadPool]: Opening a new connection, currently in state closed
07:34:31.024111 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 0.78 seconds
07:34:31.027027 [debug] [ThreadPool]: On list_analytics_dbt_nigel: Close
07:34:31.202635 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snaphots"
07:34:31.205454 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snaphots"
07:34:31.205807 [debug] [ThreadPool]: On list_analytics_snaphots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snaphots"} */

    show terse objects in analytics.snaphots
07:34:31.206009 [debug] [ThreadPool]: Opening a new connection, currently in state closed
07:34:32.047053 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.84 seconds
07:34:32.049727 [debug] [ThreadPool]: On list_analytics_snaphots: Close
07:34:32.210711 [info ] [MainThread]: 
07:34:32.211315 [info ] [MainThread]: Running 1 on-run-start hook
07:34:32.211690 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-start-0
07:34:32.213532 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-start-0"
07:34:32.216034 [info ] [MainThread]: 1 of 1 START hook: learn_dbt.on-run-start.0..................................... [RUN]
07:34:32.216697 [debug] [MainThread]: Using snowflake connection "master"
07:34:32.216923 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
07:34:32.217092 [debug] [MainThread]: Opening a new connection, currently in state init
07:34:32.927083 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.71 seconds
07:34:32.928495 [info ] [MainThread]: 1 of 1 OK hook: learn_dbt.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.71s]
07:34:32.928946 [info ] [MainThread]: 
07:34:32.929303 [debug] [MainThread]: On master: Close
07:34:33.117113 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
07:34:33.117851 [info ] [MainThread]: 
07:34:33.122767 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
07:34:33.123122 [info ] [Thread-1  ]: 1 of 7 START incremental model dbt_nigel.dates.................................. [RUN]
07:34:33.123952 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
07:34:33.124133 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
07:34:33.124310 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
07:34:33.128102 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
07:34:33.128821 [debug] [Thread-1  ]: finished collecting timing info
07:34:33.128989 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
07:34:33.160965 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
07:34:33.161640 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
07:34:33.161738 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */


      create or replace transient table analytics.dbt_nigel.dates  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


      );
07:34:33.161821 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
07:34:36.016792 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.85 seconds
07:34:36.030775 [debug] [Thread-1  ]: finished collecting timing info
07:34:36.031214 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
07:34:36.194404 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cac7c501-fad2-4c63-ae05-c2e99a602c68', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a3b370>]}
07:34:36.195202 [info ] [Thread-1  ]: 1 of 7 OK created incremental model dbt_nigel.dates............................. [[32mSUCCESS 1[0m in 3.07s]
07:34:36.195666 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
07:34:36.195932 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
07:34:36.196353 [info ] [Thread-1  ]: 2 of 7 START incremental model dbt_nigel.incremental_time....................... [RUN]
07:34:36.196924 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
07:34:36.197062 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
07:34:36.197187 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
07:34:36.200282 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
07:34:36.201267 [debug] [Thread-1  ]: finished collecting timing info
07:34:36.201396 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
07:34:36.204688 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
07:34:36.204918 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

        insert into dbt.audit (model, state, time) values ('incremental_time', 'starting model deployment', current_timestamp)
07:34:36.205041 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
07:34:38.053413 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.85 seconds
07:34:38.056069 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
07:34:38.057169 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
07:34:38.057311 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */


      create or replace transient table analytics.dbt_nigel.incremental_time  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


      );
07:34:39.175344 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.12 seconds
07:34:39.179317 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
07:34:39.179573 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

        insert into dbt.audit (model, state, time) values ('incremental_time', 'ending model deployment', current_timestamp)
07:34:39.688034 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.51 seconds
07:34:39.691341 [debug] [Thread-1  ]: finished collecting timing info
07:34:39.691758 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
07:34:39.860167 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cac7c501-fad2-4c63-ae05-c2e99a602c68', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107db27f0>]}
07:34:39.860917 [info ] [Thread-1  ]: 2 of 7 OK created incremental model dbt_nigel.incremental_time.................. [[32mSUCCESS 1[0m in 3.66s]
07:34:39.861351 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
07:34:39.861546 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
07:34:39.861852 [info ] [Thread-1  ]: 3 of 7 START table model dbt_nigel.first_model.................................. [RUN]
07:34:39.862356 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
07:34:39.862520 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
07:34:39.862665 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
07:34:39.865982 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
07:34:39.866583 [debug] [Thread-1  ]: finished collecting timing info
07:34:39.866739 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
07:34:39.876791 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
07:34:39.877012 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('first_model', 'starting model deployment', current_timestamp)
07:34:39.877158 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
07:34:41.020419 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.14 seconds
07:34:41.023782 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
07:34:41.026570 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
07:34:41.031243 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt_nigel.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id, 'NY' as state, '2020-02-01 00:01:00.000'::timestamp as updated_at
    union all
    select null as id, 'CT' as state, '2020-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select 3 as id, 'VT' as state, '2020-01-01 00:00:00.000'::timestamp as updated_at

)

select * 
from source_data


/*
select *, True as first_variable
from source_data
where id >= 1
*/
      );
07:34:41.936892 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.9 seconds
07:34:41.943154 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
07:34:41.943530 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('first_model', 'ending model deployment', current_timestamp)
07:34:42.451027 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.51 seconds
07:34:42.455289 [debug] [Thread-1  ]: finished collecting timing info
07:34:42.455911 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
07:34:42.644336 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cac7c501-fad2-4c63-ae05-c2e99a602c68', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107ad4520>]}
07:34:42.644849 [info ] [Thread-1  ]: 3 of 7 OK created table model dbt_nigel.first_model............................. [[32mSUCCESS 1[0m in 2.78s]
07:34:42.645092 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
07:34:42.645228 [debug] [Thread-1  ]: Began running node model.learn_dbt.playing_with_tests
07:34:42.645554 [info ] [Thread-1  ]: 4 of 7 START table model dbt_nigel.playing_with_tests........................... [RUN]
07:34:42.646101 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.playing_with_tests"
07:34:42.646253 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.playing_with_tests
07:34:42.646375 [debug] [Thread-1  ]: Compiling model.learn_dbt.playing_with_tests
07:34:42.647796 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.playing_with_tests"
07:34:42.648231 [debug] [Thread-1  ]: finished collecting timing info
07:34:42.648325 [debug] [Thread-1  ]: Began executing node model.learn_dbt.playing_with_tests
07:34:42.650228 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
07:34:42.650334 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */

        insert into dbt.audit (model, state, time) values ('playing_with_tests', 'starting model deployment', current_timestamp)
07:34:42.650413 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
07:34:44.519536 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.87 seconds
07:34:44.521459 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.playing_with_tests"
07:34:44.522618 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
07:34:44.522839 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */


      create or replace transient table analytics.dbt_nigel.playing_with_tests  as
      (select * 
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER"
      );
07:34:46.022374 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.5 seconds
07:34:46.036191 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
07:34:46.036608 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */

        insert into dbt.audit (model, state, time) values ('playing_with_tests', 'ending model deployment', current_timestamp)
07:34:46.839715 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.8 seconds
07:34:46.844664 [debug] [Thread-1  ]: finished collecting timing info
07:34:46.845238 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: Close
07:34:47.010612 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cac7c501-fad2-4c63-ae05-c2e99a602c68', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106bbf550>]}
07:34:47.011951 [info ] [Thread-1  ]: 4 of 7 OK created table model dbt_nigel.playing_with_tests...................... [[32mSUCCESS 1[0m in 4.36s]
07:34:47.012602 [debug] [Thread-1  ]: Finished running node model.learn_dbt.playing_with_tests
07:34:47.012901 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
07:34:47.013373 [info ] [Thread-1  ]: 5 of 7 START table model dbt_nigel.snowflake_cumulative_sales................... [RUN]
07:34:47.014392 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
07:34:47.017586 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
07:34:47.020158 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
07:34:47.027493 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
07:34:47.028167 [debug] [Thread-1  ]: finished collecting timing info
07:34:47.028299 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
07:34:47.030924 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
07:34:47.031102 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */

        insert into dbt.audit (model, state, time) values ('snowflake_cumulative_sales', 'starting model deployment', current_timestamp)
07:34:47.031243 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
07:34:48.126144 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.09 seconds
07:34:48.128659 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
07:34:48.130416 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
07:34:48.130662 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt_nigel.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
07:34:49.537576 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.41 seconds
07:34:49.546093 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
07:34:49.546451 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */

        insert into dbt.audit (model, state, time) values ('snowflake_cumulative_sales', 'ending model deployment', current_timestamp)
07:34:50.130652 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.58 seconds
07:34:50.134351 [debug] [Thread-1  ]: finished collecting timing info
07:34:50.134838 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
07:34:50.318858 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cac7c501-fad2-4c63-ae05-c2e99a602c68', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b682e0>]}
07:34:50.319415 [info ] [Thread-1  ]: 5 of 7 OK created table model dbt_nigel.snowflake_cumulative_sales.............. [[32mSUCCESS 1[0m in 3.30s]
07:34:50.319655 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
07:34:50.319785 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
07:34:50.320051 [info ] [Thread-1  ]: 6 of 7 START table model dbt_nigel.snowflake_customer_purchases................. [RUN]
07:34:50.320378 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
07:34:50.320482 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
07:34:50.320602 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
07:34:50.324624 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
07:34:50.325657 [debug] [Thread-1  ]: finished collecting timing info
07:34:50.326131 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
07:34:50.331565 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
07:34:50.331842 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */

        insert into dbt.audit (model, state, time) values ('snowflake_customer_purchases', 'starting model deployment', current_timestamp)
07:34:50.332025 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
07:34:51.308246 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.98 seconds
07:34:51.315908 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
07:34:51.318864 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
07:34:51.319224 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt_nigel.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from snowflake_sample_data.tpch_sf1.customer c
left join snowflake_sample_data.tpch_sf1.orders o
on c.c_custkey = o.o_custkey
group by 1,2,3
      );
07:34:52.648878 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.33 seconds
07:34:52.653456 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
07:34:52.654251 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */

        insert into dbt.audit (model, state, time) values ('snowflake_customer_purchases', 'ending model deployment', current_timestamp)
07:34:53.113601 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.46 seconds
07:34:53.117457 [debug] [Thread-1  ]: finished collecting timing info
07:34:53.117960 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
07:34:53.282043 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cac7c501-fad2-4c63-ae05-c2e99a602c68', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1069b8cd0>]}
07:34:53.288200 [info ] [Thread-1  ]: 6 of 7 OK created table model dbt_nigel.snowflake_customer_purchases............ [[32mSUCCESS 1[0m in 2.96s]
07:34:53.289128 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
07:34:53.289535 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
07:34:53.293312 [info ] [Thread-1  ]: 7 of 7 START table model dbt_nigel.my_second_dbt_model.......................... [RUN]
07:34:53.297015 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
07:34:53.297468 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
07:34:53.297710 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
07:34:53.301891 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
07:34:53.302893 [debug] [Thread-1  ]: finished collecting timing info
07:34:53.303124 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
07:34:53.307783 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
07:34:53.308145 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('my_second_dbt_model', 'starting model deployment', current_timestamp)
07:34:53.308360 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
07:34:54.534916 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.23 seconds
07:34:54.539176 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
07:34:54.541592 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
07:34:54.543127 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt_nigel.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt_nigel.first_model
/*
union all
select 7 as id, True as first_variable
*/
      );
07:34:55.738768 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.2 seconds
07:34:55.748481 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
07:34:55.748829 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('my_second_dbt_model', 'ending model deployment', current_timestamp)
07:34:56.583735 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.83 seconds
07:34:56.586977 [debug] [Thread-1  ]: finished collecting timing info
07:34:56.588550 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
07:34:56.762322 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cac7c501-fad2-4c63-ae05-c2e99a602c68', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106bbe1f0>]}
07:34:56.763658 [info ] [Thread-1  ]: 7 of 7 OK created table model dbt_nigel.my_second_dbt_model..................... [[32mSUCCESS 1[0m in 3.47s]
07:34:56.764210 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
07:34:56.773722 [debug] [MainThread]: Acquiring new snowflake connection "master"
07:34:56.774545 [info ] [MainThread]: 
07:34:56.775728 [info ] [MainThread]: Running 3 on-run-end hooks
07:34:56.776830 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-0
07:34:56.782787 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-0"
07:34:56.784167 [info ] [MainThread]: 1 of 3 START hook: learn_dbt.on-run-end.0....................................... [RUN]
07:34:56.784891 [debug] [MainThread]: Using snowflake connection "master"
07:34:56.785104 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
07:34:56.785284 [debug] [MainThread]: Opening a new connection, currently in state closed
07:34:57.502034 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.72 seconds
07:34:57.504486 [info ] [MainThread]: 1 of 3 OK hook: learn_dbt.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.72s]
07:34:57.505035 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-1
07:34:57.516226 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-1"
07:34:57.519554 [info ] [MainThread]: 2 of 3 START hook: learn_dbt.on-run-end.1....................................... [RUN]
07:34:57.519982 [debug] [MainThread]: Using snowflake connection "master"
07:34:57.520093 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
07:34:57.658974 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.14 seconds
07:34:57.664275 [info ] [MainThread]: 2 of 3 OK hook: learn_dbt.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.14s]
07:34:57.664911 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-2
07:34:57.670877 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-2"
07:34:57.674235 [info ] [MainThread]: 3 of 3 START hook: learn_dbt.on-run-end.2....................................... [RUN]
07:34:57.675247 [debug] [MainThread]: Using snowflake connection "master"
07:34:57.675551 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
07:34:57.809943 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.13 seconds
07:34:57.811290 [info ] [MainThread]: 3 of 3 OK hook: learn_dbt.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.14s]
07:34:57.811732 [info ] [MainThread]: 
07:34:57.812910 [debug] [MainThread]: On master: Close
07:34:57.978077 [info ] [MainThread]: 
07:34:57.978841 [info ] [MainThread]: Finished running 2 incremental models, 5 table models, 4 hooks in 29.85s.
07:34:57.979295 [debug] [MainThread]: Connection 'master' was properly closed.
07:34:57.979482 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
07:34:57.994391 [info ] [MainThread]: 
07:34:57.994935 [info ] [MainThread]: [32mCompleted successfully[0m
07:34:57.995307 [info ] [MainThread]: 
07:34:57.995665 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
07:34:57.996293 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106d0ee50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107ad4100>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106fb2e20>]}


============================== 2022-05-17 07:51:35.111941 | f90e49d5-e59d-428d-9fff-32da1d5ffbe7 ==============================
07:51:35.111941 [info ] [MainThread]: Running with dbt=1.0.1
07:51:35.112567 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['my_first_dbt_model'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
07:51:35.112714 [debug] [MainThread]: Tracking: tracking
07:51:35.112927 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10690f1c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10690fdc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10690fc10>]}
07:51:35.156888 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
07:51:35.157235 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/my_first_dbt_model.sql
07:51:35.164769 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
07:51:35.172115 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
07:51:35.185480 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f90e49d5-e59d-428d-9fff-32da1d5ffbe7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ab80d0>]}
07:51:35.189214 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f90e49d5-e59d-428d-9fff-32da1d5ffbe7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068e4cd0>]}
07:51:35.189346 [info ] [MainThread]: Found 7 models, 14 tests, 1 snapshot, 0 analyses, 180 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
07:51:35.190005 [info ] [MainThread]: 
07:51:35.190212 [debug] [MainThread]: Acquiring new snowflake connection "master"
07:51:35.190524 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
07:51:35.196288 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
07:51:35.196378 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
07:51:35.196443 [debug] [ThreadPool]: Opening a new connection, currently in state init
07:51:35.948225 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 0.75 seconds
07:51:35.950664 [debug] [ThreadPool]: On list_analytics: Close
07:51:36.117393 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snaphots"
07:51:36.125969 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snaphots"
07:51:36.126309 [debug] [ThreadPool]: On list_analytics_snaphots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snaphots"} */

    show terse objects in analytics.snaphots
07:51:36.126475 [debug] [ThreadPool]: Opening a new connection, currently in state closed
07:51:36.639473 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.51 seconds
07:51:36.641150 [debug] [ThreadPool]: On list_analytics_snaphots: Close
07:51:37.069158 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt_nigel"
07:51:37.070637 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt_nigel"
07:51:37.070785 [debug] [ThreadPool]: On list_analytics_dbt_nigel: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt_nigel"} */

    show terse objects in analytics.dbt_nigel
07:51:37.070892 [debug] [ThreadPool]: Opening a new connection, currently in state closed
07:51:37.609417 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 0.54 seconds
07:51:37.611714 [debug] [ThreadPool]: On list_analytics_dbt_nigel: Close
07:51:37.765011 [info ] [MainThread]: 
07:51:37.765722 [info ] [MainThread]: Running 1 on-run-start hook
07:51:37.766199 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-start-0
07:51:37.768275 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-start-0"
07:51:37.770541 [info ] [MainThread]: 1 of 1 START hook: learn_dbt.on-run-start.0..................................... [RUN]
07:51:37.771147 [debug] [MainThread]: Using snowflake connection "master"
07:51:37.771311 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
07:51:37.771458 [debug] [MainThread]: Opening a new connection, currently in state init
07:51:38.777991 [debug] [MainThread]: SQL status: SUCCESS 1 in 1.01 seconds
07:51:38.779651 [info ] [MainThread]: 1 of 1 OK hook: learn_dbt.on-run-start.0........................................ [[32mSUCCESS 1[0m in 1.01s]
07:51:38.780104 [info ] [MainThread]: 
07:51:38.780269 [debug] [MainThread]: On master: Close
07:51:38.952476 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
07:51:38.952848 [info ] [MainThread]: 
07:51:38.956141 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
07:51:38.956359 [info ] [Thread-1  ]: 1 of 1 START table model dbt_nigel.first_model.................................. [RUN]
07:51:38.956656 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
07:51:38.956743 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
07:51:38.956833 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
07:51:38.958855 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
07:51:38.959256 [debug] [Thread-1  ]: finished collecting timing info
07:51:38.959351 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
07:51:38.973430 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
07:51:38.973639 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('first_model', 'starting model deployment', current_timestamp)
07:51:38.973757 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
07:51:40.299970 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.33 seconds
07:51:40.312543 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
07:51:40.314177 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
07:51:40.314345 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt_nigel.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id, 'NJ' as state, '2020-02-01 00:01:00.000'::timestamp as updated_at
    union all
    select null as id, 'CT' as state, '2020-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select 3 as id, 'VT' as state, '2020-01-01 00:00:00.000'::timestamp as updated_at

)

select * 
from source_data


/*
select *, True as first_variable
from source_data
where id >= 1
*/
      );
07:51:41.406947 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.09 seconds
07:51:41.411638 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
07:51:41.411926 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('first_model', 'ending model deployment', current_timestamp)
07:51:41.943877 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.53 seconds
07:51:41.957781 [debug] [Thread-1  ]: finished collecting timing info
07:51:41.958170 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
07:51:42.112195 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f90e49d5-e59d-428d-9fff-32da1d5ffbe7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106adafa0>]}
07:51:42.113082 [info ] [Thread-1  ]: 1 of 1 OK created table model dbt_nigel.first_model............................. [[32mSUCCESS 1[0m in 3.16s]
07:51:42.113502 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
07:51:42.114409 [debug] [MainThread]: Acquiring new snowflake connection "master"
07:51:42.114643 [info ] [MainThread]: 
07:51:42.114873 [info ] [MainThread]: Running 3 on-run-end hooks
07:51:42.115214 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-0
07:51:42.116797 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-0"
07:51:42.117590 [info ] [MainThread]: 1 of 3 START hook: learn_dbt.on-run-end.0....................................... [RUN]
07:51:42.118073 [debug] [MainThread]: Using snowflake connection "master"
07:51:42.118209 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
07:51:42.118336 [debug] [MainThread]: Opening a new connection, currently in state closed
07:51:42.693878 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.58 seconds
07:51:42.695350 [info ] [MainThread]: 1 of 3 OK hook: learn_dbt.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.58s]
07:51:42.695807 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-1
07:51:42.697688 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-1"
07:51:42.698825 [info ] [MainThread]: 2 of 3 START hook: learn_dbt.on-run-end.1....................................... [RUN]
07:51:42.699499 [debug] [MainThread]: Using snowflake connection "master"
07:51:42.699697 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
07:51:42.842337 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.14 seconds
07:51:42.843868 [info ] [MainThread]: 2 of 3 OK hook: learn_dbt.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.14s]
07:51:42.844341 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-2
07:51:42.846668 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-2"
07:51:42.847836 [info ] [MainThread]: 3 of 3 START hook: learn_dbt.on-run-end.2....................................... [RUN]
07:51:42.848414 [debug] [MainThread]: Using snowflake connection "master"
07:51:42.848571 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
07:51:42.962955 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.11 seconds
07:51:42.964455 [info ] [MainThread]: 3 of 3 OK hook: learn_dbt.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.12s]
07:51:42.964854 [info ] [MainThread]: 
07:51:42.965145 [debug] [MainThread]: On master: Close
07:51:43.134628 [info ] [MainThread]: 
07:51:43.135169 [info ] [MainThread]: Finished running 1 table model, 4 hooks in 7.94s.
07:51:43.135623 [debug] [MainThread]: Connection 'master' was properly closed.
07:51:43.135819 [debug] [MainThread]: Connection 'model.learn_dbt.my_first_dbt_model' was properly closed.
07:51:43.142956 [info ] [MainThread]: 
07:51:43.143232 [info ] [MainThread]: [32mCompleted successfully[0m
07:51:43.143478 [info ] [MainThread]: 
07:51:43.143672 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
07:51:43.143946 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106cf6d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106cf65e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106cf6790>]}


============================== 2022-05-17 08:04:22.598034 | 1d6cf796-4b50-45f3-9d82-0188bcc6cfef ==============================
08:04:22.598034 [info ] [MainThread]: Running with dbt=1.0.1
08:04:22.598578 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['playing_with_tests'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
08:04:22.598703 [debug] [MainThread]: Tracking: tracking
08:04:22.598934 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108b03d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108b03c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108b038b0>]}
08:04:22.642381 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
08:04:22.642723 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/playing_with_tests.sql
08:04:22.648592 [debug] [MainThread]: 1699: static parser successfully parsed example/playing_with_tests.sql
08:04:22.677281 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1d6cf796-4b50-45f3-9d82-0188bcc6cfef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108caa0a0>]}
08:04:22.681242 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1d6cf796-4b50-45f3-9d82-0188bcc6cfef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108caa190>]}
08:04:22.681403 [info ] [MainThread]: Found 7 models, 14 tests, 1 snapshot, 0 analyses, 180 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
08:04:22.682118 [info ] [MainThread]: 
08:04:22.682344 [debug] [MainThread]: Acquiring new snowflake connection "master"
08:04:22.682683 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
08:04:22.689339 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
08:04:22.689520 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
08:04:22.689592 [debug] [ThreadPool]: Opening a new connection, currently in state init
08:04:23.642061 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 0.95 seconds
08:04:23.644614 [debug] [ThreadPool]: On list_analytics: Close
08:04:23.812973 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snaphots"
08:04:23.821410 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snaphots"
08:04:23.821642 [debug] [ThreadPool]: On list_analytics_snaphots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snaphots"} */

    show terse objects in analytics.snaphots
08:04:23.821807 [debug] [ThreadPool]: Opening a new connection, currently in state closed
08:04:24.502195 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.68 seconds
08:04:24.505560 [debug] [ThreadPool]: On list_analytics_snaphots: Close
08:04:25.104289 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt_nigel"
08:04:25.106940 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt_nigel"
08:04:25.107197 [debug] [ThreadPool]: On list_analytics_dbt_nigel: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt_nigel"} */

    show terse objects in analytics.dbt_nigel
08:04:25.107392 [debug] [ThreadPool]: Opening a new connection, currently in state closed
08:04:25.608070 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 0.5 seconds
08:04:25.612453 [debug] [ThreadPool]: On list_analytics_dbt_nigel: Close
08:04:25.775822 [info ] [MainThread]: 
08:04:25.776417 [info ] [MainThread]: Running 1 on-run-start hook
08:04:25.776786 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-start-0
08:04:25.778742 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-start-0"
08:04:25.781879 [info ] [MainThread]: 1 of 1 START hook: learn_dbt.on-run-start.0..................................... [RUN]
08:04:25.782563 [debug] [MainThread]: Using snowflake connection "master"
08:04:25.782735 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
08:04:25.782880 [debug] [MainThread]: Opening a new connection, currently in state init
08:04:26.298404 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.52 seconds
08:04:26.300460 [info ] [MainThread]: 1 of 1 OK hook: learn_dbt.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.52s]
08:04:26.300975 [info ] [MainThread]: 
08:04:26.301340 [debug] [MainThread]: On master: Close
08:04:26.463354 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
08:04:26.463996 [info ] [MainThread]: 
08:04:26.469726 [debug] [Thread-1  ]: Began running node model.learn_dbt.playing_with_tests
08:04:26.470123 [info ] [Thread-1  ]: 1 of 1 START table model dbt_nigel.playing_with_tests........................... [RUN]
08:04:26.470616 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.playing_with_tests"
08:04:26.470780 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.playing_with_tests
08:04:26.470954 [debug] [Thread-1  ]: Compiling model.learn_dbt.playing_with_tests
08:04:26.474378 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.playing_with_tests"
08:04:26.475073 [debug] [Thread-1  ]: finished collecting timing info
08:04:26.475228 [debug] [Thread-1  ]: Began executing node model.learn_dbt.playing_with_tests
08:04:26.489840 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
08:04:26.489994 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */

        insert into dbt.audit (model, state, time) values ('playing_with_tests', 'starting model deployment', current_timestamp)
08:04:26.490096 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
08:04:27.951449 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.46 seconds
08:04:27.964458 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.playing_with_tests"
08:04:27.965652 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
08:04:27.965814 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */


      create or replace transient table analytics.dbt_nigel.playing_with_tests  as
      (with sample_customer (
    select * 
    from snowflake_sample_data.tpch_sf1.customer
)

select
  c_custkey,
  c_mktsegment
from sample_customer
      );
08:04:28.087512 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a45284-3201-9ec3-0001-2052000100ce
08:04:28.087742 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 3 at position 4 unexpected 'select'.
08:04:28.088006 [debug] [Thread-1  ]: finished collecting timing info
08:04:28.088168 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: Close
08:04:28.243621 [debug] [Thread-1  ]: Database Error in model playing_with_tests (models/example/playing_with_tests.sql)
  001003 (42000): SQL compilation error:
  syntax error line 3 at position 4 unexpected 'select'.
  compiled SQL at target/run/learn_dbt/models/example/playing_with_tests.sql
08:04:28.244285 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1d6cf796-4b50-45f3-9d82-0188bcc6cfef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10adbef10>]}
08:04:28.244801 [error] [Thread-1  ]: 1 of 1 ERROR creating table model dbt_nigel.playing_with_tests.................. [[31mERROR[0m in 1.77s]
08:04:28.245255 [debug] [Thread-1  ]: Finished running node model.learn_dbt.playing_with_tests
08:04:28.246746 [debug] [MainThread]: Acquiring new snowflake connection "master"
08:04:28.247051 [info ] [MainThread]: 
08:04:28.247370 [info ] [MainThread]: Running 3 on-run-end hooks
08:04:28.247699 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-0
08:04:28.249519 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-0"
08:04:28.252289 [info ] [MainThread]: 1 of 3 START hook: learn_dbt.on-run-end.0....................................... [RUN]
08:04:28.252852 [debug] [MainThread]: Using snowflake connection "master"
08:04:28.253007 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
08:04:28.253144 [debug] [MainThread]: Opening a new connection, currently in state closed
08:04:28.757936 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.5 seconds
08:04:28.761459 [info ] [MainThread]: 1 of 3 OK hook: learn_dbt.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.51s]
08:04:28.762768 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-1
08:04:28.765001 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-1"
08:04:28.766185 [info ] [MainThread]: 2 of 3 START hook: learn_dbt.on-run-end.1....................................... [RUN]
08:04:28.766895 [debug] [MainThread]: Using snowflake connection "master"
08:04:28.767093 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
08:04:28.927168 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.16 seconds
08:04:28.929895 [info ] [MainThread]: 2 of 3 OK hook: learn_dbt.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.16s]
08:04:28.930503 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-2
08:04:28.932851 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-2"
08:04:28.933964 [info ] [MainThread]: 3 of 3 START hook: learn_dbt.on-run-end.2....................................... [RUN]
08:04:28.934625 [debug] [MainThread]: Using snowflake connection "master"
08:04:28.934820 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
08:04:29.087073 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.15 seconds
08:04:29.089185 [info ] [MainThread]: 3 of 3 OK hook: learn_dbt.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.15s]
08:04:29.089606 [info ] [MainThread]: 
08:04:29.089972 [debug] [MainThread]: On master: Close
08:04:29.305205 [info ] [MainThread]: 
08:04:29.305642 [info ] [MainThread]: Finished running 1 table model, 4 hooks in 6.62s.
08:04:29.305808 [debug] [MainThread]: Connection 'master' was properly closed.
08:04:29.305914 [debug] [MainThread]: Connection 'model.learn_dbt.playing_with_tests' was properly closed.
08:04:29.312530 [info ] [MainThread]: 
08:04:29.312723 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
08:04:29.312879 [info ] [MainThread]: 
08:04:29.313009 [error] [MainThread]: [33mDatabase Error in model playing_with_tests (models/example/playing_with_tests.sql)[0m
08:04:29.313145 [error] [MainThread]:   001003 (42000): SQL compilation error:
08:04:29.313263 [error] [MainThread]:   syntax error line 3 at position 4 unexpected 'select'.
08:04:29.313376 [error] [MainThread]:   compiled SQL at target/run/learn_dbt/models/example/playing_with_tests.sql
08:04:29.313562 [info ] [MainThread]: 
08:04:29.313706 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
08:04:29.313979 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108eff700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108fff3d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108fff040>]}


============================== 2022-05-17 08:07:06.035934 | 599fb4b3-1a31-4496-8eba-45219d5480f8 ==============================
08:07:06.035934 [info ] [MainThread]: Running with dbt=1.0.1
08:07:06.036293 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['playing_with_tests'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
08:07:06.036406 [debug] [MainThread]: Tracking: tracking
08:07:06.036648 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10717c610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10717cac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10717cb20>]}
08:07:06.083666 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
08:07:06.084030 [debug] [MainThread]: Partial parsing: update schema file: learn_dbt://models/example/schema.yml
08:07:06.089273 [debug] [MainThread]: 1699: static parser successfully parsed example/playing_with_tests.sql
08:07:06.113887 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '599fb4b3-1a31-4496-8eba-45219d5480f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10732b0d0>]}
08:07:06.117352 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '599fb4b3-1a31-4496-8eba-45219d5480f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10729d0a0>]}
08:07:06.117480 [info ] [MainThread]: Found 7 models, 12 tests, 1 snapshot, 0 analyses, 180 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
08:07:06.118169 [info ] [MainThread]: 
08:07:06.118368 [debug] [MainThread]: Acquiring new snowflake connection "master"
08:07:06.118685 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
08:07:06.124465 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
08:07:06.124567 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
08:07:06.124632 [debug] [ThreadPool]: Opening a new connection, currently in state init
08:07:06.873820 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 0.75 seconds
08:07:06.876787 [debug] [ThreadPool]: On list_analytics: Close
08:07:07.056959 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snaphots"
08:07:07.065480 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snaphots"
08:07:07.065703 [debug] [ThreadPool]: On list_analytics_snaphots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snaphots"} */

    show terse objects in analytics.snaphots
08:07:07.065863 [debug] [ThreadPool]: Opening a new connection, currently in state closed
08:07:07.819165 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.75 seconds
08:07:07.822725 [debug] [ThreadPool]: On list_analytics_snaphots: Close
08:07:08.004314 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt_nigel"
08:07:08.006669 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt_nigel"
08:07:08.006887 [debug] [ThreadPool]: On list_analytics_dbt_nigel: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt_nigel"} */

    show terse objects in analytics.dbt_nigel
08:07:08.007043 [debug] [ThreadPool]: Opening a new connection, currently in state closed
08:07:08.522544 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 0.52 seconds
08:07:08.527249 [debug] [ThreadPool]: On list_analytics_dbt_nigel: Close
08:07:09.352180 [info ] [MainThread]: 
08:07:09.352806 [info ] [MainThread]: Running 1 on-run-start hook
08:07:09.353202 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-start-0
08:07:09.355132 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-start-0"
08:07:09.357032 [info ] [MainThread]: 1 of 1 START hook: learn_dbt.on-run-start.0..................................... [RUN]
08:07:09.357619 [debug] [MainThread]: Using snowflake connection "master"
08:07:09.357783 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
08:07:09.357930 [debug] [MainThread]: Opening a new connection, currently in state init
08:07:09.938438 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.58 seconds
08:07:09.939926 [info ] [MainThread]: 1 of 1 OK hook: learn_dbt.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.58s]
08:07:09.940371 [info ] [MainThread]: 
08:07:09.940739 [debug] [MainThread]: On master: Close
08:07:10.102975 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
08:07:10.103621 [info ] [MainThread]: 
08:07:10.109495 [debug] [Thread-1  ]: Began running node model.learn_dbt.playing_with_tests
08:07:10.109882 [info ] [Thread-1  ]: 1 of 1 START table model dbt_nigel.playing_with_tests........................... [RUN]
08:07:10.110377 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.playing_with_tests"
08:07:10.110550 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.playing_with_tests
08:07:10.110718 [debug] [Thread-1  ]: Compiling model.learn_dbt.playing_with_tests
08:07:10.114217 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.playing_with_tests"
08:07:10.114857 [debug] [Thread-1  ]: finished collecting timing info
08:07:10.115032 [debug] [Thread-1  ]: Began executing node model.learn_dbt.playing_with_tests
08:07:10.128978 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
08:07:10.129118 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */

        insert into dbt.audit (model, state, time) values ('playing_with_tests', 'starting model deployment', current_timestamp)
08:07:10.129215 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
08:07:11.595788 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.47 seconds
08:07:11.610224 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.playing_with_tests"
08:07:11.611662 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
08:07:11.611825 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */


      create or replace transient table analytics.dbt_nigel.playing_with_tests  as
      (with sample_customer (
    select * 
    from snowflake_sample_data.tpch_sf1.customer
)

select
  c_custkey,
  c_mktsegment
from sample_customer
      );
08:07:11.727251 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a45287-3201-9ec3-0001-2052000100e6
08:07:11.727666 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 3 at position 4 unexpected 'select'.
08:07:11.728048 [debug] [Thread-1  ]: finished collecting timing info
08:07:11.728288 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: Close
08:07:12.131794 [debug] [Thread-1  ]: Database Error in model playing_with_tests (models/example/playing_with_tests.sql)
  001003 (42000): SQL compilation error:
  syntax error line 3 at position 4 unexpected 'select'.
  compiled SQL at target/run/learn_dbt/models/example/playing_with_tests.sql
08:07:12.132430 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '599fb4b3-1a31-4496-8eba-45219d5480f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10755ca00>]}
08:07:12.132918 [error] [Thread-1  ]: 1 of 1 ERROR creating table model dbt_nigel.playing_with_tests.................. [[31mERROR[0m in 2.02s]
08:07:12.133357 [debug] [Thread-1  ]: Finished running node model.learn_dbt.playing_with_tests
08:07:12.134633 [debug] [MainThread]: Acquiring new snowflake connection "master"
08:07:12.134911 [info ] [MainThread]: 
08:07:12.135223 [info ] [MainThread]: Running 3 on-run-end hooks
08:07:12.135550 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-0
08:07:12.137145 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-0"
08:07:12.138632 [info ] [MainThread]: 1 of 3 START hook: learn_dbt.on-run-end.0....................................... [RUN]
08:07:12.139178 [debug] [MainThread]: Using snowflake connection "master"
08:07:12.139342 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
08:07:12.139482 [debug] [MainThread]: Opening a new connection, currently in state closed
08:07:13.066733 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.93 seconds
08:07:13.068422 [info ] [MainThread]: 1 of 3 OK hook: learn_dbt.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.93s]
08:07:13.068893 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-1
08:07:13.070812 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-1"
08:07:13.072036 [info ] [MainThread]: 2 of 3 START hook: learn_dbt.on-run-end.1....................................... [RUN]
08:07:13.072667 [debug] [MainThread]: Using snowflake connection "master"
08:07:13.072842 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
08:07:13.216559 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.14 seconds
08:07:13.219128 [info ] [MainThread]: 2 of 3 OK hook: learn_dbt.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.15s]
08:07:13.219714 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-2
08:07:13.222938 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-2"
08:07:13.224214 [info ] [MainThread]: 3 of 3 START hook: learn_dbt.on-run-end.2....................................... [RUN]
08:07:13.224807 [debug] [MainThread]: Using snowflake connection "master"
08:07:13.224971 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
08:07:13.322819 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.1 seconds
08:07:13.325262 [info ] [MainThread]: 3 of 3 OK hook: learn_dbt.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.10s]
08:07:13.326049 [info ] [MainThread]: 
08:07:13.326470 [debug] [MainThread]: On master: Close
08:07:13.490001 [info ] [MainThread]: 
08:07:13.490681 [info ] [MainThread]: Finished running 1 table model, 4 hooks in 7.37s.
08:07:13.491019 [debug] [MainThread]: Connection 'master' was properly closed.
08:07:13.491190 [debug] [MainThread]: Connection 'model.learn_dbt.playing_with_tests' was properly closed.
08:07:13.498980 [info ] [MainThread]: 
08:07:13.499295 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
08:07:13.499569 [info ] [MainThread]: 
08:07:13.499797 [error] [MainThread]: [33mDatabase Error in model playing_with_tests (models/example/playing_with_tests.sql)[0m
08:07:13.500022 [error] [MainThread]:   001003 (42000): SQL compilation error:
08:07:13.500235 [error] [MainThread]:   syntax error line 3 at position 4 unexpected 'select'.
08:07:13.500442 [error] [MainThread]:   compiled SQL at target/run/learn_dbt/models/example/playing_with_tests.sql
08:07:13.500659 [info ] [MainThread]: 
08:07:13.500876 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
08:07:13.501207 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107512760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10973b7f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10973b760>]}


============================== 2022-05-17 08:08:14.665853 | def45cc6-d8eb-40a9-9163-56b489474b91 ==============================
08:08:14.665853 [info ] [MainThread]: Running with dbt=1.0.1
08:08:14.666215 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['playing_with_tests'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
08:08:14.666332 [debug] [MainThread]: Tracking: tracking
08:08:14.666542 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105833370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105833be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105833e50>]}
08:08:14.709992 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
08:08:14.710282 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/playing_with_tests.sql
08:08:14.715751 [debug] [MainThread]: 1699: static parser successfully parsed example/playing_with_tests.sql
08:08:14.741591 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'def45cc6-d8eb-40a9-9163-56b489474b91', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059c10d0>]}
08:08:14.745159 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'def45cc6-d8eb-40a9-9163-56b489474b91', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059331c0>]}
08:08:14.745294 [info ] [MainThread]: Found 7 models, 12 tests, 1 snapshot, 0 analyses, 180 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
08:08:14.746002 [info ] [MainThread]: 
08:08:14.746205 [debug] [MainThread]: Acquiring new snowflake connection "master"
08:08:14.746551 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
08:08:14.752354 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
08:08:14.752459 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
08:08:14.752525 [debug] [ThreadPool]: Opening a new connection, currently in state init
08:08:15.482844 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 0.73 seconds
08:08:15.486449 [debug] [ThreadPool]: On list_analytics: Close
08:08:15.659438 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt_nigel"
08:08:15.668068 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt_nigel"
08:08:15.668292 [debug] [ThreadPool]: On list_analytics_dbt_nigel: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt_nigel"} */

    show terse objects in analytics.dbt_nigel
08:08:15.668451 [debug] [ThreadPool]: Opening a new connection, currently in state closed
08:08:16.172263 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 0.5 seconds
08:08:16.174949 [debug] [ThreadPool]: On list_analytics_dbt_nigel: Close
08:08:16.339727 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snaphots"
08:08:16.342538 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snaphots"
08:08:16.342773 [debug] [ThreadPool]: On list_analytics_snaphots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snaphots"} */

    show terse objects in analytics.snaphots
08:08:16.342955 [debug] [ThreadPool]: Opening a new connection, currently in state closed
08:08:16.843898 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.5 seconds
08:08:16.847267 [debug] [ThreadPool]: On list_analytics_snaphots: Close
08:08:17.022983 [info ] [MainThread]: 
08:08:17.023510 [info ] [MainThread]: Running 1 on-run-start hook
08:08:17.023921 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-start-0
08:08:17.025887 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-start-0"
08:08:17.027947 [info ] [MainThread]: 1 of 1 START hook: learn_dbt.on-run-start.0..................................... [RUN]
08:08:17.028514 [debug] [MainThread]: Using snowflake connection "master"
08:08:17.028671 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
08:08:17.028822 [debug] [MainThread]: Opening a new connection, currently in state init
08:08:18.395205 [debug] [MainThread]: SQL status: SUCCESS 1 in 1.37 seconds
08:08:18.398427 [info ] [MainThread]: 1 of 1 OK hook: learn_dbt.on-run-start.0........................................ [[32mSUCCESS 1[0m in 1.37s]
08:08:18.399062 [info ] [MainThread]: 
08:08:18.399443 [debug] [MainThread]: On master: Close
08:08:18.808557 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
08:08:18.809698 [info ] [MainThread]: 
08:08:18.815687 [debug] [Thread-1  ]: Began running node model.learn_dbt.playing_with_tests
08:08:18.816065 [info ] [Thread-1  ]: 1 of 1 START table model dbt_nigel.playing_with_tests........................... [RUN]
08:08:18.816618 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.playing_with_tests"
08:08:18.816792 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.playing_with_tests
08:08:18.816960 [debug] [Thread-1  ]: Compiling model.learn_dbt.playing_with_tests
08:08:18.820515 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.playing_with_tests"
08:08:18.821121 [debug] [Thread-1  ]: finished collecting timing info
08:08:18.821267 [debug] [Thread-1  ]: Began executing node model.learn_dbt.playing_with_tests
08:08:18.835913 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
08:08:18.836083 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */

        insert into dbt.audit (model, state, time) values ('playing_with_tests', 'starting model deployment', current_timestamp)
08:08:18.836189 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
08:08:20.647672 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.81 seconds
08:08:20.659992 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.playing_with_tests"
08:08:20.661188 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
08:08:20.661330 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */


      create or replace transient table analytics.dbt_nigel.playing_with_tests  as
      (with sample_customer (
select * 
from snowflake_sample_data.tpch_sf1.customer
)

select
  c_custkey,
  c_mktsegment
from sample_customer
      );
08:08:20.781792 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a45288-3201-9ec3-0001-2052000100fa
08:08:20.782030 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 3 at position 0 unexpected 'select'.
08:08:20.782283 [debug] [Thread-1  ]: finished collecting timing info
08:08:20.782436 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: Close
08:08:20.978205 [debug] [Thread-1  ]: Database Error in model playing_with_tests (models/example/playing_with_tests.sql)
  001003 (42000): SQL compilation error:
  syntax error line 3 at position 0 unexpected 'select'.
  compiled SQL at target/run/learn_dbt/models/example/playing_with_tests.sql
08:08:20.978623 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'def45cc6-d8eb-40a9-9163-56b489474b91', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105eaa220>]}
08:08:20.979022 [error] [Thread-1  ]: 1 of 1 ERROR creating table model dbt_nigel.playing_with_tests.................. [[31mERROR[0m in 2.16s]
08:08:20.979387 [debug] [Thread-1  ]: Finished running node model.learn_dbt.playing_with_tests
08:08:20.980599 [debug] [MainThread]: Acquiring new snowflake connection "master"
08:08:20.980874 [info ] [MainThread]: 
08:08:20.981137 [info ] [MainThread]: Running 3 on-run-end hooks
08:08:20.981411 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-0
08:08:20.982968 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-0"
08:08:20.984474 [info ] [MainThread]: 1 of 3 START hook: learn_dbt.on-run-end.0....................................... [RUN]
08:08:20.984968 [debug] [MainThread]: Using snowflake connection "master"
08:08:20.985107 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
08:08:20.985225 [debug] [MainThread]: Opening a new connection, currently in state closed
08:08:21.681762 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.7 seconds
08:08:21.684559 [info ] [MainThread]: 1 of 3 OK hook: learn_dbt.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.70s]
08:08:21.685022 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-1
08:08:21.686501 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-1"
08:08:21.687501 [info ] [MainThread]: 2 of 3 START hook: learn_dbt.on-run-end.1....................................... [RUN]
08:08:21.688041 [debug] [MainThread]: Using snowflake connection "master"
08:08:21.688204 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
08:08:21.850995 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.16 seconds
08:08:21.852340 [info ] [MainThread]: 2 of 3 OK hook: learn_dbt.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.16s]
08:08:21.852716 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-2
08:08:21.855617 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-2"
08:08:21.856589 [info ] [MainThread]: 3 of 3 START hook: learn_dbt.on-run-end.2....................................... [RUN]
08:08:21.857135 [debug] [MainThread]: Using snowflake connection "master"
08:08:21.857297 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
08:08:21.964202 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.11 seconds
08:08:21.966505 [info ] [MainThread]: 3 of 3 OK hook: learn_dbt.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.11s]
08:08:21.967169 [info ] [MainThread]: 
08:08:21.967552 [debug] [MainThread]: On master: Close
08:08:22.126834 [info ] [MainThread]: 
08:08:22.127946 [info ] [MainThread]: Finished running 1 table model, 4 hooks in 7.38s.
08:08:22.128480 [debug] [MainThread]: Connection 'master' was properly closed.
08:08:22.128783 [debug] [MainThread]: Connection 'model.learn_dbt.playing_with_tests' was properly closed.
08:08:22.136295 [info ] [MainThread]: 
08:08:22.136616 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
08:08:22.136900 [info ] [MainThread]: 
08:08:22.137128 [error] [MainThread]: [33mDatabase Error in model playing_with_tests (models/example/playing_with_tests.sql)[0m
08:08:22.137361 [error] [MainThread]:   001003 (42000): SQL compilation error:
08:08:22.137575 [error] [MainThread]:   syntax error line 3 at position 0 unexpected 'select'.
08:08:22.137785 [error] [MainThread]:   compiled SQL at target/run/learn_dbt/models/example/playing_with_tests.sql
08:08:22.137971 [info ] [MainThread]: 
08:08:22.138157 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
08:08:22.138471 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d27280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ed1be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ec3a60>]}


============================== 2022-05-17 08:09:28.088518 | e4c77719-17be-411c-b3cf-ad720376f169 ==============================
08:09:28.088518 [info ] [MainThread]: Running with dbt=1.0.1
08:09:28.089033 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['playing_with_tests'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
08:09:28.089145 [debug] [MainThread]: Tracking: tracking
08:09:28.089357 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108d06a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108d065e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108d06730>]}
08:09:28.136063 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
08:09:28.136336 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/playing_with_tests.sql
08:09:28.142419 [debug] [MainThread]: 1699: static parser successfully parsed example/playing_with_tests.sql
08:09:28.167696 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e4c77719-17be-411c-b3cf-ad720376f169', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108ec50d0>]}
08:09:28.171117 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e4c77719-17be-411c-b3cf-ad720376f169', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108e2beb0>]}
08:09:28.171248 [info ] [MainThread]: Found 7 models, 12 tests, 1 snapshot, 0 analyses, 180 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
08:09:28.171946 [info ] [MainThread]: 
08:09:28.172148 [debug] [MainThread]: Acquiring new snowflake connection "master"
08:09:28.172473 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
08:09:28.178277 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
08:09:28.178395 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
08:09:28.178467 [debug] [ThreadPool]: Opening a new connection, currently in state init
08:09:28.982031 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 0.8 seconds
08:09:28.985216 [debug] [ThreadPool]: On list_analytics: Close
08:09:29.221738 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt_nigel"
08:09:29.228449 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt_nigel"
08:09:29.228649 [debug] [ThreadPool]: On list_analytics_dbt_nigel: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt_nigel"} */

    show terse objects in analytics.dbt_nigel
08:09:29.228781 [debug] [ThreadPool]: Opening a new connection, currently in state closed
08:09:30.043453 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 0.81 seconds
08:09:30.046897 [debug] [ThreadPool]: On list_analytics_dbt_nigel: Close
08:09:30.219316 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snaphots"
08:09:30.221900 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snaphots"
08:09:30.222122 [debug] [ThreadPool]: On list_analytics_snaphots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snaphots"} */

    show terse objects in analytics.snaphots
08:09:30.222284 [debug] [ThreadPool]: Opening a new connection, currently in state closed
08:09:30.726357 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.5 seconds
08:09:30.729770 [debug] [ThreadPool]: On list_analytics_snaphots: Close
08:09:30.903179 [info ] [MainThread]: 
08:09:30.903659 [info ] [MainThread]: Running 1 on-run-start hook
08:09:30.904033 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-start-0
08:09:30.905825 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-start-0"
08:09:30.907720 [info ] [MainThread]: 1 of 1 START hook: learn_dbt.on-run-start.0..................................... [RUN]
08:09:30.908297 [debug] [MainThread]: Using snowflake connection "master"
08:09:30.908463 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
08:09:30.908608 [debug] [MainThread]: Opening a new connection, currently in state init
08:09:31.402306 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.49 seconds
08:09:31.403953 [info ] [MainThread]: 1 of 1 OK hook: learn_dbt.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.50s]
08:09:31.404405 [info ] [MainThread]: 
08:09:31.404731 [debug] [MainThread]: On master: Close
08:09:31.576063 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
08:09:31.576749 [info ] [MainThread]: 
08:09:31.582142 [debug] [Thread-1  ]: Began running node model.learn_dbt.playing_with_tests
08:09:31.582528 [info ] [Thread-1  ]: 1 of 1 START table model dbt_nigel.playing_with_tests........................... [RUN]
08:09:31.583021 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.playing_with_tests"
08:09:31.583186 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.playing_with_tests
08:09:31.583361 [debug] [Thread-1  ]: Compiling model.learn_dbt.playing_with_tests
08:09:31.586852 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.playing_with_tests"
08:09:31.587407 [debug] [Thread-1  ]: finished collecting timing info
08:09:31.587555 [debug] [Thread-1  ]: Began executing node model.learn_dbt.playing_with_tests
08:09:31.602002 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
08:09:31.602148 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */

        insert into dbt.audit (model, state, time) values ('playing_with_tests', 'starting model deployment', current_timestamp)
08:09:31.602247 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
08:09:33.047264 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.44 seconds
08:09:33.061534 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.playing_with_tests"
08:09:33.062824 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
08:09:33.062984 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */


      create or replace transient table analytics.dbt_nigel.playing_with_tests  as
      (WITH sample_customer AS (select * from snowflake_sample_data.tpch_sf1.customer)

select
  c_custkey,
  c_mktsegment
from sample_customer
      );
08:09:34.032417 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.97 seconds
08:09:34.036447 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
08:09:34.036673 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */

        insert into dbt.audit (model, state, time) values ('playing_with_tests', 'ending model deployment', current_timestamp)
08:09:34.785787 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.75 seconds
08:09:34.798085 [debug] [Thread-1  ]: finished collecting timing info
08:09:34.798363 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: Close
08:09:34.944872 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4c77719-17be-411c-b3cf-ad720376f169', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108cf2460>]}
08:09:34.945517 [info ] [Thread-1  ]: 1 of 1 OK created table model dbt_nigel.playing_with_tests...................... [[32mSUCCESS 1[0m in 3.36s]
08:09:34.946023 [debug] [Thread-1  ]: Finished running node model.learn_dbt.playing_with_tests
08:09:34.947494 [debug] [MainThread]: Acquiring new snowflake connection "master"
08:09:34.947824 [info ] [MainThread]: 
08:09:34.948126 [info ] [MainThread]: Running 3 on-run-end hooks
08:09:34.948409 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-0
08:09:34.949744 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-0"
08:09:34.950559 [info ] [MainThread]: 1 of 3 START hook: learn_dbt.on-run-end.0....................................... [RUN]
08:09:34.951087 [debug] [MainThread]: Using snowflake connection "master"
08:09:34.951241 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
08:09:34.951378 [debug] [MainThread]: Opening a new connection, currently in state closed
08:09:35.490631 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.54 seconds
08:09:35.492722 [info ] [MainThread]: 1 of 3 OK hook: learn_dbt.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.54s]
08:09:35.493301 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-1
08:09:35.495016 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-1"
08:09:35.496212 [info ] [MainThread]: 2 of 3 START hook: learn_dbt.on-run-end.1....................................... [RUN]
08:09:35.496795 [debug] [MainThread]: Using snowflake connection "master"
08:09:35.496969 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
08:09:35.616790 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.12 seconds
08:09:35.618355 [info ] [MainThread]: 2 of 3 OK hook: learn_dbt.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.12s]
08:09:35.618794 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-2
08:09:35.621067 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-2"
08:09:35.622069 [info ] [MainThread]: 3 of 3 START hook: learn_dbt.on-run-end.2....................................... [RUN]
08:09:35.622594 [debug] [MainThread]: Using snowflake connection "master"
08:09:35.622751 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
08:09:35.723600 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.1 seconds
08:09:35.725809 [info ] [MainThread]: 3 of 3 OK hook: learn_dbt.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.10s]
08:09:35.726257 [info ] [MainThread]: 
08:09:35.726552 [debug] [MainThread]: On master: Close
08:09:35.885608 [info ] [MainThread]: 
08:09:35.886173 [info ] [MainThread]: Finished running 1 table model, 4 hooks in 7.71s.
08:09:35.886509 [debug] [MainThread]: Connection 'master' was properly closed.
08:09:35.886695 [debug] [MainThread]: Connection 'model.learn_dbt.playing_with_tests' was properly closed.
08:09:35.894432 [info ] [MainThread]: 
08:09:35.894727 [info ] [MainThread]: [32mCompleted successfully[0m
08:09:35.895012 [info ] [MainThread]: 
08:09:35.895242 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
08:09:35.895589 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109112850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109205d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10afcb2e0>]}


============================== 2022-05-17 08:10:21.438235 | af77bd85-afac-495d-9177-756f6a8dd99b ==============================
08:10:21.438235 [info ] [MainThread]: Running with dbt=1.0.1
08:10:21.438765 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['playing_with_tests'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
08:10:21.438892 [debug] [MainThread]: Tracking: tracking
08:10:21.439108 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1047c3af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1047c3760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1047c3b20>]}
08:10:21.484685 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
08:10:21.484942 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/playing_with_tests.sql
08:10:21.490659 [debug] [MainThread]: 1699: static parser successfully parsed example/playing_with_tests.sql
08:10:21.515138 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'af77bd85-afac-495d-9177-756f6a8dd99b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10516d0d0>]}
08:10:21.518593 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'af77bd85-afac-495d-9177-756f6a8dd99b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1050dd250>]}
08:10:21.518721 [info ] [MainThread]: Found 7 models, 12 tests, 1 snapshot, 0 analyses, 180 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
08:10:21.519400 [info ] [MainThread]: 
08:10:21.519593 [debug] [MainThread]: Acquiring new snowflake connection "master"
08:10:21.519893 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
08:10:21.525632 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
08:10:21.525740 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
08:10:21.525807 [debug] [ThreadPool]: Opening a new connection, currently in state init
08:10:22.394902 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 0.87 seconds
08:10:22.397651 [debug] [ThreadPool]: On list_analytics: Close
08:10:22.581755 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snaphots"
08:10:22.590295 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snaphots"
08:10:22.590532 [debug] [ThreadPool]: On list_analytics_snaphots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snaphots"} */

    show terse objects in analytics.snaphots
08:10:22.590692 [debug] [ThreadPool]: Opening a new connection, currently in state closed
08:10:23.370379 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.78 seconds
08:10:23.374216 [debug] [ThreadPool]: On list_analytics_snaphots: Close
08:10:23.535201 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt_nigel"
08:10:23.537923 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt_nigel"
08:10:23.538180 [debug] [ThreadPool]: On list_analytics_dbt_nigel: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt_nigel"} */

    show terse objects in analytics.dbt_nigel
08:10:23.538372 [debug] [ThreadPool]: Opening a new connection, currently in state closed
08:10:24.032490 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 0.49 seconds
08:10:24.037060 [debug] [ThreadPool]: On list_analytics_dbt_nigel: Close
08:10:24.206079 [info ] [MainThread]: 
08:10:24.206607 [info ] [MainThread]: Running 1 on-run-start hook
08:10:24.206994 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-start-0
08:10:24.208909 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-start-0"
08:10:24.212261 [info ] [MainThread]: 1 of 1 START hook: learn_dbt.on-run-start.0..................................... [RUN]
08:10:24.212897 [debug] [MainThread]: Using snowflake connection "master"
08:10:24.213064 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
08:10:24.213207 [debug] [MainThread]: Opening a new connection, currently in state init
08:10:24.726036 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.51 seconds
08:10:24.727587 [info ] [MainThread]: 1 of 1 OK hook: learn_dbt.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.51s]
08:10:24.728072 [info ] [MainThread]: 
08:10:24.728431 [debug] [MainThread]: On master: Close
08:10:24.886888 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
08:10:24.887875 [info ] [MainThread]: 
08:10:24.892178 [debug] [Thread-1  ]: Began running node model.learn_dbt.playing_with_tests
08:10:24.892534 [info ] [Thread-1  ]: 1 of 1 START table model dbt_nigel.playing_with_tests........................... [RUN]
08:10:24.893025 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.playing_with_tests"
08:10:24.893184 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.playing_with_tests
08:10:24.893336 [debug] [Thread-1  ]: Compiling model.learn_dbt.playing_with_tests
08:10:24.896699 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.playing_with_tests"
08:10:24.897270 [debug] [Thread-1  ]: finished collecting timing info
08:10:24.897421 [debug] [Thread-1  ]: Began executing node model.learn_dbt.playing_with_tests
08:10:24.911852 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
08:10:24.911987 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */

        insert into dbt.audit (model, state, time) values ('playing_with_tests', 'starting model deployment', current_timestamp)
08:10:24.912088 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
08:10:25.770090 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.86 seconds
08:10:25.782500 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.playing_with_tests"
08:10:25.783902 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
08:10:25.784049 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */


      create or replace transient table analytics.dbt_nigel.playing_with_tests  as
      (WITH sample_customer AS (
select * 
from snowflake_sample_data.tpch_sf1.customer
)

select
  c_custkey,
  c_mktsegment
from sample_customer
      );
08:10:26.465134 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.68 seconds
08:10:26.469195 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
08:10:26.469431 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */

        insert into dbt.audit (model, state, time) values ('playing_with_tests', 'ending model deployment', current_timestamp)
08:10:26.903447 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.43 seconds
08:10:26.914326 [debug] [Thread-1  ]: finished collecting timing info
08:10:26.914547 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: Close
08:10:27.101161 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af77bd85-afac-495d-9177-756f6a8dd99b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1054efa60>]}
08:10:27.101854 [info ] [Thread-1  ]: 1 of 1 OK created table model dbt_nigel.playing_with_tests...................... [[32mSUCCESS 1[0m in 2.21s]
08:10:27.102297 [debug] [Thread-1  ]: Finished running node model.learn_dbt.playing_with_tests
08:10:27.103634 [debug] [MainThread]: Acquiring new snowflake connection "master"
08:10:27.103995 [info ] [MainThread]: 
08:10:27.104341 [info ] [MainThread]: Running 3 on-run-end hooks
08:10:27.104692 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-0
08:10:27.106481 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-0"
08:10:27.107505 [info ] [MainThread]: 1 of 3 START hook: learn_dbt.on-run-end.0....................................... [RUN]
08:10:27.108060 [debug] [MainThread]: Using snowflake connection "master"
08:10:27.108211 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
08:10:27.108347 [debug] [MainThread]: Opening a new connection, currently in state closed
08:10:27.585742 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.48 seconds
08:10:27.587212 [info ] [MainThread]: 1 of 3 OK hook: learn_dbt.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.48s]
08:10:27.587680 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-1
08:10:27.589607 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-1"
08:10:27.590642 [info ] [MainThread]: 2 of 3 START hook: learn_dbt.on-run-end.1....................................... [RUN]
08:10:27.591285 [debug] [MainThread]: Using snowflake connection "master"
08:10:27.591472 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
08:10:27.731317 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.14 seconds
08:10:27.733663 [info ] [MainThread]: 2 of 3 OK hook: learn_dbt.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.14s]
08:10:27.734210 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-2
08:10:27.736242 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-2"
08:10:27.737236 [info ] [MainThread]: 3 of 3 START hook: learn_dbt.on-run-end.2....................................... [RUN]
08:10:27.737798 [debug] [MainThread]: Using snowflake connection "master"
08:10:27.737956 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
08:10:27.836541 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.1 seconds
08:10:27.838423 [info ] [MainThread]: 3 of 3 OK hook: learn_dbt.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.10s]
08:10:27.838952 [info ] [MainThread]: 
08:10:27.839305 [debug] [MainThread]: On master: Close
08:10:28.005610 [info ] [MainThread]: 
08:10:28.006254 [info ] [MainThread]: Finished running 1 table model, 4 hooks in 6.49s.
08:10:28.006586 [debug] [MainThread]: Connection 'master' was properly closed.
08:10:28.006769 [debug] [MainThread]: Connection 'model.learn_dbt.playing_with_tests' was properly closed.
08:10:28.015328 [info ] [MainThread]: 
08:10:28.015657 [info ] [MainThread]: [32mCompleted successfully[0m
08:10:28.015952 [info ] [MainThread]: 
08:10:28.016184 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
08:10:28.016523 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103e1b310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1055ea370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1055e97c0>]}


============================== 2022-05-17 08:16:00.847690 | 9628e1f6-95b7-4985-a7fc-7918da246a54 ==============================
08:16:00.847690 [info ] [MainThread]: Running with dbt=1.0.1
08:16:00.848298 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['playing_with_tests'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
08:16:00.848441 [debug] [MainThread]: Tracking: tracking
08:16:00.848665 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107873a00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1078738e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107873f40>]}
08:16:00.898804 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
08:16:00.899058 [debug] [MainThread]: Partial parsing: added file: learn_dbt://macros/rename_segments.sql
08:16:00.899209 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/playing_with_tests.sql
08:16:00.899281 [debug] [MainThread]: Parsing macros/rename_segments.sql
08:16:00.906301 [debug] [MainThread]: 1603: static parser failed on example/playing_with_tests.sql
08:16:00.913551 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/playing_with_tests.sql
08:16:00.932245 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9628e1f6-95b7-4985-a7fc-7918da246a54', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b2e0d0>]}
08:16:00.937719 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9628e1f6-95b7-4985-a7fc-7918da246a54', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a9e0d0>]}
08:16:00.937881 [info ] [MainThread]: Found 7 models, 12 tests, 1 snapshot, 0 analyses, 181 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
08:16:00.938719 [info ] [MainThread]: 
08:16:00.939007 [debug] [MainThread]: Acquiring new snowflake connection "master"
08:16:00.939378 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
08:16:00.945305 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
08:16:00.945420 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
08:16:00.945487 [debug] [ThreadPool]: Opening a new connection, currently in state init
08:16:02.141117 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1.2 seconds
08:16:02.143836 [debug] [ThreadPool]: On list_analytics: Close
08:16:02.325903 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt_nigel"
08:16:02.334162 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt_nigel"
08:16:02.334429 [debug] [ThreadPool]: On list_analytics_dbt_nigel: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt_nigel"} */

    show terse objects in analytics.dbt_nigel
08:16:02.334601 [debug] [ThreadPool]: Opening a new connection, currently in state closed
08:16:02.852019 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 0.52 seconds
08:16:02.854856 [debug] [ThreadPool]: On list_analytics_dbt_nigel: Close
08:16:03.022144 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snaphots"
08:16:03.025128 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snaphots"
08:16:03.025347 [debug] [ThreadPool]: On list_analytics_snaphots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snaphots"} */

    show terse objects in analytics.snaphots
08:16:03.025510 [debug] [ThreadPool]: Opening a new connection, currently in state closed
08:16:03.819774 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.79 seconds
08:16:03.822488 [debug] [ThreadPool]: On list_analytics_snaphots: Close
08:16:03.990820 [info ] [MainThread]: 
08:16:03.991306 [info ] [MainThread]: Running 1 on-run-start hook
08:16:03.991581 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-start-0
08:16:03.992969 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-start-0"
08:16:03.994986 [info ] [MainThread]: 1 of 1 START hook: learn_dbt.on-run-start.0..................................... [RUN]
08:16:03.995498 [debug] [MainThread]: Using snowflake connection "master"
08:16:03.995635 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
08:16:03.995757 [debug] [MainThread]: Opening a new connection, currently in state init
08:16:04.498431 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.5 seconds
08:16:04.501194 [info ] [MainThread]: 1 of 1 OK hook: learn_dbt.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.51s]
08:16:04.501773 [info ] [MainThread]: 
08:16:04.502246 [debug] [MainThread]: On master: Close
08:16:04.673578 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
08:16:04.674255 [info ] [MainThread]: 
08:16:04.680198 [debug] [Thread-1  ]: Began running node model.learn_dbt.playing_with_tests
08:16:04.680645 [info ] [Thread-1  ]: 1 of 1 START table model dbt_nigel.playing_with_tests........................... [RUN]
08:16:04.681165 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.playing_with_tests"
08:16:04.681337 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.playing_with_tests
08:16:04.681506 [debug] [Thread-1  ]: Compiling model.learn_dbt.playing_with_tests
08:16:04.685406 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.playing_with_tests"
08:16:04.686129 [debug] [Thread-1  ]: finished collecting timing info
08:16:04.686321 [debug] [Thread-1  ]: Began executing node model.learn_dbt.playing_with_tests
08:16:04.701468 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
08:16:04.701630 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */

        insert into dbt.audit (model, state, time) values ('playing_with_tests', 'starting model deployment', current_timestamp)
08:16:04.701733 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
08:16:06.916995 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.22 seconds
08:16:06.926444 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.playing_with_tests"
08:16:06.927442 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
08:16:06.927568 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */


      create or replace transient table analytics.dbt_nigel.playing_with_tests  as
      (WITH sample_customer AS (
select * 
from snowflake_sample_data.tpch_sf1.customer
)

select
  c_custkey,
  c_mktsegment,
  
CASE
  WHEN  in ("BUILDING", "HOUSEHOLD", "FURNITURE")
    THEN "segment_1"
  ELSE "segment_2"
END
 mkt_segment_adjusted
from sample_customer
      );
08:16:07.031853 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a45290-3201-9ec3-0001-205200010142
08:16:07.032252 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 12 at position 8 unexpected 'in'.
syntax error line 12 at position 12 unexpected '"BUILDING"'.
syntax error line 13 at position 4 unexpected 'THEN'.
08:16:07.032567 [debug] [Thread-1  ]: finished collecting timing info
08:16:07.032768 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: Close
08:16:07.228435 [debug] [Thread-1  ]: Database Error in model playing_with_tests (models/example/playing_with_tests.sql)
  001003 (42000): SQL compilation error:
  syntax error line 12 at position 8 unexpected 'in'.
  syntax error line 12 at position 12 unexpected '"BUILDING"'.
  syntax error line 13 at position 4 unexpected 'THEN'.
  compiled SQL at target/run/learn_dbt/models/example/playing_with_tests.sql
08:16:07.229268 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9628e1f6-95b7-4985-a7fc-7918da246a54', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107dab3a0>]}
08:16:07.229842 [error] [Thread-1  ]: 1 of 1 ERROR creating table model dbt_nigel.playing_with_tests.................. [[31mERROR[0m in 2.55s]
08:16:07.230325 [debug] [Thread-1  ]: Finished running node model.learn_dbt.playing_with_tests
08:16:07.231685 [debug] [MainThread]: Acquiring new snowflake connection "master"
08:16:07.232040 [info ] [MainThread]: 
08:16:07.232386 [info ] [MainThread]: Running 3 on-run-end hooks
08:16:07.232718 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-0
08:16:07.234442 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-0"
08:16:07.237247 [info ] [MainThread]: 1 of 3 START hook: learn_dbt.on-run-end.0....................................... [RUN]
08:16:07.237900 [debug] [MainThread]: Using snowflake connection "master"
08:16:07.238065 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
08:16:07.238209 [debug] [MainThread]: Opening a new connection, currently in state closed
08:16:07.750436 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.51 seconds
08:16:07.752542 [info ] [MainThread]: 1 of 3 OK hook: learn_dbt.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.51s]
08:16:07.753075 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-1
08:16:07.754945 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-1"
08:16:07.756124 [info ] [MainThread]: 2 of 3 START hook: learn_dbt.on-run-end.1....................................... [RUN]
08:16:07.756726 [debug] [MainThread]: Using snowflake connection "master"
08:16:07.756893 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
08:16:07.920957 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.16 seconds
08:16:07.922521 [info ] [MainThread]: 2 of 3 OK hook: learn_dbt.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.17s]
08:16:07.923067 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-2
08:16:07.924859 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-2"
08:16:07.925455 [info ] [MainThread]: 3 of 3 START hook: learn_dbt.on-run-end.2....................................... [RUN]
08:16:07.925785 [debug] [MainThread]: Using snowflake connection "master"
08:16:07.925881 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
08:16:08.048409 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.12 seconds
08:16:08.050329 [info ] [MainThread]: 3 of 3 OK hook: learn_dbt.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.12s]
08:16:08.050647 [info ] [MainThread]: 
08:16:08.050912 [debug] [MainThread]: On master: Close
08:16:08.238008 [info ] [MainThread]: 
08:16:08.238894 [info ] [MainThread]: Finished running 1 table model, 4 hooks in 7.30s.
08:16:08.239236 [debug] [MainThread]: Connection 'master' was properly closed.
08:16:08.239421 [debug] [MainThread]: Connection 'model.learn_dbt.playing_with_tests' was properly closed.
08:16:08.246549 [info ] [MainThread]: 
08:16:08.246900 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
08:16:08.247351 [info ] [MainThread]: 
08:16:08.247818 [error] [MainThread]: [33mDatabase Error in model playing_with_tests (models/example/playing_with_tests.sql)[0m
08:16:08.248123 [error] [MainThread]:   001003 (42000): SQL compilation error:
08:16:08.248353 [error] [MainThread]:   syntax error line 12 at position 8 unexpected 'in'.
08:16:08.248571 [error] [MainThread]:   syntax error line 12 at position 12 unexpected '"BUILDING"'.
08:16:08.248761 [error] [MainThread]:   syntax error line 13 at position 4 unexpected 'THEN'.
08:16:08.248939 [error] [MainThread]:   compiled SQL at target/run/learn_dbt/models/example/playing_with_tests.sql
08:16:08.249129 [info ] [MainThread]: 
08:16:08.249316 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
08:16:08.249586 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d721f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d191c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d813a0>]}


============================== 2022-05-17 08:17:55.448386 | 2ba7999c-eb25-4e61-8898-c4fd06bc9902 ==============================
08:17:55.448386 [info ] [MainThread]: Running with dbt=1.0.1
08:17:55.448949 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['playing_with_tests'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
08:17:55.449096 [debug] [MainThread]: Tracking: tracking
08:17:55.449302 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10518b7f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10518bca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10518bd00>]}
08:17:55.498043 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
08:17:55.498392 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://macros/rename_segments.sql
08:17:55.498473 [debug] [MainThread]: Parsing macros/rename_segments.sql
08:17:55.505532 [debug] [MainThread]: 1603: static parser failed on example/playing_with_tests.sql
08:17:55.512647 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/playing_with_tests.sql
08:17:55.535748 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2ba7999c-eb25-4e61-8898-c4fd06bc9902', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1054900d0>]}
08:17:55.539621 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2ba7999c-eb25-4e61-8898-c4fd06bc9902', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10544a730>]}
08:17:55.539753 [info ] [MainThread]: Found 7 models, 12 tests, 1 snapshot, 0 analyses, 181 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
08:17:55.540445 [info ] [MainThread]: 
08:17:55.540641 [debug] [MainThread]: Acquiring new snowflake connection "master"
08:17:55.540957 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
08:17:55.546747 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
08:17:55.546849 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
08:17:55.546914 [debug] [ThreadPool]: Opening a new connection, currently in state init
08:17:56.370028 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 0.82 seconds
08:17:56.371119 [debug] [ThreadPool]: On list_analytics: Close
08:17:56.530575 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snaphots"
08:17:56.535521 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snaphots"
08:17:56.535637 [debug] [ThreadPool]: On list_analytics_snaphots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snaphots"} */

    show terse objects in analytics.snaphots
08:17:56.535716 [debug] [ThreadPool]: Opening a new connection, currently in state closed
08:17:57.031703 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.5 seconds
08:17:57.035321 [debug] [ThreadPool]: On list_analytics_snaphots: Close
08:17:57.218707 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt_nigel"
08:17:57.221369 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt_nigel"
08:17:57.221620 [debug] [ThreadPool]: On list_analytics_dbt_nigel: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt_nigel"} */

    show terse objects in analytics.dbt_nigel
08:17:57.221813 [debug] [ThreadPool]: Opening a new connection, currently in state closed
08:17:57.771217 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 0.55 seconds
08:17:57.774197 [debug] [ThreadPool]: On list_analytics_dbt_nigel: Close
08:17:57.939773 [info ] [MainThread]: 
08:17:57.940222 [info ] [MainThread]: Running 1 on-run-start hook
08:17:57.940593 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-start-0
08:17:57.942491 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-start-0"
08:17:57.944590 [info ] [MainThread]: 1 of 1 START hook: learn_dbt.on-run-start.0..................................... [RUN]
08:17:57.945164 [debug] [MainThread]: Using snowflake connection "master"
08:17:57.945322 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
08:17:57.945462 [debug] [MainThread]: Opening a new connection, currently in state init
08:17:58.728393 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.78 seconds
08:17:58.730091 [info ] [MainThread]: 1 of 1 OK hook: learn_dbt.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.79s]
08:17:58.730488 [info ] [MainThread]: 
08:17:58.730753 [debug] [MainThread]: On master: Close
08:17:58.901649 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
08:17:58.902229 [info ] [MainThread]: 
08:17:58.907886 [debug] [Thread-1  ]: Began running node model.learn_dbt.playing_with_tests
08:17:58.908287 [info ] [Thread-1  ]: 1 of 1 START table model dbt_nigel.playing_with_tests........................... [RUN]
08:17:58.908801 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.playing_with_tests"
08:17:58.908971 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.playing_with_tests
08:17:58.909142 [debug] [Thread-1  ]: Compiling model.learn_dbt.playing_with_tests
08:17:58.912938 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.playing_with_tests"
08:17:58.913590 [debug] [Thread-1  ]: finished collecting timing info
08:17:58.913743 [debug] [Thread-1  ]: Began executing node model.learn_dbt.playing_with_tests
08:17:58.928053 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
08:17:58.928186 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */

        insert into dbt.audit (model, state, time) values ('playing_with_tests', 'starting model deployment', current_timestamp)
08:17:58.928286 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
08:18:00.970942 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.04 seconds
08:18:00.985581 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.playing_with_tests"
08:18:00.986827 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
08:18:00.986983 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */


      create or replace transient table analytics.dbt_nigel.playing_with_tests  as
      (WITH sample_customer AS (
select * 
from snowflake_sample_data.tpch_sf1.customer
)

select
  c_custkey,
  c_mktsegment,
  CASE
  WHEN  in ('BUILDING', 'HOUSEHOLD', 'FURNITURE')
    THEN 'segment_1'
  ELSE 'segment_2'
END mkt_segment_adjusted
from sample_customer
      );
08:18:01.113229 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a45292-3201-9eaa-0000-00012052d13d
08:18:01.113614 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 11 at position 8 unexpected 'in'.
syntax error line 11 at position 12 unexpected ''BUILDING''.
syntax error line 12 at position 4 unexpected 'THEN'.
08:18:01.113990 [debug] [Thread-1  ]: finished collecting timing info
08:18:01.114222 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: Close
08:18:01.279891 [debug] [Thread-1  ]: Database Error in model playing_with_tests (models/example/playing_with_tests.sql)
  001003 (42000): SQL compilation error:
  syntax error line 11 at position 8 unexpected 'in'.
  syntax error line 11 at position 12 unexpected ''BUILDING''.
  syntax error line 12 at position 4 unexpected 'THEN'.
  compiled SQL at target/run/learn_dbt/models/example/playing_with_tests.sql
08:18:01.280848 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2ba7999c-eb25-4e61-8898-c4fd06bc9902', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1056b0460>]}
08:18:01.281601 [error] [Thread-1  ]: 1 of 1 ERROR creating table model dbt_nigel.playing_with_tests.................. [[31mERROR[0m in 2.37s]
08:18:01.282130 [debug] [Thread-1  ]: Finished running node model.learn_dbt.playing_with_tests
08:18:01.283738 [debug] [MainThread]: Acquiring new snowflake connection "master"
08:18:01.284118 [info ] [MainThread]: 
08:18:01.284464 [info ] [MainThread]: Running 3 on-run-end hooks
08:18:01.284817 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-0
08:18:01.286437 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-0"
08:18:01.287996 [info ] [MainThread]: 1 of 3 START hook: learn_dbt.on-run-end.0....................................... [RUN]
08:18:01.288557 [debug] [MainThread]: Using snowflake connection "master"
08:18:01.288711 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
08:18:01.288851 [debug] [MainThread]: Opening a new connection, currently in state closed
08:18:01.777099 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.49 seconds
08:18:01.779837 [info ] [MainThread]: 1 of 3 OK hook: learn_dbt.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.49s]
08:18:01.780541 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-1
08:18:01.782631 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-1"
08:18:01.783847 [info ] [MainThread]: 2 of 3 START hook: learn_dbt.on-run-end.1....................................... [RUN]
08:18:01.784559 [debug] [MainThread]: Using snowflake connection "master"
08:18:01.784725 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
08:18:01.929742 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.14 seconds
08:18:01.931889 [info ] [MainThread]: 2 of 3 OK hook: learn_dbt.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.15s]
08:18:01.932480 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-2
08:18:01.934558 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-2"
08:18:01.935248 [info ] [MainThread]: 3 of 3 START hook: learn_dbt.on-run-end.2....................................... [RUN]
08:18:01.935586 [debug] [MainThread]: Using snowflake connection "master"
08:18:01.935661 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
08:18:02.050338 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.11 seconds
08:18:02.051404 [info ] [MainThread]: 3 of 3 OK hook: learn_dbt.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.12s]
08:18:02.051680 [info ] [MainThread]: 
08:18:02.051905 [debug] [MainThread]: On master: Close
08:18:02.206570 [info ] [MainThread]: 
08:18:02.207535 [info ] [MainThread]: Finished running 1 table model, 4 hooks in 6.67s.
08:18:02.208089 [debug] [MainThread]: Connection 'master' was properly closed.
08:18:02.208270 [debug] [MainThread]: Connection 'model.learn_dbt.playing_with_tests' was properly closed.
08:18:02.216301 [info ] [MainThread]: 
08:18:02.216726 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
08:18:02.217015 [info ] [MainThread]: 
08:18:02.217282 [error] [MainThread]: [33mDatabase Error in model playing_with_tests (models/example/playing_with_tests.sql)[0m
08:18:02.217511 [error] [MainThread]:   001003 (42000): SQL compilation error:
08:18:02.217697 [error] [MainThread]:   syntax error line 11 at position 8 unexpected 'in'.
08:18:02.217876 [error] [MainThread]:   syntax error line 11 at position 12 unexpected ''BUILDING''.
08:18:02.218055 [error] [MainThread]:   syntax error line 12 at position 4 unexpected 'THEN'.
08:18:02.218238 [error] [MainThread]:   compiled SQL at target/run/learn_dbt/models/example/playing_with_tests.sql
08:18:02.218421 [info ] [MainThread]: 
08:18:02.218618 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
08:18:02.218899 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107770490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105709400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077959d0>]}


============================== 2022-05-17 08:20:11.091866 | e8347cc6-c714-4398-85a0-f3c9f61a6482 ==============================
08:20:11.091866 [info ] [MainThread]: Running with dbt=1.0.1
08:20:11.092351 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['playing_with_tests'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
08:20:11.092499 [debug] [MainThread]: Tracking: tracking
08:20:11.092700 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10667fe80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10667f4f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10667f9d0>]}
08:20:11.139119 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
08:20:11.139456 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://macros/rename_segments.sql
08:20:11.139537 [debug] [MainThread]: Parsing macros/rename_segments.sql
08:20:11.145825 [debug] [MainThread]: 1603: static parser failed on example/playing_with_tests.sql
08:20:11.152930 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/playing_with_tests.sql
08:20:11.176511 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e8347cc6-c714-4398-85a0-f3c9f61a6482', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10685dac0>]}
08:20:11.180384 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e8347cc6-c714-4398-85a0-f3c9f61a6482', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106815df0>]}
08:20:11.180524 [info ] [MainThread]: Found 7 models, 12 tests, 1 snapshot, 0 analyses, 181 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
08:20:11.181247 [info ] [MainThread]: 
08:20:11.181447 [debug] [MainThread]: Acquiring new snowflake connection "master"
08:20:11.181768 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
08:20:11.187487 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
08:20:11.187593 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
08:20:11.187658 [debug] [ThreadPool]: Opening a new connection, currently in state init
08:20:12.078075 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 0.89 seconds
08:20:12.082180 [debug] [ThreadPool]: On list_analytics: Close
08:20:12.280839 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt_nigel"
08:20:12.289707 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt_nigel"
08:20:12.289936 [debug] [ThreadPool]: On list_analytics_dbt_nigel: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt_nigel"} */

    show terse objects in analytics.dbt_nigel
08:20:12.290098 [debug] [ThreadPool]: Opening a new connection, currently in state closed
08:20:12.792349 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 0.5 seconds
08:20:12.794872 [debug] [ThreadPool]: On list_analytics_dbt_nigel: Close
08:20:12.960720 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snaphots"
08:20:12.962624 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snaphots"
08:20:12.962770 [debug] [ThreadPool]: On list_analytics_snaphots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snaphots"} */

    show terse objects in analytics.snaphots
08:20:12.962874 [debug] [ThreadPool]: Opening a new connection, currently in state closed
08:20:13.667721 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.7 seconds
08:20:13.670300 [debug] [ThreadPool]: On list_analytics_snaphots: Close
08:20:13.847746 [info ] [MainThread]: 
08:20:13.848228 [info ] [MainThread]: Running 1 on-run-start hook
08:20:13.848621 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-start-0
08:20:13.850656 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-start-0"
08:20:13.852842 [info ] [MainThread]: 1 of 1 START hook: learn_dbt.on-run-start.0..................................... [RUN]
08:20:13.853419 [debug] [MainThread]: Using snowflake connection "master"
08:20:13.853581 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
08:20:13.853719 [debug] [MainThread]: Opening a new connection, currently in state init
08:20:14.369347 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.52 seconds
08:20:14.370453 [info ] [MainThread]: 1 of 1 OK hook: learn_dbt.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.52s]
08:20:14.370766 [info ] [MainThread]: 
08:20:14.371025 [debug] [MainThread]: On master: Close
08:20:14.531782 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
08:20:14.532704 [info ] [MainThread]: 
08:20:14.538566 [debug] [Thread-1  ]: Began running node model.learn_dbt.playing_with_tests
08:20:14.538942 [info ] [Thread-1  ]: 1 of 1 START table model dbt_nigel.playing_with_tests........................... [RUN]
08:20:14.539443 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.playing_with_tests"
08:20:14.539610 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.playing_with_tests
08:20:14.539771 [debug] [Thread-1  ]: Compiling model.learn_dbt.playing_with_tests
08:20:14.543608 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.playing_with_tests"
08:20:14.544254 [debug] [Thread-1  ]: finished collecting timing info
08:20:14.544413 [debug] [Thread-1  ]: Began executing node model.learn_dbt.playing_with_tests
08:20:14.559230 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
08:20:14.559371 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */

        insert into dbt.audit (model, state, time) values ('playing_with_tests', 'starting model deployment', current_timestamp)
08:20:14.559471 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
08:20:15.945632 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.39 seconds
08:20:15.960083 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.playing_with_tests"
08:20:15.961457 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
08:20:15.961619 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */


      create or replace transient table analytics.dbt_nigel.playing_with_tests  as
      (WITH sample_customer AS (
select * 
from snowflake_sample_data.tpch_sf1.customer
)

select
  c_custkey,
  c_mktsegment,
  CASE
    WHEN  in ('BUILDING', 'HOUSEHOLD', 'FURNITURE')
      THEN 'segment_1'
    ELSE 'segment_2'
  END mkt_segment_adjusted
from sample_customer
      );
08:20:16.071544 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a45294-3201-9ec3-0001-20520001016a
08:20:16.071771 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 11 at position 10 unexpected 'in'.
syntax error line 11 at position 14 unexpected ''BUILDING''.
syntax error line 12 at position 6 unexpected 'THEN'.
08:20:16.072006 [debug] [Thread-1  ]: finished collecting timing info
08:20:16.072147 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: Close
08:20:16.233916 [debug] [Thread-1  ]: Database Error in model playing_with_tests (models/example/playing_with_tests.sql)
  001003 (42000): SQL compilation error:
  syntax error line 11 at position 10 unexpected 'in'.
  syntax error line 11 at position 14 unexpected ''BUILDING''.
  syntax error line 12 at position 6 unexpected 'THEN'.
  compiled SQL at target/run/learn_dbt/models/example/playing_with_tests.sql
08:20:16.234448 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e8347cc6-c714-4398-85a0-f3c9f61a6482', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106aab370>]}
08:20:16.234940 [error] [Thread-1  ]: 1 of 1 ERROR creating table model dbt_nigel.playing_with_tests.................. [[31mERROR[0m in 1.70s]
08:20:16.235379 [debug] [Thread-1  ]: Finished running node model.learn_dbt.playing_with_tests
08:20:16.236851 [debug] [MainThread]: Acquiring new snowflake connection "master"
08:20:16.237183 [info ] [MainThread]: 
08:20:16.237468 [info ] [MainThread]: Running 3 on-run-end hooks
08:20:16.237749 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-0
08:20:16.239346 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-0"
08:20:16.240992 [info ] [MainThread]: 1 of 3 START hook: learn_dbt.on-run-end.0....................................... [RUN]
08:20:16.241565 [debug] [MainThread]: Using snowflake connection "master"
08:20:16.241730 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
08:20:16.241871 [debug] [MainThread]: Opening a new connection, currently in state closed
08:20:16.771646 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.53 seconds
08:20:16.774095 [info ] [MainThread]: 1 of 3 OK hook: learn_dbt.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.53s]
08:20:16.774693 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-1
08:20:16.777018 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-1"
08:20:16.778336 [info ] [MainThread]: 2 of 3 START hook: learn_dbt.on-run-end.1....................................... [RUN]
08:20:16.779060 [debug] [MainThread]: Using snowflake connection "master"
08:20:16.779253 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
08:20:16.913977 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.13 seconds
08:20:16.916550 [info ] [MainThread]: 2 of 3 OK hook: learn_dbt.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.14s]
08:20:16.917055 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-2
08:20:16.919067 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-2"
08:20:16.920163 [info ] [MainThread]: 3 of 3 START hook: learn_dbt.on-run-end.2....................................... [RUN]
08:20:16.920730 [debug] [MainThread]: Using snowflake connection "master"
08:20:16.920897 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
08:20:17.030268 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.11 seconds
08:20:17.032730 [info ] [MainThread]: 3 of 3 OK hook: learn_dbt.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.11s]
08:20:17.033329 [info ] [MainThread]: 
08:20:17.033676 [debug] [MainThread]: On master: Close
08:20:17.188547 [info ] [MainThread]: 
08:20:17.189168 [info ] [MainThread]: Finished running 1 table model, 4 hooks in 6.01s.
08:20:17.189496 [debug] [MainThread]: Connection 'master' was properly closed.
08:20:17.189690 [debug] [MainThread]: Connection 'model.learn_dbt.playing_with_tests' was properly closed.
08:20:17.197107 [info ] [MainThread]: 
08:20:17.197414 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
08:20:17.197689 [info ] [MainThread]: 
08:20:17.197916 [error] [MainThread]: [33mDatabase Error in model playing_with_tests (models/example/playing_with_tests.sql)[0m
08:20:17.198145 [error] [MainThread]:   001003 (42000): SQL compilation error:
08:20:17.198356 [error] [MainThread]:   syntax error line 11 at position 10 unexpected 'in'.
08:20:17.198564 [error] [MainThread]:   syntax error line 11 at position 14 unexpected ''BUILDING''.
08:20:17.198771 [error] [MainThread]:   syntax error line 12 at position 6 unexpected 'THEN'.
08:20:17.198977 [error] [MainThread]:   compiled SQL at target/run/learn_dbt/models/example/playing_with_tests.sql
08:20:17.199194 [info ] [MainThread]: 
08:20:17.199385 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
08:20:17.199676 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106a87730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ad1f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106adecd0>]}


============================== 2022-05-17 08:30:47.960523 | fd18a2cc-ae56-4278-988b-2e998e22a0a3 ==============================
08:30:47.960523 [info ] [MainThread]: Running with dbt=1.0.1
08:30:47.961127 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['playing_with_tests'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
08:30:47.961260 [debug] [MainThread]: Tracking: tracking
08:30:47.961482 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109d1fe20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109d1f8e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109d1fa00>]}
08:30:48.006972 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
08:30:48.007292 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://macros/rename_segments.sql
08:30:48.007370 [debug] [MainThread]: Parsing macros/rename_segments.sql
08:30:48.013304 [debug] [MainThread]: 1603: static parser failed on example/playing_with_tests.sql
08:30:48.020215 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/playing_with_tests.sql
08:30:48.043271 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'fd18a2cc-ae56-4278-988b-2e998e22a0a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109efbf40>]}
08:30:48.047105 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'fd18a2cc-ae56-4278-988b-2e998e22a0a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109eb59a0>]}
08:30:48.047234 [info ] [MainThread]: Found 7 models, 12 tests, 1 snapshot, 0 analyses, 181 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
08:30:48.047932 [info ] [MainThread]: 
08:30:48.048130 [debug] [MainThread]: Acquiring new snowflake connection "master"
08:30:48.048471 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
08:30:48.054503 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
08:30:48.054639 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
08:30:48.054708 [debug] [ThreadPool]: Opening a new connection, currently in state init
08:30:48.911636 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 0.86 seconds
08:30:48.914162 [debug] [ThreadPool]: On list_analytics: Close
08:30:49.173925 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt_nigel"
08:30:49.183414 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt_nigel"
08:30:49.183680 [debug] [ThreadPool]: On list_analytics_dbt_nigel: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt_nigel"} */

    show terse objects in analytics.dbt_nigel
08:30:49.183843 [debug] [ThreadPool]: Opening a new connection, currently in state closed
08:30:49.677601 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 0.49 seconds
08:30:49.682647 [debug] [ThreadPool]: On list_analytics_dbt_nigel: Close
08:30:49.854928 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snaphots"
08:30:49.857490 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snaphots"
08:30:49.857712 [debug] [ThreadPool]: On list_analytics_snaphots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snaphots"} */

    show terse objects in analytics.snaphots
08:30:49.857873 [debug] [ThreadPool]: Opening a new connection, currently in state closed
08:30:50.633747 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.78 seconds
08:30:50.637838 [debug] [ThreadPool]: On list_analytics_snaphots: Close
08:30:50.819955 [info ] [MainThread]: 
08:30:50.820337 [info ] [MainThread]: Running 1 on-run-start hook
08:30:50.820554 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-start-0
08:30:50.821668 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-start-0"
08:30:50.822945 [info ] [MainThread]: 1 of 1 START hook: learn_dbt.on-run-start.0..................................... [RUN]
08:30:50.823378 [debug] [MainThread]: Using snowflake connection "master"
08:30:50.823487 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
08:30:50.823587 [debug] [MainThread]: Opening a new connection, currently in state init
08:30:51.501955 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.68 seconds
08:30:51.503903 [info ] [MainThread]: 1 of 1 OK hook: learn_dbt.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.68s]
08:30:51.504391 [info ] [MainThread]: 
08:30:51.504753 [debug] [MainThread]: On master: Close
08:30:51.814624 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
08:30:51.815314 [info ] [MainThread]: 
08:30:51.821296 [debug] [Thread-1  ]: Began running node model.learn_dbt.playing_with_tests
08:30:51.821709 [info ] [Thread-1  ]: 1 of 1 START table model dbt_nigel.playing_with_tests........................... [RUN]
08:30:51.822221 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.playing_with_tests"
08:30:51.822396 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.playing_with_tests
08:30:51.822560 [debug] [Thread-1  ]: Compiling model.learn_dbt.playing_with_tests
08:30:51.826405 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.playing_with_tests"
08:30:51.827042 [debug] [Thread-1  ]: finished collecting timing info
08:30:51.827198 [debug] [Thread-1  ]: Began executing node model.learn_dbt.playing_with_tests
08:30:51.841743 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
08:30:51.841888 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */

        insert into dbt.audit (model, state, time) values ('playing_with_tests', 'starting model deployment', current_timestamp)
08:30:51.841993 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
08:30:53.469831 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.63 seconds
08:30:53.483295 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.playing_with_tests"
08:30:53.484653 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
08:30:53.484814 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */


      create or replace transient table analytics.dbt_nigel.playing_with_tests  as
      (WITH sample_customer AS (
select * 
from snowflake_sample_data.tpch_sf1.customer
)

select
  c_custkey,
  c_mktsegment,
  
    CASE
      WHEN  IN ('BUILDING', 'HOUSEHOLD', 'FURMITURE')
        THEN  'segment_1'
        ELSE 'segment_2'
    END
 mkt_segment_adjusted
from sample_customer
      );
08:30:53.633137 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a4529e-3201-9ec3-0001-205200010182
08:30:53.633516 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 12 at position 12 unexpected 'IN'.
syntax error line 12 at position 16 unexpected ''BUILDING''.
syntax error line 13 at position 8 unexpected 'THEN'.
08:30:53.633837 [debug] [Thread-1  ]: finished collecting timing info
08:30:53.634028 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: Close
08:30:53.817319 [debug] [Thread-1  ]: Database Error in model playing_with_tests (models/example/playing_with_tests.sql)
  001003 (42000): SQL compilation error:
  syntax error line 12 at position 12 unexpected 'IN'.
  syntax error line 12 at position 16 unexpected ''BUILDING''.
  syntax error line 13 at position 8 unexpected 'THEN'.
  compiled SQL at target/run/learn_dbt/models/example/playing_with_tests.sql
08:30:53.818574 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd18a2cc-ae56-4278-988b-2e998e22a0a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a95dd30>]}
08:30:53.819375 [error] [Thread-1  ]: 1 of 1 ERROR creating table model dbt_nigel.playing_with_tests.................. [[31mERROR[0m in 2.00s]
08:30:53.819923 [debug] [Thread-1  ]: Finished running node model.learn_dbt.playing_with_tests
08:30:53.821548 [debug] [MainThread]: Acquiring new snowflake connection "master"
08:30:53.821844 [info ] [MainThread]: 
08:30:53.822128 [info ] [MainThread]: Running 3 on-run-end hooks
08:30:53.822421 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-0
08:30:53.824016 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-0"
08:30:53.825777 [info ] [MainThread]: 1 of 3 START hook: learn_dbt.on-run-end.0....................................... [RUN]
08:30:53.826384 [debug] [MainThread]: Using snowflake connection "master"
08:30:53.826553 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
08:30:53.826701 [debug] [MainThread]: Opening a new connection, currently in state closed
08:30:54.318735 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.49 seconds
08:30:54.321840 [info ] [MainThread]: 1 of 3 OK hook: learn_dbt.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.50s]
08:30:54.322552 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-1
08:30:54.324690 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-1"
08:30:54.325853 [info ] [MainThread]: 2 of 3 START hook: learn_dbt.on-run-end.1....................................... [RUN]
08:30:54.326429 [debug] [MainThread]: Using snowflake connection "master"
08:30:54.326593 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
08:30:54.506829 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.18 seconds
08:30:54.508390 [info ] [MainThread]: 2 of 3 OK hook: learn_dbt.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.18s]
08:30:54.508866 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-2
08:30:54.511063 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-2"
08:30:54.512125 [info ] [MainThread]: 3 of 3 START hook: learn_dbt.on-run-end.2....................................... [RUN]
08:30:54.512660 [debug] [MainThread]: Using snowflake connection "master"
08:30:54.512818 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
08:30:54.629407 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.12 seconds
08:30:54.632853 [info ] [MainThread]: 3 of 3 OK hook: learn_dbt.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.12s]
08:30:54.633399 [info ] [MainThread]: 
08:30:54.633760 [debug] [MainThread]: On master: Close
08:30:54.802775 [info ] [MainThread]: 
08:30:54.803337 [info ] [MainThread]: Finished running 1 table model, 4 hooks in 6.75s.
08:30:54.803663 [debug] [MainThread]: Connection 'master' was properly closed.
08:30:54.803832 [debug] [MainThread]: Connection 'model.learn_dbt.playing_with_tests' was properly closed.
08:30:54.811289 [info ] [MainThread]: 
08:30:54.811589 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
08:30:54.811861 [info ] [MainThread]: 
08:30:54.812127 [error] [MainThread]: [33mDatabase Error in model playing_with_tests (models/example/playing_with_tests.sql)[0m
08:30:54.812441 [error] [MainThread]:   001003 (42000): SQL compilation error:
08:30:54.812671 [error] [MainThread]:   syntax error line 12 at position 12 unexpected 'IN'.
08:30:54.812889 [error] [MainThread]:   syntax error line 12 at position 16 unexpected ''BUILDING''.
08:30:54.813081 [error] [MainThread]:   syntax error line 13 at position 8 unexpected 'THEN'.
08:30:54.813257 [error] [MainThread]:   compiled SQL at target/run/learn_dbt/models/example/playing_with_tests.sql
08:30:54.813449 [info ] [MainThread]: 
08:30:54.813637 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
08:30:54.813942 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a93e370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a964b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a9414c0>]}


============================== 2022-05-17 08:39:49.100892 | 293f4366-1967-4911-bd4c-6307cb06a73c ==============================
08:39:49.100892 [info ] [MainThread]: Running with dbt=1.0.1
08:39:49.101401 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['playing_with_tests'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
08:39:49.101528 [debug] [MainThread]: Tracking: tracking
08:39:49.101738 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111c7f730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111c7f640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111c7f9d0>]}
08:39:49.153585 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
08:39:49.153903 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://macros/rename_segments.sql
08:39:49.153983 [debug] [MainThread]: Parsing macros/rename_segments.sql
08:39:49.159900 [debug] [MainThread]: 1603: static parser failed on example/playing_with_tests.sql
08:39:49.166896 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/playing_with_tests.sql
08:39:49.192338 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '293f4366-1967-4911-bd4c-6307cb06a73c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111e75f40>]}
08:39:49.196315 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '293f4366-1967-4911-bd4c-6307cb06a73c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111e366a0>]}
08:39:49.196450 [info ] [MainThread]: Found 7 models, 12 tests, 1 snapshot, 0 analyses, 181 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
08:39:49.197141 [info ] [MainThread]: 
08:39:49.197341 [debug] [MainThread]: Acquiring new snowflake connection "master"
08:39:49.197680 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
08:39:49.203330 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
08:39:49.203431 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
08:39:49.203493 [debug] [ThreadPool]: Opening a new connection, currently in state init
08:39:50.022449 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 0.82 seconds
08:39:50.027212 [debug] [ThreadPool]: On list_analytics: Close
08:39:50.195002 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snaphots"
08:39:50.203474 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snaphots"
08:39:50.203714 [debug] [ThreadPool]: On list_analytics_snaphots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snaphots"} */

    show terse objects in analytics.snaphots
08:39:50.203881 [debug] [ThreadPool]: Opening a new connection, currently in state closed
08:39:50.865267 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.66 seconds
08:39:50.871015 [debug] [ThreadPool]: On list_analytics_snaphots: Close
08:39:51.040284 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt_nigel"
08:39:51.043090 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt_nigel"
08:39:51.043377 [debug] [ThreadPool]: On list_analytics_dbt_nigel: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt_nigel"} */

    show terse objects in analytics.dbt_nigel
08:39:51.043578 [debug] [ThreadPool]: Opening a new connection, currently in state closed
08:39:51.719490 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 0.68 seconds
08:39:51.723337 [debug] [ThreadPool]: On list_analytics_dbt_nigel: Close
08:39:51.879436 [info ] [MainThread]: 
08:39:51.879893 [info ] [MainThread]: Running 1 on-run-start hook
08:39:51.880259 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-start-0
08:39:51.882226 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-start-0"
08:39:51.885653 [info ] [MainThread]: 1 of 1 START hook: learn_dbt.on-run-start.0..................................... [RUN]
08:39:51.886274 [debug] [MainThread]: Using snowflake connection "master"
08:39:51.886430 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
08:39:51.886569 [debug] [MainThread]: Opening a new connection, currently in state init
08:39:52.450266 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.56 seconds
08:39:52.452778 [info ] [MainThread]: 1 of 1 OK hook: learn_dbt.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.57s]
08:39:52.453330 [info ] [MainThread]: 
08:39:52.453602 [debug] [MainThread]: On master: Close
08:39:52.628452 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
08:39:52.629097 [info ] [MainThread]: 
08:39:52.635545 [debug] [Thread-1  ]: Began running node model.learn_dbt.playing_with_tests
08:39:52.635924 [info ] [Thread-1  ]: 1 of 1 START table model dbt_nigel.playing_with_tests........................... [RUN]
08:39:52.636451 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.playing_with_tests"
08:39:52.636623 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.playing_with_tests
08:39:52.636792 [debug] [Thread-1  ]: Compiling model.learn_dbt.playing_with_tests
08:39:52.640649 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.playing_with_tests"
08:39:52.641460 [debug] [Thread-1  ]: finished collecting timing info
08:39:52.641619 [debug] [Thread-1  ]: Began executing node model.learn_dbt.playing_with_tests
08:39:52.655944 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
08:39:52.656078 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */

        insert into dbt.audit (model, state, time) values ('playing_with_tests', 'starting model deployment', current_timestamp)
08:39:52.656178 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
08:39:54.035801 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.38 seconds
08:39:54.050397 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.playing_with_tests"
08:39:54.051765 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
08:39:54.051924 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */


      create or replace transient table analytics.dbt_nigel.playing_with_tests  as
      (WITH sample_customer AS (
select * 
from snowflake_sample_data.tpch_sf1.customer
)

select
  c_custkey,
  c_mktsegment,
  
  CASE
    WHEN  in ('BUILDING', 'HOUSEHOLD', 'FURNITURE')
      THEN 'segment_1'
    ELSE 'segment_2'
  END
 mkt_segment_adjusted
from sample_customer
      );
08:39:54.231757 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a452a7-3201-9ec3-0001-205200010196
08:39:54.232013 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 12 at position 10 unexpected 'in'.
syntax error line 12 at position 14 unexpected ''BUILDING''.
syntax error line 13 at position 6 unexpected 'THEN'.
08:39:54.232315 [debug] [Thread-1  ]: finished collecting timing info
08:39:54.232498 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: Close
08:39:54.514905 [debug] [Thread-1  ]: Database Error in model playing_with_tests (models/example/playing_with_tests.sql)
  001003 (42000): SQL compilation error:
  syntax error line 12 at position 10 unexpected 'in'.
  syntax error line 12 at position 14 unexpected ''BUILDING''.
  syntax error line 13 at position 6 unexpected 'THEN'.
  compiled SQL at target/run/learn_dbt/models/example/playing_with_tests.sql
08:39:54.515452 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '293f4366-1967-4911-bd4c-6307cb06a73c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112b05cd0>]}
08:39:54.515934 [error] [Thread-1  ]: 1 of 1 ERROR creating table model dbt_nigel.playing_with_tests.................. [[31mERROR[0m in 1.88s]
08:39:54.516373 [debug] [Thread-1  ]: Finished running node model.learn_dbt.playing_with_tests
08:39:54.517710 [debug] [MainThread]: Acquiring new snowflake connection "master"
08:39:54.518061 [info ] [MainThread]: 
08:39:54.518395 [info ] [MainThread]: Running 3 on-run-end hooks
08:39:54.518732 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-0
08:39:54.519962 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-0"
08:39:54.521889 [info ] [MainThread]: 1 of 3 START hook: learn_dbt.on-run-end.0....................................... [RUN]
08:39:54.522248 [debug] [MainThread]: Using snowflake connection "master"
08:39:54.522342 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
08:39:54.522427 [debug] [MainThread]: Opening a new connection, currently in state closed
08:39:54.997687 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.48 seconds
08:39:55.007928 [info ] [MainThread]: 1 of 3 OK hook: learn_dbt.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.49s]
08:39:55.009148 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-1
08:39:55.010142 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-1"
08:39:55.010763 [info ] [MainThread]: 2 of 3 START hook: learn_dbt.on-run-end.1....................................... [RUN]
08:39:55.011087 [debug] [MainThread]: Using snowflake connection "master"
08:39:55.011175 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
08:39:55.152923 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.14 seconds
08:39:55.154242 [info ] [MainThread]: 2 of 3 OK hook: learn_dbt.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.14s]
08:39:55.154640 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-2
08:39:55.156683 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-2"
08:39:55.157663 [info ] [MainThread]: 3 of 3 START hook: learn_dbt.on-run-end.2....................................... [RUN]
08:39:55.158237 [debug] [MainThread]: Using snowflake connection "master"
08:39:55.158400 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
08:39:55.353499 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.19 seconds
08:39:55.355835 [info ] [MainThread]: 3 of 3 OK hook: learn_dbt.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.20s]
08:39:55.356391 [info ] [MainThread]: 
08:39:55.356766 [debug] [MainThread]: On master: Close
08:39:55.603315 [info ] [MainThread]: 
08:39:55.604036 [info ] [MainThread]: Finished running 1 table model, 4 hooks in 6.41s.
08:39:55.604370 [debug] [MainThread]: Connection 'master' was properly closed.
08:39:55.604550 [debug] [MainThread]: Connection 'model.learn_dbt.playing_with_tests' was properly closed.
08:39:55.612762 [info ] [MainThread]: 
08:39:55.613100 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
08:39:55.613397 [info ] [MainThread]: 
08:39:55.613637 [error] [MainThread]: [33mDatabase Error in model playing_with_tests (models/example/playing_with_tests.sql)[0m
08:39:55.613871 [error] [MainThread]:   001003 (42000): SQL compilation error:
08:39:55.614094 [error] [MainThread]:   syntax error line 12 at position 10 unexpected 'in'.
08:39:55.614317 [error] [MainThread]:   syntax error line 12 at position 14 unexpected ''BUILDING''.
08:39:55.614533 [error] [MainThread]:   syntax error line 13 at position 6 unexpected 'THEN'.
08:39:55.614731 [error] [MainThread]:   compiled SQL at target/run/learn_dbt/models/example/playing_with_tests.sql
08:39:55.614917 [info ] [MainThread]: 
08:39:55.615102 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
08:39:55.615396 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111e75b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1129d9730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112b22fa0>]}


============================== 2022-05-17 08:47:34.362812 | f37d18f7-6950-4499-8581-e9b681ab5540 ==============================
08:47:34.362812 [info ] [MainThread]: Running with dbt=1.0.1
08:47:34.363358 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['playing_with_tests'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
08:47:34.363481 [debug] [MainThread]: Tracking: tracking
08:47:34.363691 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c3f370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c3fbe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c3f9d0>]}
08:47:34.410351 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
08:47:34.410664 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://macros/rename_segments.sql
08:47:34.410741 [debug] [MainThread]: Parsing macros/rename_segments.sql
08:47:34.416899 [debug] [MainThread]: 1603: static parser failed on example/playing_with_tests.sql
08:47:34.423938 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/playing_with_tests.sql
08:47:34.447079 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f37d18f7-6950-4499-8581-e9b681ab5540', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e1a0d0>]}
08:47:34.450979 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f37d18f7-6950-4499-8581-e9b681ab5540', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106dc9040>]}
08:47:34.451109 [info ] [MainThread]: Found 7 models, 12 tests, 1 snapshot, 0 analyses, 181 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
08:47:34.451793 [info ] [MainThread]: 
08:47:34.451993 [debug] [MainThread]: Acquiring new snowflake connection "master"
08:47:34.452312 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
08:47:34.458152 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
08:47:34.458266 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
08:47:34.458330 [debug] [ThreadPool]: Opening a new connection, currently in state init
08:47:35.268201 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 0.81 seconds
08:47:35.270965 [debug] [ThreadPool]: On list_analytics: Close
08:47:35.438647 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snaphots"
08:47:35.446896 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snaphots"
08:47:35.447120 [debug] [ThreadPool]: On list_analytics_snaphots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snaphots"} */

    show terse objects in analytics.snaphots
08:47:35.447255 [debug] [ThreadPool]: Opening a new connection, currently in state closed
08:47:36.107940 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.66 seconds
08:47:36.110081 [debug] [ThreadPool]: On list_analytics_snaphots: Close
08:47:36.254727 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt_nigel"
08:47:36.257211 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt_nigel"
08:47:36.257447 [debug] [ThreadPool]: On list_analytics_dbt_nigel: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt_nigel"} */

    show terse objects in analytics.dbt_nigel
08:47:36.257634 [debug] [ThreadPool]: Opening a new connection, currently in state closed
08:47:36.931146 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 0.67 seconds
08:47:36.933681 [debug] [ThreadPool]: On list_analytics_dbt_nigel: Close
08:47:37.108732 [info ] [MainThread]: 
08:47:37.109154 [info ] [MainThread]: Running 1 on-run-start hook
08:47:37.109391 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-start-0
08:47:37.110685 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-start-0"
08:47:37.112556 [info ] [MainThread]: 1 of 1 START hook: learn_dbt.on-run-start.0..................................... [RUN]
08:47:37.113171 [debug] [MainThread]: Using snowflake connection "master"
08:47:37.113332 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
08:47:37.113475 [debug] [MainThread]: Opening a new connection, currently in state init
08:47:37.627558 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.51 seconds
08:47:37.628901 [info ] [MainThread]: 1 of 1 OK hook: learn_dbt.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.52s]
08:47:37.629325 [info ] [MainThread]: 
08:47:37.629688 [debug] [MainThread]: On master: Close
08:47:37.793238 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
08:47:37.793809 [info ] [MainThread]: 
08:47:37.799102 [debug] [Thread-1  ]: Began running node model.learn_dbt.playing_with_tests
08:47:37.799507 [info ] [Thread-1  ]: 1 of 1 START table model dbt_nigel.playing_with_tests........................... [RUN]
08:47:37.800065 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.playing_with_tests"
08:47:37.800268 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.playing_with_tests
08:47:37.800451 [debug] [Thread-1  ]: Compiling model.learn_dbt.playing_with_tests
08:47:37.804112 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.playing_with_tests"
08:47:37.804740 [debug] [Thread-1  ]: finished collecting timing info
08:47:37.804915 [debug] [Thread-1  ]: Began executing node model.learn_dbt.playing_with_tests
08:47:37.819949 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
08:47:37.820103 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */

        insert into dbt.audit (model, state, time) values ('playing_with_tests', 'starting model deployment', current_timestamp)
08:47:37.820213 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
08:47:39.122169 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.3 seconds
08:47:39.134111 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.playing_with_tests"
08:47:39.135634 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
08:47:39.135802 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */


      create or replace transient table analytics.dbt_nigel.playing_with_tests  as
      (WITH sample_customer AS (
select * 
from snowflake_sample_data.tpch_sf1.customer
)

select
  c_custkey,
  c_mktsegment,
  
  CASE
    WHEN '' in ('BUILDING', 'HOUSEHOLD', 'FURNITURE')
      THEN 'segment_1'
    ELSE 'segment_2'
  END
 mkt_segment_adjusted
from sample_customer
      );
08:47:40.222719 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.09 seconds
08:47:40.227560 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
08:47:40.227836 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */

        insert into dbt.audit (model, state, time) values ('playing_with_tests', 'ending model deployment', current_timestamp)
08:47:40.758426 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.53 seconds
08:47:40.771907 [debug] [Thread-1  ]: finished collecting timing info
08:47:40.772210 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: Close
08:47:40.923363 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f37d18f7-6950-4499-8581-e9b681ab5540', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107065af0>]}
08:47:40.924515 [info ] [Thread-1  ]: 1 of 1 OK created table model dbt_nigel.playing_with_tests...................... [[32mSUCCESS 1[0m in 3.12s]
08:47:40.925082 [debug] [Thread-1  ]: Finished running node model.learn_dbt.playing_with_tests
08:47:40.926593 [debug] [MainThread]: Acquiring new snowflake connection "master"
08:47:40.926938 [info ] [MainThread]: 
08:47:40.927269 [info ] [MainThread]: Running 3 on-run-end hooks
08:47:40.927619 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-0
08:47:40.929203 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-0"
08:47:40.930239 [info ] [MainThread]: 1 of 3 START hook: learn_dbt.on-run-end.0....................................... [RUN]
08:47:40.930802 [debug] [MainThread]: Using snowflake connection "master"
08:47:40.930969 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
08:47:40.931117 [debug] [MainThread]: Opening a new connection, currently in state closed
08:47:41.449223 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.52 seconds
08:47:41.450466 [info ] [MainThread]: 1 of 3 OK hook: learn_dbt.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.52s]
08:47:41.450857 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-1
08:47:41.452486 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-1"
08:47:41.453505 [info ] [MainThread]: 2 of 3 START hook: learn_dbt.on-run-end.1....................................... [RUN]
08:47:41.454052 [debug] [MainThread]: Using snowflake connection "master"
08:47:41.454212 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
08:47:41.611069 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.16 seconds
08:47:41.612758 [info ] [MainThread]: 2 of 3 OK hook: learn_dbt.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.16s]
08:47:41.613216 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-2
08:47:41.615580 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-2"
08:47:41.617904 [info ] [MainThread]: 3 of 3 START hook: learn_dbt.on-run-end.2....................................... [RUN]
08:47:41.618551 [debug] [MainThread]: Using snowflake connection "master"
08:47:41.618756 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
08:47:41.719326 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.1 seconds
08:47:41.720395 [info ] [MainThread]: 3 of 3 OK hook: learn_dbt.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.10s]
08:47:41.720747 [info ] [MainThread]: 
08:47:41.721033 [debug] [MainThread]: On master: Close
08:47:41.888015 [info ] [MainThread]: 
08:47:41.889435 [info ] [MainThread]: Finished running 1 table model, 4 hooks in 7.44s.
08:47:41.889782 [debug] [MainThread]: Connection 'master' was properly closed.
08:47:41.889888 [debug] [MainThread]: Connection 'model.learn_dbt.playing_with_tests' was properly closed.
08:47:41.894951 [info ] [MainThread]: 
08:47:41.895150 [info ] [MainThread]: [32mCompleted successfully[0m
08:47:41.895327 [info ] [MainThread]: 
08:47:41.895462 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
08:47:41.895655 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107054160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10703b0d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107093a30>]}


============================== 2022-05-17 08:58:55.666461 | cb23f5ca-ea74-4254-adbf-e7cf0921eccc ==============================
08:58:55.666461 [info ] [MainThread]: Running with dbt=1.0.1
08:58:55.667153 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['playing_with_tests'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
08:58:55.667344 [debug] [MainThread]: Tracking: tracking
08:58:55.667554 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10829f2b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10829feb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10829f910>]}
08:58:55.717461 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
08:58:55.717691 [debug] [MainThread]: Partial parsing: added file: learn_dbt://macros/suspend_warehouse.sql
08:58:55.717766 [debug] [MainThread]: Parsing macros/suspend_warehouse.sql
08:58:55.723827 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cb23f5ca-ea74-4254-adbf-e7cf0921eccc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1083e10d0>]}
08:58:55.727619 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cb23f5ca-ea74-4254-adbf-e7cf0921eccc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108336c10>]}
08:58:55.727751 [info ] [MainThread]: Found 7 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
08:58:55.728383 [info ] [MainThread]: 
08:58:55.728577 [debug] [MainThread]: Acquiring new snowflake connection "master"
08:58:55.728906 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
08:58:55.735199 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
08:58:55.735324 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
08:58:55.735387 [debug] [ThreadPool]: Opening a new connection, currently in state init
08:58:56.558663 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 0.82 seconds
08:58:56.561102 [debug] [ThreadPool]: On list_analytics: Close
08:58:56.741311 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt_nigel"
08:58:56.749853 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt_nigel"
08:58:56.750064 [debug] [ThreadPool]: On list_analytics_dbt_nigel: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt_nigel"} */

    show terse objects in analytics.dbt_nigel
08:58:56.750220 [debug] [ThreadPool]: Opening a new connection, currently in state closed
08:58:57.506515 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 0.76 seconds
08:58:57.510238 [debug] [ThreadPool]: On list_analytics_dbt_nigel: Close
08:58:57.670324 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snaphots"
08:58:57.673268 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snaphots"
08:58:57.673513 [debug] [ThreadPool]: On list_analytics_snaphots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snaphots"} */

    show terse objects in analytics.snaphots
08:58:57.673699 [debug] [ThreadPool]: Opening a new connection, currently in state closed
08:58:58.178647 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.5 seconds
08:58:58.182011 [debug] [ThreadPool]: On list_analytics_snaphots: Close
08:58:58.360491 [info ] [MainThread]: 
08:58:58.360999 [info ] [MainThread]: Running 1 on-run-start hook
08:58:58.361365 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-start-0
08:58:58.363322 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-start-0"
08:58:58.366775 [info ] [MainThread]: 1 of 1 START hook: learn_dbt.on-run-start.0..................................... [RUN]
08:58:58.367399 [debug] [MainThread]: Using snowflake connection "master"
08:58:58.367562 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
08:58:58.367706 [debug] [MainThread]: Opening a new connection, currently in state init
08:58:58.954582 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.59 seconds
08:58:58.956875 [info ] [MainThread]: 1 of 1 OK hook: learn_dbt.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.59s]
08:58:58.957344 [info ] [MainThread]: 
08:58:58.957655 [debug] [MainThread]: On master: Close
08:58:59.385572 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
08:58:59.386231 [info ] [MainThread]: 
08:58:59.391287 [debug] [Thread-1  ]: Began running node model.learn_dbt.playing_with_tests
08:58:59.391630 [info ] [Thread-1  ]: 1 of 1 START table model dbt_nigel.playing_with_tests........................... [RUN]
08:58:59.392042 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.playing_with_tests"
08:58:59.392181 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.playing_with_tests
08:58:59.392328 [debug] [Thread-1  ]: Compiling model.learn_dbt.playing_with_tests
08:58:59.396663 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.playing_with_tests"
08:58:59.397406 [debug] [Thread-1  ]: finished collecting timing info
08:58:59.397536 [debug] [Thread-1  ]: Began executing node model.learn_dbt.playing_with_tests
08:58:59.410238 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
08:58:59.410369 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */

        insert into dbt.audit (model, state, time) values ('playing_with_tests', 'starting model deployment', current_timestamp)
08:58:59.410456 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
08:59:01.175738 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.77 seconds
08:59:01.188735 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.playing_with_tests"
08:59:01.192135 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
08:59:01.192299 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */


      create or replace transient table analytics.dbt_nigel.playing_with_tests  as
      (WITH sample_customer AS (
select * 
from snowflake_sample_data.tpch_sf1.customer
)

select
  c_custkey,
  c_mktsegment,
  
  CASE
    WHEN '' in ('BUILDING', 'HOUSEHOLD', 'FURNITURE')
      THEN 'segment_1'
    ELSE 'segment_2'
  END
 mkt_segment_adjusted
from sample_customer
      );
08:59:02.140360 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.95 seconds
08:59:02.146584 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
08:59:02.146882 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */

        insert into dbt.audit (model, state, time) values ('playing_with_tests', 'ending model deployment', current_timestamp)
08:59:02.921916 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.77 seconds
08:59:02.933989 [debug] [Thread-1  ]: finished collecting timing info
08:59:02.934149 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: Close
08:59:03.093850 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cb23f5ca-ea74-4254-adbf-e7cf0921eccc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a4a66a0>]}
08:59:03.094253 [info ] [Thread-1  ]: 1 of 1 OK created table model dbt_nigel.playing_with_tests...................... [[32mSUCCESS 1[0m in 3.70s]
08:59:03.094483 [debug] [Thread-1  ]: Finished running node model.learn_dbt.playing_with_tests
08:59:03.095549 [debug] [MainThread]: Acquiring new snowflake connection "master"
08:59:03.095984 [info ] [MainThread]: 
08:59:03.096331 [info ] [MainThread]: Running 3 on-run-end hooks
08:59:03.096675 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-0
08:59:03.098223 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-0"
08:59:03.101195 [info ] [MainThread]: 1 of 3 START hook: learn_dbt.on-run-end.0....................................... [RUN]
08:59:03.101800 [debug] [MainThread]: Using snowflake connection "master"
08:59:03.101966 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
08:59:03.102117 [debug] [MainThread]: Opening a new connection, currently in state closed
08:59:03.655801 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.55 seconds
08:59:03.658475 [info ] [MainThread]: 1 of 3 OK hook: learn_dbt.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.56s]
08:59:03.659019 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-1
08:59:03.660968 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-1"
08:59:03.663775 [info ] [MainThread]: 2 of 3 START hook: learn_dbt.on-run-end.1....................................... [RUN]
08:59:03.664352 [debug] [MainThread]: Using snowflake connection "master"
08:59:03.664516 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
08:59:03.822924 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.16 seconds
08:59:03.825269 [info ] [MainThread]: 2 of 3 OK hook: learn_dbt.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.16s]
08:59:03.825803 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-2
08:59:03.828008 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-2"
08:59:03.830377 [info ] [MainThread]: 3 of 3 START hook: learn_dbt.on-run-end.2....................................... [RUN]
08:59:03.830946 [debug] [MainThread]: Using snowflake connection "master"
08:59:03.831113 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
08:59:03.933421 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.1 seconds
08:59:03.934842 [info ] [MainThread]: 3 of 3 OK hook: learn_dbt.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.10s]
08:59:03.935302 [info ] [MainThread]: 
08:59:03.935684 [debug] [MainThread]: On master: Close
08:59:04.112388 [info ] [MainThread]: 
08:59:04.112743 [info ] [MainThread]: Finished running 1 table model, 4 hooks in 8.38s.
08:59:04.113157 [debug] [MainThread]: Connection 'master' was properly closed.
08:59:04.113364 [debug] [MainThread]: Connection 'model.learn_dbt.playing_with_tests' was properly closed.
08:59:04.120743 [info ] [MainThread]: 
08:59:04.121159 [info ] [MainThread]: [32mCompleted successfully[0m
08:59:04.121505 [info ] [MainThread]: 
08:59:04.121710 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
08:59:04.122001 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1082749a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a51dac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a51d310>]}


============================== 2022-05-17 08:59:48.608723 | 39ef83fd-f4c0-4c73-ae8a-f766034f5cc8 ==============================
08:59:48.608723 [info ] [MainThread]: Running with dbt=1.0.1
08:59:48.609396 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, macro='suspend', args='{warehouse_name: transform_wh}', defer=None, state=None, cls=<class 'dbt.task.run_operation.RunOperationTask'>, which='run-operation', rpc_method='run-operation')
08:59:48.609528 [debug] [MainThread]: Tracking: tracking
08:59:48.609759 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104393220>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104393c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104393eb0>]}
08:59:48.655595 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
08:59:48.655720 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
08:59:48.658974 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '39ef83fd-f4c0-4c73-ae8a-f766034f5cc8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10433c1f0>]}
08:59:48.661682 [debug] [MainThread]: Acquiring new snowflake connection "macro_suspend"
08:59:48.666002 [debug] [MainThread]: Using snowflake connection "macro_suspend"
08:59:48.666086 [debug] [MainThread]: On macro_suspend: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "macro_suspend"} */

    
    alter warehouse transform_wh suspend
08:59:48.666149 [debug] [MainThread]: Opening a new connection, currently in state init
08:59:49.410226 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.74 seconds
08:59:49.413547 [debug] [MainThread]: On macro_suspend: Close
08:59:49.577207 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104393220>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1044cc100>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1044cc9a0>]}
08:59:50.041219 [debug] [MainThread]: Connection 'macro_suspend' was properly closed.


============================== 2022-05-17 09:02:36.419278 | 318bf395-81ec-4613-82fc-ec767a9a092a ==============================
09:02:36.419278 [info ] [MainThread]: Running with dbt=1.0.1
09:02:36.419950 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['playing_with_tests'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
09:02:36.420102 [debug] [MainThread]: Tracking: tracking
09:02:36.420342 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a9df370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a9dfbe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a9df9d0>]}
09:02:36.468899 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
09:02:36.469039 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
09:02:36.472469 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '318bf395-81ec-4613-82fc-ec767a9a092a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a9a51c0>]}
09:02:36.476684 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '318bf395-81ec-4613-82fc-ec767a9a092a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aa76040>]}
09:02:36.476827 [info ] [MainThread]: Found 7 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
09:02:36.477463 [info ] [MainThread]: 
09:02:36.477667 [debug] [MainThread]: Acquiring new snowflake connection "master"
09:02:36.478061 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
09:02:36.483979 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
09:02:36.484066 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
09:02:36.484131 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:02:37.261427 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 0.78 seconds
09:02:37.264097 [debug] [ThreadPool]: On list_analytics: Close
09:02:37.448910 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt_nigel"
09:02:37.453262 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt_nigel"
09:02:37.453393 [debug] [ThreadPool]: On list_analytics_dbt_nigel: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt_nigel"} */

    show terse objects in analytics.dbt_nigel
09:02:37.453484 [debug] [ThreadPool]: Opening a new connection, currently in state closed
09:02:38.275119 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 0.82 seconds
09:02:38.278967 [debug] [ThreadPool]: On list_analytics_dbt_nigel: Close
09:02:38.496093 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snaphots"
09:02:38.497164 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snaphots"
09:02:38.497255 [debug] [ThreadPool]: On list_analytics_snaphots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snaphots"} */

    show terse objects in analytics.snaphots
09:02:38.497323 [debug] [ThreadPool]: Opening a new connection, currently in state closed
09:02:39.046257 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.55 seconds
09:02:39.050039 [debug] [ThreadPool]: On list_analytics_snaphots: Close
09:02:39.214970 [info ] [MainThread]: 
09:02:39.215549 [info ] [MainThread]: Running 1 on-run-start hook
09:02:39.215838 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-start-0
09:02:39.217496 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-start-0"
09:02:39.219612 [info ] [MainThread]: 1 of 1 START hook: learn_dbt.on-run-start.0..................................... [RUN]
09:02:39.220237 [debug] [MainThread]: Using snowflake connection "master"
09:02:39.220405 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
09:02:39.220551 [debug] [MainThread]: Opening a new connection, currently in state init
09:02:39.726414 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.51 seconds
09:02:39.730501 [info ] [MainThread]: 1 of 1 OK hook: learn_dbt.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.51s]
09:02:39.731482 [info ] [MainThread]: 
09:02:39.732326 [debug] [MainThread]: On master: Close
09:02:39.895973 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
09:02:39.896402 [info ] [MainThread]: 
09:02:39.900494 [debug] [Thread-1  ]: Began running node model.learn_dbt.playing_with_tests
09:02:39.900964 [info ] [Thread-1  ]: 1 of 1 START table model dbt_nigel.playing_with_tests........................... [RUN]
09:02:39.901465 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.playing_with_tests"
09:02:39.901633 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.playing_with_tests
09:02:39.901802 [debug] [Thread-1  ]: Compiling model.learn_dbt.playing_with_tests
09:02:39.906800 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.playing_with_tests"
09:02:39.907967 [debug] [Thread-1  ]: finished collecting timing info
09:02:39.908185 [debug] [Thread-1  ]: Began executing node model.learn_dbt.playing_with_tests
09:02:39.922631 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
09:02:39.922800 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */

        insert into dbt.audit (model, state, time) values ('playing_with_tests', 'starting model deployment', current_timestamp)
09:02:39.922902 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:02:41.281137 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.36 seconds
09:02:41.295776 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.playing_with_tests"
09:02:41.297296 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
09:02:41.297461 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */


      create or replace transient table analytics.dbt_nigel.playing_with_tests  as
      (WITH sample_customer AS (
select * 
from snowflake_sample_data.tpch_sf1.customer
)

select
  c_custkey,
  c_mktsegment,
  
  CASE
    WHEN '' in ('BUILDING', 'HOUSEHOLD', 'FURNITURE')
      THEN 'segment_1'
    ELSE 'segment_2'
  END
 mkt_segment_adjusted
from sample_customer
      );
09:02:42.198375 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.9 seconds
09:02:42.203626 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
09:02:42.203908 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */

        insert into dbt.audit (model, state, time) values ('playing_with_tests', 'ending model deployment', current_timestamp)
09:02:43.551452 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.35 seconds
09:02:43.565114 [debug] [Thread-1  ]: finished collecting timing info
09:02:43.565415 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: Close
09:02:43.722511 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '318bf395-81ec-4613-82fc-ec767a9a092a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ea55580>]}
09:02:43.723046 [info ] [Thread-1  ]: 1 of 1 OK created table model dbt_nigel.playing_with_tests...................... [[32mSUCCESS 1[0m in 3.82s]
09:02:43.723335 [debug] [Thread-1  ]: Finished running node model.learn_dbt.playing_with_tests
09:02:43.724228 [debug] [MainThread]: Acquiring new snowflake connection "master"
09:02:43.724419 [info ] [MainThread]: 
09:02:43.724616 [info ] [MainThread]: Running 3 on-run-end hooks
09:02:43.724818 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-0
09:02:43.725931 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-0"
09:02:43.727561 [info ] [MainThread]: 1 of 3 START hook: learn_dbt.on-run-end.0....................................... [RUN]
09:02:43.727958 [debug] [MainThread]: Using snowflake connection "master"
09:02:43.728076 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
09:02:43.728186 [debug] [MainThread]: Opening a new connection, currently in state closed
09:02:44.222625 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.49 seconds
09:02:44.224517 [info ] [MainThread]: 1 of 3 OK hook: learn_dbt.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.50s]
09:02:44.225152 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-1
09:02:44.225931 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-1"
09:02:44.226438 [info ] [MainThread]: 2 of 3 START hook: learn_dbt.on-run-end.1....................................... [RUN]
09:02:44.226707 [debug] [MainThread]: Using snowflake connection "master"
09:02:44.226779 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
09:02:44.350139 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.12 seconds
09:02:44.352015 [info ] [MainThread]: 2 of 3 OK hook: learn_dbt.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.13s]
09:02:44.353040 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-2
09:02:44.355279 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-2"
09:02:44.357420 [info ] [MainThread]: 3 of 3 START hook: learn_dbt.on-run-end.2....................................... [RUN]
09:02:44.358122 [debug] [MainThread]: Using snowflake connection "master"
09:02:44.358325 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
09:02:44.500736 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.14 seconds
09:02:44.502086 [info ] [MainThread]: 3 of 3 OK hook: learn_dbt.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.14s]
09:02:44.502803 [info ] [MainThread]: 
09:02:44.503191 [debug] [MainThread]: On master: Close
09:02:44.715657 [info ] [MainThread]: 
09:02:44.716442 [info ] [MainThread]: Finished running 1 table model, 4 hooks in 8.24s.
09:02:44.716832 [debug] [MainThread]: Connection 'master' was properly closed.
09:02:44.717042 [debug] [MainThread]: Connection 'model.learn_dbt.playing_with_tests' was properly closed.
09:02:44.723380 [info ] [MainThread]: 
09:02:44.723661 [info ] [MainThread]: [32mCompleted successfully[0m
09:02:44.723877 [info ] [MainThread]: 
09:02:44.724050 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
09:02:44.724291 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aeae6a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ae77a30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ea559d0>]}


============================== 2022-05-17 09:09:38.108319 | 97811127-a6e3-4f05-818a-bcecd6dd59cf ==============================
09:09:38.108319 [info ] [MainThread]: Running with dbt=1.0.1
09:09:38.108865 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
09:09:38.108986 [debug] [MainThread]: Tracking: tracking
09:09:38.109201 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104113bb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104113f40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104113fa0>]}
09:09:38.155706 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
09:09:38.155989 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/snowflake_cumulative_sales.sql
09:09:38.156118 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/snowflake_customer_purchases.sql
09:09:38.162290 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_cumulative_sales.sql
09:09:38.170230 [debug] [MainThread]: 1603: static parser failed on example/snowflake_customer_purchases.sql
09:09:38.173539 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/snowflake_customer_purchases.sql
09:09:38.190421 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '97811127-a6e3-4f05-818a-bcecd6dd59cf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1042ae0d0>]}
09:09:38.193974 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '97811127-a6e3-4f05-818a-bcecd6dd59cf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1040e4eb0>]}
09:09:38.194184 [info ] [MainThread]: Found 7 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
09:09:38.195030 [info ] [MainThread]: 
09:09:38.195241 [debug] [MainThread]: Acquiring new snowflake connection "master"
09:09:38.195702 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
09:09:38.202014 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
09:09:38.202162 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
09:09:38.202225 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:09:38.980912 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 0.78 seconds
09:09:38.983972 [debug] [ThreadPool]: On list_analytics: Close
09:09:39.311217 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt_nigel"
09:09:39.319875 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt_nigel"
09:09:39.320100 [debug] [ThreadPool]: On list_analytics_dbt_nigel: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt_nigel"} */

    show terse objects in analytics.dbt_nigel
09:09:39.320259 [debug] [ThreadPool]: Opening a new connection, currently in state closed
09:09:40.016728 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 0.7 seconds
09:09:40.020732 [debug] [ThreadPool]: On list_analytics_dbt_nigel: Close
09:09:40.188750 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snaphots"
09:09:40.191710 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snaphots"
09:09:40.191926 [debug] [ThreadPool]: On list_analytics_snaphots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snaphots"} */

    show terse objects in analytics.snaphots
09:09:40.192084 [debug] [ThreadPool]: Opening a new connection, currently in state closed
09:09:40.716768 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.52 seconds
09:09:40.719905 [debug] [ThreadPool]: On list_analytics_snaphots: Close
09:09:40.902664 [info ] [MainThread]: 
09:09:40.903174 [info ] [MainThread]: Running 1 on-run-start hook
09:09:40.903546 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-start-0
09:09:40.905493 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-start-0"
09:09:40.908976 [info ] [MainThread]: 1 of 1 START hook: learn_dbt.on-run-start.0..................................... [RUN]
09:09:40.909628 [debug] [MainThread]: Using snowflake connection "master"
09:09:40.909802 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
09:09:40.909947 [debug] [MainThread]: Opening a new connection, currently in state init
09:09:41.421502 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.51 seconds
09:09:41.422916 [info ] [MainThread]: 1 of 1 OK hook: learn_dbt.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.51s]
09:09:41.423295 [info ] [MainThread]: 
09:09:41.423603 [debug] [MainThread]: On master: Close
09:09:41.577003 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
09:09:41.577620 [info ] [MainThread]: 
09:09:41.583317 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
09:09:41.583724 [info ] [Thread-1  ]: 1 of 7 START incremental model dbt_nigel.dates.................................. [RUN]
09:09:41.584601 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
09:09:41.584777 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
09:09:41.584945 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
09:09:41.593900 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
09:09:41.595458 [debug] [Thread-1  ]: finished collecting timing info
09:09:41.595603 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
09:09:41.622697 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
09:09:41.622847 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt_nigel.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt_nigel.dates)

      );
09:09:41.622928 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:09:43.274042 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.65 seconds
09:09:43.285723 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
09:09:43.285925 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt_nigel.dates__dbt_tmp
09:09:43.408415 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.12 seconds
09:09:43.413117 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
09:09:43.413305 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt_nigel.dates
09:09:43.505302 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.09 seconds
09:09:43.518034 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
09:09:43.518252 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT_NIGEL"."DATES"
09:09:43.619817 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.1 seconds
09:09:43.643016 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
09:09:43.645162 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
09:09:43.645294 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
09:09:43.804679 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.16 seconds
09:09:43.806094 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
09:09:43.806346 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt_nigel.dates as DBT_INTERNAL_DEST
        using analytics.dbt_nigel.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
09:09:44.389580 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.58 seconds
09:09:44.390016 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
09:09:44.390178 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
09:09:44.578011 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.19 seconds
09:09:44.592599 [debug] [Thread-1  ]: finished collecting timing info
09:09:44.592963 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
09:09:44.771548 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97811127-a6e3-4f05-818a-bcecd6dd59cf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1043e0100>]}
09:09:44.772095 [info ] [Thread-1  ]: 1 of 7 OK created incremental model dbt_nigel.dates............................. [[32mSUCCESS 1[0m in 3.19s]
09:09:44.772458 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
09:09:44.772663 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
09:09:44.773020 [info ] [Thread-1  ]: 2 of 7 START incremental model dbt_nigel.incremental_time....................... [RUN]
09:09:44.773541 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
09:09:44.773709 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
09:09:44.773868 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
09:09:44.776955 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
09:09:44.779093 [debug] [Thread-1  ]: finished collecting timing info
09:09:44.779340 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
09:09:44.782673 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
09:09:44.782874 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

        insert into dbt.audit (model, state, time) values ('incremental_time', 'starting model deployment', current_timestamp)
09:09:44.782979 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:09:45.722985 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.94 seconds
09:09:45.727172 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
09:09:45.727565 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt_nigel.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt_nigel.incremental_time)

      );
09:09:46.863656 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.14 seconds
09:09:46.869716 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
09:09:46.870076 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt_nigel.incremental_time__dbt_tmp
09:09:46.995915 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.13 seconds
09:09:47.002614 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
09:09:47.002948 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt_nigel.incremental_time
09:09:47.136279 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.13 seconds
09:09:47.143695 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
09:09:47.143923 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT_NIGEL"."INCREMENTAL_TIME"
09:09:47.240543 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
09:09:47.245050 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
09:09:47.247442 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
09:09:47.247623 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
09:09:47.373831 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.13 seconds
09:09:47.376042 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
09:09:47.376296 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt_nigel.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt_nigel.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
09:09:48.291605 [debug] [Thread-1  ]: SQL status: SUCCESS 4265 in 0.92 seconds
09:09:48.292864 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
09:09:48.293171 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
09:09:48.598339 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.3 seconds
09:09:48.603388 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
09:09:48.603617 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

        insert into dbt.audit (model, state, time) values ('incremental_time', 'ending model deployment', current_timestamp)
09:09:49.110674 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.51 seconds
09:09:49.115393 [debug] [Thread-1  ]: finished collecting timing info
09:09:49.115833 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
09:09:49.300593 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97811127-a6e3-4f05-818a-bcecd6dd59cf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1044c5370>]}
09:09:49.301743 [info ] [Thread-1  ]: 2 of 7 OK created incremental model dbt_nigel.incremental_time.................. [[32mSUCCESS 1[0m in 4.53s]
09:09:49.302016 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
09:09:49.302133 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
09:09:49.302332 [info ] [Thread-1  ]: 3 of 7 START table model dbt_nigel.first_model.................................. [RUN]
09:09:49.302691 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
09:09:49.302802 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
09:09:49.302907 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
09:09:49.305780 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
09:09:49.307430 [debug] [Thread-1  ]: finished collecting timing info
09:09:49.307633 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
09:09:49.315225 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
09:09:49.315362 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('first_model', 'starting model deployment', current_timestamp)
09:09:49.315452 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:09:50.544562 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.23 seconds
09:09:50.547621 [debug] [Thread-1  ]: Dropping relation "ANALYTICS"."DBT_NIGEL"."FIRST_MODEL" because it is of type view
09:09:50.556280 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
09:09:50.556503 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */
drop view if exists "ANALYTICS"."DBT_NIGEL"."FIRST_MODEL" cascade
09:09:50.687356 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.13 seconds
09:09:50.690432 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
09:09:50.693727 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
09:09:50.693927 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt_nigel.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id, 'NJ' as state, '2020-02-01 00:01:00.000'::timestamp as updated_at
    union all
    select null as id, 'CT' as state, '2020-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select 3 as id, 'VT' as state, '2020-01-01 00:00:00.000'::timestamp as updated_at

)

select * 
from source_data


/*
select *, True as first_variable
from source_data
where id >= 1
*/
      );
09:09:51.464927 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.77 seconds
09:09:51.469430 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
09:09:51.469653 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('first_model', 'ending model deployment', current_timestamp)
09:09:51.978712 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.51 seconds
09:09:51.981965 [debug] [Thread-1  ]: finished collecting timing info
09:09:51.982436 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
09:09:52.148893 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97811127-a6e3-4f05-818a-bcecd6dd59cf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10635b790>]}
09:09:52.149657 [info ] [Thread-1  ]: 3 of 7 OK created table model dbt_nigel.first_model............................. [[32mSUCCESS 1[0m in 2.85s]
09:09:52.150133 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
09:09:52.150390 [debug] [Thread-1  ]: Began running node model.learn_dbt.playing_with_tests
09:09:52.150824 [info ] [Thread-1  ]: 4 of 7 START table model dbt_nigel.playing_with_tests........................... [RUN]
09:09:52.151485 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.playing_with_tests"
09:09:52.151699 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.playing_with_tests
09:09:52.152023 [debug] [Thread-1  ]: Compiling model.learn_dbt.playing_with_tests
09:09:52.156858 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.playing_with_tests"
09:09:52.157805 [debug] [Thread-1  ]: finished collecting timing info
09:09:52.157988 [debug] [Thread-1  ]: Began executing node model.learn_dbt.playing_with_tests
09:09:52.160928 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
09:09:52.161195 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */

        insert into dbt.audit (model, state, time) values ('playing_with_tests', 'starting model deployment', current_timestamp)
09:09:52.161335 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:09:53.104168 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.94 seconds
09:09:53.106634 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.playing_with_tests"
09:09:53.107995 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
09:09:53.108188 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */


      create or replace transient table analytics.dbt_nigel.playing_with_tests  as
      (WITH sample_customer AS (
select * 
from snowflake_sample_data.tpch_sf1.customer
)

select
  c_custkey,
  c_mktsegment,
  
  CASE
    WHEN '' in ('BUILDING', 'HOUSEHOLD', 'FURNITURE')
      THEN 'segment_1'
    ELSE 'segment_2'
  END
 mkt_segment_adjusted
from sample_customer
      );
09:09:54.537270 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.43 seconds
09:09:54.540222 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
09:09:54.540385 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */

        insert into dbt.audit (model, state, time) values ('playing_with_tests', 'ending model deployment', current_timestamp)
09:09:55.008540 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.47 seconds
09:09:55.011866 [debug] [Thread-1  ]: finished collecting timing info
09:09:55.012289 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: Close
09:09:55.190599 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97811127-a6e3-4f05-818a-bcecd6dd59cf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1063e6220>]}
09:09:55.191422 [info ] [Thread-1  ]: 4 of 7 OK created table model dbt_nigel.playing_with_tests...................... [[32mSUCCESS 1[0m in 3.04s]
09:09:55.191869 [debug] [Thread-1  ]: Finished running node model.learn_dbt.playing_with_tests
09:09:55.192124 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
09:09:55.192535 [info ] [Thread-1  ]: 5 of 7 START table model dbt_nigel.snowflake_cumulative_sales................... [RUN]
09:09:55.193157 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
09:09:55.193366 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
09:09:55.193573 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
09:09:55.197322 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
09:09:55.199749 [debug] [Thread-1  ]: finished collecting timing info
09:09:55.199929 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
09:09:55.203214 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
09:09:55.203452 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */

        insert into dbt.audit (model, state, time) values ('snowflake_cumulative_sales', 'starting model deployment', current_timestamp)
09:09:55.203589 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:09:56.281321 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.08 seconds
09:09:56.285388 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
09:09:56.287354 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
09:09:56.287584 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt_nigel.snowflake_cumulative_sales  as
      (with orders as (
	select *
	from snowflake_sample_data.tpch_sf1.orders
)

select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from orders
order by o_orderdate
      );
09:09:57.396695 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.11 seconds
09:09:57.400959 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
09:09:57.401236 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */

        insert into dbt.audit (model, state, time) values ('snowflake_cumulative_sales', 'ending model deployment', current_timestamp)
09:09:57.917043 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.52 seconds
09:09:57.920656 [debug] [Thread-1  ]: finished collecting timing info
09:09:57.921124 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
09:09:58.107441 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97811127-a6e3-4f05-818a-bcecd6dd59cf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106437f10>]}
09:09:58.108997 [info ] [Thread-1  ]: 5 of 7 OK created table model dbt_nigel.snowflake_cumulative_sales.............. [[32mSUCCESS 1[0m in 2.91s]
09:09:58.109523 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
09:09:58.109982 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
09:09:58.110354 [info ] [Thread-1  ]: 6 of 7 START table model dbt_nigel.snowflake_customer_purchases................. [RUN]
09:09:58.111140 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
09:09:58.111375 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
09:09:58.111555 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
09:09:58.117488 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
09:09:58.120086 [debug] [Thread-1  ]: finished collecting timing info
09:09:58.120325 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
09:09:58.123293 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
09:09:58.123431 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */

        insert into dbt.audit (model, state, time) values ('snowflake_customer_purchases', 'starting model deployment', current_timestamp)
09:09:58.123543 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:09:59.043750 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.92 seconds
09:09:59.047278 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
09:09:59.050791 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
09:09:59.050981 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt_nigel.snowflake_customer_purchases  as
      (with sample_customer as(
	select *
	from snowflake_sample_data.tpch_sf1.customer
),

sample_orders as (
	select * 
	from snowflake_sample_data.tpch_sf1.orders
)



select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from sample_customer c
left join sample_orders o
on c.c_custkey = o.o_custkey
group by 1,2,3
      );
09:10:00.322537 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.27 seconds
09:10:00.327640 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
09:10:00.327904 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */

        insert into dbt.audit (model, state, time) values ('snowflake_customer_purchases', 'ending model deployment', current_timestamp)
09:10:00.886161 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.56 seconds
09:10:00.889367 [debug] [Thread-1  ]: finished collecting timing info
09:10:00.889798 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
09:10:01.082471 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97811127-a6e3-4f05-818a-bcecd6dd59cf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106369940>]}
09:10:01.083155 [info ] [Thread-1  ]: 6 of 7 OK created table model dbt_nigel.snowflake_customer_purchases............ [[32mSUCCESS 1[0m in 2.97s]
09:10:01.083590 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
09:10:01.083841 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
09:10:01.084255 [info ] [Thread-1  ]: 7 of 7 START table model dbt_nigel.my_second_dbt_model.......................... [RUN]
09:10:01.084902 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
09:10:01.085120 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
09:10:01.085335 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
09:10:01.089321 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
09:10:01.090064 [debug] [Thread-1  ]: finished collecting timing info
09:10:01.090253 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
09:10:01.093609 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
09:10:01.093782 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('my_second_dbt_model', 'starting model deployment', current_timestamp)
09:10:01.093911 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:10:01.946472 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.85 seconds
09:10:01.949387 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
09:10:01.951749 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
09:10:01.951935 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt_nigel.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt_nigel.first_model
/*
union all
select 7 as id, True as first_variable
*/
      );
09:10:02.935142 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.98 seconds
09:10:02.940487 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
09:10:02.940816 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('my_second_dbt_model', 'ending model deployment', current_timestamp)
09:10:03.445108 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.5 seconds
09:10:03.448872 [debug] [Thread-1  ]: finished collecting timing info
09:10:03.449251 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
09:10:03.622094 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97811127-a6e3-4f05-818a-bcecd6dd59cf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10452fd90>]}
09:10:03.622688 [info ] [Thread-1  ]: 7 of 7 OK created table model dbt_nigel.my_second_dbt_model..................... [[32mSUCCESS 1[0m in 2.54s]
09:10:03.622972 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
09:10:03.624119 [debug] [MainThread]: Acquiring new snowflake connection "master"
09:10:03.624537 [info ] [MainThread]: 
09:10:03.624871 [info ] [MainThread]: Running 3 on-run-end hooks
09:10:03.625208 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-0
09:10:03.626951 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-0"
09:10:03.629342 [info ] [MainThread]: 1 of 3 START hook: learn_dbt.on-run-end.0....................................... [RUN]
09:10:03.629746 [debug] [MainThread]: Using snowflake connection "master"
09:10:03.629842 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
09:10:03.629925 [debug] [MainThread]: Opening a new connection, currently in state closed
09:10:04.143683 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.51 seconds
09:10:04.145613 [info ] [MainThread]: 1 of 3 OK hook: learn_dbt.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.52s]
09:10:04.146295 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-1
09:10:04.149425 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-1"
09:10:04.151476 [info ] [MainThread]: 2 of 3 START hook: learn_dbt.on-run-end.1....................................... [RUN]
09:10:04.152183 [debug] [MainThread]: Using snowflake connection "master"
09:10:04.152394 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
09:10:04.288020 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.14 seconds
09:10:04.290397 [info ] [MainThread]: 2 of 3 OK hook: learn_dbt.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.14s]
09:10:04.290978 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-2
09:10:04.293431 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-2"
09:10:04.294514 [info ] [MainThread]: 3 of 3 START hook: learn_dbt.on-run-end.2....................................... [RUN]
09:10:04.295079 [debug] [MainThread]: Using snowflake connection "master"
09:10:04.295239 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
09:10:04.414388 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.12 seconds
09:10:04.415504 [info ] [MainThread]: 3 of 3 OK hook: learn_dbt.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.12s]
09:10:04.415864 [info ] [MainThread]: 
09:10:04.416151 [debug] [MainThread]: On master: Close
09:10:04.626224 [info ] [MainThread]: 
09:10:04.626641 [info ] [MainThread]: Finished running 2 incremental models, 5 table models, 4 hooks in 26.43s.
09:10:04.626853 [debug] [MainThread]: Connection 'master' was properly closed.
09:10:04.626961 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
09:10:04.633711 [info ] [MainThread]: 
09:10:04.633936 [info ] [MainThread]: [32mCompleted successfully[0m
09:10:04.634129 [info ] [MainThread]: 
09:10:04.634297 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
09:10:04.634512 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106423a00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1064236d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1064239a0>]}


============================== 2022-05-17 09:15:02.811397 | 47f96c54-9365-435f-a652-ffcf85c67498 ==============================
09:15:02.811397 [info ] [MainThread]: Running with dbt=1.0.1
09:15:02.811973 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tag:nightly'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
09:15:02.812089 [debug] [MainThread]: Tracking: tracking
09:15:02.812298 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108e7e5e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108e7ebb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108e7e7f0>]}
09:15:02.845619 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
09:15:02.845850 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '47f96c54-9365-435f-a652-ffcf85c67498', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108e812b0>]}
09:15:02.861059 [debug] [MainThread]: Parsing macros/suspend_warehouse.sql
09:15:02.861661 [debug] [MainThread]: Parsing macros/rename_segments.sql
09:15:02.861926 [debug] [MainThread]: Parsing macros/group_by.sql
09:15:02.862782 [debug] [MainThread]: Parsing macros/catalog.sql
09:15:02.863765 [debug] [MainThread]: Parsing macros/adapters.sql
09:15:02.882722 [debug] [MainThread]: Parsing macros/materializations/merge.sql
09:15:02.884493 [debug] [MainThread]: Parsing macros/materializations/seed.sql
09:15:02.886908 [debug] [MainThread]: Parsing macros/materializations/view.sql
09:15:02.887500 [debug] [MainThread]: Parsing macros/materializations/table.sql
09:15:02.888891 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
09:15:02.892880 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
09:15:02.893301 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
09:15:02.895005 [debug] [MainThread]: Parsing macros/materializations/configs.sql
09:15:02.896005 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
09:15:02.896744 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
09:15:02.904424 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
09:15:02.909890 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
09:15:02.915671 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
09:15:02.917742 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
09:15:02.918526 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
09:15:02.919320 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
09:15:02.921298 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
09:15:02.926626 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
09:15:02.927305 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
09:15:02.932155 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
09:15:02.939802 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
09:15:02.943427 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
09:15:02.944687 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
09:15:02.948141 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
09:15:02.948706 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
09:15:02.949919 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
09:15:02.950919 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
09:15:02.953707 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
09:15:02.961591 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
09:15:02.962246 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
09:15:02.963340 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
09:15:02.964014 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
09:15:02.964407 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
09:15:02.964636 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
09:15:02.964931 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
09:15:02.965531 [debug] [MainThread]: Parsing macros/etc/statement.sql
09:15:02.967537 [debug] [MainThread]: Parsing macros/etc/datetime.sql
09:15:02.971543 [debug] [MainThread]: Parsing macros/adapters/schema.sql
09:15:02.972471 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
09:15:02.973648 [debug] [MainThread]: Parsing macros/adapters/relation.sql
09:15:02.977940 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
09:15:02.979206 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
09:15:02.981169 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
09:15:02.984434 [debug] [MainThread]: Parsing macros/adapters/columns.sql
09:15:02.988908 [debug] [MainThread]: Parsing tests/generic/builtin.sql
09:15:03.077580 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
09:15:03.084494 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
09:15:03.085124 [debug] [MainThread]: 1603: static parser failed on example/playing_with_tests.sql
09:15:03.087516 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/playing_with_tests.sql
09:15:03.088093 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_cumulative_sales.sql
09:15:03.090156 [debug] [MainThread]: 1603: static parser failed on example/my_second_dbt_model.sql
09:15:03.092124 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_second_dbt_model.sql
09:15:03.092687 [debug] [MainThread]: 1603: static parser failed on example/incremental_time.sql
09:15:03.096428 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_time.sql
09:15:03.097016 [debug] [MainThread]: 1603: static parser failed on example/snowflake_customer_purchases.sql
09:15:03.100332 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/snowflake_customer_purchases.sql
09:15:03.100776 [debug] [MainThread]: 1603: static parser failed on new/dates.sql
09:15:03.102261 [debug] [MainThread]: 1602: parser fallback to jinja rendering on new/dates.sql
09:15:03.166458 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '47f96c54-9365-435f-a652-ffcf85c67498', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109025c10>]}
09:15:03.170060 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '47f96c54-9365-435f-a652-ffcf85c67498', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109025070>]}
09:15:03.170259 [info ] [MainThread]: Found 7 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
09:15:03.170957 [info ] [MainThread]: 
09:15:03.171171 [debug] [MainThread]: Acquiring new snowflake connection "master"
09:15:03.171607 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
09:15:03.177425 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
09:15:03.177544 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
09:15:03.177608 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:15:04.463058 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1.29 seconds
09:15:04.465504 [debug] [ThreadPool]: On list_analytics: Close
09:15:04.637914 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snaphots"
09:15:04.646616 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snaphots"
09:15:04.646848 [debug] [ThreadPool]: On list_analytics_snaphots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snaphots"} */

    show terse objects in analytics.snaphots
09:15:04.647017 [debug] [ThreadPool]: Opening a new connection, currently in state closed
09:15:05.170388 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.52 seconds
09:15:05.173513 [debug] [ThreadPool]: On list_analytics_snaphots: Close
09:15:05.356752 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt_nigel"
09:15:05.359329 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt_nigel"
09:15:05.359575 [debug] [ThreadPool]: On list_analytics_dbt_nigel: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt_nigel"} */

    show terse objects in analytics.dbt_nigel
09:15:05.359769 [debug] [ThreadPool]: Opening a new connection, currently in state closed
09:15:05.859404 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 0.5 seconds
09:15:05.862820 [debug] [ThreadPool]: On list_analytics_dbt_nigel: Close
09:15:06.036435 [info ] [MainThread]: 
09:15:06.037067 [info ] [MainThread]: Running 1 on-run-start hook
09:15:06.037451 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-start-0
09:15:06.039360 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-start-0"
09:15:06.041152 [info ] [MainThread]: 1 of 1 START hook: learn_dbt.on-run-start.0..................................... [RUN]
09:15:06.041740 [debug] [MainThread]: Using snowflake connection "master"
09:15:06.041896 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
09:15:06.042048 [debug] [MainThread]: Opening a new connection, currently in state init
09:15:06.538053 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.5 seconds
09:15:06.539617 [info ] [MainThread]: 1 of 1 OK hook: learn_dbt.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.50s]
09:15:06.540259 [info ] [MainThread]: 
09:15:06.540770 [debug] [MainThread]: On master: Close
09:15:06.709081 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
09:15:06.709727 [info ] [MainThread]: 
09:15:06.714457 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
09:15:06.714855 [info ] [Thread-1  ]: 1 of 6 START incremental model dbt_nigel.incremental_time....................... [RUN]
09:15:06.715763 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
09:15:06.715954 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
09:15:06.716132 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
09:15:06.722099 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
09:15:06.722682 [debug] [Thread-1  ]: finished collecting timing info
09:15:06.722836 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
09:15:06.747270 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
09:15:06.747406 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

        insert into dbt.audit (model, state, time) values ('incremental_time', 'starting model deployment', current_timestamp)
09:15:06.747501 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:15:08.247119 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.5 seconds
09:15:08.255303 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
09:15:08.255459 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt_nigel.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt_nigel.incremental_time)

      );
09:15:09.592366 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.34 seconds
09:15:09.603271 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
09:15:09.603486 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt_nigel.incremental_time__dbt_tmp
09:15:09.708042 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
09:15:09.713523 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
09:15:09.713804 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt_nigel.incremental_time
09:15:09.826206 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.11 seconds
09:15:09.839138 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
09:15:09.839455 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT_NIGEL"."INCREMENTAL_TIME"
09:15:09.945298 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.11 seconds
09:15:09.966369 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
09:15:09.975380 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
09:15:09.975524 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
09:15:10.091276 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.12 seconds
09:15:10.092245 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
09:15:10.092532 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt_nigel.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt_nigel.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
09:15:10.791101 [debug] [Thread-1  ]: SQL status: SUCCESS 323 in 0.7 seconds
09:15:10.791825 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
09:15:10.792015 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
09:15:11.162274 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.37 seconds
09:15:11.166931 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
09:15:11.167178 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

        insert into dbt.audit (model, state, time) values ('incremental_time', 'ending model deployment', current_timestamp)
09:15:11.638700 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.47 seconds
09:15:11.653571 [debug] [Thread-1  ]: finished collecting timing info
09:15:11.653868 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
09:15:11.847915 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '47f96c54-9365-435f-a652-ffcf85c67498', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1094247f0>]}
09:15:11.848652 [info ] [Thread-1  ]: 1 of 6 OK created incremental model dbt_nigel.incremental_time.................. [[32mSUCCESS 1[0m in 5.13s]
09:15:11.849116 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
09:15:11.849369 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
09:15:11.849809 [info ] [Thread-1  ]: 2 of 6 START table model dbt_nigel.first_model.................................. [RUN]
09:15:11.850463 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
09:15:11.850676 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
09:15:11.850854 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
09:15:11.854556 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
09:15:11.856206 [debug] [Thread-1  ]: finished collecting timing info
09:15:11.856358 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
09:15:11.892725 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
09:15:11.892884 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('first_model', 'starting model deployment', current_timestamp)
09:15:11.892966 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:15:13.102038 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.21 seconds
09:15:13.105432 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
09:15:13.107648 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
09:15:13.107878 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt_nigel.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id, 'NJ' as state, '2020-02-01 00:01:00.000'::timestamp as updated_at
    union all
    select null as id, 'CT' as state, '2020-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select 3 as id, 'VT' as state, '2020-01-01 00:00:00.000'::timestamp as updated_at

)

select * 
from source_data


/*
select *, True as first_variable
from source_data
where id >= 1
*/
      );
09:15:13.825179 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.72 seconds
09:15:13.829999 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
09:15:13.830229 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('first_model', 'ending model deployment', current_timestamp)
09:15:14.354557 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.52 seconds
09:15:14.357663 [debug] [Thread-1  ]: finished collecting timing info
09:15:14.358060 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
09:15:14.520507 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '47f96c54-9365-435f-a652-ffcf85c67498', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109022730>]}
09:15:14.521109 [info ] [Thread-1  ]: 2 of 6 OK created table model dbt_nigel.first_model............................. [[32mSUCCESS 1[0m in 2.67s]
09:15:14.521552 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
09:15:14.521815 [debug] [Thread-1  ]: Began running node model.learn_dbt.playing_with_tests
09:15:14.522233 [info ] [Thread-1  ]: 3 of 6 START table model dbt_nigel.playing_with_tests........................... [RUN]
09:15:14.522979 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.playing_with_tests"
09:15:14.523247 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.playing_with_tests
09:15:14.523470 [debug] [Thread-1  ]: Compiling model.learn_dbt.playing_with_tests
09:15:14.527475 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.playing_with_tests"
09:15:14.528389 [debug] [Thread-1  ]: finished collecting timing info
09:15:14.528567 [debug] [Thread-1  ]: Began executing node model.learn_dbt.playing_with_tests
09:15:14.531827 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
09:15:14.531997 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */

        insert into dbt.audit (model, state, time) values ('playing_with_tests', 'starting model deployment', current_timestamp)
09:15:14.532123 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:15:15.770818 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.24 seconds
09:15:15.773600 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.playing_with_tests"
09:15:15.775354 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
09:15:15.775595 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */


      create or replace transient table analytics.dbt_nigel.playing_with_tests  as
      (WITH sample_customer AS (
select * 
from snowflake_sample_data.tpch_sf1.customer
)

select
  c_custkey,
  c_mktsegment,
  
  CASE
    WHEN '' in ('BUILDING', 'HOUSEHOLD', 'FURNITURE')
      THEN 'segment_1'
    ELSE 'segment_2'
  END
 mkt_segment_adjusted
from sample_customer
      );
09:15:16.705198 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.93 seconds
09:15:16.710076 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
09:15:16.710324 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */

        insert into dbt.audit (model, state, time) values ('playing_with_tests', 'ending model deployment', current_timestamp)
09:15:17.154792 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.44 seconds
09:15:17.157268 [debug] [Thread-1  ]: finished collecting timing info
09:15:17.157570 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: Close
09:15:17.325426 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '47f96c54-9365-435f-a652-ffcf85c67498', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109022eb0>]}
09:15:17.325973 [info ] [Thread-1  ]: 3 of 6 OK created table model dbt_nigel.playing_with_tests...................... [[32mSUCCESS 1[0m in 2.80s]
09:15:17.326242 [debug] [Thread-1  ]: Finished running node model.learn_dbt.playing_with_tests
09:15:17.326393 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
09:15:17.326693 [info ] [Thread-1  ]: 4 of 6 START table model dbt_nigel.snowflake_cumulative_sales................... [RUN]
09:15:17.327113 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
09:15:17.327244 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
09:15:17.327374 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
09:15:17.330241 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
09:15:17.330987 [debug] [Thread-1  ]: finished collecting timing info
09:15:17.331105 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
09:15:17.333322 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
09:15:17.333480 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */

        insert into dbt.audit (model, state, time) values ('snowflake_cumulative_sales', 'starting model deployment', current_timestamp)
09:15:17.333575 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:15:18.228050 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.89 seconds
09:15:18.230596 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
09:15:18.232310 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
09:15:18.232533 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt_nigel.snowflake_cumulative_sales  as
      (with orders as (
	select *
	from snowflake_sample_data.tpch_sf1.orders
)

select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from orders
order by o_orderdate
      );
09:15:19.559079 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.33 seconds
09:15:19.562789 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
09:15:19.562988 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */

        insert into dbt.audit (model, state, time) values ('snowflake_cumulative_sales', 'ending model deployment', current_timestamp)
09:15:20.071227 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.51 seconds
09:15:20.075493 [debug] [Thread-1  ]: finished collecting timing info
09:15:20.075930 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
09:15:20.248824 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '47f96c54-9365-435f-a652-ffcf85c67498', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1092af160>]}
09:15:20.249568 [info ] [Thread-1  ]: 4 of 6 OK created table model dbt_nigel.snowflake_cumulative_sales.............. [[32mSUCCESS 1[0m in 2.92s]
09:15:20.250016 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
09:15:20.250266 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
09:15:20.250676 [info ] [Thread-1  ]: 5 of 6 START table model dbt_nigel.snowflake_customer_purchases................. [RUN]
09:15:20.251339 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
09:15:20.251562 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
09:15:20.251784 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
09:15:20.256356 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
09:15:20.257385 [debug] [Thread-1  ]: finished collecting timing info
09:15:20.257573 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
09:15:20.260760 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
09:15:20.260936 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */

        insert into dbt.audit (model, state, time) values ('snowflake_customer_purchases', 'starting model deployment', current_timestamp)
09:15:20.261231 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:15:21.299990 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.04 seconds
09:15:21.303442 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
09:15:21.306712 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
09:15:21.306909 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt_nigel.snowflake_customer_purchases  as
      (with sample_customer as(
	select *
	from snowflake_sample_data.tpch_sf1.customer
),

sample_orders as (
	select * 
	from snowflake_sample_data.tpch_sf1.orders
)



select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from sample_customer c
left join sample_orders o
on c.c_custkey = o.o_custkey
group by 1,2,3
      );
09:15:22.426112 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.12 seconds
09:15:22.431210 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
09:15:22.431530 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */

        insert into dbt.audit (model, state, time) values ('snowflake_customer_purchases', 'ending model deployment', current_timestamp)
09:15:23.301276 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.87 seconds
09:15:23.303757 [debug] [Thread-1  ]: finished collecting timing info
09:15:23.304115 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
09:15:23.490697 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '47f96c54-9365-435f-a652-ffcf85c67498', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109062880>]}
09:15:23.491576 [info ] [Thread-1  ]: 5 of 6 OK created table model dbt_nigel.snowflake_customer_purchases............ [[32mSUCCESS 1[0m in 3.24s]
09:15:23.492060 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
09:15:23.492318 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
09:15:23.492742 [info ] [Thread-1  ]: 6 of 6 START table model dbt_nigel.my_second_dbt_model.......................... [RUN]
09:15:23.493411 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
09:15:23.493641 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
09:15:23.493857 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
09:15:23.497755 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
09:15:23.498619 [debug] [Thread-1  ]: finished collecting timing info
09:15:23.498802 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
09:15:23.501830 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
09:15:23.501982 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('my_second_dbt_model', 'starting model deployment', current_timestamp)
09:15:23.502095 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:15:24.481970 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.98 seconds
09:15:24.484390 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
09:15:24.485743 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
09:15:24.485874 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt_nigel.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt_nigel.first_model
/*
union all
select 7 as id, True as first_variable
*/
      );
09:15:25.191939 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.71 seconds
09:15:25.197422 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
09:15:25.197731 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('my_second_dbt_model', 'ending model deployment', current_timestamp)
09:15:25.703293 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.51 seconds
09:15:25.707180 [debug] [Thread-1  ]: finished collecting timing info
09:15:25.707578 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
09:15:25.895863 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '47f96c54-9365-435f-a652-ffcf85c67498', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1090984c0>]}
09:15:25.896467 [info ] [Thread-1  ]: 6 of 6 OK created table model dbt_nigel.my_second_dbt_model..................... [[32mSUCCESS 1[0m in 2.40s]
09:15:25.896841 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
09:15:25.898153 [debug] [MainThread]: Acquiring new snowflake connection "master"
09:15:25.898525 [info ] [MainThread]: 
09:15:25.898869 [info ] [MainThread]: Running 3 on-run-end hooks
09:15:25.899218 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-0
09:15:25.901076 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-0"
09:15:25.903699 [info ] [MainThread]: 1 of 3 START hook: learn_dbt.on-run-end.0....................................... [RUN]
09:15:25.904262 [debug] [MainThread]: Using snowflake connection "master"
09:15:25.904427 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
09:15:25.904573 [debug] [MainThread]: Opening a new connection, currently in state closed
09:15:26.647206 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.74 seconds
09:15:26.648932 [info ] [MainThread]: 1 of 3 OK hook: learn_dbt.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.74s]
09:15:26.649416 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-1
09:15:26.651417 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-1"
09:15:26.652706 [info ] [MainThread]: 2 of 3 START hook: learn_dbt.on-run-end.1....................................... [RUN]
09:15:26.653352 [debug] [MainThread]: Using snowflake connection "master"
09:15:26.653507 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
09:15:26.780509 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.13 seconds
09:15:26.783368 [info ] [MainThread]: 2 of 3 OK hook: learn_dbt.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.13s]
09:15:26.783932 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-2
09:15:26.787136 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-2"
09:15:26.789208 [info ] [MainThread]: 3 of 3 START hook: learn_dbt.on-run-end.2....................................... [RUN]
09:15:26.789731 [debug] [MainThread]: Using snowflake connection "master"
09:15:26.789874 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
09:15:26.894763 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.1 seconds
09:15:26.896943 [info ] [MainThread]: 3 of 3 OK hook: learn_dbt.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.11s]
09:15:26.897491 [info ] [MainThread]: 
09:15:26.898025 [debug] [MainThread]: On master: Close
09:15:27.059480 [info ] [MainThread]: 
09:15:27.060134 [info ] [MainThread]: Finished running 1 incremental model, 5 table models, 4 hooks in 23.89s.
09:15:27.060464 [debug] [MainThread]: Connection 'master' was properly closed.
09:15:27.060638 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
09:15:27.069304 [info ] [MainThread]: 
09:15:27.069639 [info ] [MainThread]: [32mCompleted successfully[0m
09:15:27.069939 [info ] [MainThread]: 
09:15:27.070166 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
09:15:27.070517 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108fd93a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108eda850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108f2f610>]}


============================== 2022-05-17 09:16:54.233508 | fee08c8d-9932-44b0-b07b-e51b127006d5 ==============================
09:16:54.233508 [info ] [MainThread]: Running with dbt=1.0.1
09:16:54.234522 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tag:nightly'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
09:16:54.234884 [debug] [MainThread]: Tracking: tracking
09:16:54.235331 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109823190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1098230a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109823b20>]}
09:16:54.269465 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
09:16:54.269687 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'fee08c8d-9932-44b0-b07b-e51b127006d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108d48ac0>]}
09:16:54.284669 [debug] [MainThread]: Parsing macros/suspend_warehouse.sql
09:16:54.285318 [debug] [MainThread]: Parsing macros/rename_segments.sql
09:16:54.285559 [debug] [MainThread]: Parsing macros/group_by.sql
09:16:54.286415 [debug] [MainThread]: Parsing macros/catalog.sql
09:16:54.287361 [debug] [MainThread]: Parsing macros/adapters.sql
09:16:54.306911 [debug] [MainThread]: Parsing macros/materializations/merge.sql
09:16:54.308814 [debug] [MainThread]: Parsing macros/materializations/seed.sql
09:16:54.311306 [debug] [MainThread]: Parsing macros/materializations/view.sql
09:16:54.311911 [debug] [MainThread]: Parsing macros/materializations/table.sql
09:16:54.313339 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
09:16:54.317416 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
09:16:54.317841 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
09:16:54.319585 [debug] [MainThread]: Parsing macros/materializations/configs.sql
09:16:54.320614 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
09:16:54.321365 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
09:16:54.329184 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
09:16:54.334745 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
09:16:54.340698 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
09:16:54.342832 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
09:16:54.343642 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
09:16:54.344464 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
09:16:54.346476 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
09:16:54.351887 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
09:16:54.352566 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
09:16:54.357646 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
09:16:54.365447 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
09:16:54.369173 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
09:16:54.370476 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
09:16:54.373994 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
09:16:54.374565 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
09:16:54.375791 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
09:16:54.376799 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
09:16:54.379634 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
09:16:54.388159 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
09:16:54.388948 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
09:16:54.390085 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
09:16:54.390825 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
09:16:54.391238 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
09:16:54.391480 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
09:16:54.391793 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
09:16:54.392415 [debug] [MainThread]: Parsing macros/etc/statement.sql
09:16:54.394731 [debug] [MainThread]: Parsing macros/etc/datetime.sql
09:16:54.399013 [debug] [MainThread]: Parsing macros/adapters/schema.sql
09:16:54.399995 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
09:16:54.401283 [debug] [MainThread]: Parsing macros/adapters/relation.sql
09:16:54.405724 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
09:16:54.407046 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
09:16:54.409054 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
09:16:54.412402 [debug] [MainThread]: Parsing macros/adapters/columns.sql
09:16:54.417172 [debug] [MainThread]: Parsing tests/generic/builtin.sql
09:16:54.508984 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
09:16:54.510880 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109820370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1098dae50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1098e2a00>]}


============================== 2022-05-17 09:17:21.607523 | fbb341ac-c12f-46d7-ad4f-dd5d9a48a498 ==============================
09:17:21.607523 [info ] [MainThread]: Running with dbt=1.0.1
09:17:21.608169 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tag:nightly'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
09:17:21.608297 [debug] [MainThread]: Tracking: tracking
09:17:21.608486 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106643d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106643cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1066439d0>]}
09:17:21.644469 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
09:17:21.644695 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'fbb341ac-c12f-46d7-ad4f-dd5d9a48a498', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1066498e0>]}
09:17:21.659263 [debug] [MainThread]: Parsing macros/suspend_warehouse.sql
09:17:21.659877 [debug] [MainThread]: Parsing macros/rename_segments.sql
09:17:21.660133 [debug] [MainThread]: Parsing macros/group_by.sql
09:17:21.660980 [debug] [MainThread]: Parsing macros/catalog.sql
09:17:21.661924 [debug] [MainThread]: Parsing macros/adapters.sql
09:17:21.681031 [debug] [MainThread]: Parsing macros/materializations/merge.sql
09:17:21.682829 [debug] [MainThread]: Parsing macros/materializations/seed.sql
09:17:21.685261 [debug] [MainThread]: Parsing macros/materializations/view.sql
09:17:21.685860 [debug] [MainThread]: Parsing macros/materializations/table.sql
09:17:21.687260 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
09:17:21.691300 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
09:17:21.691724 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
09:17:21.693438 [debug] [MainThread]: Parsing macros/materializations/configs.sql
09:17:21.694462 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
09:17:21.695199 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
09:17:21.702905 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
09:17:21.708378 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
09:17:21.714181 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
09:17:21.716323 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
09:17:21.717194 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
09:17:21.717998 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
09:17:21.720096 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
09:17:21.725553 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
09:17:21.726233 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
09:17:21.731128 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
09:17:21.738790 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
09:17:21.742504 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
09:17:21.743772 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
09:17:21.747385 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
09:17:21.748011 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
09:17:21.749265 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
09:17:21.750282 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
09:17:21.753109 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
09:17:21.761049 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
09:17:21.761713 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
09:17:21.762798 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
09:17:21.763486 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
09:17:21.763887 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
09:17:21.764116 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
09:17:21.764413 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
09:17:21.765014 [debug] [MainThread]: Parsing macros/etc/statement.sql
09:17:21.767014 [debug] [MainThread]: Parsing macros/etc/datetime.sql
09:17:21.771085 [debug] [MainThread]: Parsing macros/adapters/schema.sql
09:17:21.772015 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
09:17:21.773202 [debug] [MainThread]: Parsing macros/adapters/relation.sql
09:17:21.777529 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
09:17:21.778800 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
09:17:21.780765 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
09:17:21.784053 [debug] [MainThread]: Parsing macros/adapters/columns.sql
09:17:21.788521 [debug] [MainThread]: Parsing tests/generic/builtin.sql
09:17:21.876748 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
09:17:21.883838 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
09:17:21.884593 [debug] [MainThread]: 1603: static parser failed on example/playing_with_tests.sql
09:17:21.887081 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/playing_with_tests.sql
09:17:21.887669 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_cumulative_sales.sql
09:17:21.889732 [debug] [MainThread]: 1603: static parser failed on example/my_second_dbt_model.sql
09:17:21.891737 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_second_dbt_model.sql
09:17:21.892301 [debug] [MainThread]: 1603: static parser failed on example/incremental_time.sql
09:17:21.896128 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_time.sql
09:17:21.896721 [debug] [MainThread]: 1603: static parser failed on example/snowflake_customer_purchases.sql
09:17:21.900099 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/snowflake_customer_purchases.sql
09:17:21.900554 [debug] [MainThread]: 1603: static parser failed on new/dates.sql
09:17:21.902045 [debug] [MainThread]: 1602: parser fallback to jinja rendering on new/dates.sql
09:17:21.966353 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'fbb341ac-c12f-46d7-ad4f-dd5d9a48a498', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068590d0>]}
09:17:21.969762 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'fbb341ac-c12f-46d7-ad4f-dd5d9a48a498', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10677ad60>]}
09:17:21.969945 [info ] [MainThread]: Found 7 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
09:17:21.970533 [info ] [MainThread]: 
09:17:21.970733 [debug] [MainThread]: Acquiring new snowflake connection "master"
09:17:21.971035 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
09:17:21.976683 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
09:17:21.976815 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
09:17:21.976912 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:17:22.763702 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 0.79 seconds
09:17:22.766955 [debug] [ThreadPool]: On list_analytics: Close
09:17:22.930357 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snaphots"
09:17:22.939354 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snaphots"
09:17:22.939583 [debug] [ThreadPool]: On list_analytics_snaphots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snaphots"} */

    show terse objects in analytics.snaphots
09:17:22.939745 [debug] [ThreadPool]: Opening a new connection, currently in state closed
09:17:23.792684 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.85 seconds
09:17:23.795379 [debug] [ThreadPool]: On list_analytics_snaphots: Close
09:17:23.958756 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt_nigel"
09:17:23.959885 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt_nigel"
09:17:23.959996 [debug] [ThreadPool]: On list_analytics_dbt_nigel: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt_nigel"} */

    show terse objects in analytics.dbt_nigel
09:17:23.960074 [debug] [ThreadPool]: Opening a new connection, currently in state closed
09:17:24.462104 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 0.5 seconds
09:17:24.463905 [debug] [ThreadPool]: On list_analytics_dbt_nigel: Close
09:17:24.629100 [info ] [MainThread]: 
09:17:24.629657 [info ] [MainThread]: Running 1 on-run-start hook
09:17:24.629969 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-start-0
09:17:24.631607 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-start-0"
09:17:24.633521 [info ] [MainThread]: 1 of 1 START hook: learn_dbt.on-run-start.0..................................... [RUN]
09:17:24.634132 [debug] [MainThread]: Using snowflake connection "master"
09:17:24.634314 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
09:17:24.634460 [debug] [MainThread]: Opening a new connection, currently in state init
09:17:25.144697 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.51 seconds
09:17:25.146139 [info ] [MainThread]: 1 of 1 OK hook: learn_dbt.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.51s]
09:17:25.146634 [info ] [MainThread]: 
09:17:25.146953 [debug] [MainThread]: On master: Close
09:17:25.326358 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
09:17:25.326731 [info ] [MainThread]: 
09:17:25.329847 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
09:17:25.330073 [info ] [Thread-1  ]: 1 of 1 START table model dbt_nigel.first_model.................................. [RUN]
09:17:25.330439 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
09:17:25.330624 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
09:17:25.330730 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
09:17:25.332967 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
09:17:25.333337 [debug] [Thread-1  ]: finished collecting timing info
09:17:25.333431 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
09:17:25.343299 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
09:17:25.343408 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('first_model', 'starting model deployment', current_timestamp)
09:17:25.343482 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:17:26.913224 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.57 seconds
09:17:26.934640 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
09:17:26.937925 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
09:17:26.938216 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt_nigel.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id, 'NJ' as state, '2020-02-01 00:01:00.000'::timestamp as updated_at
    union all
    select null as id, 'CT' as state, '2020-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select 3 as id, 'VT' as state, '2020-01-01 00:00:00.000'::timestamp as updated_at

)

select * 
from source_data


/*
select *, True as first_variable
from source_data
where id >= 1
*/
      );
09:17:27.670983 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.73 seconds
09:17:27.682857 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
09:17:27.683527 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('first_model', 'ending model deployment', current_timestamp)
09:17:28.225138 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.54 seconds
09:17:28.249054 [debug] [Thread-1  ]: finished collecting timing info
09:17:28.249330 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
09:17:28.419053 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fbb341ac-c12f-46d7-ad4f-dd5d9a48a498', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108934f70>]}
09:17:28.419793 [info ] [Thread-1  ]: 1 of 1 OK created table model dbt_nigel.first_model............................. [[32mSUCCESS 1[0m in 3.09s]
09:17:28.420244 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
09:17:28.433240 [debug] [MainThread]: Acquiring new snowflake connection "master"
09:17:28.433573 [info ] [MainThread]: 
09:17:28.433903 [info ] [MainThread]: Running 3 on-run-end hooks
09:17:28.434086 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-0
09:17:28.434954 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-0"
09:17:28.436910 [info ] [MainThread]: 1 of 3 START hook: learn_dbt.on-run-end.0....................................... [RUN]
09:17:28.437364 [debug] [MainThread]: Using snowflake connection "master"
09:17:28.437473 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
09:17:28.437560 [debug] [MainThread]: Opening a new connection, currently in state closed
09:17:28.953985 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.52 seconds
09:17:28.956612 [info ] [MainThread]: 1 of 3 OK hook: learn_dbt.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.52s]
09:17:28.957523 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-1
09:17:28.969404 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-1"
09:17:28.970668 [info ] [MainThread]: 2 of 3 START hook: learn_dbt.on-run-end.1....................................... [RUN]
09:17:28.971210 [debug] [MainThread]: Using snowflake connection "master"
09:17:28.971355 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
09:17:29.110231 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.14 seconds
09:17:29.113074 [info ] [MainThread]: 2 of 3 OK hook: learn_dbt.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.14s]
09:17:29.114161 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-2
09:17:29.120409 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-2"
09:17:29.124839 [info ] [MainThread]: 3 of 3 START hook: learn_dbt.on-run-end.2....................................... [RUN]
09:17:29.125735 [debug] [MainThread]: Using snowflake connection "master"
09:17:29.125993 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
09:17:29.279378 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.15 seconds
09:17:29.282384 [info ] [MainThread]: 3 of 3 OK hook: learn_dbt.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.16s]
09:17:29.283011 [info ] [MainThread]: 
09:17:29.283415 [debug] [MainThread]: On master: Close
09:17:29.462816 [info ] [MainThread]: 
09:17:29.463406 [info ] [MainThread]: Finished running 1 table model, 4 hooks in 7.49s.
09:17:29.463840 [debug] [MainThread]: Connection 'master' was properly closed.
09:17:29.464159 [debug] [MainThread]: Connection 'model.learn_dbt.my_first_dbt_model' was properly closed.
09:17:29.509221 [info ] [MainThread]: 
09:17:29.509558 [info ] [MainThread]: [32mCompleted successfully[0m
09:17:29.509834 [info ] [MainThread]: 
09:17:29.510064 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
09:17:29.510291 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106a752e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b119a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106629130>]}


============================== 2022-05-17 09:18:43.948784 | 690fdb8f-e4d5-4f92-a9a9-d51eb041f46b ==============================
09:18:43.948784 [info ] [MainThread]: Running with dbt=1.0.1
09:18:43.949419 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['tag:example'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
09:18:43.949558 [debug] [MainThread]: Tracking: tracking
09:18:43.949802 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1092931c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1092934c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109293c10>]}
09:18:43.997066 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
09:18:43.997444 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/my_first_dbt_model.sql
09:18:44.003516 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
09:18:44.011148 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
09:18:44.024107 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '690fdb8f-e4d5-4f92-a9a9-d51eb041f46b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1094320d0>]}
09:18:44.028049 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '690fdb8f-e4d5-4f92-a9a9-d51eb041f46b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109268ca0>]}
09:18:44.028285 [info ] [MainThread]: Found 7 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
09:18:44.028962 [info ] [MainThread]: 
09:18:44.029187 [debug] [MainThread]: Acquiring new snowflake connection "master"
09:18:44.029542 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
09:18:44.035365 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
09:18:44.035456 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
09:18:44.035520 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:18:44.838461 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 0.8 seconds
09:18:44.839877 [debug] [ThreadPool]: On list_analytics: Close
09:18:45.001109 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snaphots"
09:18:45.009499 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snaphots"
09:18:45.009772 [debug] [ThreadPool]: On list_analytics_snaphots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snaphots"} */

    show terse objects in analytics.snaphots
09:18:45.009945 [debug] [ThreadPool]: Opening a new connection, currently in state closed
09:18:45.777762 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.77 seconds
09:18:45.781411 [debug] [ThreadPool]: On list_analytics_snaphots: Close
09:18:45.952933 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt_nigel"
09:18:45.955306 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt_nigel"
09:18:45.955565 [debug] [ThreadPool]: On list_analytics_dbt_nigel: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt_nigel"} */

    show terse objects in analytics.dbt_nigel
09:18:45.955764 [debug] [ThreadPool]: Opening a new connection, currently in state closed
09:18:46.478182 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 0.52 seconds
09:18:46.480960 [debug] [ThreadPool]: On list_analytics_dbt_nigel: Close
09:18:46.652338 [info ] [MainThread]: 
09:18:46.652944 [info ] [MainThread]: Running 1 on-run-start hook
09:18:46.653335 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-start-0
09:18:46.655204 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-start-0"
09:18:46.658094 [info ] [MainThread]: 1 of 1 START hook: learn_dbt.on-run-start.0..................................... [RUN]
09:18:46.658674 [debug] [MainThread]: Using snowflake connection "master"
09:18:46.658829 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
09:18:46.658968 [debug] [MainThread]: Opening a new connection, currently in state init
09:18:47.191052 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.53 seconds
09:18:47.193813 [info ] [MainThread]: 1 of 1 OK hook: learn_dbt.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.54s]
09:18:47.194373 [info ] [MainThread]: 
09:18:47.194744 [debug] [MainThread]: On master: Close
09:18:47.366721 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
09:18:47.367469 [info ] [MainThread]: 
09:18:47.373331 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
09:18:47.373738 [info ] [Thread-1  ]: 1 of 1 START table model dbt_nigel.first_model.................................. [RUN]
09:18:47.374261 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
09:18:47.374442 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
09:18:47.374622 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
09:18:47.378745 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
09:18:47.379701 [debug] [Thread-1  ]: finished collecting timing info
09:18:47.379946 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
09:18:47.394387 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
09:18:47.394540 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('first_model', 'starting model deployment', current_timestamp)
09:18:47.394641 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:18:48.838888 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.44 seconds
09:18:48.849178 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
09:18:48.851058 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
09:18:48.851150 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt_nigel.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id, 'NJ' as state, '2020-02-01 00:01:00.000'::timestamp as updated_at
    union all
    select null as id, 'CT' as state, '2020-01-01 00:00:00.000'::timestamp as updated_at
    union all
    select 3 as id, 'VT' as state, '2020-01-01 00:00:00.000'::timestamp as updated_at

)

select * 
from source_data


/*
select *, True as first_variable
from source_data
where id >= 1
*/
      );
09:18:50.164979 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.31 seconds
09:18:50.167785 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
09:18:50.167937 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */

        insert into dbt.audit (model, state, time) values ('first_model', 'ending model deployment', current_timestamp)
09:18:50.961823 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.79 seconds
09:18:50.975205 [debug] [Thread-1  ]: finished collecting timing info
09:18:50.975553 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
09:18:51.136766 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '690fdb8f-e4d5-4f92-a9a9-d51eb041f46b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c1159a0>]}
09:18:51.137412 [info ] [Thread-1  ]: 1 of 1 OK created table model dbt_nigel.first_model............................. [[32mSUCCESS 1[0m in 3.76s]
09:18:51.137697 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
09:18:51.138612 [debug] [MainThread]: Acquiring new snowflake connection "master"
09:18:51.138857 [info ] [MainThread]: 
09:18:51.139054 [info ] [MainThread]: Running 3 on-run-end hooks
09:18:51.139255 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-0
09:18:51.140504 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-0"
09:18:51.141583 [info ] [MainThread]: 1 of 3 START hook: learn_dbt.on-run-end.0....................................... [RUN]
09:18:51.141939 [debug] [MainThread]: Using snowflake connection "master"
09:18:51.142042 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
09:18:51.142134 [debug] [MainThread]: Opening a new connection, currently in state closed
09:18:51.642232 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.5 seconds
09:18:51.644454 [info ] [MainThread]: 1 of 3 OK hook: learn_dbt.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.50s]
09:18:51.644935 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-1
09:18:51.646773 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-1"
09:18:51.647722 [info ] [MainThread]: 2 of 3 START hook: learn_dbt.on-run-end.1....................................... [RUN]
09:18:51.648493 [debug] [MainThread]: Using snowflake connection "master"
09:18:51.648669 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
09:18:51.786950 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.14 seconds
09:18:51.789931 [info ] [MainThread]: 2 of 3 OK hook: learn_dbt.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.14s]
09:18:51.790547 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-2
09:18:51.792965 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-2"
09:18:51.794245 [info ] [MainThread]: 3 of 3 START hook: learn_dbt.on-run-end.2....................................... [RUN]
09:18:51.794894 [debug] [MainThread]: Using snowflake connection "master"
09:18:51.795061 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
09:18:51.913971 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.12 seconds
09:18:51.915629 [info ] [MainThread]: 3 of 3 OK hook: learn_dbt.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.12s]
09:18:51.916096 [info ] [MainThread]: 
09:18:51.916420 [debug] [MainThread]: On master: Close
09:18:52.149576 [info ] [MainThread]: 
09:18:52.150300 [info ] [MainThread]: Finished running 1 table model, 4 hooks in 8.12s.
09:18:52.150646 [debug] [MainThread]: Connection 'master' was properly closed.
09:18:52.151056 [debug] [MainThread]: Connection 'model.learn_dbt.my_first_dbt_model' was properly closed.
09:18:52.159874 [info ] [MainThread]: 
09:18:52.160237 [info ] [MainThread]: [32mCompleted successfully[0m
09:18:52.160496 [info ] [MainThread]: 
09:18:52.160693 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
09:18:52.161001 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c12ab80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c12a070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c12abe0>]}


============================== 2022-05-17 09:24:21.265125 | 5faf97db-9738-406b-a4ff-03d9ab8cb09f ==============================
09:24:21.265125 [info ] [MainThread]: Running with dbt=1.0.1
09:24:21.266051 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['snowflake_cumulative_sales'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
09:24:21.266277 [debug] [MainThread]: Tracking: tracking
09:24:21.267029 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1061b1e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1061b1a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1061b1d30>]}
09:24:21.314524 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
09:24:21.314894 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/snowflake_cumulative_sales.sql
09:24:21.321830 [debug] [MainThread]: 1603: static parser failed on example/snowflake_cumulative_sales.sql
09:24:21.329399 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/snowflake_cumulative_sales.sql
09:24:21.344178 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5faf97db-9738-406b-a4ff-03d9ab8cb09f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1063470d0>]}
09:24:21.347805 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5faf97db-9738-406b-a4ff-03d9ab8cb09f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10618d880>]}
09:24:21.347994 [info ] [MainThread]: Found 7 models, 12 tests, 1 snapshot, 0 analyses, 182 macros, 4 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
09:24:21.348654 [info ] [MainThread]: 
09:24:21.348865 [debug] [MainThread]: Acquiring new snowflake connection "master"
09:24:21.349210 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
09:24:21.355141 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
09:24:21.355265 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
09:24:21.355334 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:24:22.140036 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 0.78 seconds
09:24:22.141258 [debug] [ThreadPool]: On list_analytics: Close
09:24:22.301231 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_snaphots"
09:24:22.310195 [debug] [ThreadPool]: Using snowflake connection "list_analytics_snaphots"
09:24:22.310428 [debug] [ThreadPool]: On list_analytics_snaphots: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_snaphots"} */

    show terse objects in analytics.snaphots
09:24:22.310589 [debug] [ThreadPool]: Opening a new connection, currently in state closed
09:24:22.815255 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.5 seconds
09:24:22.818593 [debug] [ThreadPool]: On list_analytics_snaphots: Close
09:24:23.064087 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt_nigel"
09:24:23.066898 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt_nigel"
09:24:23.067098 [debug] [ThreadPool]: On list_analytics_dbt_nigel: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt_nigel"} */

    show terse objects in analytics.dbt_nigel
09:24:23.067180 [debug] [ThreadPool]: Opening a new connection, currently in state closed
09:24:23.850210 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 0.78 seconds
09:24:23.853434 [debug] [ThreadPool]: On list_analytics_dbt_nigel: Close
09:24:24.028685 [info ] [MainThread]: 
09:24:24.029469 [info ] [MainThread]: Running 1 on-run-start hook
09:24:24.029868 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-start-0
09:24:24.031943 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-start-0"
09:24:24.034243 [info ] [MainThread]: 1 of 1 START hook: learn_dbt.on-run-start.0..................................... [RUN]
09:24:24.034857 [debug] [MainThread]: Using snowflake connection "master"
09:24:24.035022 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
create table if not exists audit (model text, state text, time timestamp_ltz)
09:24:24.035170 [debug] [MainThread]: Opening a new connection, currently in state init
09:24:24.565941 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.53 seconds
09:24:24.567067 [info ] [MainThread]: 1 of 1 OK hook: learn_dbt.on-run-start.0........................................ [[32mSUCCESS 1[0m in 0.53s]
09:24:24.567367 [info ] [MainThread]: 
09:24:24.567585 [debug] [MainThread]: On master: Close
09:24:24.725918 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
09:24:24.726367 [info ] [MainThread]: 
09:24:24.729568 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
09:24:24.729801 [info ] [Thread-1  ]: 1 of 1 START table model dbt_nigel.snowflake_cumulative_sales................... [RUN]
09:24:24.730305 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
09:24:24.730516 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
09:24:24.730707 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
09:24:24.735308 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
09:24:24.736307 [debug] [Thread-1  ]: finished collecting timing info
09:24:24.736498 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
09:24:24.752408 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
09:24:24.752565 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */

        insert into dbt.audit (model, state, time) values ('snowflake_cumulative_sales', 'starting model deployment', current_timestamp)
09:24:24.752681 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:24:26.292254 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.54 seconds
09:24:26.300864 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
09:24:26.301691 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
09:24:26.301803 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt_nigel.snowflake_cumulative_sales  as
      (with orders as (
	select *
	from snowflake_sample_data.tpch_sf1.orders
)

select distinct
  o_orderdate 
, sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from orders


where year(o_orderdate) = 1996



order by o_orderdate
      );
09:24:27.474460 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.17 seconds
09:24:27.477607 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
09:24:27.477746 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */

        insert into dbt.audit (model, state, time) values ('snowflake_cumulative_sales', 'ending model deployment', current_timestamp)
09:24:27.892965 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.42 seconds
09:24:27.907187 [debug] [Thread-1  ]: finished collecting timing info
09:24:27.907656 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
09:24:28.099310 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5faf97db-9738-406b-a4ff-03d9ab8cb09f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107917a00>]}
09:24:28.100646 [info ] [Thread-1  ]: 1 of 1 OK created table model dbt_nigel.snowflake_cumulative_sales.............. [[32mSUCCESS 1[0m in 3.37s]
09:24:28.101286 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
09:24:28.102711 [debug] [MainThread]: Acquiring new snowflake connection "master"
09:24:28.103037 [info ] [MainThread]: 
09:24:28.103356 [info ] [MainThread]: Running 3 on-run-end hooks
09:24:28.103688 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-0
09:24:28.105583 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-0"
09:24:28.106820 [info ] [MainThread]: 1 of 3 START hook: learn_dbt.on-run-end.0....................................... [RUN]
09:24:28.107389 [debug] [MainThread]: Using snowflake connection "master"
09:24:28.107547 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant usage on schema analytics.dbt to role analyst
09:24:28.107692 [debug] [MainThread]: Opening a new connection, currently in state closed
09:24:28.611820 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.5 seconds
09:24:28.613857 [info ] [MainThread]: 1 of 3 OK hook: learn_dbt.on-run-end.0.......................................... [[32mSUCCESS 1[0m in 0.51s]
09:24:28.614394 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-1
09:24:28.616472 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-1"
09:24:28.617805 [info ] [MainThread]: 2 of 3 START hook: learn_dbt.on-run-end.1....................................... [RUN]
09:24:28.618408 [debug] [MainThread]: Using snowflake connection "master"
09:24:28.618574 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all tables in schema analytics.dbt to role analyst
09:24:28.781823 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.16 seconds
09:24:28.783363 [info ] [MainThread]: 2 of 3 OK hook: learn_dbt.on-run-end.1.......................................... [[32mSUCCESS 1[0m in 0.17s]
09:24:28.783692 [debug] [MainThread]: Compiling operation.learn_dbt.learn_dbt-on-run-end-2
09:24:28.784698 [debug] [MainThread]: Writing injected SQL for node "operation.learn_dbt.learn_dbt-on-run-end-2"
09:24:28.785229 [info ] [MainThread]: 3 of 3 START hook: learn_dbt.on-run-end.2....................................... [RUN]
09:24:28.785545 [debug] [MainThread]: Using snowflake connection "master"
09:24:28.785636 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "master"} */
grant select on all views in schema analytics.dbt to role analyst
09:24:28.886735 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.1 seconds
09:24:28.889037 [info ] [MainThread]: 3 of 3 OK hook: learn_dbt.on-run-end.2.......................................... [[32mSUCCESS 1[0m in 0.10s]
09:24:28.889663 [info ] [MainThread]: 
09:24:28.890034 [debug] [MainThread]: On master: Close
09:24:29.061621 [info ] [MainThread]: 
09:24:29.062318 [info ] [MainThread]: Finished running 1 table model, 4 hooks in 7.71s.
09:24:29.062669 [debug] [MainThread]: Connection 'master' was properly closed.
09:24:29.062750 [debug] [MainThread]: Connection 'model.learn_dbt.snowflake_cumulative_sales' was properly closed.
09:24:29.068723 [info ] [MainThread]: 
09:24:29.069042 [info ] [MainThread]: [32mCompleted successfully[0m
09:24:29.069333 [info ] [MainThread]: 
09:24:29.069563 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
09:24:29.069880 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1065ecbe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1065ecac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1065ecf40>]}
