

============================== 2022-05-12 17:07:07.125229 | 47baacbd-99ea-4c78-b5d1-9a8fdd35f24a ==============================
17:07:07.125229 [info ] [MainThread]: Running with dbt=1.0.1
17:07:07.125437 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, project_name='learn-dbt', skip_profile_setup=False, defer=None, state=None, cls=<class 'dbt.task.init.InitTask'>, which='init', rpc_method=None)
17:07:07.125520 [debug] [MainThread]: Tracking: tracking
17:07:07.141291 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10797fe50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079ab7c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079ab1f0>]}
17:07:07.142442 [debug] [MainThread]: Starter project path: /opt/homebrew/Cellar/dbt-snowflake/1.0.0_1/libexec/lib/python3.9/site-packages/dbt/include/starter_project
08:01:39.980641 [info ] [MainThread]: Profile learn-dbt written to /Users/nigelbrown/.dbt/profiles.yml using target's profile_template.yml and your supplied values. Run 'dbt debug' to validate the connection.
08:01:39.985085 [info ] [MainThread]: 
Your new dbt project "learn-dbt" was created!

For more information on how to configure the profiles.yml file,
please consult the dbt documentation here:

  https://docs.getdbt.com/docs/configure-your-profile

One more thing:

Need help? Don't hesitate to reach out to us via GitHub issues or on Slack:

  https://community.getdbt.com/

Happy modeling!

08:01:39.986728 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10798c370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10798c190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10798c910>]}


============================== 2022-05-13 08:06:38.926001 | 62e784e7-e185-4ec5-94dd-2d0f94150f4c ==============================
08:06:38.926001 [info ] [MainThread]: Running with dbt=1.0.1
08:06:38.926191 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, config_dir=True, defer=None, state=None, cls=<class 'dbt.task.debug.DebugTask'>, which='debug', rpc_method=None)
08:06:38.926274 [debug] [MainThread]: Tracking: tracking
08:06:38.946532 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105cfbee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105cfbe50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105cfbfd0>]}
08:06:38.947618 [info ] [MainThread]: To view your profiles.yml file, run:

open /Users/nigelbrown/.dbt
08:06:38.947937 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105cfbf40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105cfb7f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105cbfb20>]}


============================== 2022-05-13 08:23:45.322453 | 812aa8a3-1c32-456a-b70e-52a6d0b08f2e ==============================
08:23:45.322453 [info ] [MainThread]: Running with dbt=1.0.1
08:23:45.322833 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, config_dir=False, defer=None, state=None, cls=<class 'dbt.task.debug.DebugTask'>, which='debug', rpc_method=None)
08:23:45.322956 [debug] [MainThread]: Tracking: tracking
08:23:45.337227 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d2d220>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105bd4d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105bd4400>]}
08:23:45.339321 [debug] [MainThread]: Executing "git --help"
08:23:45.356654 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--super-prefix=<path>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
08:23:45.357115 [debug] [MainThread]: STDERR: "b''"
08:23:45.357525 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d05c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d05c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d05190>]}


============================== 2022-05-13 08:35:22.710985 | cfc1122d-12bf-4662-abc5-5f25ffc3481d ==============================
08:35:22.710985 [info ] [MainThread]: Running with dbt=1.0.1
08:35:22.711179 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, config_dir=True, defer=None, state=None, cls=<class 'dbt.task.debug.DebugTask'>, which='debug', rpc_method=None)
08:35:22.711261 [debug] [MainThread]: Tracking: tracking
08:35:22.725769 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10688d220>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106854fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106854af0>]}
08:35:22.726457 [info ] [MainThread]: To view your profiles.yml file, run:

open /Users/nigelbrown/.dbt
08:35:22.726706 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106854d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106854df0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106854400>]}


============================== 2022-05-13 08:36:41.151161 | 1fa27abb-7d55-4a41-bce3-a5f71fccd934 ==============================
08:36:41.151161 [info ] [MainThread]: Running with dbt=1.0.1
08:36:41.151359 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, config_dir=False, defer=None, state=None, cls=<class 'dbt.task.debug.DebugTask'>, which='debug', rpc_method=None)
08:36:41.151491 [debug] [MainThread]: Tracking: tracking
08:36:41.161946 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079edb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079b4cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079b4d00>]}
08:36:41.167374 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079c7ca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079c4fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079c49a0>]}


============================== 2022-05-13 08:38:53.312621 | 5d3770fe-5bab-4e96-9f08-884e99361c79 ==============================
08:38:53.312621 [info ] [MainThread]: Running with dbt=1.0.1
08:38:53.312956 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, config_dir=False, defer=None, state=None, cls=<class 'dbt.task.debug.DebugTask'>, which='debug', rpc_method=None)
08:38:53.313053 [debug] [MainThread]: Tracking: tracking
08:38:53.326578 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105cd1b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105c98cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105c98d00>]}
08:38:53.332642 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105cabca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ca8fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ca89a0>]}


============================== 2022-05-13 08:39:32.561209 | fe429ea6-6bf7-4a1f-8fd0-acdb4d12452b ==============================
08:39:32.561209 [info ] [MainThread]: Running with dbt=1.0.1
08:39:32.561396 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, config_dir=False, defer=None, state=None, cls=<class 'dbt.task.debug.DebugTask'>, which='debug', rpc_method=None)
08:39:32.561475 [debug] [MainThread]: Tracking: tracking
08:39:32.571481 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e28d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e28130>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e14d60>]}
08:39:32.785124 [debug] [MainThread]: Executing "git --help"
08:39:32.800317 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--super-prefix=<path>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
08:39:32.800778 [debug] [MainThread]: STDERR: "b''"
08:39:32.806956 [debug] [MainThread]: Acquiring new snowflake connection "debug"
08:39:32.808166 [debug] [MainThread]: Using snowflake connection "debug"
08:39:32.808254 [debug] [MainThread]: On debug: select 1 as id
08:39:32.808330 [debug] [MainThread]: Opening a new connection, currently in state init
08:39:34.365745 [debug] [MainThread]: SQL status: SUCCESS 1 in 1.56 seconds
08:39:34.367769 [debug] [MainThread]: On debug: Close
08:39:34.667422 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105b86ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e280a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e28880>]}
08:39:35.547265 [debug] [MainThread]: Connection 'debug' was properly closed.


============================== 2022-05-13 08:42:53.845517 | 1395b417-50c3-433a-9d0e-cf01cb608eb8 ==============================
08:42:53.845517 [info ] [MainThread]: Running with dbt=1.0.1
08:42:53.845833 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, config_dir=False, defer=None, state=None, cls=<class 'dbt.task.debug.DebugTask'>, which='debug', rpc_method=None)
08:42:53.845916 [debug] [MainThread]: Tracking: tracking
08:42:53.860412 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067c39d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067c3fa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067c3e50>]}
08:42:54.068805 [debug] [MainThread]: Executing "git --help"
08:42:54.081592 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--super-prefix=<path>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
08:42:54.082104 [debug] [MainThread]: STDERR: "b''"
08:42:54.085855 [debug] [MainThread]: Acquiring new snowflake connection "debug"
08:42:54.086833 [debug] [MainThread]: Using snowflake connection "debug"
08:42:54.086942 [debug] [MainThread]: On debug: select 1 as id
08:42:54.087033 [debug] [MainThread]: Opening a new connection, currently in state init
08:42:55.063438 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.98 seconds
08:42:55.065249 [debug] [MainThread]: On debug: Close
08:42:55.329348 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1073a05b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1073a0670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1073970a0>]}
08:42:55.981829 [debug] [MainThread]: Connection 'debug' was properly closed.


============================== 2022-05-13 08:44:29.879832 | 2b26ca51-6616-4ab2-9e7d-245ab2c90ef0 ==============================
08:44:29.879832 [info ] [MainThread]: Running with dbt=1.0.1
08:44:29.880214 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
08:44:29.880318 [debug] [MainThread]: Tracking: tracking
08:44:29.880524 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11161bfa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11161bf40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11161bbb0>]}
08:44:29.887803 [info ] [MainThread]: Partial parse save file not found. Starting full parse.
08:44:29.887959 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '2b26ca51-6616-4ab2-9e7d-245ab2c90ef0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11165d2b0>]}
08:44:29.900263 [debug] [MainThread]: Parsing macros/catalog.sql
08:44:29.901731 [debug] [MainThread]: Parsing macros/adapters.sql
08:44:29.923022 [debug] [MainThread]: Parsing macros/materializations/merge.sql
08:44:29.924882 [debug] [MainThread]: Parsing macros/materializations/seed.sql
08:44:29.927280 [debug] [MainThread]: Parsing macros/materializations/view.sql
08:44:29.927892 [debug] [MainThread]: Parsing macros/materializations/table.sql
08:44:29.929333 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
08:44:29.933233 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
08:44:29.933648 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
08:44:29.935336 [debug] [MainThread]: Parsing macros/materializations/configs.sql
08:44:29.936344 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
08:44:29.937087 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
08:44:29.945530 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
08:44:29.951703 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
08:44:29.980328 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
08:44:29.982627 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
08:44:29.983619 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
08:44:29.984486 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
08:44:29.986540 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
08:44:29.991996 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
08:44:29.992680 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
08:44:29.997568 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
08:44:30.005230 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
08:44:30.008880 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
08:44:30.010271 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
08:44:30.014006 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
08:44:30.014614 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
08:44:30.015844 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
08:44:30.016875 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
08:44:30.019695 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
08:44:30.027793 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
08:44:30.028531 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
08:44:30.029655 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
08:44:30.030382 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
08:44:30.030796 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
08:44:30.031037 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
08:44:30.031342 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
08:44:30.031956 [debug] [MainThread]: Parsing macros/etc/statement.sql
08:44:30.033971 [debug] [MainThread]: Parsing macros/etc/datetime.sql
08:44:30.037965 [debug] [MainThread]: Parsing macros/adapters/schema.sql
08:44:30.038915 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
08:44:30.040107 [debug] [MainThread]: Parsing macros/adapters/relation.sql
08:44:30.044812 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
08:44:30.046227 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
08:44:30.048221 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
08:44:30.051589 [debug] [MainThread]: Parsing macros/adapters/columns.sql
08:44:30.056245 [debug] [MainThread]: Parsing tests/generic/builtin.sql
08:44:30.150335 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
08:44:30.155985 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
08:44:30.179913 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2b26ca51-6616-4ab2-9e7d-245ab2c90ef0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11173f040>]}
08:44:30.182575 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2b26ca51-6616-4ab2-9e7d-245ab2c90ef0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11173f280>]}
08:44:30.182702 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
08:44:30.183239 [info ] [MainThread]: 
08:44:30.183442 [debug] [MainThread]: Acquiring new snowflake connection "master"
08:44:30.183805 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
08:44:30.189814 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
08:44:30.189918 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
08:44:30.189981 [debug] [ThreadPool]: Opening a new connection, currently in state init
08:44:31.530954 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1.34 seconds
08:44:31.533971 [debug] [ThreadPool]: On list_analytics: Close
08:44:31.924504 [debug] [ThreadPool]: Acquiring new snowflake connection "create_analytics_dbt"
08:44:31.925259 [debug] [ThreadPool]: Acquiring new snowflake connection "create_analytics_dbt"
08:44:31.925694 [debug] [ThreadPool]: Creating schema "_ReferenceKey(database='analytics', schema='dbt', identifier=None)"
08:44:31.933322 [debug] [ThreadPool]: Using snowflake connection "create_analytics_dbt"
08:44:31.933624 [debug] [ThreadPool]: On create_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "create_analytics_dbt"} */
create schema if not exists analytics.dbt
08:44:31.933778 [debug] [ThreadPool]: Opening a new connection, currently in state closed
08:44:32.977319 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01a43c2c-3201-9cea-0000-0001205251ad
08:44:32.977626 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 003041 (42710): SQL compilation error:
Schema 'DBT' already exists, but current role has no privileges on it. If this is unexpected and you cannot resolve this problem, contact your system administrator. ACCOUNTADMIN role may be required to manage the privileges on the object.
08:44:32.977872 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro create_schema
08:44:32.977995 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
08:44:32.978160 [debug] [ThreadPool]: On create_analytics_dbt: Close
08:44:33.157067 [debug] [MainThread]: Connection 'master' was properly closed.
08:44:33.157525 [debug] [MainThread]: Connection 'create_analytics_dbt' was properly closed.
08:44:33.157948 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11173fa30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11173faf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111cce9d0>]}


============================== 2022-05-13 08:49:42.180202 | be2c0c8e-88f6-450e-9810-222a7f0c0fb8 ==============================
08:49:42.180202 [info ] [MainThread]: Running with dbt=1.0.1
08:49:42.180792 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
08:49:42.180927 [debug] [MainThread]: Tracking: tracking
08:49:42.181141 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067734c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106773460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067738b0>]}
08:49:42.225153 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
08:49:42.225317 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
08:49:42.228772 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'be2c0c8e-88f6-450e-9810-222a7f0c0fb8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067390d0>]}
08:49:42.232115 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'be2c0c8e-88f6-450e-9810-222a7f0c0fb8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10675d100>]}
08:49:42.232252 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
08:49:42.232828 [info ] [MainThread]: 
08:49:42.233074 [debug] [MainThread]: Acquiring new snowflake connection "master"
08:49:42.233579 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
08:49:42.240270 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
08:49:42.240418 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
08:49:42.240491 [debug] [ThreadPool]: Opening a new connection, currently in state init
08:49:43.509176 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.27 seconds
08:49:43.511424 [debug] [ThreadPool]: On list_analytics: Close
08:49:43.701032 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
08:49:43.709960 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
08:49:43.710158 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
08:49:43.710231 [debug] [ThreadPool]: Opening a new connection, currently in state closed
08:49:44.585244 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 0.87 seconds
08:49:44.587612 [debug] [ThreadPool]: On list_analytics_dbt: Close
08:49:44.965123 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
08:49:44.965643 [info ] [MainThread]: 
08:49:44.986594 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
08:49:44.986928 [info ] [Thread-1  ]: 1 of 2 START table model dbt.my_first_dbt_model................................. [RUN]
08:49:44.987345 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
08:49:44.987466 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
08:49:44.987584 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
08:49:44.989711 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
08:49:44.990311 [debug] [Thread-1  ]: finished collecting timing info
08:49:44.990435 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
08:49:45.008013 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
08:49:45.008935 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
08:49:45.009029 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
08:49:45.009116 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
08:49:45.806449 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a43c31-3201-9c86-0000-0001205223bd
08:49:45.806848 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 003001 (42501): SQL access control error:
Insufficient privileges to operate on schema 'DBT'
08:49:45.807216 [debug] [Thread-1  ]: finished collecting timing info
08:49:45.807460 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
08:49:46.110476 [debug] [Thread-1  ]: Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  003001 (42501): SQL access control error:
  Insufficient privileges to operate on schema 'DBT'
  compiled SQL at target/run/learn_dbt/models/example/my_first_dbt_model.sql
08:49:46.111449 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'be2c0c8e-88f6-450e-9810-222a7f0c0fb8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106cb4f40>]}
08:49:46.111920 [error] [Thread-1  ]: 1 of 2 ERROR creating table model dbt.my_first_dbt_model........................ [[31mERROR[0m in 1.12s]
08:49:46.112624 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
08:49:46.113139 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
08:49:46.113320 [info ] [Thread-1  ]: 2 of 2 SKIP relation dbt.my_second_dbt_model.................................... [[33mSKIP[0m]
08:49:46.113562 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
08:49:46.114476 [debug] [MainThread]: Acquiring new snowflake connection "master"
08:49:46.114952 [info ] [MainThread]: 
08:49:46.115283 [info ] [MainThread]: Finished running 1 table model, 1 view model in 3.88s.
08:49:46.115577 [debug] [MainThread]: Connection 'master' was properly closed.
08:49:46.115742 [debug] [MainThread]: Connection 'model.learn_dbt.my_first_dbt_model' was properly closed.
08:49:46.122841 [info ] [MainThread]: 
08:49:46.123193 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
08:49:46.123452 [info ] [MainThread]: 
08:49:46.123652 [error] [MainThread]: [33mDatabase Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)[0m
08:49:46.123853 [error] [MainThread]:   003001 (42501): SQL access control error:
08:49:46.124042 [error] [MainThread]:   Insufficient privileges to operate on schema 'DBT'
08:49:46.124399 [error] [MainThread]:   compiled SQL at target/run/learn_dbt/models/example/my_first_dbt_model.sql
08:49:46.124627 [info ] [MainThread]: 
08:49:46.124826 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=1 TOTAL=2
08:49:46.125137 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10675daf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10675dcd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e27fd0>]}


============================== 2022-05-13 08:51:38.314166 | 117a0d02-afd4-43c3-b040-1e3af1ea6193 ==============================
08:51:38.314166 [info ] [MainThread]: Running with dbt=1.0.1
08:51:38.314511 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
08:51:38.314650 [debug] [MainThread]: Tracking: tracking
08:51:38.314879 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076b32b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076b3eb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076b39a0>]}
08:51:38.354009 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
08:51:38.354151 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
08:51:38.357120 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '117a0d02-afd4-43c3-b040-1e3af1ea6193', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107675a90>]}
08:51:38.359935 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '117a0d02-afd4-43c3-b040-1e3af1ea6193', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10768f8b0>]}
08:51:38.360058 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
08:51:38.360579 [info ] [MainThread]: 
08:51:38.360769 [debug] [MainThread]: Acquiring new snowflake connection "master"
08:51:38.361089 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
08:51:38.366976 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
08:51:38.367065 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
08:51:38.367130 [debug] [ThreadPool]: Opening a new connection, currently in state init
08:51:39.419369 [debug] [ThreadPool]: SQL status: SUCCESS 2 in 1.05 seconds
08:51:39.421653 [debug] [ThreadPool]: On list_analytics: Close
08:51:41.032019 [debug] [ThreadPool]: Acquiring new snowflake connection "create_analytics_dbt"
08:51:41.032621 [debug] [ThreadPool]: Acquiring new snowflake connection "create_analytics_dbt"
08:51:41.032931 [debug] [ThreadPool]: Creating schema "_ReferenceKey(database='analytics', schema='dbt', identifier=None)"
08:51:41.039100 [debug] [ThreadPool]: Using snowflake connection "create_analytics_dbt"
08:51:41.039322 [debug] [ThreadPool]: On create_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "create_analytics_dbt"} */
create schema if not exists analytics.dbt
08:51:41.039470 [debug] [ThreadPool]: Opening a new connection, currently in state closed
08:51:42.052864 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1.01 seconds
08:51:42.055380 [debug] [ThreadPool]: On create_analytics_dbt: Close
08:51:42.222202 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
08:51:42.230662 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
08:51:42.230880 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
08:51:42.231037 [debug] [ThreadPool]: Opening a new connection, currently in state closed
08:51:43.145956 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 0.91 seconds
08:51:43.148370 [debug] [ThreadPool]: On list_analytics_dbt: Close
08:51:43.451450 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
08:51:43.451996 [info ] [MainThread]: 
08:51:43.455522 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
08:51:43.455966 [info ] [Thread-1  ]: 1 of 2 START table model dbt.my_first_dbt_model................................. [RUN]
08:51:43.456528 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
08:51:43.456720 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
08:51:43.456900 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
08:51:43.459887 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
08:51:43.460531 [debug] [Thread-1  ]: finished collecting timing info
08:51:43.460702 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
08:51:43.483240 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
08:51:43.484221 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
08:51:43.484344 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
08:51:43.484448 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
08:51:44.297597 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a43c33-3201-9c86-0000-00012052243d
08:51:44.297866 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.

08:51:44.298007 [debug] [Thread-1  ]: finished collecting timing info
08:51:44.298094 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
08:51:44.601223 [debug] [Thread-1  ]: Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
  
  compiled SQL at target/run/learn_dbt/models/example/my_first_dbt_model.sql
08:51:44.601778 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '117a0d02-afd4-43c3-b040-1e3af1ea6193', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a2e790>]}
08:51:44.602240 [error] [Thread-1  ]: 1 of 2 ERROR creating table model dbt.my_first_dbt_model........................ [[31mERROR[0m in 1.15s]
08:51:44.602662 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
08:51:44.603462 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
08:51:44.603756 [info ] [Thread-1  ]: 2 of 2 SKIP relation dbt.my_second_dbt_model.................................... [[33mSKIP[0m]
08:51:44.604137 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
08:51:44.605174 [debug] [MainThread]: Acquiring new snowflake connection "master"
08:51:44.605624 [info ] [MainThread]: 
08:51:44.605905 [info ] [MainThread]: Finished running 1 table model, 1 view model in 6.24s.
08:51:44.606172 [debug] [MainThread]: Connection 'master' was properly closed.
08:51:44.606305 [debug] [MainThread]: Connection 'model.learn_dbt.my_first_dbt_model' was properly closed.
08:51:44.612218 [info ] [MainThread]: 
08:51:44.612534 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
08:51:44.612792 [info ] [MainThread]: 
08:51:44.612993 [error] [MainThread]: [33mDatabase Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)[0m
08:51:44.613183 [error] [MainThread]:   000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
08:51:44.613363 [error] [MainThread]:   
08:51:44.613540 [error] [MainThread]:   compiled SQL at target/run/learn_dbt/models/example/my_first_dbt_model.sql
08:51:44.613723 [info ] [MainThread]: 
08:51:44.613902 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=1 TOTAL=2
08:51:44.614164 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106d1b1c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a03070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076a90a0>]}


============================== 2022-05-13 08:53:58.504709 | e363b1f0-3d52-40e5-a8e6-6d9af0bfc7db ==============================
08:53:58.504709 [info ] [MainThread]: Running with dbt=1.0.1
08:53:58.505207 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
08:53:58.505336 [debug] [MainThread]: Tracking: tracking
08:53:58.505547 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106abd610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106abdac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106abdb20>]}
08:53:58.547752 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
08:53:58.547894 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
08:53:58.550903 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e363b1f0-3d52-40e5-a8e6-6d9af0bfc7db', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106a8a2b0>]}
08:53:58.554053 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e363b1f0-3d52-40e5-a8e6-6d9af0bfc7db', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ac6ac0>]}
08:53:58.554203 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
08:53:58.554749 [info ] [MainThread]: 
08:53:58.554964 [debug] [MainThread]: Acquiring new snowflake connection "master"
08:53:58.555320 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
08:53:58.561281 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
08:53:58.561387 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
08:53:58.561452 [debug] [ThreadPool]: Opening a new connection, currently in state init
08:53:59.826366 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.26 seconds
08:53:59.828626 [debug] [ThreadPool]: On list_analytics: Close
08:54:00.020903 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
08:54:00.026231 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
08:54:00.026572 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
08:54:00.026740 [debug] [ThreadPool]: Opening a new connection, currently in state closed
08:54:00.978003 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 0.95 seconds
08:54:00.986588 [debug] [ThreadPool]: On list_analytics_dbt: Close
08:54:01.400351 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
08:54:01.400857 [info ] [MainThread]: 
08:54:01.405660 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
08:54:01.406027 [info ] [Thread-1  ]: 1 of 2 START table model dbt.my_first_dbt_model................................. [RUN]
08:54:01.406530 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
08:54:01.406694 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
08:54:01.407228 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
08:54:01.410203 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
08:54:01.410745 [debug] [Thread-1  ]: finished collecting timing info
08:54:01.410914 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
08:54:01.432703 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
08:54:01.433674 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
08:54:01.433895 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
08:54:01.434051 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
08:54:02.390464 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a43c36-3201-9c86-0000-000120522459
08:54:02.390825 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.

08:54:02.391066 [debug] [Thread-1  ]: finished collecting timing info
08:54:02.391198 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
08:54:02.554939 [debug] [Thread-1  ]: Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
  
  compiled SQL at target/run/learn_dbt/models/example/my_first_dbt_model.sql
08:54:02.556002 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e363b1f0-3d52-40e5-a8e6-6d9af0bfc7db', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1226e5df0>]}
08:54:02.556693 [error] [Thread-1  ]: 1 of 2 ERROR creating table model dbt.my_first_dbt_model........................ [[31mERROR[0m in 1.15s]
08:54:02.557318 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
08:54:02.558207 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
08:54:02.558559 [info ] [Thread-1  ]: 2 of 2 SKIP relation dbt.my_second_dbt_model.................................... [[33mSKIP[0m]
08:54:02.558937 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
08:54:02.559951 [debug] [MainThread]: Acquiring new snowflake connection "master"
08:54:02.560403 [info ] [MainThread]: 
08:54:02.560727 [info ] [MainThread]: Finished running 1 table model, 1 view model in 4.01s.
08:54:02.561019 [debug] [MainThread]: Connection 'master' was properly closed.
08:54:02.561177 [debug] [MainThread]: Connection 'model.learn_dbt.my_first_dbt_model' was properly closed.
08:54:02.568001 [info ] [MainThread]: 
08:54:02.568341 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
08:54:02.568582 [info ] [MainThread]: 
08:54:02.568786 [error] [MainThread]: [33mDatabase Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)[0m
08:54:02.568988 [error] [MainThread]:   000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
08:54:02.569170 [error] [MainThread]:   
08:54:02.569357 [error] [MainThread]:   compiled SQL at target/run/learn_dbt/models/example/my_first_dbt_model.sql
08:54:02.569550 [info ] [MainThread]: 
08:54:02.569990 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=1 TOTAL=2
08:54:02.570318 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1208776a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ac6070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1208c7b80>]}


============================== 2022-05-13 09:03:10.055375 | 391d4129-e590-4cd3-9371-422090825d89 ==============================
09:03:10.055375 [info ] [MainThread]: Running with dbt=1.0.1
09:03:10.055982 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
09:03:10.056171 [debug] [MainThread]: Tracking: tracking
09:03:10.056485 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bd91610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bd91ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bd91b20>]}
09:03:10.102002 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
09:03:10.102149 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
09:03:10.105242 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '391d4129-e590-4cd3-9371-422090825d89', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a913b50>]}
09:03:10.108159 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '391d4129-e590-4cd3-9371-422090825d89', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bd9aac0>]}
09:03:10.108319 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
09:03:10.108877 [info ] [MainThread]: 
09:03:10.109089 [debug] [MainThread]: Acquiring new snowflake connection "master"
09:03:10.109474 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
09:03:10.115583 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
09:03:10.115703 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
09:03:10.115786 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:03:11.519556 [debug] [ThreadPool]: SQL status: SUCCESS 2 in 1.4 seconds
09:03:11.522361 [debug] [ThreadPool]: On list_analytics: Close
09:03:11.915869 [debug] [ThreadPool]: Acquiring new snowflake connection "create_analytics_dbt"
09:03:11.916555 [debug] [ThreadPool]: Acquiring new snowflake connection "create_analytics_dbt"
09:03:11.916881 [debug] [ThreadPool]: Creating schema "_ReferenceKey(database='analytics', schema='dbt', identifier=None)"
09:03:11.923292 [debug] [ThreadPool]: Using snowflake connection "create_analytics_dbt"
09:03:11.923563 [debug] [ThreadPool]: On create_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "create_analytics_dbt"} */
create schema if not exists analytics.dbt
09:03:11.923715 [debug] [ThreadPool]: Opening a new connection, currently in state closed
09:03:12.865883 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.94 seconds
09:03:12.869531 [debug] [ThreadPool]: On create_analytics_dbt: Close
09:03:13.222630 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
09:03:13.227352 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
09:03:13.227479 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
09:03:13.227571 [debug] [ThreadPool]: Opening a new connection, currently in state closed
09:03:14.174402 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 0.95 seconds
09:03:14.176894 [debug] [ThreadPool]: On list_analytics_dbt: Close
09:03:14.562441 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
09:03:14.563024 [info ] [MainThread]: 
09:03:14.568118 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
09:03:14.568490 [info ] [Thread-1  ]: 1 of 2 START table model dbt.my_first_dbt_model................................. [RUN]
09:03:14.568975 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
09:03:14.569145 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
09:03:14.569310 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
09:03:14.572372 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
09:03:14.572953 [debug] [Thread-1  ]: finished collecting timing info
09:03:14.573122 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
09:03:14.593946 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
09:03:14.594830 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
09:03:14.594949 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
09:03:14.595045 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:03:15.491436 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a43c3f-3201-9c12-0000-000120521055
09:03:15.491846 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.

09:03:15.492217 [debug] [Thread-1  ]: finished collecting timing info
09:03:15.492470 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
09:03:15.677099 [debug] [Thread-1  ]: Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
  
  compiled SQL at target/run/learn_dbt/models/example/my_first_dbt_model.sql
09:03:15.677851 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '391d4129-e590-4cd3-9371-422090825d89', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c5de2b0>]}
09:03:15.678382 [error] [Thread-1  ]: 1 of 2 ERROR creating table model dbt.my_first_dbt_model........................ [[31mERROR[0m in 1.11s]
09:03:15.678817 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
09:03:15.679600 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
09:03:15.679942 [info ] [Thread-1  ]: 2 of 2 SKIP relation dbt.my_second_dbt_model.................................... [[33mSKIP[0m]
09:03:15.680398 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
09:03:15.681518 [debug] [MainThread]: Acquiring new snowflake connection "master"
09:03:15.681943 [info ] [MainThread]: 
09:03:15.682268 [info ] [MainThread]: Finished running 1 table model, 1 view model in 5.57s.
09:03:15.682554 [debug] [MainThread]: Connection 'master' was properly closed.
09:03:15.682716 [debug] [MainThread]: Connection 'model.learn_dbt.my_first_dbt_model' was properly closed.
09:03:15.688290 [info ] [MainThread]: 
09:03:15.688603 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
09:03:15.688847 [info ] [MainThread]: 
09:03:15.689046 [error] [MainThread]: [33mDatabase Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)[0m
09:03:15.689239 [error] [MainThread]:   000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
09:03:15.689424 [error] [MainThread]:   
09:03:15.689604 [error] [MainThread]:   compiled SQL at target/run/learn_dbt/models/example/my_first_dbt_model.sql
09:03:15.689789 [info ] [MainThread]: 
09:03:15.689971 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=1 TOTAL=2
09:03:15.690231 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bd9a070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bd9aeb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c45d4c0>]}


============================== 2022-05-13 09:05:11.508316 | 5049d4f0-fa56-4896-8f6f-56a08aa2f94c ==============================
09:05:11.508316 [info ] [MainThread]: Running with dbt=1.0.1
09:05:11.509537 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
09:05:11.509693 [debug] [MainThread]: Tracking: tracking
09:05:11.509897 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122733df0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122733c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1227338b0>]}
09:05:11.543198 [info ] [MainThread]: Unable to do partial parsing because profile has changed
09:05:11.543460 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '5049d4f0-fa56-4896-8f6f-56a08aa2f94c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122738e50>]}
09:05:11.553662 [debug] [MainThread]: Parsing macros/catalog.sql
09:05:11.554855 [debug] [MainThread]: Parsing macros/adapters.sql
09:05:11.574543 [debug] [MainThread]: Parsing macros/materializations/merge.sql
09:05:11.576425 [debug] [MainThread]: Parsing macros/materializations/seed.sql
09:05:11.578848 [debug] [MainThread]: Parsing macros/materializations/view.sql
09:05:11.579432 [debug] [MainThread]: Parsing macros/materializations/table.sql
09:05:11.580836 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
09:05:11.584836 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
09:05:11.585246 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
09:05:11.586954 [debug] [MainThread]: Parsing macros/materializations/configs.sql
09:05:11.587948 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
09:05:11.588686 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
09:05:11.596353 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
09:05:11.601843 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
09:05:11.607611 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
09:05:11.609672 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
09:05:11.610454 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
09:05:11.611239 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
09:05:11.613203 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
09:05:11.618652 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
09:05:11.619389 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
09:05:11.624394 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
09:05:11.632085 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
09:05:11.635697 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
09:05:11.636947 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
09:05:11.640411 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
09:05:11.640973 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
09:05:11.642180 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
09:05:11.643165 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
09:05:11.645974 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
09:05:11.654408 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
09:05:11.655262 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
09:05:11.656398 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
09:05:11.657117 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
09:05:11.657523 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
09:05:11.657762 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
09:05:11.658063 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
09:05:11.658676 [debug] [MainThread]: Parsing macros/etc/statement.sql
09:05:11.660935 [debug] [MainThread]: Parsing macros/etc/datetime.sql
09:05:11.665247 [debug] [MainThread]: Parsing macros/adapters/schema.sql
09:05:11.666286 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
09:05:11.667720 [debug] [MainThread]: Parsing macros/adapters/relation.sql
09:05:11.672277 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
09:05:11.673565 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
09:05:11.675548 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
09:05:11.678878 [debug] [MainThread]: Parsing macros/adapters/columns.sql
09:05:11.683595 [debug] [MainThread]: Parsing tests/generic/builtin.sql
09:05:11.779746 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
09:05:11.785221 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
09:05:11.808438 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5049d4f0-fa56-4896-8f6f-56a08aa2f94c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1227a29d0>]}
09:05:11.811006 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5049d4f0-fa56-4896-8f6f-56a08aa2f94c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122718850>]}
09:05:11.811135 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
09:05:11.811677 [info ] [MainThread]: 
09:05:11.811871 [debug] [MainThread]: Acquiring new snowflake connection "master"
09:05:11.812210 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
09:05:11.817987 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
09:05:11.818080 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
09:05:11.818152 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:05:12.627137 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.81 seconds
09:05:12.630374 [debug] [ThreadPool]: On list_analytics: Close
09:05:12.924422 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
09:05:12.933161 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
09:05:12.933426 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
09:05:12.933596 [debug] [ThreadPool]: Opening a new connection, currently in state closed
09:05:13.971256 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 1.04 seconds
09:05:13.973687 [debug] [ThreadPool]: On list_analytics_dbt: Close
09:05:14.156177 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
09:05:14.156821 [info ] [MainThread]: 
09:05:14.162008 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
09:05:14.162425 [info ] [Thread-1  ]: 1 of 2 START table model dbt.my_first_dbt_model................................. [RUN]
09:05:14.162966 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
09:05:14.163140 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
09:05:14.163674 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
09:05:14.166468 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
09:05:14.167057 [debug] [Thread-1  ]: finished collecting timing info
09:05:14.167234 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
09:05:14.189219 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
09:05:14.190061 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
09:05:14.190170 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
09:05:14.190258 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:05:15.026254 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a43c41-3201-9c12-0000-000120521061
09:05:15.026599 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.

09:05:15.026945 [debug] [Thread-1  ]: finished collecting timing info
09:05:15.027261 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
09:05:15.210646 [debug] [Thread-1  ]: Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
  
  compiled SQL at target/run/learn_dbt/models/example/my_first_dbt_model.sql
09:05:15.211010 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5049d4f0-fa56-4896-8f6f-56a08aa2f94c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122f30100>]}
09:05:15.211299 [error] [Thread-1  ]: 1 of 2 ERROR creating table model dbt.my_first_dbt_model........................ [[31mERROR[0m in 1.05s]
09:05:15.211516 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
09:05:15.212018 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
09:05:15.212272 [info ] [Thread-1  ]: 2 of 2 SKIP relation dbt.my_second_dbt_model.................................... [[33mSKIP[0m]
09:05:15.212573 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
09:05:15.213287 [debug] [MainThread]: Acquiring new snowflake connection "master"
09:05:15.213544 [info ] [MainThread]: 
09:05:15.213701 [info ] [MainThread]: Finished running 1 table model, 1 view model in 3.40s.
09:05:15.213834 [debug] [MainThread]: Connection 'master' was properly closed.
09:05:15.213904 [debug] [MainThread]: Connection 'model.learn_dbt.my_first_dbt_model' was properly closed.
09:05:15.216993 [info ] [MainThread]: 
09:05:15.217180 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
09:05:15.217328 [info ] [MainThread]: 
09:05:15.217448 [error] [MainThread]: [33mDatabase Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)[0m
09:05:15.217569 [error] [MainThread]:   000606 (57P03): No active warehouse selected in the current session.  Select an active warehouse with the 'use warehouse' command.
09:05:15.217684 [error] [MainThread]:   
09:05:15.217797 [error] [MainThread]:   compiled SQL at target/run/learn_dbt/models/example/my_first_dbt_model.sql
09:05:15.217919 [info ] [MainThread]: 
09:05:15.218037 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=1 TOTAL=2
09:05:15.218216 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1228335e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1227a2ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122c0a550>]}


============================== 2022-05-13 09:08:37.807686 | f30dde7d-7412-4489-82e8-931d87ba7f0c ==============================
09:08:37.807686 [info ] [MainThread]: Running with dbt=1.0.1
09:08:37.808029 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
09:08:37.808155 [debug] [MainThread]: Tracking: tracking
09:08:37.808337 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e48a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108237a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e832b0>]}
09:08:37.850417 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
09:08:37.850566 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
09:08:37.853690 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f30dde7d-7412-4489-82e8-931d87ba7f0c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1082150d0>]}
09:08:37.856405 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f30dde7d-7412-4489-82e8-931d87ba7f0c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10823edc0>]}
09:08:37.856541 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
09:08:37.857105 [info ] [MainThread]: 
09:08:37.857305 [debug] [MainThread]: Acquiring new snowflake connection "master"
09:08:37.857670 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
09:08:37.863694 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
09:08:37.863798 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
09:08:37.863867 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:08:38.934934 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.07 seconds
09:08:38.937153 [debug] [ThreadPool]: On list_analytics: Close
09:08:39.167172 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
09:08:39.176166 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
09:08:39.176435 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
09:08:39.176593 [debug] [ThreadPool]: Opening a new connection, currently in state closed
09:08:40.193802 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 1.02 seconds
09:08:40.196491 [debug] [ThreadPool]: On list_analytics_dbt: Close
09:08:40.599596 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
09:08:40.600685 [info ] [MainThread]: 
09:08:40.606392 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
09:08:40.606862 [info ] [Thread-1  ]: 1 of 2 START table model dbt.my_first_dbt_model................................. [RUN]
09:08:40.607441 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
09:08:40.607693 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
09:08:40.608475 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
09:08:40.611262 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
09:08:40.612024 [debug] [Thread-1  ]: finished collecting timing info
09:08:40.612212 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
09:08:40.633697 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
09:08:40.634459 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
09:08:40.634565 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
09:08:40.634654 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:08:42.724085 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.09 seconds
09:08:42.737381 [debug] [Thread-1  ]: finished collecting timing info
09:08:42.737780 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
09:08:42.907359 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f30dde7d-7412-4489-82e8-931d87ba7f0c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1085a5100>]}
09:08:42.907826 [info ] [Thread-1  ]: 1 of 2 OK created table model dbt.my_first_dbt_model............................ [[32mSUCCESS 1[0m in 2.30s]
09:08:42.908071 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
09:08:42.908713 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
09:08:42.909162 [info ] [Thread-1  ]: 2 of 2 START view model dbt.my_second_dbt_model................................. [RUN]
09:08:42.909579 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
09:08:42.909717 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
09:08:42.909843 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
09:08:42.912992 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
09:08:42.913635 [debug] [Thread-1  ]: finished collecting timing info
09:08:42.913793 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
09:08:42.928207 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
09:08:42.929045 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
09:08:42.929186 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */

  create or replace  view analytics.dbt.my_second_dbt_model 
  
   as (
    -- Use the `ref` function to select from other models

select *
from analytics.dbt.my_first_dbt_model
where id = 1
  );
09:08:42.929299 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:08:43.911558 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.98 seconds
09:08:43.914986 [debug] [Thread-1  ]: finished collecting timing info
09:08:43.915351 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
09:08:44.314355 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f30dde7d-7412-4489-82e8-931d87ba7f0c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1085b0d60>]}
09:08:44.316725 [info ] [Thread-1  ]: 2 of 2 OK created view model dbt.my_second_dbt_model............................ [[32mSUCCESS 1[0m in 1.40s]
09:08:44.317060 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
09:08:44.317717 [debug] [MainThread]: Acquiring new snowflake connection "master"
09:08:44.317936 [info ] [MainThread]: 
09:08:44.318094 [info ] [MainThread]: Finished running 1 table model, 1 view model in 6.46s.
09:08:44.318238 [debug] [MainThread]: Connection 'master' was properly closed.
09:08:44.318314 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
09:08:44.324380 [info ] [MainThread]: 
09:08:44.324742 [info ] [MainThread]: [32mCompleted successfully[0m
09:08:44.325040 [info ] [MainThread]: 
09:08:44.325268 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
09:08:44.325574 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1085b0b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1085a48b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10823bb20>]}


============================== 2022-05-13 09:22:35.513052 | f18ef690-fea8-4b16-8c9c-30db2b6baf7c ==============================
09:22:35.513052 [info ] [MainThread]: Running with dbt=1.0.1
09:22:35.513572 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
09:22:35.513709 [debug] [MainThread]: Tracking: tracking
09:22:35.513917 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11125f2b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11125fb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11125f9a0>]}
09:22:35.551296 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10794f0a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111255400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1112555b0>]}


============================== 2022-05-13 09:22:57.623011 | cdab71e1-726f-4a09-859e-c1749deddf84 ==============================
09:22:57.623011 [info ] [MainThread]: Running with dbt=1.0.1
09:22:57.623361 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
09:22:57.623486 [debug] [MainThread]: Tracking: tracking
09:22:57.623705 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a9031c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a903d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a903e50>]}
09:22:57.667223 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
09:22:57.667424 [debug] [MainThread]: Partial parsing: added file: learn_dbt://models/example/snowflake_customer_purchases.sql
09:22:57.667572 [debug] [MainThread]: Partial parsing: update schema file: learn_dbt://models/example/schema.yml
09:22:57.673349 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
09:22:57.693223 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cdab71e1-726f-4a09-859e-c1749deddf84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a8e1d30>]}
09:22:57.695997 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cdab71e1-726f-4a09-859e-c1749deddf84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a8e9820>]}
09:22:57.696139 [info ] [MainThread]: Found 3 models, 6 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
09:22:57.696743 [info ] [MainThread]: 
09:22:57.696942 [debug] [MainThread]: Acquiring new snowflake connection "master"
09:22:57.697411 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
09:22:57.703288 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
09:22:57.703391 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
09:22:57.703454 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:22:58.739887 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.04 seconds
09:22:58.741059 [debug] [ThreadPool]: On list_analytics: Close
09:22:58.990887 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
09:22:58.999000 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
09:22:58.999395 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
09:22:58.999572 [debug] [ThreadPool]: Opening a new connection, currently in state closed
09:22:59.989543 [debug] [ThreadPool]: SQL status: SUCCESS 2 in 0.99 seconds
09:22:59.993886 [debug] [ThreadPool]: On list_analytics_dbt: Close
09:23:00.376164 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
09:23:00.376755 [info ] [MainThread]: 
09:23:00.382575 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
09:23:00.383011 [info ] [Thread-1  ]: 1 of 3 START table model dbt.my_first_dbt_model................................. [RUN]
09:23:00.384101 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
09:23:00.384381 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
09:23:00.384576 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
09:23:00.387657 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
09:23:00.388367 [debug] [Thread-1  ]: finished collecting timing info
09:23:00.388573 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
09:23:00.409860 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
09:23:00.410820 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
09:23:00.410931 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
09:23:00.411026 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:23:02.404957 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.99 seconds
09:23:02.418484 [debug] [Thread-1  ]: finished collecting timing info
09:23:02.418872 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
09:23:02.614783 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cdab71e1-726f-4a09-859e-c1749deddf84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ad6ea60>]}
09:23:02.615651 [info ] [Thread-1  ]: 1 of 3 OK created table model dbt.my_first_dbt_model............................ [[32mSUCCESS 1[0m in 2.23s]
09:23:02.616131 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
09:23:02.616547 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
09:23:02.616895 [info ] [Thread-1  ]: 2 of 3 START table model dbt.snowflake_customer_purchases....................... [RUN]
09:23:02.617648 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
09:23:02.618039 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
09:23:02.618336 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
09:23:02.621553 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
09:23:02.622262 [debug] [Thread-1  ]: finished collecting timing info
09:23:02.622544 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
09:23:02.624889 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
09:23:02.626173 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
09:23:02.626352 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (

select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
;
09:23:02.626516 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:23:03.581819 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a43c53-3201-9c78-0000-00012052602d
09:23:03.582303 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 15 at position 0 unexpected ';'.
09:23:03.582655 [debug] [Thread-1  ]: finished collecting timing info
09:23:03.582760 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
09:23:03.746868 [debug] [Thread-1  ]: Database Error in model snowflake_customer_purchases (models/example/snowflake_customer_purchases.sql)
  001003 (42000): SQL compilation error:
  syntax error line 15 at position 0 unexpected ';'.
  compiled SQL at target/run/learn_dbt/models/example/snowflake_customer_purchases.sql
09:23:03.747460 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cdab71e1-726f-4a09-859e-c1749deddf84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cf66340>]}
09:23:03.747976 [error] [Thread-1  ]: 2 of 3 ERROR creating table model dbt.snowflake_customer_purchases.............. [[31mERROR[0m in 1.13s]
09:23:03.748403 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
09:23:03.748634 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
09:23:03.749060 [info ] [Thread-1  ]: 3 of 3 START view model dbt.my_second_dbt_model................................. [RUN]
09:23:03.749700 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
09:23:03.749916 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
09:23:03.750131 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
09:23:03.753408 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
09:23:03.754234 [debug] [Thread-1  ]: finished collecting timing info
09:23:03.754447 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
09:23:03.774682 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
09:23:03.775584 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
09:23:03.775723 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */

  create or replace  view analytics.dbt.my_second_dbt_model 
  
   as (
    -- Use the `ref` function to select from other models

select *
from analytics.dbt.my_first_dbt_model
where id = 1
  );
09:23:03.775825 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:23:04.785183 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.01 seconds
09:23:04.789841 [debug] [Thread-1  ]: finished collecting timing info
09:23:04.790237 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
09:23:05.184688 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cdab71e1-726f-4a09-859e-c1749deddf84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10adc0340>]}
09:23:05.185040 [info ] [Thread-1  ]: 3 of 3 OK created view model dbt.my_second_dbt_model............................ [[32mSUCCESS 1[0m in 1.44s]
09:23:05.185204 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
09:23:05.185765 [debug] [MainThread]: Acquiring new snowflake connection "master"
09:23:05.185968 [info ] [MainThread]: 
09:23:05.186091 [info ] [MainThread]: Finished running 2 table models, 1 view model in 7.49s.
09:23:05.186196 [debug] [MainThread]: Connection 'master' was properly closed.
09:23:05.186253 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
09:23:05.189553 [info ] [MainThread]: 
09:23:05.189769 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
09:23:05.189922 [info ] [MainThread]: 
09:23:05.190047 [error] [MainThread]: [33mDatabase Error in model snowflake_customer_purchases (models/example/snowflake_customer_purchases.sql)[0m
09:23:05.190171 [error] [MainThread]:   001003 (42000): SQL compilation error:
09:23:05.190285 [error] [MainThread]:   syntax error line 15 at position 0 unexpected ';'.
09:23:05.190397 [error] [MainThread]:   compiled SQL at target/run/learn_dbt/models/example/snowflake_customer_purchases.sql
09:23:05.190514 [info ] [MainThread]: 
09:23:05.190638 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=0 TOTAL=3
09:23:05.190818 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ada5b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ae12730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10adc08e0>]}


============================== 2022-05-13 09:23:56.121102 | 59fcf14f-3bbd-40b6-bb80-4cf0ee3c9889 ==============================
09:23:56.121102 [info ] [MainThread]: Running with dbt=1.0.1
09:23:56.121720 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
09:23:56.121856 [debug] [MainThread]: Tracking: tracking
09:23:56.122071 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1061439a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106143b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1061433a0>]}
09:23:56.166935 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
09:23:56.167214 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/snowflake_customer_purchases.sql
09:23:56.173041 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
09:23:56.192907 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '59fcf14f-3bbd-40b6-bb80-4cf0ee3c9889', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106267af0>]}
09:23:56.195625 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '59fcf14f-3bbd-40b6-bb80-4cf0ee3c9889', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106131400>]}
09:23:56.195758 [info ] [MainThread]: Found 3 models, 6 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
09:23:56.196357 [info ] [MainThread]: 
09:23:56.196558 [debug] [MainThread]: Acquiring new snowflake connection "master"
09:23:56.196987 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
09:23:56.202879 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
09:23:56.202977 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
09:23:56.203038 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:23:57.059138 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.86 seconds
09:23:57.061849 [debug] [ThreadPool]: On list_analytics: Close
09:23:57.228386 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
09:23:57.237720 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
09:23:57.237952 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
09:23:57.238112 [debug] [ThreadPool]: Opening a new connection, currently in state closed
09:23:58.112840 [debug] [ThreadPool]: SQL status: SUCCESS 2 in 0.87 seconds
09:23:58.115757 [debug] [ThreadPool]: On list_analytics_dbt: Close
09:23:58.374494 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
09:23:58.375138 [info ] [MainThread]: 
09:23:58.380193 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
09:23:58.380642 [info ] [Thread-1  ]: 1 of 3 START table model dbt.my_first_dbt_model................................. [RUN]
09:23:58.381885 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
09:23:58.382092 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
09:23:58.382263 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
09:23:58.385022 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
09:23:58.385624 [debug] [Thread-1  ]: finished collecting timing info
09:23:58.385839 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
09:23:58.406587 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
09:23:58.407318 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
09:23:58.407403 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
09:23:58.407469 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:24:00.139626 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.73 seconds
09:24:00.151966 [debug] [Thread-1  ]: finished collecting timing info
09:24:00.152355 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
09:24:00.321405 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '59fcf14f-3bbd-40b6-bb80-4cf0ee3c9889', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067d6820>]}
09:24:00.322068 [info ] [Thread-1  ]: 1 of 3 OK created table model dbt.my_first_dbt_model............................ [[32mSUCCESS 1[0m in 1.94s]
09:24:00.322504 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
09:24:00.322752 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
09:24:00.323152 [info ] [Thread-1  ]: 2 of 3 START table model dbt.snowflake_customer_purchases....................... [RUN]
09:24:00.323729 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
09:24:00.323930 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
09:24:00.324216 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
09:24:00.327527 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
09:24:00.328134 [debug] [Thread-1  ]: finished collecting timing info
09:24:00.328301 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
09:24:00.330545 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
09:24:00.331859 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
09:24:00.332047 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (

select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
09:24:00.332201 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:24:02.725651 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.39 seconds
09:24:02.731379 [debug] [Thread-1  ]: finished collecting timing info
09:24:02.731823 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
09:24:02.884596 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '59fcf14f-3bbd-40b6-bb80-4cf0ee3c9889', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067d6910>]}
09:24:02.885485 [info ] [Thread-1  ]: 2 of 3 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.56s]
09:24:02.885954 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
09:24:02.886259 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
09:24:02.886719 [info ] [Thread-1  ]: 3 of 3 START view model dbt.my_second_dbt_model................................. [RUN]
09:24:02.887403 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
09:24:02.887625 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
09:24:02.887836 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
09:24:02.890933 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
09:24:02.891568 [debug] [Thread-1  ]: finished collecting timing info
09:24:02.891743 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
09:24:02.911134 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
09:24:02.911905 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
09:24:02.912024 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */

  create or replace  view analytics.dbt.my_second_dbt_model 
  
   as (
    -- Use the `ref` function to select from other models

select *
from analytics.dbt.my_first_dbt_model
where id = 1
  );
09:24:02.912122 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:24:04.002332 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.09 seconds
09:24:04.005579 [debug] [Thread-1  ]: finished collecting timing info
09:24:04.005976 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
09:24:04.271108 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '59fcf14f-3bbd-40b6-bb80-4cf0ee3c9889', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108e64c10>]}
09:24:04.271733 [info ] [Thread-1  ]: 3 of 3 OK created view model dbt.my_second_dbt_model............................ [[32mSUCCESS 1[0m in 1.38s]
09:24:04.272173 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
09:24:04.273329 [debug] [MainThread]: Acquiring new snowflake connection "master"
09:24:04.273682 [info ] [MainThread]: 
09:24:04.273921 [info ] [MainThread]: Finished running 2 table models, 1 view model in 8.08s.
09:24:04.274121 [debug] [MainThread]: Connection 'master' was properly closed.
09:24:04.274225 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
09:24:04.279371 [info ] [MainThread]: 
09:24:04.279741 [info ] [MainThread]: [32mCompleted successfully[0m
09:24:04.280049 [info ] [MainThread]: 
09:24:04.280282 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
09:24:04.280595 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1066f9d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1061318e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1066f75b0>]}


============================== 2022-05-13 09:54:17.002977 | 4847f8b1-0605-40c5-8429-cd2e966440b7 ==============================
09:54:17.002977 [info ] [MainThread]: Running with dbt=1.0.1
09:54:17.003521 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
09:54:17.003664 [debug] [MainThread]: Tracking: tracking
09:54:17.003880 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1046e7190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1046e70a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1046e7b20>]}
09:54:17.048631 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
09:54:17.048843 [debug] [MainThread]: Partial parsing: added file: learn_dbt://models/example/snowflake_cumulative_sales.sql
09:54:17.049056 [debug] [MainThread]: Partial parsing: update schema file: learn_dbt://models/example/schema.yml
09:54:17.054680 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_cumulative_sales.sql
09:54:17.074629 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4847f8b1-0605-40c5-8429-cd2e966440b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10482e0d0>]}
09:54:17.077529 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4847f8b1-0605-40c5-8429-cd2e966440b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1046f4df0>]}
09:54:17.077666 [info ] [MainThread]: Found 4 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
09:54:17.078305 [info ] [MainThread]: 
09:54:17.078502 [debug] [MainThread]: Acquiring new snowflake connection "master"
09:54:17.078968 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
09:54:17.085193 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
09:54:17.085342 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
09:54:17.085414 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:54:18.159868 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.07 seconds
09:54:18.162222 [debug] [ThreadPool]: On list_analytics: Close
09:54:18.354693 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
09:54:18.363818 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
09:54:18.364061 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
09:54:18.364227 [debug] [ThreadPool]: Opening a new connection, currently in state closed
09:54:19.357991 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.99 seconds
09:54:19.363265 [debug] [ThreadPool]: On list_analytics_dbt: Close
09:54:19.733194 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
09:54:19.733990 [info ] [MainThread]: 
09:54:19.738795 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
09:54:19.739240 [info ] [Thread-1  ]: 1 of 4 START table model dbt.my_first_dbt_model................................. [RUN]
09:54:19.740129 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
09:54:19.740313 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
09:54:19.740481 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
09:54:19.743303 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
09:54:19.743906 [debug] [Thread-1  ]: finished collecting timing info
09:54:19.744076 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
09:54:19.765491 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
09:54:19.766440 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
09:54:19.766565 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
09:54:19.766667 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:54:21.500734 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.73 seconds
09:54:21.509106 [debug] [Thread-1  ]: finished collecting timing info
09:54:21.509364 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
09:54:21.714615 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4847f8b1-0605-40c5-8429-cd2e966440b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106944f40>]}
09:54:21.715589 [info ] [Thread-1  ]: 1 of 4 OK created table model dbt.my_first_dbt_model............................ [[32mSUCCESS 1[0m in 1.97s]
09:54:21.716061 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
09:54:21.716315 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
09:54:21.716749 [info ] [Thread-1  ]: 2 of 4 START table model dbt.snowflake_cumulative_sales......................... [RUN]
09:54:21.717504 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
09:54:21.717724 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
09:54:21.717924 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
09:54:21.721391 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
09:54:21.722029 [debug] [Thread-1  ]: finished collecting timing info
09:54:21.722206 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
09:54:21.724546 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
09:54:21.725787 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
09:54:21.725984 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (

select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate;
09:54:21.726138 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:54:22.359293 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a43c72-3201-9c12-0000-000120521525
09:54:22.359673 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 7 at position 20 unexpected ';'.
09:54:22.360024 [debug] [Thread-1  ]: finished collecting timing info
09:54:22.360261 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
09:54:22.522971 [debug] [Thread-1  ]: Database Error in model snowflake_cumulative_sales (models/example/snowflake_cumulative_sales.sql)
  001003 (42000): SQL compilation error:
  syntax error line 7 at position 20 unexpected ';'.
  compiled SQL at target/run/learn_dbt/models/example/snowflake_cumulative_sales.sql
09:54:22.523933 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4847f8b1-0605-40c5-8429-cd2e966440b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106977100>]}
09:54:22.524412 [error] [Thread-1  ]: 2 of 4 ERROR creating table model dbt.snowflake_cumulative_sales................ [[31mERROR[0m in 0.81s]
09:54:22.524808 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
09:54:22.524982 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
09:54:22.525300 [info ] [Thread-1  ]: 3 of 4 START table model dbt.snowflake_customer_purchases....................... [RUN]
09:54:22.525740 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
09:54:22.525895 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
09:54:22.526032 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
09:54:22.528213 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
09:54:22.528743 [debug] [Thread-1  ]: finished collecting timing info
09:54:22.528880 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
09:54:22.531249 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
09:54:22.532537 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
09:54:22.532719 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (

select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
09:54:22.532870 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:54:24.273982 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.74 seconds
09:54:24.276212 [debug] [Thread-1  ]: finished collecting timing info
09:54:24.276471 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
09:54:24.548797 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4847f8b1-0605-40c5-8429-cd2e966440b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104b899d0>]}
09:54:24.549565 [info ] [Thread-1  ]: 3 of 4 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.02s]
09:54:24.550028 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
09:54:24.550282 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
09:54:24.550691 [info ] [Thread-1  ]: 4 of 4 START view model dbt.my_second_dbt_model................................. [RUN]
09:54:24.551340 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
09:54:24.551553 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
09:54:24.551755 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
09:54:24.554614 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
09:54:24.555299 [debug] [Thread-1  ]: finished collecting timing info
09:54:24.555480 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
09:54:24.573856 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
09:54:24.574666 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
09:54:24.574784 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */

  create or replace  view analytics.dbt.my_second_dbt_model 
  
   as (
    -- Use the `ref` function to select from other models

select *
from analytics.dbt.my_first_dbt_model
where id = 1
  );
09:54:24.574890 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:54:25.501707 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.93 seconds
09:54:25.505830 [debug] [Thread-1  ]: finished collecting timing info
09:54:25.506231 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
09:54:25.676733 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4847f8b1-0605-40c5-8429-cd2e966440b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104ad0460>]}
09:54:25.677747 [info ] [Thread-1  ]: 4 of 4 OK created view model dbt.my_second_dbt_model............................ [[32mSUCCESS 1[0m in 1.13s]
09:54:25.678248 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
09:54:25.679660 [debug] [MainThread]: Acquiring new snowflake connection "master"
09:54:25.680152 [info ] [MainThread]: 
09:54:25.680501 [info ] [MainThread]: Finished running 3 table models, 1 view model in 8.60s.
09:54:25.680801 [debug] [MainThread]: Connection 'master' was properly closed.
09:54:25.680971 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
09:54:25.687377 [info ] [MainThread]: 
09:54:25.687752 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
09:54:25.688043 [info ] [MainThread]: 
09:54:25.688261 [error] [MainThread]: [33mDatabase Error in model snowflake_cumulative_sales (models/example/snowflake_cumulative_sales.sql)[0m
09:54:25.688458 [error] [MainThread]:   001003 (42000): SQL compilation error:
09:54:25.688645 [error] [MainThread]:   syntax error line 7 at position 20 unexpected ';'.
09:54:25.688826 [error] [MainThread]:   compiled SQL at target/run/learn_dbt/models/example/snowflake_cumulative_sales.sql
09:54:25.689021 [info ] [MainThread]: 
09:54:25.689207 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=1 SKIP=0 TOTAL=4
09:54:25.689587 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1047001c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106979d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1069701f0>]}


============================== 2022-05-13 09:54:41.082217 | d89147e0-651a-4b7b-ae3b-0a37710672dc ==============================
09:54:41.082217 [info ] [MainThread]: Running with dbt=1.0.1
09:54:41.082558 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
09:54:41.082670 [debug] [MainThread]: Tracking: tracking
09:54:41.082891 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e432b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e43b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e439a0>]}
09:54:41.126449 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
09:54:41.126724 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/snowflake_cumulative_sales.sql
09:54:41.131941 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_cumulative_sales.sql
09:54:41.151223 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd89147e0-651a-4b7b-ae3b-0a37710672dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10390b100>]}
09:54:41.154087 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd89147e0-651a-4b7b-ae3b-0a37710672dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e1b340>]}
09:54:41.154221 [info ] [MainThread]: Found 4 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
09:54:41.154863 [info ] [MainThread]: 
09:54:41.155073 [debug] [MainThread]: Acquiring new snowflake connection "master"
09:54:41.155571 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
09:54:41.161661 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
09:54:41.161791 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
09:54:41.161861 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:54:42.275029 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.11 seconds
09:54:42.278260 [debug] [ThreadPool]: On list_analytics: Close
09:54:42.495752 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
09:54:42.506304 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
09:54:42.506580 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
09:54:42.506749 [debug] [ThreadPool]: Opening a new connection, currently in state closed
09:54:43.436242 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.93 seconds
09:54:43.438668 [debug] [ThreadPool]: On list_analytics_dbt: Close
09:54:43.622459 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
09:54:43.622718 [info ] [MainThread]: 
09:54:43.627390 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
09:54:43.627811 [info ] [Thread-1  ]: 1 of 4 START table model dbt.my_first_dbt_model................................. [RUN]
09:54:43.628641 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
09:54:43.628816 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
09:54:43.628978 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
09:54:43.631627 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
09:54:43.632192 [debug] [Thread-1  ]: finished collecting timing info
09:54:43.632365 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
09:54:43.654012 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
09:54:43.654919 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
09:54:43.655040 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
09:54:43.655142 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:54:45.421579 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.77 seconds
09:54:45.435665 [debug] [Thread-1  ]: finished collecting timing info
09:54:45.435946 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
09:54:45.618324 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd89147e0-651a-4b7b-ae3b-0a37710672dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107065d60>]}
09:54:45.619080 [info ] [Thread-1  ]: 1 of 4 OK created table model dbt.my_first_dbt_model............................ [[32mSUCCESS 1[0m in 1.99s]
09:54:45.619532 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
09:54:45.619782 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
09:54:45.620216 [info ] [Thread-1  ]: 2 of 4 START table model dbt.snowflake_cumulative_sales......................... [RUN]
09:54:45.621032 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
09:54:45.621280 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
09:54:45.621488 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
09:54:45.624906 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
09:54:45.625661 [debug] [Thread-1  ]: finished collecting timing info
09:54:45.625831 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
09:54:45.628080 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
09:54:45.629309 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
09:54:45.629490 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (

select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
09:54:45.629645 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:54:47.001818 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.37 seconds
09:54:47.005242 [debug] [Thread-1  ]: finished collecting timing info
09:54:47.005710 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
09:54:47.168470 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd89147e0-651a-4b7b-ae3b-0a37710672dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1056faa60>]}
09:54:47.169156 [info ] [Thread-1  ]: 2 of 4 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 1.55s]
09:54:47.169678 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
09:54:47.169844 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
09:54:47.170041 [info ] [Thread-1  ]: 3 of 4 START table model dbt.snowflake_customer_purchases....................... [RUN]
09:54:47.170320 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
09:54:47.170405 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
09:54:47.170484 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
09:54:47.171879 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
09:54:47.172279 [debug] [Thread-1  ]: finished collecting timing info
09:54:47.172359 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
09:54:47.173630 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
09:54:47.174939 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
09:54:47.175136 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (

select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
09:54:47.175314 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:54:48.643809 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.47 seconds
09:54:48.646642 [debug] [Thread-1  ]: finished collecting timing info
09:54:48.647039 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
09:54:48.808018 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd89147e0-651a-4b7b-ae3b-0a37710672dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1070882b0>]}
09:54:48.809267 [info ] [Thread-1  ]: 3 of 4 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 1.64s]
09:54:48.809855 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
09:54:48.810110 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
09:54:48.810507 [info ] [Thread-1  ]: 4 of 4 START view model dbt.my_second_dbt_model................................. [RUN]
09:54:48.811170 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
09:54:48.811391 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
09:54:48.811610 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
09:54:48.814913 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
09:54:48.816755 [debug] [Thread-1  ]: finished collecting timing info
09:54:48.817083 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
09:54:48.835122 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
09:54:48.836057 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
09:54:48.836191 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */

  create or replace  view analytics.dbt.my_second_dbt_model 
  
   as (
    -- Use the `ref` function to select from other models

select *
from analytics.dbt.my_first_dbt_model
where id = 1
  );
09:54:48.836338 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
09:54:49.613498 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.78 seconds
09:54:49.616406 [debug] [Thread-1  ]: finished collecting timing info
09:54:49.616807 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
09:54:49.798509 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd89147e0-651a-4b7b-ae3b-0a37710672dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10531dd90>]}
09:54:49.799228 [info ] [Thread-1  ]: 4 of 4 OK created view model dbt.my_second_dbt_model............................ [[32mSUCCESS 1[0m in 0.99s]
09:54:49.799681 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
09:54:49.800998 [debug] [MainThread]: Acquiring new snowflake connection "master"
09:54:49.801477 [info ] [MainThread]: 
09:54:49.801811 [info ] [MainThread]: Finished running 3 table models, 1 view model in 8.65s.
09:54:49.802111 [debug] [MainThread]: Connection 'master' was properly closed.
09:54:49.802304 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
09:54:49.809201 [info ] [MainThread]: 
09:54:49.809556 [info ] [MainThread]: [32mCompleted successfully[0m
09:54:49.809935 [info ] [MainThread]: 
09:54:49.810164 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
09:54:49.810465 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e38e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e1ba30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105744640>]}


============================== 2022-05-13 10:07:46.864603 | 3cef4318-224c-46d2-bf0b-0c6246e1ac30 ==============================
10:07:46.864603 [info ] [MainThread]: Running with dbt=1.0.1
10:07:46.865245 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
10:07:46.865425 [debug] [MainThread]: Tracking: tracking
10:07:46.865687 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105793ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105793cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1057939d0>]}
10:07:46.912437 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 3 files changed.
10:07:46.912700 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/my_first_dbt_model.sql
10:07:46.912881 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/snowflake_cumulative_sales.sql
10:07:46.913000 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/snowflake_customer_purchases.sql
10:07:46.918857 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
10:07:46.924857 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_cumulative_sales.sql
10:07:46.925965 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
10:07:46.947093 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3cef4318-224c-46d2-bf0b-0c6246e1ac30', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10405e1f0>]}
10:07:46.950451 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3cef4318-224c-46d2-bf0b-0c6246e1ac30', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105771670>]}
10:07:46.950612 [info ] [MainThread]: Found 4 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
10:07:46.951242 [info ] [MainThread]: 
10:07:46.951466 [debug] [MainThread]: Acquiring new snowflake connection "master"
10:07:46.951907 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
10:07:46.958525 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
10:07:46.958677 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
10:07:46.958751 [debug] [ThreadPool]: Opening a new connection, currently in state init
10:07:48.150899 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.19 seconds
10:07:48.154857 [debug] [ThreadPool]: On list_analytics: Close
10:07:48.376099 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
10:07:48.393916 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
10:07:48.394378 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
10:07:48.394766 [debug] [ThreadPool]: Opening a new connection, currently in state closed
10:07:49.329158 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 0.93 seconds
10:07:49.334210 [debug] [ThreadPool]: On list_analytics_dbt: Close
10:07:49.551927 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
10:07:49.552789 [info ] [MainThread]: 
10:07:49.573368 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
10:07:49.573949 [info ] [Thread-1  ]: 1 of 4 START view model dbt.my_first_dbt_model.................................. [RUN]
10:07:49.574796 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
10:07:49.574928 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
10:07:49.575052 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
10:07:49.577034 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
10:07:49.577389 [debug] [Thread-1  ]: finished collecting timing info
10:07:49.577486 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
10:07:49.596537 [debug] [Thread-1  ]: Dropping relation "ANALYTICS"."DBT"."MY_FIRST_DBT_MODEL" because it is of type table
10:07:49.600605 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
10:07:49.600763 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */
drop table if exists "ANALYTICS"."DBT"."MY_FIRST_DBT_MODEL" cascade
10:07:49.600879 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:07:50.362081 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.76 seconds
10:07:50.388069 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
10:07:50.389222 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
10:07:50.389391 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */

  create or replace  view analytics.dbt.my_first_dbt_model 
  
   as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
10:07:50.595658 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.21 seconds
10:07:50.611859 [debug] [Thread-1  ]: finished collecting timing info
10:07:50.612381 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
10:07:50.971184 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3cef4318-224c-46d2-bf0b-0c6246e1ac30', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067c35e0>]}
10:07:50.972391 [info ] [Thread-1  ]: 1 of 4 OK created view model dbt.my_first_dbt_model............................. [[32mSUCCESS 1[0m in 1.40s]
10:07:50.973014 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
10:07:50.978611 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
10:07:50.979375 [info ] [Thread-1  ]: 2 of 4 START view model dbt.snowflake_cumulative_sales.......................... [RUN]
10:07:50.982462 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
10:07:50.983241 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
10:07:50.983576 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
10:07:50.989190 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
10:07:50.991706 [debug] [Thread-1  ]: finished collecting timing info
10:07:50.992163 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
10:07:50.997283 [debug] [Thread-1  ]: Dropping relation "ANALYTICS"."DBT"."SNOWFLAKE_CUMULATIVE_SALES" because it is of type table
10:07:50.999985 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
10:07:51.000325 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */
drop table if exists "ANALYTICS"."DBT"."SNOWFLAKE_CUMULATIVE_SALES" cascade
10:07:51.000554 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:07:51.574956 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.57 seconds
10:07:51.585579 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
10:07:51.588972 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
10:07:51.589260 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */

  create or replace  view analytics.dbt.snowflake_cumulative_sales 
  
   as (
    

select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
  );
10:07:51.830472 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.24 seconds
10:07:51.833574 [debug] [Thread-1  ]: finished collecting timing info
10:07:51.833877 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
10:07:52.032839 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3cef4318-224c-46d2-bf0b-0c6246e1ac30', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107830550>]}
10:07:52.035369 [info ] [Thread-1  ]: 2 of 4 OK created view model dbt.snowflake_cumulative_sales..................... [[32mSUCCESS 1[0m in 1.05s]
10:07:52.036209 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
10:07:52.036774 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
10:07:52.037103 [info ] [Thread-1  ]: 3 of 4 START view model dbt.snowflake_customer_purchases........................ [RUN]
10:07:52.047570 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
10:07:52.048086 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
10:07:52.048387 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
10:07:52.049893 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
10:07:52.050280 [debug] [Thread-1  ]: finished collecting timing info
10:07:52.050376 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
10:07:52.051884 [debug] [Thread-1  ]: Dropping relation "ANALYTICS"."DBT"."SNOWFLAKE_CUSTOMER_PURCHASES" because it is of type table
10:07:52.052933 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
10:07:52.053031 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */
drop table if exists "ANALYTICS"."DBT"."SNOWFLAKE_CUSTOMER_PURCHASES" cascade
10:07:52.053116 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:07:53.339277 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.29 seconds
10:07:53.344574 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
10:07:53.346546 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
10:07:53.346860 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */

  create or replace  view analytics.dbt.snowflake_customer_purchases 
  
   as (
    

select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
  );
10:07:53.655003 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.31 seconds
10:07:53.657899 [debug] [Thread-1  ]: finished collecting timing info
10:07:53.658510 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
10:07:53.989801 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3cef4318-224c-46d2-bf0b-0c6246e1ac30', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107875af0>]}
10:07:53.991083 [info ] [Thread-1  ]: 3 of 4 OK created view model dbt.snowflake_customer_purchases................... [[32mSUCCESS 1[0m in 1.95s]
10:07:53.993684 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
10:07:53.996859 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
10:07:54.002486 [info ] [Thread-1  ]: 4 of 4 START view model dbt.my_second_dbt_model................................. [RUN]
10:07:54.006182 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
10:07:54.006808 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
10:07:54.009639 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
10:07:54.011266 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
10:07:54.012090 [debug] [Thread-1  ]: finished collecting timing info
10:07:54.012296 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
10:07:54.014300 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
10:07:54.014942 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
10:07:54.015100 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */

  create or replace  view analytics.dbt.my_second_dbt_model 
  
   as (
    -- Use the `ref` function to select from other models

select *
from analytics.dbt.my_first_dbt_model
where id = 1
  );
10:07:54.015209 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:07:55.034350 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.02 seconds
10:07:55.038862 [debug] [Thread-1  ]: finished collecting timing info
10:07:55.039195 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
10:07:55.490963 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3cef4318-224c-46d2-bf0b-0c6246e1ac30', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1078758e0>]}
10:07:55.493667 [info ] [Thread-1  ]: 4 of 4 OK created view model dbt.my_second_dbt_model............................ [[32mSUCCESS 1[0m in 1.49s]
10:07:55.494468 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
10:07:55.504931 [debug] [MainThread]: Acquiring new snowflake connection "master"
10:07:55.511276 [info ] [MainThread]: 
10:07:55.511872 [info ] [MainThread]: Finished running 4 view models in 8.56s.
10:07:55.512221 [debug] [MainThread]: Connection 'master' was properly closed.
10:07:55.512397 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
10:07:55.518282 [info ] [MainThread]: 
10:07:55.518606 [info ] [MainThread]: [32mCompleted successfully[0m
10:07:55.518883 [info ] [MainThread]: 
10:07:55.519180 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
10:07:55.519591 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10579a160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1057716d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107844040>]}


============================== 2022-05-13 10:10:07.559830 | aa3b7e75-aa45-4ffa-bc80-b51313bbf248 ==============================
10:10:07.559830 [info ] [MainThread]: Running with dbt=1.0.1
10:10:07.560495 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
10:10:07.560702 [debug] [MainThread]: Tracking: tracking
10:10:07.561041 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10642bf70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10642b460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10642b8b0>]}
10:10:07.595867 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
10:10:07.596094 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'aa3b7e75-aa45-4ffa-bc80-b51313bbf248', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1064325e0>]}
10:10:07.609460 [debug] [MainThread]: Parsing macros/catalog.sql
10:10:07.610709 [debug] [MainThread]: Parsing macros/adapters.sql
10:10:07.631405 [debug] [MainThread]: Parsing macros/materializations/merge.sql
10:10:07.633495 [debug] [MainThread]: Parsing macros/materializations/seed.sql
10:10:07.636210 [debug] [MainThread]: Parsing macros/materializations/view.sql
10:10:07.636871 [debug] [MainThread]: Parsing macros/materializations/table.sql
10:10:07.638358 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
10:10:07.642432 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
10:10:07.642866 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
10:10:07.644637 [debug] [MainThread]: Parsing macros/materializations/configs.sql
10:10:07.645679 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
10:10:07.646448 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
10:10:07.654748 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
10:10:07.660599 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
10:10:07.666814 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
10:10:07.669164 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
10:10:07.670064 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
10:10:07.670895 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
10:10:07.673051 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
10:10:07.678747 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
10:10:07.679507 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
10:10:07.684772 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
10:10:07.692922 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
10:10:07.696696 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
10:10:07.698340 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
10:10:07.702226 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
10:10:07.702864 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
10:10:07.704158 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
10:10:07.705234 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
10:10:07.708216 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
10:10:07.716610 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
10:10:07.717503 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
10:10:07.718691 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
10:10:07.719578 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
10:10:07.720139 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
10:10:07.720512 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
10:10:07.720963 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
10:10:07.721611 [debug] [MainThread]: Parsing macros/etc/statement.sql
10:10:07.723792 [debug] [MainThread]: Parsing macros/etc/datetime.sql
10:10:07.728278 [debug] [MainThread]: Parsing macros/adapters/schema.sql
10:10:07.729391 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
10:10:07.730696 [debug] [MainThread]: Parsing macros/adapters/relation.sql
10:10:07.735561 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
10:10:07.736940 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
10:10:07.739368 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
10:10:07.743090 [debug] [MainThread]: Parsing macros/adapters/columns.sql
10:10:07.747809 [debug] [MainThread]: Parsing tests/generic/builtin.sql
10:10:07.845699 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
10:10:07.851737 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_cumulative_sales.sql
10:10:07.852833 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
10:10:07.853805 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
10:10:07.884430 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'aa3b7e75-aa45-4ffa-bc80-b51313bbf248', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10653e2b0>]}
10:10:07.887864 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'aa3b7e75-aa45-4ffa-bc80-b51313bbf248', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10653e280>]}
10:10:07.888074 [info ] [MainThread]: Found 4 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
10:10:07.888830 [info ] [MainThread]: 
10:10:07.889085 [debug] [MainThread]: Acquiring new snowflake connection "master"
10:10:07.889581 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
10:10:07.896310 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
10:10:07.896440 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
10:10:07.896509 [debug] [ThreadPool]: Opening a new connection, currently in state init
10:10:08.987528 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.09 seconds
10:10:08.991367 [debug] [ThreadPool]: On list_analytics: Close
10:10:09.304231 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
10:10:09.312608 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
10:10:09.312909 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
10:10:09.313074 [debug] [ThreadPool]: Opening a new connection, currently in state closed
10:10:10.295756 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 0.98 seconds
10:10:10.297897 [debug] [ThreadPool]: On list_analytics_dbt: Close
10:10:10.481390 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
10:10:10.483026 [info ] [MainThread]: 
10:10:10.486322 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
10:10:10.486599 [info ] [Thread-1  ]: 1 of 4 START view model dbt.my_first_dbt_model.................................. [RUN]
10:10:10.487179 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
10:10:10.487313 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
10:10:10.487427 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
10:10:10.490080 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
10:10:10.490704 [debug] [Thread-1  ]: finished collecting timing info
10:10:10.490894 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
10:10:10.511713 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
10:10:10.512673 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
10:10:10.512796 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */

  create or replace  view analytics.dbt.my_first_dbt_model 
  
   as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
    

*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
10:10:10.512899 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:10:11.573986 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.06 seconds
10:10:11.579871 [debug] [Thread-1  ]: finished collecting timing info
10:10:11.580162 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
10:10:12.033431 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'aa3b7e75-aa45-4ffa-bc80-b51313bbf248', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079a6190>]}
10:10:12.033937 [info ] [Thread-1  ]: 1 of 4 OK created view model dbt.my_first_dbt_model............................. [[32mSUCCESS 1[0m in 1.55s]
10:10:12.034274 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
10:10:12.034453 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
10:10:12.034772 [info ] [Thread-1  ]: 2 of 4 START table model dbt.snowflake_cumulative_sales......................... [RUN]
10:10:12.035359 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
10:10:12.035535 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
10:10:12.035680 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
10:10:12.036906 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
10:10:12.037496 [debug] [Thread-1  ]: finished collecting timing info
10:10:12.037646 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
10:10:12.046255 [debug] [Thread-1  ]: Dropping relation "ANALYTICS"."DBT"."SNOWFLAKE_CUMULATIVE_SALES" because it is of type view
10:10:12.052982 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
10:10:12.053198 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */
drop view if exists "ANALYTICS"."DBT"."SNOWFLAKE_CUMULATIVE_SALES" cascade
10:10:12.053331 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:10:13.029692 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.98 seconds
10:10:13.041963 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
10:10:13.043621 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
10:10:13.043899 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
10:10:15.110511 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.07 seconds
10:10:15.118543 [debug] [Thread-1  ]: finished collecting timing info
10:10:15.118766 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
10:10:15.283924 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'aa3b7e75-aa45-4ffa-bc80-b51313bbf248', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079f7e80>]}
10:10:15.300691 [info ] [Thread-1  ]: 2 of 4 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 3.25s]
10:10:15.301587 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
10:10:15.301899 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
10:10:15.302225 [info ] [Thread-1  ]: 3 of 4 START table model dbt.snowflake_customer_purchases....................... [RUN]
10:10:15.303395 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
10:10:15.303664 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
10:10:15.303808 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
10:10:15.305111 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
10:10:15.305595 [debug] [Thread-1  ]: finished collecting timing info
10:10:15.305703 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
10:10:15.306701 [debug] [Thread-1  ]: Dropping relation "ANALYTICS"."DBT"."SNOWFLAKE_CUSTOMER_PURCHASES" because it is of type view
10:10:15.307913 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
10:10:15.308065 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */
drop view if exists "ANALYTICS"."DBT"."SNOWFLAKE_CUSTOMER_PURCHASES" cascade
10:10:15.308152 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:10:16.159893 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.85 seconds
10:10:16.162344 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
10:10:16.163813 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
10:10:16.164044 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
10:10:17.746974 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.58 seconds
10:10:17.749941 [debug] [Thread-1  ]: finished collecting timing info
10:10:17.750166 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
10:10:17.966155 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'aa3b7e75-aa45-4ffa-bc80-b51313bbf248', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b9cdc0>]}
10:10:17.966490 [info ] [Thread-1  ]: 3 of 4 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.66s]
10:10:17.966699 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
10:10:17.966819 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
10:10:17.967098 [info ] [Thread-1  ]: 4 of 4 START table model dbt.my_second_dbt_model................................ [RUN]
10:10:17.967501 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
10:10:17.967608 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
10:10:17.967711 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
10:10:17.969252 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
10:10:17.970341 [debug] [Thread-1  ]: finished collecting timing info
10:10:17.970468 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
10:10:17.971744 [debug] [Thread-1  ]: Dropping relation "ANALYTICS"."DBT"."MY_SECOND_DBT_MODEL" because it is of type view
10:10:17.972825 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
10:10:17.972922 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */
drop view if exists "ANALYTICS"."DBT"."MY_SECOND_DBT_MODEL" cascade
10:10:17.973006 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:10:18.617260 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.64 seconds
10:10:18.623686 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
10:10:18.626107 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
10:10:18.626482 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.my_first_dbt_model
where id = 1
      );
10:10:19.368150 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.74 seconds
10:10:19.370391 [debug] [Thread-1  ]: finished collecting timing info
10:10:19.370629 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
10:10:19.668536 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'aa3b7e75-aa45-4ffa-bc80-b51313bbf248', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107bd1d00>]}
10:10:19.669377 [info ] [Thread-1  ]: 4 of 4 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.70s]
10:10:19.670011 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
10:10:19.671743 [debug] [MainThread]: Acquiring new snowflake connection "master"
10:10:19.672322 [info ] [MainThread]: 
10:10:19.672688 [info ] [MainThread]: Finished running 1 view model, 3 table models in 11.78s.
10:10:19.672998 [debug] [MainThread]: Connection 'master' was properly closed.
10:10:19.673168 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
10:10:19.680319 [info ] [MainThread]: 
10:10:19.680747 [info ] [MainThread]: [32mCompleted successfully[0m
10:10:19.680904 [info ] [MainThread]: 
10:10:19.681013 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
10:10:19.681194 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10653ee50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10653ee80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079f4a00>]}


============================== 2022-05-13 10:11:40.046224 | f9ab338d-651f-4b5c-a4cd-fbdf0e252ff8 ==============================
10:11:40.046224 [info ] [MainThread]: Running with dbt=1.0.1
10:11:40.046813 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
10:11:40.046947 [debug] [MainThread]: Tracking: tracking
10:11:40.047173 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059c2070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059c21c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059c2d60>]}
10:11:40.091287 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
10:11:40.091565 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/my_first_dbt_model.sql
10:11:40.098147 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
10:11:40.117658 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f9ab338d-651f-4b5c-a4cd-fbdf0e252ff8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104523c10>]}
10:11:40.120622 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f9ab338d-651f-4b5c-a4cd-fbdf0e252ff8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059aecd0>]}
10:11:40.120755 [info ] [MainThread]: Found 4 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
10:11:40.121412 [info ] [MainThread]: 
10:11:40.121616 [debug] [MainThread]: Acquiring new snowflake connection "master"
10:11:40.122081 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
10:11:40.127930 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
10:11:40.128024 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
10:11:40.128088 [debug] [ThreadPool]: Opening a new connection, currently in state init
10:11:41.664125 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.54 seconds
10:11:41.666682 [debug] [ThreadPool]: On list_analytics: Close
10:11:42.068264 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
10:11:42.077650 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
10:11:42.077908 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
10:11:42.078071 [debug] [ThreadPool]: Opening a new connection, currently in state closed
10:11:43.023777 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 0.95 seconds
10:11:43.024909 [debug] [ThreadPool]: On list_analytics_dbt: Close
10:11:43.222683 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
10:11:43.223147 [info ] [MainThread]: 
10:11:43.227677 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
10:11:43.228184 [info ] [Thread-1  ]: 1 of 4 START table model dbt.my_first_dbt_model................................. [RUN]
10:11:43.229275 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
10:11:43.229428 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
10:11:43.229548 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
10:11:43.230860 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
10:11:43.231411 [debug] [Thread-1  ]: finished collecting timing info
10:11:43.231584 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
10:11:43.247157 [debug] [Thread-1  ]: Dropping relation "ANALYTICS"."DBT"."MY_FIRST_DBT_MODEL" because it is of type view
10:11:43.252066 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
10:11:43.252242 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */
drop view if exists "ANALYTICS"."DBT"."MY_FIRST_DBT_MODEL" cascade
10:11:43.252354 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:11:44.208918 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.96 seconds
10:11:44.222982 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
10:11:44.224447 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
10:11:44.224622 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
10:11:45.728459 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.5 seconds
10:11:45.749614 [debug] [Thread-1  ]: finished collecting timing info
10:11:45.750073 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
10:11:46.183459 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f9ab338d-651f-4b5c-a4cd-fbdf0e252ff8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ec23a0>]}
10:11:46.183819 [info ] [Thread-1  ]: 1 of 4 OK created table model dbt.my_first_dbt_model............................ [[32mSUCCESS 1[0m in 2.95s]
10:11:46.184028 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
10:11:46.184144 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
10:11:46.184516 [info ] [Thread-1  ]: 2 of 4 START table model dbt.snowflake_cumulative_sales......................... [RUN]
10:11:46.184877 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
10:11:46.184973 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
10:11:46.185061 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
10:11:46.186077 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
10:11:46.186476 [debug] [Thread-1  ]: finished collecting timing info
10:11:46.186575 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
10:11:46.188447 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
10:11:46.189104 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
10:11:46.189206 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
10:11:46.189293 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:11:48.181530 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.99 seconds
10:11:48.188969 [debug] [Thread-1  ]: finished collecting timing info
10:11:48.189545 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
10:11:48.365975 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f9ab338d-651f-4b5c-a4cd-fbdf0e252ff8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059ad5e0>]}
10:11:48.367050 [info ] [Thread-1  ]: 2 of 4 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 2.18s]
10:11:48.367698 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
10:11:48.368526 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
10:11:48.372650 [info ] [Thread-1  ]: 3 of 4 START table model dbt.snowflake_customer_purchases....................... [RUN]
10:11:48.374013 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
10:11:48.374471 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
10:11:48.378034 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
10:11:48.380153 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
10:11:48.382010 [debug] [Thread-1  ]: finished collecting timing info
10:11:48.382296 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
10:11:48.384771 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
10:11:48.385916 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
10:11:48.386095 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
10:11:48.386259 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:11:50.475895 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.09 seconds
10:11:50.483017 [debug] [Thread-1  ]: finished collecting timing info
10:11:50.483504 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
10:11:50.686506 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f9ab338d-651f-4b5c-a4cd-fbdf0e252ff8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105b91a30>]}
10:11:50.687182 [info ] [Thread-1  ]: 3 of 4 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.31s]
10:11:50.687586 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
10:11:50.687952 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
10:11:50.688666 [info ] [Thread-1  ]: 4 of 4 START table model dbt.my_second_dbt_model................................ [RUN]
10:11:50.689806 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
10:11:50.690228 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
10:11:50.694696 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
10:11:50.701589 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
10:11:50.702562 [debug] [Thread-1  ]: finished collecting timing info
10:11:50.702883 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
10:11:50.705072 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
10:11:50.706083 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
10:11:50.706314 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.my_first_dbt_model
where id = 1
      );
10:11:50.706459 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:11:52.001425 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.29 seconds
10:11:52.007036 [debug] [Thread-1  ]: finished collecting timing info
10:11:52.007732 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
10:11:52.170583 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f9ab338d-651f-4b5c-a4cd-fbdf0e252ff8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108f65d30>]}
10:11:52.171743 [info ] [Thread-1  ]: 4 of 4 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.48s]
10:11:52.172313 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
10:11:52.182554 [debug] [MainThread]: Acquiring new snowflake connection "master"
10:11:52.183033 [info ] [MainThread]: 
10:11:52.183297 [info ] [MainThread]: Finished running 4 table models in 12.06s.
10:11:52.183515 [debug] [MainThread]: Connection 'master' was properly closed.
10:11:52.183630 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
10:11:52.189749 [info ] [MainThread]: 
10:11:52.189993 [info ] [MainThread]: [32mCompleted successfully[0m
10:11:52.190160 [info ] [MainThread]: 
10:11:52.190286 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
10:11:52.190480 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059ad430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059aeac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105f4b190>]}


============================== 2022-05-13 10:22:40.475516 | b5ae4c6a-e79c-494d-a821-d98627e37916 ==============================
10:22:40.475516 [info ] [MainThread]: Running with dbt=1.0.1
10:22:40.476066 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
10:22:40.476192 [debug] [MainThread]: Tracking: tracking
10:22:40.476432 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10736ddc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10736d7f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107f626d0>]}
10:22:40.522042 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
10:22:40.522260 [debug] [MainThread]: Partial parsing: added file: learn_dbt://models/example/dates.sql
10:22:40.522460 [debug] [MainThread]: Partial parsing: update schema file: learn_dbt://models/example/schema.yml
10:22:40.527812 [debug] [MainThread]: 1603: static parser failed on example/dates.sql
10:22:40.536387 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/dates.sql
10:22:40.544631 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b5ae4c6a-e79c-494d-a821-d98627e37916', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ac40d0>]}
10:22:40.547794 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b5ae4c6a-e79c-494d-a821-d98627e37916', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105b8d1f0>]}
10:22:40.547939 [info ] [MainThread]: Found 5 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
10:22:40.548667 [info ] [MainThread]: 
10:22:40.548873 [debug] [MainThread]: Acquiring new snowflake connection "master"
10:22:40.549307 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
10:22:40.555292 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
10:22:40.555447 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
10:22:40.555520 [debug] [ThreadPool]: Opening a new connection, currently in state init
10:22:42.140268 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.58 seconds
10:22:42.141626 [debug] [ThreadPool]: On list_analytics: Close
10:22:42.628921 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
10:22:42.637539 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
10:22:42.637987 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
10:22:42.638158 [debug] [ThreadPool]: Opening a new connection, currently in state closed
10:22:43.660655 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.02 seconds
10:22:43.663529 [debug] [ThreadPool]: On list_analytics_dbt: Close
10:22:43.868965 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
10:22:43.870006 [info ] [MainThread]: 
10:22:43.876045 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
10:22:43.876787 [info ] [Thread-1  ]: 1 of 5 START incremental model dbt.dates........................................ [RUN]
10:22:43.877302 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
10:22:43.877479 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
10:22:43.877641 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
10:22:43.880957 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
10:22:43.881849 [debug] [Thread-1  ]: finished collecting timing info
10:22:43.882145 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
10:22:43.914867 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
10:22:43.915609 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:22:43.915712 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */


      create or replace transient table analytics.dbt.dates  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


      );
10:22:43.915798 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:22:46.320899 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.41 seconds
10:22:46.335237 [debug] [Thread-1  ]: finished collecting timing info
10:22:46.335648 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
10:22:46.676972 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b5ae4c6a-e79c-494d-a821-d98627e37916', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105b8d190>]}
10:22:46.677846 [info ] [Thread-1  ]: 1 of 5 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 2.80s]
10:22:46.678376 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
10:22:46.678660 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
10:22:46.679074 [info ] [Thread-1  ]: 2 of 5 START table model dbt.my_first_dbt_model................................. [RUN]
10:22:46.679797 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
10:22:46.679985 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
10:22:46.680156 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
10:22:46.681885 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
10:22:46.682567 [debug] [Thread-1  ]: finished collecting timing info
10:22:46.682748 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
10:22:46.692175 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
10:22:46.693323 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
10:22:46.693496 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
10:22:46.693610 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:22:48.245112 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.55 seconds
10:22:48.248337 [debug] [Thread-1  ]: finished collecting timing info
10:22:48.248667 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
10:22:48.437942 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b5ae4c6a-e79c-494d-a821-d98627e37916', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108793190>]}
10:22:48.438478 [info ] [Thread-1  ]: 2 of 5 OK created table model dbt.my_first_dbt_model............................ [[32mSUCCESS 1[0m in 1.76s]
10:22:48.438821 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
10:22:48.438995 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
10:22:48.439206 [info ] [Thread-1  ]: 3 of 5 START table model dbt.snowflake_cumulative_sales......................... [RUN]
10:22:48.439627 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
10:22:48.439907 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
10:22:48.440088 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
10:22:48.441198 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
10:22:48.442661 [debug] [Thread-1  ]: finished collecting timing info
10:22:48.442825 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
10:22:48.445223 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
10:22:48.446264 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
10:22:48.446437 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
10:22:48.446592 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:22:49.770067 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.32 seconds
10:22:49.773283 [debug] [Thread-1  ]: finished collecting timing info
10:22:49.773693 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
10:22:49.961223 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b5ae4c6a-e79c-494d-a821-d98627e37916', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108783310>]}
10:22:49.962345 [info ] [Thread-1  ]: 3 of 5 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 1.52s]
10:22:49.962910 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
10:22:49.963168 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
10:22:49.963457 [info ] [Thread-1  ]: 4 of 5 START table model dbt.snowflake_customer_purchases....................... [RUN]
10:22:49.964230 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
10:22:49.964478 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
10:22:49.964684 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
10:22:49.966159 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
10:22:49.966822 [debug] [Thread-1  ]: finished collecting timing info
10:22:49.966951 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
10:22:49.968933 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
10:22:49.969818 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
10:22:49.969979 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
10:22:49.970126 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:22:51.509218 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.54 seconds
10:22:51.512048 [debug] [Thread-1  ]: finished collecting timing info
10:22:51.512486 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
10:22:51.689990 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b5ae4c6a-e79c-494d-a821-d98627e37916', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108591c40>]}
10:22:51.691504 [info ] [Thread-1  ]: 4 of 5 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 1.73s]
10:22:51.691957 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
10:22:51.692162 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
10:22:51.692514 [info ] [Thread-1  ]: 5 of 5 START table model dbt.my_second_dbt_model................................ [RUN]
10:22:51.693084 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
10:22:51.693263 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
10:22:51.693430 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
10:22:51.696049 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
10:22:51.697682 [debug] [Thread-1  ]: finished collecting timing info
10:22:51.697917 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
10:22:51.700700 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
10:22:51.701698 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
10:22:51.701875 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.my_first_dbt_model
where id = 1
      );
10:22:51.702024 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:22:53.255479 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.55 seconds
10:22:53.258778 [debug] [Thread-1  ]: finished collecting timing info
10:22:53.259119 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
10:22:53.585650 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b5ae4c6a-e79c-494d-a821-d98627e37916', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1087e8190>]}
10:22:53.586065 [info ] [Thread-1  ]: 5 of 5 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.89s]
10:22:53.586306 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
10:22:53.587222 [debug] [MainThread]: Acquiring new snowflake connection "master"
10:22:53.587567 [info ] [MainThread]: 
10:22:53.587763 [info ] [MainThread]: Finished running 1 incremental model, 4 table models in 13.04s.
10:22:53.587924 [debug] [MainThread]: Connection 'master' was properly closed.
10:22:53.588010 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
10:22:53.592427 [info ] [MainThread]: 
10:22:53.592636 [info ] [MainThread]: [32mCompleted successfully[0m
10:22:53.592845 [info ] [MainThread]: 
10:22:53.593013 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
10:22:53.593260 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107f58a30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107f58cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108595280>]}


============================== 2022-05-13 10:23:58.873944 | 23c79a0b-2ec6-4c8b-bb70-1f3ce53759ff ==============================
10:23:58.873944 [info ] [MainThread]: Running with dbt=1.0.1
10:23:58.874506 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
10:23:58.874622 [debug] [MainThread]: Tracking: tracking
10:23:58.874846 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e95190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e950a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e95b20>]}
10:23:58.919476 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
10:23:58.919622 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
10:23:58.922837 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '23c79a0b-2ec6-4c8b-bb70-1f3ce53759ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e69100>]}
10:23:58.926150 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '23c79a0b-2ec6-4c8b-bb70-1f3ce53759ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106480fa0>]}
10:23:58.926287 [info ] [MainThread]: Found 5 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
10:23:58.927031 [info ] [MainThread]: 
10:23:58.927243 [debug] [MainThread]: Acquiring new snowflake connection "master"
10:23:58.927682 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
10:23:58.933842 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
10:23:58.933985 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
10:23:58.934054 [debug] [ThreadPool]: Opening a new connection, currently in state init
10:23:59.715391 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.78 seconds
10:23:59.719088 [debug] [ThreadPool]: On list_analytics: Close
10:24:00.139071 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
10:24:00.146720 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
10:24:00.146939 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
10:24:00.147052 [debug] [ThreadPool]: Opening a new connection, currently in state closed
10:24:01.317830 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1.17 seconds
10:24:01.319837 [debug] [ThreadPool]: On list_analytics_dbt: Close
10:24:01.483093 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
10:24:01.483626 [info ] [MainThread]: 
10:24:01.487668 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
10:24:01.488196 [info ] [Thread-1  ]: 1 of 5 START incremental model dbt.dates........................................ [RUN]
10:24:01.488509 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
10:24:01.488592 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
10:24:01.488676 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
10:24:01.496978 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
10:24:01.497654 [debug] [Thread-1  ]: finished collecting timing info
10:24:01.498006 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
10:24:01.529096 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:24:01.529299 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
10:24:01.529388 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:24:02.854987 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.33 seconds
10:24:02.866162 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:24:02.866460 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
10:24:02.975256 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.11 seconds
10:24:02.983665 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:24:02.983995 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
10:24:03.218934 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.23 seconds
10:24:03.226690 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:24:03.226974 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
10:24:03.324761 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.1 seconds
10:24:03.351791 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
10:24:03.354516 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:24:03.354683 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
10:24:03.537475 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.18 seconds
10:24:03.538585 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:24:03.538844 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
10:24:04.345712 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.81 seconds
10:24:04.346560 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:24:04.346793 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
10:24:04.582804 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.24 seconds
10:24:04.597293 [debug] [Thread-1  ]: finished collecting timing info
10:24:04.597685 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
10:24:04.891622 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '23c79a0b-2ec6-4c8b-bb70-1f3ce53759ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107041220>]}
10:24:04.892644 [info ] [Thread-1  ]: 1 of 5 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 3.40s]
10:24:04.893279 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
10:24:04.893549 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
10:24:04.893977 [info ] [Thread-1  ]: 2 of 5 START table model dbt.my_first_dbt_model................................. [RUN]
10:24:04.894596 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
10:24:04.894763 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
10:24:04.894908 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
10:24:04.896413 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
10:24:04.896997 [debug] [Thread-1  ]: finished collecting timing info
10:24:04.897160 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
10:24:04.907093 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
10:24:04.908239 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
10:24:04.908401 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
10:24:04.908536 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:24:06.427799 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.52 seconds
10:24:06.430605 [debug] [Thread-1  ]: finished collecting timing info
10:24:06.431182 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
10:24:06.612349 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '23c79a0b-2ec6-4c8b-bb70-1f3ce53759ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10726b460>]}
10:24:06.613509 [info ] [Thread-1  ]: 2 of 5 OK created table model dbt.my_first_dbt_model............................ [[32mSUCCESS 1[0m in 1.72s]
10:24:06.615451 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
10:24:06.615947 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
10:24:06.617513 [info ] [Thread-1  ]: 3 of 5 START table model dbt.snowflake_cumulative_sales......................... [RUN]
10:24:06.618272 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
10:24:06.618689 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
10:24:06.618923 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
10:24:06.620715 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
10:24:06.621417 [debug] [Thread-1  ]: finished collecting timing info
10:24:06.621623 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
10:24:06.625346 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
10:24:06.626373 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
10:24:06.626546 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
10:24:06.626702 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:24:08.810552 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.18 seconds
10:24:08.813982 [debug] [Thread-1  ]: finished collecting timing info
10:24:08.814447 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
10:24:09.092187 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '23c79a0b-2ec6-4c8b-bb70-1f3ce53759ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10740e3a0>]}
10:24:09.092929 [info ] [Thread-1  ]: 3 of 5 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 2.47s]
10:24:09.093376 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
10:24:09.093619 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
10:24:09.094065 [info ] [Thread-1  ]: 4 of 5 START table model dbt.snowflake_customer_purchases....................... [RUN]
10:24:09.094704 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
10:24:09.094919 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
10:24:09.095121 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
10:24:09.096933 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
10:24:09.097518 [debug] [Thread-1  ]: finished collecting timing info
10:24:09.097691 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
10:24:09.100081 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
10:24:09.101119 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
10:24:09.101252 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
10:24:09.101372 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:24:11.145268 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.04 seconds
10:24:11.150441 [debug] [Thread-1  ]: finished collecting timing info
10:24:11.150733 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
10:24:11.314221 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '23c79a0b-2ec6-4c8b-bb70-1f3ce53759ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107426580>]}
10:24:11.314740 [info ] [Thread-1  ]: 4 of 5 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.22s]
10:24:11.315040 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
10:24:11.315213 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
10:24:11.315572 [info ] [Thread-1  ]: 5 of 5 START table model dbt.my_second_dbt_model................................ [RUN]
10:24:11.316037 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
10:24:11.316173 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
10:24:11.316304 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
10:24:11.318332 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
10:24:11.319131 [debug] [Thread-1  ]: finished collecting timing info
10:24:11.319312 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
10:24:11.321581 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
10:24:11.322413 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
10:24:11.322650 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.my_first_dbt_model
where id = 1
      );
10:24:11.322779 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:24:13.201459 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.88 seconds
10:24:13.205212 [debug] [Thread-1  ]: finished collecting timing info
10:24:13.205582 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
10:24:13.391513 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '23c79a0b-2ec6-4c8b-bb70-1f3ce53759ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107214af0>]}
10:24:13.392370 [info ] [Thread-1  ]: 5 of 5 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 2.08s]
10:24:13.392790 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
10:24:13.394010 [debug] [MainThread]: Acquiring new snowflake connection "master"
10:24:13.394487 [info ] [MainThread]: 
10:24:13.394787 [info ] [MainThread]: Finished running 1 incremental model, 4 table models in 14.47s.
10:24:13.395034 [debug] [MainThread]: Connection 'master' was properly closed.
10:24:13.395168 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
10:24:13.402255 [info ] [MainThread]: 
10:24:13.402580 [info ] [MainThread]: [32mCompleted successfully[0m
10:24:13.402873 [info ] [MainThread]: 
10:24:13.403102 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
10:24:13.403499 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106eb6be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10730c730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107269b80>]}


============================== 2022-05-13 10:27:13.941039 | b085d19b-3e35-4321-ace1-821965bfeecd ==============================
10:27:13.941039 [info ] [MainThread]: Running with dbt=1.0.1
10:27:13.941584 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
10:27:13.941714 [debug] [MainThread]: Tracking: tracking
10:27:13.941943 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x118421520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x118421100>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x118421280>]}
10:27:13.986426 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
10:27:13.986715 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/my_first_dbt_model.sql
10:27:13.992423 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
10:27:14.013643 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b085d19b-3e35-4321-ace1-821965bfeecd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075758e0>]}
10:27:14.016617 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b085d19b-3e35-4321-ace1-821965bfeecd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107935eb0>]}
10:27:14.016751 [info ] [MainThread]: Found 5 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
10:27:14.017495 [info ] [MainThread]: 
10:27:14.017729 [debug] [MainThread]: Acquiring new snowflake connection "master"
10:27:14.018141 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
10:27:14.024103 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
10:27:14.024192 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
10:27:14.024258 [debug] [ThreadPool]: Opening a new connection, currently in state init
10:27:15.134093 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.11 seconds
10:27:15.139788 [debug] [ThreadPool]: On list_analytics: Close
10:27:15.329902 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
10:27:15.339704 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
10:27:15.339982 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
10:27:15.340143 [debug] [ThreadPool]: Opening a new connection, currently in state closed
10:27:16.246134 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 0.91 seconds
10:27:16.249078 [debug] [ThreadPool]: On list_analytics_dbt: Close
10:27:16.427611 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
10:27:16.427976 [info ] [MainThread]: 
10:27:16.431385 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
10:27:16.431927 [info ] [Thread-1  ]: 1 of 4 START incremental model dbt.dates........................................ [RUN]
10:27:16.432430 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
10:27:16.432543 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
10:27:16.432639 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
10:27:16.438538 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
10:27:16.439108 [debug] [Thread-1  ]: finished collecting timing info
10:27:16.439228 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
10:27:16.468724 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:27:16.468943 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
10:27:16.469033 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:27:18.390949 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.92 seconds
10:27:18.408115 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:27:18.408370 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
10:27:18.517374 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.11 seconds
10:27:18.527283 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:27:18.527721 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
10:27:18.705042 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.18 seconds
10:27:18.717119 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:27:18.717378 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
10:27:18.833129 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.12 seconds
10:27:18.855766 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
10:27:18.858123 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:27:18.858258 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
10:27:19.093273 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.23 seconds
10:27:19.094039 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:27:19.094324 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
10:27:19.882306 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.79 seconds
10:27:19.882853 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:27:19.883070 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
10:27:20.143258 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.26 seconds
10:27:20.154967 [debug] [Thread-1  ]: finished collecting timing info
10:27:20.155304 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
10:27:20.345107 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b085d19b-3e35-4321-ace1-821965bfeecd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1072a80a0>]}
10:27:20.346120 [info ] [Thread-1  ]: 1 of 4 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 3.91s]
10:27:20.346728 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
10:27:20.346996 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
10:27:20.347613 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
10:27:20.347902 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
10:27:20.348133 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
10:27:20.350601 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
10:27:20.351133 [debug] [Thread-1  ]: finished collecting timing info
10:27:20.351378 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
10:27:20.351472 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
10:27:20.351672 [info ] [Thread-1  ]: 2 of 4 START table model dbt.snowflake_cumulative_sales......................... [RUN]
10:27:20.351875 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
10:27:20.351945 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
10:27:20.352010 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
10:27:20.352749 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
10:27:20.353019 [debug] [Thread-1  ]: finished collecting timing info
10:27:20.353104 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
10:27:20.362029 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
10:27:20.363060 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
10:27:20.363202 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
10:27:20.363330 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:27:21.845889 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.48 seconds
10:27:21.854512 [debug] [Thread-1  ]: finished collecting timing info
10:27:21.855137 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
10:27:22.021403 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b085d19b-3e35-4321-ace1-821965bfeecd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b2e5fd0>]}
10:27:22.021912 [info ] [Thread-1  ]: 2 of 4 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 1.67s]
10:27:22.022267 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
10:27:22.022466 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
10:27:22.022922 [info ] [Thread-1  ]: 3 of 4 START table model dbt.snowflake_customer_purchases....................... [RUN]
10:27:22.023607 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
10:27:22.023833 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
10:27:22.024046 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
10:27:22.025907 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
10:27:22.026791 [debug] [Thread-1  ]: finished collecting timing info
10:27:22.026968 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
10:27:22.029681 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
10:27:22.031055 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
10:27:22.031240 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
10:27:22.031395 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:27:24.072971 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.04 seconds
10:27:24.076198 [debug] [Thread-1  ]: finished collecting timing info
10:27:24.082590 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
10:27:24.340493 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b085d19b-3e35-4321-ace1-821965bfeecd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1187590a0>]}
10:27:24.341251 [info ] [Thread-1  ]: 3 of 4 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.32s]
10:27:24.341692 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
10:27:24.341892 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
10:27:24.342327 [info ] [Thread-1  ]: 4 of 4 START table model dbt.my_second_dbt_model................................ [RUN]
10:27:24.342923 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
10:27:24.343107 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
10:27:24.343271 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
10:27:24.352834 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
10:27:24.353477 [debug] [Thread-1  ]: finished collecting timing info
10:27:24.353647 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
10:27:24.355702 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
10:27:24.356815 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
10:27:24.356948 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (with __dbt__cte__my_first_dbt_model as (
/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
)-- Use the `ref` function to select from other models

select *
from __dbt__cte__my_first_dbt_model
where id = 1
      );
10:27:24.357063 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:27:25.654590 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.3 seconds
10:27:25.659022 [debug] [Thread-1  ]: finished collecting timing info
10:27:25.659503 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
10:27:25.831773 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b085d19b-3e35-4321-ace1-821965bfeecd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x118759760>]}
10:27:25.832399 [info ] [Thread-1  ]: 4 of 4 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.49s]
10:27:25.832841 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
10:27:25.834091 [debug] [MainThread]: Acquiring new snowflake connection "master"
10:27:25.834489 [info ] [MainThread]: 
10:27:25.834778 [info ] [MainThread]: Finished running 1 incremental model, 3 table models in 11.82s.
10:27:25.835230 [debug] [MainThread]: Connection 'master' was properly closed.
10:27:25.835613 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
10:27:25.842008 [info ] [MainThread]: 
10:27:25.842335 [info ] [MainThread]: [32mCompleted successfully[0m
10:27:25.842627 [info ] [MainThread]: 
10:27:25.842835 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
10:27:25.843113 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1072a84c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11842f5b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1191593a0>]}


============================== 2022-05-13 10:28:28.959836 | 9f672fa7-bca0-4677-ba30-16ff5b6bf7e8 ==============================
10:28:28.959836 [info ] [MainThread]: Running with dbt=1.0.1
10:28:28.960220 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
10:28:28.960353 [debug] [MainThread]: Tracking: tracking
10:28:28.960577 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112612580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1126120d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112612220>]}
10:28:29.002348 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
10:28:29.002488 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
10:28:29.005473 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9f672fa7-bca0-4677-ba30-16ff5b6bf7e8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112733fd0>]}
10:28:29.008660 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9f672fa7-bca0-4677-ba30-16ff5b6bf7e8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111b477f0>]}
10:28:29.008798 [info ] [MainThread]: Found 5 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
10:28:29.009461 [info ] [MainThread]: 
10:28:29.009661 [debug] [MainThread]: Acquiring new snowflake connection "master"
10:28:29.010147 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
10:28:29.016532 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
10:28:29.016654 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
10:28:29.016725 [debug] [ThreadPool]: Opening a new connection, currently in state init
10:28:29.812555 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.8 seconds
10:28:29.814837 [debug] [ThreadPool]: On list_analytics: Close
10:28:30.160995 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
10:28:30.169524 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
10:28:30.169765 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
10:28:30.169928 [debug] [ThreadPool]: Opening a new connection, currently in state closed
10:28:31.273550 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.1 seconds
10:28:31.276328 [debug] [ThreadPool]: On list_analytics_dbt: Close
10:28:31.726727 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
10:28:31.727373 [info ] [MainThread]: 
10:28:31.730805 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
10:28:31.731318 [info ] [Thread-1  ]: 1 of 4 START incremental model dbt.dates........................................ [RUN]
10:28:31.731679 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
10:28:31.731783 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
10:28:31.731879 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
10:28:31.737956 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
10:28:31.738469 [debug] [Thread-1  ]: finished collecting timing info
10:28:31.738573 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
10:28:31.766877 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:28:31.767120 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
10:28:31.767221 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:28:33.670015 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.9 seconds
10:28:33.682918 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:28:33.683275 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
10:28:33.838281 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.15 seconds
10:28:33.845247 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:28:33.845589 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
10:28:33.980484 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.13 seconds
10:28:33.991733 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:28:33.992021 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
10:28:34.196656 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.2 seconds
10:28:34.225900 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
10:28:34.228352 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:28:34.228538 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
10:28:34.367229 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.14 seconds
10:28:34.368049 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:28:34.368244 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
10:28:34.917145 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.55 seconds
10:28:34.918792 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:28:34.919189 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
10:28:35.241282 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.32 seconds
10:28:35.256119 [debug] [Thread-1  ]: finished collecting timing info
10:28:35.256413 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
10:28:35.899124 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f672fa7-bca0-4677-ba30-16ff5b6bf7e8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1127aa1f0>]}
10:28:35.899870 [info ] [Thread-1  ]: 1 of 4 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 4.17s]
10:28:35.900532 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
10:28:35.900916 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
10:28:35.901582 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
10:28:35.901819 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
10:28:35.902004 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
10:28:35.905279 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
10:28:35.906121 [debug] [Thread-1  ]: finished collecting timing info
10:28:35.906562 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
10:28:35.906764 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
10:28:35.907162 [info ] [Thread-1  ]: 2 of 4 START table model dbt.snowflake_cumulative_sales......................... [RUN]
10:28:35.907953 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
10:28:35.908183 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
10:28:35.908316 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
10:28:35.909287 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
10:28:35.909660 [debug] [Thread-1  ]: finished collecting timing info
10:28:35.909751 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
10:28:35.918069 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
10:28:35.918880 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
10:28:35.919015 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
10:28:35.919129 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:28:37.372169 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.45 seconds
10:28:37.375620 [debug] [Thread-1  ]: finished collecting timing info
10:28:37.375985 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
10:28:37.549663 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f672fa7-bca0-4677-ba30-16ff5b6bf7e8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1127b0880>]}
10:28:37.550010 [info ] [Thread-1  ]: 2 of 4 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 1.64s]
10:28:37.550219 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
10:28:37.550339 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
10:28:37.550563 [info ] [Thread-1  ]: 3 of 4 START table model dbt.snowflake_customer_purchases....................... [RUN]
10:28:37.550881 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
10:28:37.550975 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
10:28:37.551067 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
10:28:37.551900 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
10:28:37.552289 [debug] [Thread-1  ]: finished collecting timing info
10:28:37.552396 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
10:28:37.554101 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
10:28:37.555014 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
10:28:37.555124 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
10:28:37.555213 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:28:39.063901 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.51 seconds
10:28:39.067215 [debug] [Thread-1  ]: finished collecting timing info
10:28:39.067641 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
10:28:39.235011 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f672fa7-bca0-4677-ba30-16ff5b6bf7e8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1127b0e20>]}
10:28:39.235781 [info ] [Thread-1  ]: 3 of 4 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 1.68s]
10:28:39.236256 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
10:28:39.236508 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
10:28:39.236923 [info ] [Thread-1  ]: 4 of 4 START table model dbt.my_second_dbt_model................................ [RUN]
10:28:39.237589 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
10:28:39.237805 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
10:28:39.238007 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
10:28:39.249801 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
10:28:39.250484 [debug] [Thread-1  ]: finished collecting timing info
10:28:39.250655 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
10:28:39.252635 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
10:28:39.253563 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
10:28:39.253693 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (with __dbt__cte__my_first_dbt_model as (
/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
)-- Use the `ref` function to select from other models

select *
from __dbt__cte__my_first_dbt_model
where id = 1
      );
10:28:39.253806 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:28:40.726364 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.47 seconds
10:28:40.731888 [debug] [Thread-1  ]: finished collecting timing info
10:28:40.732278 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
10:28:41.189233 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f672fa7-bca0-4677-ba30-16ff5b6bf7e8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1127b05b0>]}
10:28:41.189914 [info ] [Thread-1  ]: 4 of 4 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.95s]
10:28:41.190224 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
10:28:41.191300 [debug] [MainThread]: Acquiring new snowflake connection "master"
10:28:41.191666 [info ] [MainThread]: 
10:28:41.191879 [info ] [MainThread]: Finished running 1 incremental model, 3 table models in 12.18s.
10:28:41.192061 [debug] [MainThread]: Connection 'master' was properly closed.
10:28:41.192159 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
10:28:41.197646 [info ] [MainThread]: 
10:28:41.198003 [info ] [MainThread]: [32mCompleted successfully[0m
10:28:41.198277 [info ] [MainThread]: 
10:28:41.198485 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
10:28:41.198792 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1049d6040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114ad1a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112b0f430>]}


============================== 2022-05-13 10:37:45.305180 | 49a4559c-d665-4d64-817f-b485e33b3fba ==============================
10:37:45.305180 [info ] [MainThread]: Running with dbt=1.0.1
10:37:45.305541 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
10:37:45.305660 [debug] [MainThread]: Tracking: tracking
10:37:45.305905 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c93f70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c93460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c938b0>]}
10:37:45.347958 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
10:37:45.348187 [debug] [MainThread]: Partial parsing: added file: learn_dbt://models/example/incremental_time.sql
10:37:45.348401 [debug] [MainThread]: Partial parsing: update schema file: learn_dbt://models/example/schema.yml
10:37:45.353977 [debug] [MainThread]: 1603: static parser failed on example/incremental_time.sql
10:37:45.362310 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_time.sql
10:37:45.370483 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '49a4559c-d665-4d64-817f-b485e33b3fba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102cd94f0>]}
10:37:45.373443 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '49a4559c-d665-4d64-817f-b485e33b3fba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c6d610>]}
10:37:45.373585 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
10:37:45.374297 [info ] [MainThread]: 
10:37:45.374496 [debug] [MainThread]: Acquiring new snowflake connection "master"
10:37:45.374901 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
10:37:45.381044 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
10:37:45.381182 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
10:37:45.381252 [debug] [ThreadPool]: Opening a new connection, currently in state init
10:37:46.441923 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.06 seconds
10:37:46.444023 [debug] [ThreadPool]: On list_analytics: Close
10:37:46.798257 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
10:37:46.807696 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
10:37:46.807878 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
10:37:46.808003 [debug] [ThreadPool]: Opening a new connection, currently in state closed
10:37:48.893965 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 2.09 seconds
10:37:48.897053 [debug] [ThreadPool]: On list_analytics_dbt: Close
10:37:49.065113 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
10:37:49.065669 [info ] [MainThread]: 
10:37:49.069516 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
10:37:49.070240 [info ] [Thread-1  ]: 1 of 5 START incremental model dbt.dates........................................ [RUN]
10:37:49.070735 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
10:37:49.070909 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
10:37:49.071271 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
10:37:49.076914 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
10:37:49.077504 [debug] [Thread-1  ]: finished collecting timing info
10:37:49.077664 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
10:37:49.108852 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:37:49.109057 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
10:37:49.109145 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:37:50.662306 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.55 seconds
10:37:50.672857 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:37:50.673171 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
10:37:50.793277 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.12 seconds
10:37:50.799320 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:37:50.799572 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
10:37:50.993148 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.19 seconds
10:37:50.999659 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:37:50.999873 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
10:37:51.099521 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.1 seconds
10:37:51.122003 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
10:37:51.124382 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:37:51.124519 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
10:37:51.263955 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.14 seconds
10:37:51.264619 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:37:51.264799 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
10:37:52.252040 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.99 seconds
10:37:52.252582 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:37:52.252799 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
10:37:52.462437 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.21 seconds
10:37:52.474700 [debug] [Thread-1  ]: finished collecting timing info
10:37:52.475025 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
10:37:52.694218 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '49a4559c-d665-4d64-817f-b485e33b3fba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a189a60>]}
10:37:52.697085 [info ] [Thread-1  ]: 1 of 5 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 3.62s]
10:37:52.697267 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
10:37:52.697357 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
10:37:52.697461 [info ] [Thread-1  ]: 2 of 5 START incremental model dbt.incremental_time............................. [RUN]
10:37:52.697669 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
10:37:52.697742 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
10:37:52.697815 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
10:37:52.699368 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
10:37:52.699914 [debug] [Thread-1  ]: finished collecting timing info
10:37:52.700063 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
10:37:52.701512 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
10:37:52.701981 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
10:37:52.702060 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */


      create or replace transient table analytics.dbt.incremental_time  as
      (

select to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) time
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where time <= current_time


      );
10:37:52.702126 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:37:54.131916 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.43 seconds
10:37:54.135313 [debug] [Thread-1  ]: finished collecting timing info
10:37:54.135655 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
10:37:54.322820 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '49a4559c-d665-4d64-817f-b485e33b3fba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a1acf40>]}
10:37:54.323596 [info ] [Thread-1  ]: 2 of 5 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 1.63s]
10:37:54.324068 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
10:37:54.324310 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
10:37:54.324837 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
10:37:54.325097 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
10:37:54.325305 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
10:37:54.328550 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
10:37:54.329222 [debug] [Thread-1  ]: finished collecting timing info
10:37:54.329597 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
10:37:54.329789 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
10:37:54.330175 [info ] [Thread-1  ]: 3 of 5 START table model dbt.snowflake_cumulative_sales......................... [RUN]
10:37:54.330796 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
10:37:54.331082 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
10:37:54.331267 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
10:37:54.333047 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
10:37:54.333634 [debug] [Thread-1  ]: finished collecting timing info
10:37:54.333806 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
10:37:54.342153 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
10:37:54.343115 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
10:37:54.343259 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
10:37:54.343380 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:37:55.762609 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.42 seconds
10:37:55.766088 [debug] [Thread-1  ]: finished collecting timing info
10:37:55.766451 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
10:37:55.961141 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '49a4559c-d665-4d64-817f-b485e33b3fba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a200e80>]}
10:37:55.961961 [info ] [Thread-1  ]: 3 of 5 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 1.63s]
10:37:55.962407 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
10:37:55.962651 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
10:37:55.963071 [info ] [Thread-1  ]: 4 of 5 START table model dbt.snowflake_customer_purchases....................... [RUN]
10:37:55.963720 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
10:37:55.963932 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
10:37:55.964135 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
10:37:55.965900 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
10:37:55.966643 [debug] [Thread-1  ]: finished collecting timing info
10:37:55.966836 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
10:37:55.969218 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
10:37:55.970377 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
10:37:55.970537 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
10:37:55.970678 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:37:57.577553 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.61 seconds
10:37:57.580279 [debug] [Thread-1  ]: finished collecting timing info
10:37:57.580627 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
10:37:57.851170 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '49a4559c-d665-4d64-817f-b485e33b3fba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a2495e0>]}
10:37:57.851880 [info ] [Thread-1  ]: 4 of 5 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 1.89s]
10:37:57.852299 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
10:37:57.852560 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
10:37:57.853020 [info ] [Thread-1  ]: 5 of 5 START table model dbt.my_second_dbt_model................................ [RUN]
10:37:57.854118 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
10:37:57.854400 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
10:37:57.854617 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
10:37:57.865727 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
10:37:57.866455 [debug] [Thread-1  ]: finished collecting timing info
10:37:57.866625 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
10:37:57.868739 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
10:37:57.869831 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
10:37:57.869977 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (with __dbt__cte__my_first_dbt_model as (
/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
)-- Use the `ref` function to select from other models

select *
from __dbt__cte__my_first_dbt_model
where id = 1
      );
10:37:57.870106 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:37:59.167299 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.3 seconds
10:37:59.171692 [debug] [Thread-1  ]: finished collecting timing info
10:37:59.172154 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
10:37:59.478576 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '49a4559c-d665-4d64-817f-b485e33b3fba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a1bbb50>]}
10:37:59.479085 [info ] [Thread-1  ]: 5 of 5 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.62s]
10:37:59.479346 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
10:37:59.480167 [debug] [MainThread]: Acquiring new snowflake connection "master"
10:37:59.480462 [info ] [MainThread]: 
10:37:59.480649 [info ] [MainThread]: Finished running 2 incremental models, 3 table models in 14.11s.
10:37:59.480804 [debug] [MainThread]: Connection 'master' was properly closed.
10:37:59.480897 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
10:37:59.486067 [info ] [MainThread]: 
10:37:59.486321 [info ] [MainThread]: [32mCompleted successfully[0m
10:37:59.486535 [info ] [MainThread]: 
10:37:59.486702 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
10:37:59.486957 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1055b68e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c80d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108331c40>]}


============================== 2022-05-13 10:38:49.118267 | 41174521-8b7a-4e81-b3df-0e3b0ccab80f ==============================
10:38:49.118267 [info ] [MainThread]: Running with dbt=1.0.1
10:38:49.118639 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
10:38:49.118759 [debug] [MainThread]: Tracking: tracking
10:38:49.119004 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119239520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119239100>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119239280>]}
10:38:49.161022 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
10:38:49.161162 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
10:38:49.164175 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '41174521-8b7a-4e81-b3df-0e3b0ccab80f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119225190>]}
10:38:49.167323 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '41174521-8b7a-4e81-b3df-0e3b0ccab80f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1181345e0>]}
10:38:49.167458 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
10:38:49.168204 [info ] [MainThread]: 
10:38:49.168412 [debug] [MainThread]: Acquiring new snowflake connection "master"
10:38:49.168860 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
10:38:49.174978 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
10:38:49.175098 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
10:38:49.175166 [debug] [ThreadPool]: Opening a new connection, currently in state init
10:38:49.967962 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.79 seconds
10:38:49.970775 [debug] [ThreadPool]: On list_analytics: Close
10:38:50.347042 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
10:38:50.355713 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
10:38:50.355965 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
10:38:50.356128 [debug] [ThreadPool]: Opening a new connection, currently in state closed
10:38:51.511202 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1.16 seconds
10:38:51.513375 [debug] [ThreadPool]: On list_analytics_dbt: Close
10:38:51.810224 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
10:38:51.811184 [info ] [MainThread]: 
10:38:51.815337 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
10:38:51.816131 [info ] [Thread-1  ]: 1 of 5 START incremental model dbt.dates........................................ [RUN]
10:38:51.816657 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
10:38:51.816829 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
10:38:51.816994 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
10:38:51.827062 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
10:38:51.827693 [debug] [Thread-1  ]: finished collecting timing info
10:38:51.827855 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
10:38:51.857456 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:38:51.857675 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
10:38:51.857767 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:38:53.243439 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.39 seconds
10:38:53.257049 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:38:53.257445 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
10:38:53.406593 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.15 seconds
10:38:53.412550 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:38:53.412809 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
10:38:53.527584 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.11 seconds
10:38:53.538431 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:38:53.538766 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
10:38:53.647571 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.11 seconds
10:38:53.666667 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
10:38:53.668621 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:38:53.668734 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
10:38:53.899495 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.23 seconds
10:38:53.901983 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:38:53.902261 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
10:38:54.291830 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.39 seconds
10:38:54.294135 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:38:54.294530 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
10:38:54.488616 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.19 seconds
10:38:54.504057 [debug] [Thread-1  ]: finished collecting timing info
10:38:54.504456 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
10:38:54.751233 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '41174521-8b7a-4e81-b3df-0e3b0ccab80f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104bdb940>]}
10:38:54.752427 [info ] [Thread-1  ]: 1 of 5 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 2.93s]
10:38:54.753068 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
10:38:54.753332 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
10:38:54.753764 [info ] [Thread-1  ]: 2 of 5 START incremental model dbt.incremental_time............................. [RUN]
10:38:54.754439 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
10:38:54.754656 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
10:38:54.754857 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
10:38:54.759168 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
10:38:54.759815 [debug] [Thread-1  ]: finished collecting timing info
10:38:54.760001 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
10:38:54.763589 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
10:38:54.763909 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) time
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where time <= current_time


	and time > (select max(time) from analytics.dbt.incremental_time)

      );
10:38:54.764090 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:38:56.074315 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.31 seconds
10:38:56.081646 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
10:38:56.082091 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
10:38:56.221763 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.14 seconds
10:38:56.226740 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
10:38:56.227088 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
10:38:56.390799 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.16 seconds
10:38:56.395464 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
10:38:56.395785 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
10:38:56.512757 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.12 seconds
10:38:56.517830 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
10:38:56.519576 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
10:38:56.519795 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
10:38:56.657110 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.14 seconds
10:38:56.657725 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
10:38:56.657984 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.time = DBT_INTERNAL_DEST.time
        

    
    when matched then update set
        "TIME" = DBT_INTERNAL_SOURCE."TIME"
    

    when not matched then insert
        ("TIME")
    values
        ("TIME")

;
10:38:57.468818 [debug] [Thread-1  ]: SQL status: SUCCESS 62 in 0.81 seconds
10:38:57.469747 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
10:38:57.470294 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
10:38:57.717950 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.25 seconds
10:38:57.727029 [debug] [Thread-1  ]: finished collecting timing info
10:38:57.727509 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
10:38:57.924220 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '41174521-8b7a-4e81-b3df-0e3b0ccab80f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119755a00>]}
10:38:57.926068 [info ] [Thread-1  ]: 2 of 5 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 3.17s]
10:38:57.926518 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
10:38:57.926663 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
10:38:57.926938 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
10:38:57.927046 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
10:38:57.927134 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
10:38:57.928667 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
10:38:57.929023 [debug] [Thread-1  ]: finished collecting timing info
10:38:57.929222 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
10:38:57.929319 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
10:38:57.929485 [info ] [Thread-1  ]: 3 of 5 START table model dbt.snowflake_cumulative_sales......................... [RUN]
10:38:57.929702 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
10:38:57.929828 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
10:38:57.929940 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
10:38:57.930677 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
10:38:57.931016 [debug] [Thread-1  ]: finished collecting timing info
10:38:57.931102 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
10:38:57.935649 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
10:38:57.936202 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
10:38:57.936287 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
10:38:57.936365 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:38:59.237027 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.3 seconds
10:38:59.240404 [debug] [Thread-1  ]: finished collecting timing info
10:38:59.240827 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
10:38:59.537095 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '41174521-8b7a-4e81-b3df-0e3b0ccab80f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119b0c3d0>]}
10:38:59.537774 [info ] [Thread-1  ]: 3 of 5 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 1.61s]
10:38:59.538207 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
10:38:59.538455 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
10:38:59.538865 [info ] [Thread-1  ]: 4 of 5 START table model dbt.snowflake_customer_purchases....................... [RUN]
10:38:59.539506 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
10:38:59.539716 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
10:38:59.539926 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
10:38:59.541912 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
10:38:59.542761 [debug] [Thread-1  ]: finished collecting timing info
10:38:59.542943 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
10:38:59.545750 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
10:38:59.547113 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
10:38:59.547291 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
10:38:59.547441 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:39:01.327510 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.78 seconds
10:39:01.331382 [debug] [Thread-1  ]: finished collecting timing info
10:39:01.331813 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
10:39:01.530890 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '41174521-8b7a-4e81-b3df-0e3b0ccab80f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1197557f0>]}
10:39:01.531843 [info ] [Thread-1  ]: 4 of 5 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 1.99s]
10:39:01.532338 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
10:39:01.532587 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
10:39:01.532988 [info ] [Thread-1  ]: 5 of 5 START table model dbt.my_second_dbt_model................................ [RUN]
10:39:01.533637 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
10:39:01.533845 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
10:39:01.534052 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
10:39:01.547138 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
10:39:01.547746 [debug] [Thread-1  ]: finished collecting timing info
10:39:01.547907 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
10:39:01.549837 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
10:39:01.550768 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
10:39:01.550893 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (with __dbt__cte__my_first_dbt_model as (
/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
)-- Use the `ref` function to select from other models

select *
from __dbt__cte__my_first_dbt_model
where id = 1
      );
10:39:01.551009 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:39:02.977705 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.43 seconds
10:39:02.980930 [debug] [Thread-1  ]: finished collecting timing info
10:39:02.981330 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
10:39:03.337672 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '41174521-8b7a-4e81-b3df-0e3b0ccab80f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119b26760>]}
10:39:03.338456 [info ] [Thread-1  ]: 5 of 5 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.80s]
10:39:03.338904 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
10:39:03.340263 [debug] [MainThread]: Acquiring new snowflake connection "master"
10:39:03.340737 [info ] [MainThread]: 
10:39:03.341077 [info ] [MainThread]: Finished running 2 incremental models, 3 table models in 14.17s.
10:39:03.341371 [debug] [MainThread]: Connection 'master' was properly closed.
10:39:03.341533 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
10:39:03.348303 [info ] [MainThread]: 
10:39:03.348653 [info ] [MainThread]: [32mCompleted successfully[0m
10:39:03.348951 [info ] [MainThread]: 
10:39:03.349174 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
10:39:03.349454 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1194a3c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1063e2670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119759820>]}


============================== 2022-05-13 10:43:03.805216 | af664626-bbe0-4961-8861-a4cf7189da6c ==============================
10:43:03.805216 [info ] [MainThread]: Running with dbt=1.0.1
10:43:03.805917 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
10:43:03.806094 [debug] [MainThread]: Tracking: tracking
10:43:03.806331 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1082b2190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1082b20a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1082b2b20>]}
10:43:03.852369 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
10:43:03.852676 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/incremental_time.sql
10:43:03.858150 [debug] [MainThread]: 1603: static parser failed on example/incremental_time.sql
10:43:03.866707 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_time.sql
10:43:03.874863 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'af664626-bbe0-4961-8861-a4cf7189da6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10841df70>]}
10:43:03.878402 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'af664626-bbe0-4961-8861-a4cf7189da6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104441a30>]}
10:43:03.878572 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
10:43:03.879314 [info ] [MainThread]: 
10:43:03.879537 [debug] [MainThread]: Acquiring new snowflake connection "master"
10:43:03.879956 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
10:43:03.885793 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
10:43:03.885882 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
10:43:03.885945 [debug] [ThreadPool]: Opening a new connection, currently in state init
10:43:04.700347 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.81 seconds
10:43:04.702690 [debug] [ThreadPool]: On list_analytics: Close
10:43:05.091785 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
10:43:05.101905 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
10:43:05.102230 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
10:43:05.102391 [debug] [ThreadPool]: Opening a new connection, currently in state closed
10:43:06.139680 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1.04 seconds
10:43:06.142605 [debug] [ThreadPool]: On list_analytics_dbt: Close
10:43:06.332725 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
10:43:06.333054 [info ] [MainThread]: 
10:43:06.337898 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
10:43:06.338713 [info ] [Thread-1  ]: 1 of 5 START incremental model dbt.dates........................................ [RUN]
10:43:06.339240 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
10:43:06.339412 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
10:43:06.339580 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
10:43:06.345562 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
10:43:06.346216 [debug] [Thread-1  ]: finished collecting timing info
10:43:06.346378 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
10:43:06.378129 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:43:06.378346 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
10:43:06.378440 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:43:08.326142 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.95 seconds
10:43:08.339227 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:43:08.339628 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
10:43:08.473015 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.13 seconds
10:43:08.478398 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:43:08.478609 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
10:43:08.691087 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.21 seconds
10:43:08.703882 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:43:08.704288 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
10:43:08.906381 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.2 seconds
10:43:08.928888 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
10:43:08.931321 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:43:08.931465 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
10:43:09.215977 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.28 seconds
10:43:09.217515 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:43:09.217774 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
10:43:10.004165 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.79 seconds
10:43:10.004670 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
10:43:10.004847 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
10:43:10.265214 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.26 seconds
10:43:10.279885 [debug] [Thread-1  ]: finished collecting timing info
10:43:10.280279 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
10:43:10.486812 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af664626-bbe0-4961-8861-a4cf7189da6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102e82040>]}
10:43:10.487854 [info ] [Thread-1  ]: 1 of 5 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 4.15s]
10:43:10.488310 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
10:43:10.488547 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
10:43:10.488970 [info ] [Thread-1  ]: 2 of 5 START incremental model dbt.incremental_time............................. [RUN]
10:43:10.489626 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
10:43:10.489846 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
10:43:10.490046 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
10:43:10.493876 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
10:43:10.494564 [debug] [Thread-1  ]: finished collecting timing info
10:43:10.494745 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
10:43:10.498409 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
10:43:10.498582 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
10:43:10.498725 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:43:11.486308 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a43ca3-3201-9c12-0000-0001205218b1
10:43:11.486680 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 002036 (42601): SQL compilation error:
Subquery containing correlated aggregate function [MAX(TIME_DIM.T_TIME)] can only appear in having or select clause
10:43:11.487038 [debug] [Thread-1  ]: finished collecting timing info
10:43:11.487262 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
10:43:11.675295 [debug] [Thread-1  ]: Database Error in model incremental_time (models/example/incremental_time.sql)
  002036 (42601): SQL compilation error:
  Subquery containing correlated aggregate function [MAX(TIME_DIM.T_TIME)] can only appear in having or select clause
10:43:11.676198 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af664626-bbe0-4961-8861-a4cf7189da6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c081370>]}
10:43:11.676814 [error] [Thread-1  ]: 2 of 5 ERROR creating incremental model dbt.incremental_time.................... [[31mERROR[0m in 1.19s]
10:43:11.677293 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
10:43:11.677534 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
10:43:11.678217 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
10:43:11.678494 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
10:43:11.678715 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
10:43:11.681965 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
10:43:11.682632 [debug] [Thread-1  ]: finished collecting timing info
10:43:11.683027 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
10:43:11.683239 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
10:43:11.683653 [info ] [Thread-1  ]: 3 of 5 START table model dbt.snowflake_cumulative_sales......................... [RUN]
10:43:11.684903 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
10:43:11.685132 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
10:43:11.685292 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
10:43:11.686668 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
10:43:11.687353 [debug] [Thread-1  ]: finished collecting timing info
10:43:11.687635 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
10:43:11.696001 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
10:43:11.696934 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
10:43:11.697066 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
10:43:11.697175 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:43:13.642419 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.95 seconds
10:43:13.645213 [debug] [Thread-1  ]: finished collecting timing info
10:43:13.645719 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
10:43:13.938452 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af664626-bbe0-4961-8861-a4cf7189da6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c0b1850>]}
10:43:13.939143 [info ] [Thread-1  ]: 3 of 5 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 2.25s]
10:43:13.939582 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
10:43:13.939828 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
10:43:13.940238 [info ] [Thread-1  ]: 4 of 5 START table model dbt.snowflake_customer_purchases....................... [RUN]
10:43:13.940889 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
10:43:13.941102 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
10:43:13.941306 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
10:43:13.943092 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
10:43:13.943734 [debug] [Thread-1  ]: finished collecting timing info
10:43:13.943861 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
10:43:13.945677 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
10:43:13.946811 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
10:43:13.947016 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
10:43:13.947122 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:43:15.573750 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.63 seconds
10:43:15.578034 [debug] [Thread-1  ]: finished collecting timing info
10:43:15.578438 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
10:43:15.764174 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af664626-bbe0-4961-8861-a4cf7189da6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1087d4c70>]}
10:43:15.765016 [info ] [Thread-1  ]: 4 of 5 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 1.82s]
10:43:15.765671 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
10:43:15.765936 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
10:43:15.766367 [info ] [Thread-1  ]: 5 of 5 START table model dbt.my_second_dbt_model................................ [RUN]
10:43:15.767088 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
10:43:15.767305 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
10:43:15.767501 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
10:43:15.778253 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
10:43:15.779028 [debug] [Thread-1  ]: finished collecting timing info
10:43:15.779200 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
10:43:15.781212 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
10:43:15.782317 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
10:43:15.782464 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (with __dbt__cte__my_first_dbt_model as (
/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
)-- Use the `ref` function to select from other models

select *
from __dbt__cte__my_first_dbt_model
where id = 1
      );
10:43:15.782588 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
10:43:17.207450 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.42 seconds
10:43:17.210668 [debug] [Thread-1  ]: finished collecting timing info
10:43:17.211111 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
10:43:17.720702 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af664626-bbe0-4961-8861-a4cf7189da6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1087d33a0>]}
10:43:17.723786 [info ] [Thread-1  ]: 5 of 5 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.95s]
10:43:17.724371 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
10:43:17.725806 [debug] [MainThread]: Acquiring new snowflake connection "master"
10:43:17.726378 [info ] [MainThread]: 
10:43:17.726743 [info ] [MainThread]: Finished running 2 incremental models, 3 table models in 13.85s.
10:43:17.727071 [debug] [MainThread]: Connection 'master' was properly closed.
10:43:17.727234 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
10:43:17.733893 [info ] [MainThread]: 
10:43:17.734252 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
10:43:17.734534 [info ] [MainThread]: 
10:43:17.734756 [error] [MainThread]: [33mDatabase Error in model incremental_time (models/example/incremental_time.sql)[0m
10:43:17.734980 [error] [MainThread]:   002036 (42601): SQL compilation error:
10:43:17.735186 [error] [MainThread]:   Subquery containing correlated aggregate function [MAX(TIME_DIM.T_TIME)] can only appear in having or select clause
10:43:17.735513 [info ] [MainThread]: 
10:43:17.735767 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
10:43:17.736052 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106fa6c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10442dd60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1087d4130>]}


============================== 2022-05-13 11:31:21.630030 | 591506dd-ca27-4580-a8bf-838d217489e2 ==============================
11:31:21.630030 [info ] [MainThread]: Running with dbt=1.0.1
11:31:21.630660 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
11:31:21.630798 [debug] [MainThread]: Tracking: tracking
11:31:21.631043 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079cb160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079cb070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079cb400>]}
11:31:21.677308 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
11:31:21.677503 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
11:31:21.680801 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '591506dd-ca27-4580-a8bf-838d217489e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079b10a0>]}
11:31:21.684491 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '591506dd-ca27-4580-a8bf-838d217489e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10681ec40>]}
11:31:21.684643 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
11:31:21.685417 [info ] [MainThread]: 
11:31:21.685650 [debug] [MainThread]: Acquiring new snowflake connection "master"
11:31:21.686107 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
11:31:21.692619 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
11:31:21.692763 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
11:31:21.692831 [debug] [ThreadPool]: Opening a new connection, currently in state init
11:31:22.675971 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.98 seconds
11:31:22.677112 [debug] [ThreadPool]: On list_analytics: Close
11:31:22.865627 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
11:31:22.876516 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
11:31:22.876827 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
11:31:22.876993 [debug] [ThreadPool]: Opening a new connection, currently in state closed
11:31:23.909742 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.03 seconds
11:31:23.912853 [debug] [ThreadPool]: On list_analytics_dbt: Close
11:31:24.117722 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
11:31:24.118394 [info ] [MainThread]: 
11:31:24.123272 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
11:31:24.124038 [info ] [Thread-1  ]: 1 of 5 START incremental model dbt.dates........................................ [RUN]
11:31:24.124536 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
11:31:24.124711 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
11:31:24.124887 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
11:31:24.133252 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
11:31:24.134294 [debug] [Thread-1  ]: finished collecting timing info
11:31:24.134454 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
11:31:24.164189 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
11:31:24.164415 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
11:31:24.164508 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:31:25.823176 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.66 seconds
11:31:25.833029 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
11:31:25.833276 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
11:31:25.978849 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.15 seconds
11:31:25.986390 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
11:31:25.986721 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
11:31:26.078422 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.09 seconds
11:31:26.091211 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
11:31:26.091576 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
11:31:26.211752 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.12 seconds
11:31:26.238296 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
11:31:26.240940 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
11:31:26.241086 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
11:31:26.386260 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.15 seconds
11:31:26.387154 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
11:31:26.387415 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
11:31:27.014724 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.63 seconds
11:31:27.015618 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
11:31:27.015853 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
11:31:27.262638 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.25 seconds
11:31:27.273967 [debug] [Thread-1  ]: finished collecting timing info
11:31:27.274336 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
11:31:27.449750 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '591506dd-ca27-4580-a8bf-838d217489e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104654190>]}
11:31:27.450546 [info ] [Thread-1  ]: 1 of 5 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 3.33s]
11:31:27.451078 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
11:31:27.451470 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
11:31:27.452067 [info ] [Thread-1  ]: 2 of 5 START incremental model dbt.incremental_time............................. [RUN]
11:31:27.452637 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
11:31:27.452818 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
11:31:27.452975 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
11:31:27.456365 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
11:31:27.458667 [debug] [Thread-1  ]: finished collecting timing info
11:31:27.458952 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
11:31:27.462598 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
11:31:27.463686 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
11:31:27.463850 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */


      create or replace transient table analytics.dbt.incremental_time  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


      );
11:31:27.463990 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:31:29.357062 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.89 seconds
11:31:29.366555 [debug] [Thread-1  ]: finished collecting timing info
11:31:29.367004 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
11:31:29.556591 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '591506dd-ca27-4580-a8bf-838d217489e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107eaef40>]}
11:31:29.557325 [info ] [Thread-1  ]: 2 of 5 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 2.10s]
11:31:29.557841 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
11:31:29.558099 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
11:31:29.558677 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
11:31:29.558919 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
11:31:29.559117 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
11:31:29.562406 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
11:31:29.564402 [debug] [Thread-1  ]: finished collecting timing info
11:31:29.564965 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
11:31:29.565198 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
11:31:29.565577 [info ] [Thread-1  ]: 3 of 5 START table model dbt.snowflake_cumulative_sales......................... [RUN]
11:31:29.566229 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
11:31:29.566479 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
11:31:29.566664 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
11:31:29.569479 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
11:31:29.570497 [debug] [Thread-1  ]: finished collecting timing info
11:31:29.570749 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
11:31:29.578557 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
11:31:29.579522 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
11:31:29.579665 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
11:31:29.579778 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:31:31.650276 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.07 seconds
11:31:31.654058 [debug] [Thread-1  ]: finished collecting timing info
11:31:31.654473 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
11:31:31.824354 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '591506dd-ca27-4580-a8bf-838d217489e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110302460>]}
11:31:31.825167 [info ] [Thread-1  ]: 3 of 5 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 2.26s]
11:31:31.825632 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
11:31:31.826029 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
11:31:31.826655 [info ] [Thread-1  ]: 4 of 5 START table model dbt.snowflake_customer_purchases....................... [RUN]
11:31:31.827387 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
11:31:31.827605 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
11:31:31.827814 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
11:31:31.829482 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
11:31:31.831134 [debug] [Thread-1  ]: finished collecting timing info
11:31:31.831390 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
11:31:31.834164 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
11:31:31.835444 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
11:31:31.835615 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
11:31:31.835777 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:31:34.219607 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.38 seconds
11:31:34.223012 [debug] [Thread-1  ]: finished collecting timing info
11:31:34.223345 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
11:31:34.386029 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '591506dd-ca27-4580-a8bf-838d217489e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107c968e0>]}
11:31:34.387240 [info ] [Thread-1  ]: 4 of 5 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.56s]
11:31:34.387851 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
11:31:34.388399 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
11:31:34.388986 [info ] [Thread-1  ]: 5 of 5 START table model dbt.my_second_dbt_model................................ [RUN]
11:31:34.389658 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
11:31:34.389878 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
11:31:34.390060 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
11:31:34.402092 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
11:31:34.404153 [debug] [Thread-1  ]: finished collecting timing info
11:31:34.404353 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
11:31:34.406219 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
11:31:34.407079 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
11:31:34.407161 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (with __dbt__cte__my_first_dbt_model as (
/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
)-- Use the `ref` function to select from other models

select *
from __dbt__cte__my_first_dbt_model
where id = 1
      );
11:31:34.407224 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:31:35.807802 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.4 seconds
11:31:35.813049 [debug] [Thread-1  ]: finished collecting timing info
11:31:35.813453 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
11:31:35.974506 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '591506dd-ca27-4580-a8bf-838d217489e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107e22b50>]}
11:31:35.975322 [info ] [Thread-1  ]: 5 of 5 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.58s]
11:31:35.975779 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
11:31:35.977147 [debug] [MainThread]: Acquiring new snowflake connection "master"
11:31:35.977643 [info ] [MainThread]: 
11:31:35.977988 [info ] [MainThread]: Finished running 2 incremental models, 3 table models in 14.29s.
11:31:35.978236 [debug] [MainThread]: Connection 'master' was properly closed.
11:31:35.978370 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
11:31:35.985153 [info ] [MainThread]: 
11:31:35.985521 [info ] [MainThread]: [32mCompleted successfully[0m
11:31:35.985828 [info ] [MainThread]: 
11:31:35.986035 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
11:31:35.986311 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110382580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10482bc70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107e96760>]}


============================== 2022-05-13 11:33:29.624616 | 5e05f29a-0035-47c2-b39e-248747587022 ==============================
11:33:29.624616 [info ] [MainThread]: Running with dbt=1.0.1
11:33:29.625262 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
11:33:29.625394 [debug] [MainThread]: Tracking: tracking
11:33:29.625602 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a378b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a37b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a37610>]}
11:33:29.670346 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
11:33:29.670672 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/my_first_dbt_model.sql
11:33:29.676380 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
11:33:29.696246 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5e05f29a-0035-47c2-b39e-248747587022', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b7df40>]}
11:33:29.699257 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5e05f29a-0035-47c2-b39e-248747587022', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105f8b5e0>]}
11:33:29.699394 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
11:33:29.700112 [info ] [MainThread]: 
11:33:29.700310 [debug] [MainThread]: Acquiring new snowflake connection "master"
11:33:29.700750 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
11:33:29.706658 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
11:33:29.706766 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
11:33:29.706830 [debug] [ThreadPool]: Opening a new connection, currently in state init
11:33:30.800438 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.09 seconds
11:33:30.803790 [debug] [ThreadPool]: On list_analytics: Close
11:33:31.347388 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
11:33:31.351474 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
11:33:31.351822 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
11:33:31.352026 [debug] [ThreadPool]: Opening a new connection, currently in state closed
11:33:32.274623 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.92 seconds
11:33:32.277624 [debug] [ThreadPool]: On list_analytics: Close
11:33:32.482200 [debug] [ThreadPool]: Acquiring new snowflake connection "create_analytics_dbt_nigel_test"
11:33:32.482884 [debug] [ThreadPool]: Acquiring new snowflake connection "create_analytics_dbt_nigel_test"
11:33:32.483206 [debug] [ThreadPool]: Creating schema "_ReferenceKey(database='analytics', schema='dbt_nigel_test', identifier=None)"
11:33:32.489470 [debug] [ThreadPool]: Using snowflake connection "create_analytics_dbt_nigel_test"
11:33:32.489713 [debug] [ThreadPool]: On create_analytics_dbt_nigel_test: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "create_analytics_dbt_nigel_test"} */
create schema if not exists analytics.dbt_nigel_test
11:33:32.489870 [debug] [ThreadPool]: Opening a new connection, currently in state closed
11:33:33.377848 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.89 seconds
11:33:33.379872 [debug] [ThreadPool]: On create_analytics_dbt_nigel_test: Close
11:33:33.548626 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
11:33:33.574844 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
11:33:33.582471 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
11:33:33.582723 [debug] [ThreadPool]: Opening a new connection, currently in state closed
11:33:34.789993 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1.21 seconds
11:33:34.793262 [debug] [ThreadPool]: On list_analytics_dbt: Close
11:33:34.979429 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt_nigel_test"
11:33:34.982461 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt_nigel_test"
11:33:34.982709 [debug] [ThreadPool]: On list_analytics_dbt_nigel_test: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt_nigel_test"} */

    show terse objects in analytics.dbt_nigel_test
11:33:34.982906 [debug] [ThreadPool]: Opening a new connection, currently in state closed
11:33:35.838811 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 0.86 seconds
11:33:35.841104 [debug] [ThreadPool]: On list_analytics_dbt_nigel_test: Close
11:33:36.017710 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
11:33:36.018406 [info ] [MainThread]: 
11:33:36.023680 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
11:33:36.024052 [info ] [Thread-1  ]: 1 of 6 START incremental model dbt.dates........................................ [RUN]
11:33:36.024546 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
11:33:36.024712 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
11:33:36.025309 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
11:33:36.035201 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
11:33:36.035829 [debug] [Thread-1  ]: finished collecting timing info
11:33:36.035986 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
11:33:36.065002 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
11:33:36.065169 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
11:33:36.065256 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:33:37.948913 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.88 seconds
11:33:37.960908 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
11:33:37.961206 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
11:33:38.331034 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.37 seconds
11:33:38.338420 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
11:33:38.338688 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
11:33:38.453228 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.11 seconds
11:33:38.466208 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
11:33:38.466674 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
11:33:38.581611 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.11 seconds
11:33:38.609745 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
11:33:38.612131 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
11:33:38.612262 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
11:33:38.744223 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.13 seconds
11:33:38.746726 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
11:33:38.747068 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
11:33:39.396049 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.65 seconds
11:33:39.396958 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
11:33:39.397980 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
11:33:39.580950 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.18 seconds
11:33:39.593927 [debug] [Thread-1  ]: finished collecting timing info
11:33:39.594326 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
11:33:39.815321 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5e05f29a-0035-47c2-b39e-248747587022', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1098436a0>]}
11:33:39.815872 [info ] [Thread-1  ]: 1 of 6 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 3.79s]
11:33:39.816288 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
11:33:39.816533 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
11:33:39.816948 [info ] [Thread-1  ]: 2 of 6 START incremental model dbt.incremental_time............................. [RUN]
11:33:39.817599 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
11:33:39.817860 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
11:33:39.818064 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
11:33:39.821910 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
11:33:39.822787 [debug] [Thread-1  ]: finished collecting timing info
11:33:39.822964 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
11:33:39.826606 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
11:33:39.826785 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
11:33:39.826920 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:33:41.904906 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.08 seconds
11:33:41.909321 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
11:33:41.909650 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
11:33:42.145893 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.24 seconds
11:33:42.151448 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
11:33:42.151802 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
11:33:42.283899 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.13 seconds
11:33:42.288608 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
11:33:42.288868 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
11:33:42.653314 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.36 seconds
11:33:42.658127 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
11:33:42.660609 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
11:33:42.660847 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
11:33:42.853986 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.19 seconds
11:33:42.855132 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
11:33:42.855375 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
11:33:43.701160 [debug] [Thread-1  ]: SQL status: SUCCESS 132 in 0.85 seconds
11:33:43.702108 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
11:33:43.702461 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
11:33:44.052426 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.35 seconds
11:33:44.055607 [debug] [Thread-1  ]: finished collecting timing info
11:33:44.056070 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
11:33:44.442181 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5e05f29a-0035-47c2-b39e-248747587022', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109843880>]}
11:33:44.443009 [info ] [Thread-1  ]: 2 of 6 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 4.62s]
11:33:44.443485 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
11:33:44.443744 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
11:33:44.444162 [info ] [Thread-1  ]: 3 of 6 START table model dbt_nigel_test.first model............................. [RUN]
11:33:44.444822 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
11:33:44.445046 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
11:33:44.445254 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
11:33:44.449204 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
11:33:44.450151 [debug] [Thread-1  ]: finished collecting timing info
11:33:44.450446 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
11:33:44.459603 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
11:33:44.460680 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
11:33:44.460819 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt_nigel_test.first model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
11:33:44.460933 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:33:45.463337 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a43cd5-3201-9c12-0000-000120521929
11:33:45.463777 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 1 at position 72 unexpected 'as'.
11:33:45.464112 [debug] [Thread-1  ]: finished collecting timing info
11:33:45.464333 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
11:33:45.803332 [debug] [Thread-1  ]: Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  001003 (42000): SQL compilation error:
  syntax error line 1 at position 72 unexpected 'as'.
  compiled SQL at target/run/learn_dbt/models/example/my_first_dbt_model.sql
11:33:45.803992 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5e05f29a-0035-47c2-b39e-248747587022', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b80f970>]}
11:33:45.804503 [error] [Thread-1  ]: 3 of 6 ERROR creating table model dbt_nigel_test.first model.................... [[31mERROR[0m in 1.36s]
11:33:45.804952 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
11:33:45.805197 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
11:33:45.805711 [info ] [Thread-1  ]: 4 of 6 START table model dbt.snowflake_cumulative_sales......................... [RUN]
11:33:45.806751 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
11:33:45.807003 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
11:33:45.807183 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
11:33:45.808580 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
11:33:45.809134 [debug] [Thread-1  ]: finished collecting timing info
11:33:45.809294 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
11:33:45.812080 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
11:33:45.813113 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
11:33:45.813280 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
11:33:45.813426 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:33:47.411777 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.6 seconds
11:33:47.414471 [debug] [Thread-1  ]: finished collecting timing info
11:33:47.414857 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
11:33:47.602937 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5e05f29a-0035-47c2-b39e-248747587022', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b822580>]}
11:33:47.603709 [info ] [Thread-1  ]: 4 of 6 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 1.80s]
11:33:47.604285 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
11:33:47.604707 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
11:33:47.605141 [info ] [Thread-1  ]: 5 of 6 START table model dbt.snowflake_customer_purchases....................... [RUN]
11:33:47.605767 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
11:33:47.605959 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
11:33:47.606134 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
11:33:47.607959 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
11:33:47.608726 [debug] [Thread-1  ]: finished collecting timing info
11:33:47.608932 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
11:33:47.611961 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
11:33:47.613303 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
11:33:47.613489 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
11:33:47.613648 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:33:49.766577 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.15 seconds
11:33:49.769205 [debug] [Thread-1  ]: finished collecting timing info
11:33:49.769497 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
11:33:50.030245 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5e05f29a-0035-47c2-b39e-248747587022', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10981e910>]}
11:33:50.031381 [info ] [Thread-1  ]: 5 of 6 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.42s]
11:33:50.032003 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
11:33:50.032271 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
11:33:50.032608 [info ] [Thread-1  ]: 6 of 6 SKIP relation dbt.my_second_dbt_model.................................... [[33mSKIP[0m]
11:33:50.033076 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
11:33:50.034429 [debug] [MainThread]: Acquiring new snowflake connection "master"
11:33:50.034989 [info ] [MainThread]: 
11:33:50.035343 [info ] [MainThread]: Finished running 2 incremental models, 4 table models in 20.33s.
11:33:50.035661 [debug] [MainThread]: Connection 'master' was properly closed.
11:33:50.035828 [debug] [MainThread]: Connection 'model.learn_dbt.snowflake_customer_purchases' was properly closed.
11:33:50.042480 [info ] [MainThread]: 
11:33:50.042913 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
11:33:50.043363 [info ] [MainThread]: 
11:33:50.043585 [error] [MainThread]: [33mDatabase Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)[0m
11:33:50.043785 [error] [MainThread]:   001003 (42000): SQL compilation error:
11:33:50.044013 [error] [MainThread]:   syntax error line 1 at position 72 unexpected 'as'.
11:33:50.044283 [error] [MainThread]:   compiled SQL at target/run/learn_dbt/models/example/my_first_dbt_model.sql
11:33:50.044500 [info ] [MainThread]: 
11:33:50.044697 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=1 TOTAL=6
11:33:50.045019 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104b0ecd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105f26f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109828610>]}


============================== 2022-05-13 11:36:52.301461 | b05ae46b-a079-4f2c-9b61-93925b65de27 ==============================
11:36:52.301461 [info ] [MainThread]: Running with dbt=1.0.1
11:36:52.302081 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
11:36:52.302196 [debug] [MainThread]: Tracking: tracking
11:36:52.302410 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1050072b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105007eb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1050079a0>]}
11:36:52.348081 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
11:36:52.348435 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/my_first_dbt_model.sql
11:36:52.354175 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
11:36:52.373622 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b05ae46b-a079-4f2c-9b61-93925b65de27', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x101371580>]}
11:36:52.376617 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b05ae46b-a079-4f2c-9b61-93925b65de27', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104fe5610>]}
11:36:52.376754 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
11:36:52.377499 [info ] [MainThread]: 
11:36:52.377697 [debug] [MainThread]: Acquiring new snowflake connection "master"
11:36:52.378143 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
11:36:52.384271 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
11:36:52.384408 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
11:36:52.384480 [debug] [ThreadPool]: Opening a new connection, currently in state init
11:36:53.390304 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.01 seconds
11:36:53.392552 [debug] [ThreadPool]: On list_analytics: Close
11:36:53.567485 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
11:36:53.570482 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
11:36:53.570748 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
11:36:53.570942 [debug] [ThreadPool]: Opening a new connection, currently in state closed
11:36:54.618073 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.05 seconds
11:36:54.619296 [debug] [ThreadPool]: On list_analytics: Close
11:36:54.824386 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
11:36:54.833233 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
11:36:54.833529 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
11:36:54.833690 [debug] [ThreadPool]: Opening a new connection, currently in state closed
11:36:55.644732 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 0.81 seconds
11:36:55.647540 [debug] [ThreadPool]: On list_analytics_dbt: Close
11:36:55.834668 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt_nigel_test"
11:36:55.837948 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt_nigel_test"
11:36:55.838339 [debug] [ThreadPool]: On list_analytics_dbt_nigel_test: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt_nigel_test"} */

    show terse objects in analytics.dbt_nigel_test
11:36:55.838539 [debug] [ThreadPool]: Opening a new connection, currently in state closed
11:36:56.501085 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 0.66 seconds
11:36:56.503702 [debug] [ThreadPool]: On list_analytics_dbt_nigel_test: Close
11:36:56.684324 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
11:36:56.684855 [info ] [MainThread]: 
11:36:56.690086 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
11:36:56.690493 [info ] [Thread-1  ]: 1 of 6 START incremental model dbt.dates........................................ [RUN]
11:36:56.691407 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
11:36:56.691615 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
11:36:56.691796 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
11:36:56.702172 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
11:36:56.702817 [debug] [Thread-1  ]: finished collecting timing info
11:36:56.702958 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
11:36:56.731492 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
11:36:56.731670 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
11:36:56.731756 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:36:58.322723 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.59 seconds
11:36:58.336494 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
11:36:58.336815 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
11:36:58.465984 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.13 seconds
11:36:58.472664 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
11:36:58.472872 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
11:36:58.599468 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.13 seconds
11:36:58.611633 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
11:36:58.611925 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
11:36:58.717485 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.11 seconds
11:36:58.744423 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
11:36:58.746875 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
11:36:58.746999 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
11:36:58.880542 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.13 seconds
11:36:58.882450 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
11:36:58.883116 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
11:36:59.254142 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.37 seconds
11:36:59.254925 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
11:36:59.255156 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
11:36:59.423355 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.17 seconds
11:36:59.438255 [debug] [Thread-1  ]: finished collecting timing info
11:36:59.438674 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
11:36:59.648489 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b05ae46b-a079-4f2c-9b61-93925b65de27', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1052f1430>]}
11:36:59.649576 [info ] [Thread-1  ]: 1 of 6 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 2.96s]
11:36:59.650155 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
11:36:59.650413 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
11:36:59.650822 [info ] [Thread-1  ]: 2 of 6 START incremental model dbt.incremental_time............................. [RUN]
11:36:59.651463 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
11:36:59.651680 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
11:36:59.651876 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
11:36:59.656032 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
11:36:59.656789 [debug] [Thread-1  ]: finished collecting timing info
11:36:59.656962 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
11:36:59.660692 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
11:36:59.660891 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
11:36:59.661042 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:37:00.890895 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.23 seconds
11:37:00.896673 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
11:37:00.897017 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
11:37:01.010264 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.11 seconds
11:37:01.014797 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
11:37:01.015079 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
11:37:01.145459 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.13 seconds
11:37:01.150722 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
11:37:01.150955 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
11:37:01.417758 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.27 seconds
11:37:01.422779 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
11:37:01.425142 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
11:37:01.425367 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
11:37:01.604082 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.18 seconds
11:37:01.604817 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
11:37:01.605052 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
11:37:02.557017 [debug] [Thread-1  ]: SQL status: SUCCESS 200 in 0.95 seconds
11:37:02.558879 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
11:37:02.561093 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
11:37:02.939284 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.38 seconds
11:37:02.942162 [debug] [Thread-1  ]: finished collecting timing info
11:37:02.942482 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
11:37:03.261977 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b05ae46b-a079-4f2c-9b61-93925b65de27', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10720e370>]}
11:37:03.262859 [info ] [Thread-1  ]: 2 of 6 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 3.61s]
11:37:03.263302 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
11:37:03.263556 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
11:37:03.263955 [info ] [Thread-1  ]: 3 of 6 START table model dbt_nigel_test.first_model............................. [RUN]
11:37:03.264597 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
11:37:03.264814 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
11:37:03.265019 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
11:37:03.268518 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
11:37:03.269178 [debug] [Thread-1  ]: finished collecting timing info
11:37:03.269356 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
11:37:03.278322 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
11:37:03.279485 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
11:37:03.279650 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt_nigel_test.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
11:37:03.279783 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:37:04.654052 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.37 seconds
11:37:04.665606 [debug] [Thread-1  ]: finished collecting timing info
11:37:04.665954 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
11:37:05.021661 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b05ae46b-a079-4f2c-9b61-93925b65de27', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10720e760>]}
11:37:05.023033 [info ] [Thread-1  ]: 3 of 6 OK created table model dbt_nigel_test.first_model........................ [[32mSUCCESS 1[0m in 1.76s]
11:37:05.023644 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
11:37:05.023901 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
11:37:05.024324 [info ] [Thread-1  ]: 4 of 6 START table model dbt.snowflake_cumulative_sales......................... [RUN]
11:37:05.025070 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
11:37:05.025324 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
11:37:05.025575 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
11:37:05.026969 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
11:37:05.027859 [debug] [Thread-1  ]: finished collecting timing info
11:37:05.028077 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
11:37:05.030973 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
11:37:05.032296 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
11:37:05.032481 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
11:37:05.032633 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:37:07.115468 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.08 seconds
11:37:07.118939 [debug] [Thread-1  ]: finished collecting timing info
11:37:07.119353 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
11:37:07.395556 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b05ae46b-a079-4f2c-9b61-93925b65de27', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10720e250>]}
11:37:07.396395 [info ] [Thread-1  ]: 4 of 6 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 2.37s]
11:37:07.396861 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
11:37:07.397107 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
11:37:07.397515 [info ] [Thread-1  ]: 5 of 6 START table model dbt.snowflake_customer_purchases....................... [RUN]
11:37:07.398169 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
11:37:07.398385 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
11:37:07.398589 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
11:37:07.400393 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
11:37:07.401089 [debug] [Thread-1  ]: finished collecting timing info
11:37:07.401282 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
11:37:07.403980 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
11:37:07.405373 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
11:37:07.405553 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
11:37:07.405708 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:37:09.955808 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.55 seconds
11:37:09.963065 [debug] [Thread-1  ]: finished collecting timing info
11:37:09.963500 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
11:37:10.439017 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b05ae46b-a079-4f2c-9b61-93925b65de27', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10720e100>]}
11:37:10.439605 [info ] [Thread-1  ]: 5 of 6 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 3.04s]
11:37:10.439933 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
11:37:10.440109 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
11:37:10.440396 [info ] [Thread-1  ]: 6 of 6 START table model dbt.my_second_dbt_model................................ [RUN]
11:37:10.440937 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
11:37:10.441119 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
11:37:10.441314 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
11:37:10.443844 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
11:37:10.444658 [debug] [Thread-1  ]: finished collecting timing info
11:37:10.444839 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
11:37:10.447304 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
11:37:10.448178 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
11:37:10.448342 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt_nigel_test.first_model
where id = 1
      );
11:37:10.448487 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:37:12.083363 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.63 seconds
11:37:12.085492 [debug] [Thread-1  ]: finished collecting timing info
11:37:12.085710 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
11:37:12.473630 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b05ae46b-a079-4f2c-9b61-93925b65de27', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10720e340>]}
11:37:12.474445 [info ] [Thread-1  ]: 6 of 6 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 2.03s]
11:37:12.474833 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
11:37:12.476226 [debug] [MainThread]: Acquiring new snowflake connection "master"
11:37:12.476847 [info ] [MainThread]: 
11:37:12.477218 [info ] [MainThread]: Finished running 2 incremental models, 4 table models in 20.10s.
11:37:12.477536 [debug] [MainThread]: Connection 'master' was properly closed.
11:37:12.477704 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
11:37:12.484242 [info ] [MainThread]: 
11:37:12.484578 [info ] [MainThread]: [32mCompleted successfully[0m
11:37:12.484872 [info ] [MainThread]: 
11:37:12.485106 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
11:37:12.485412 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104ffdfa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10528c1f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053e5dc0>]}


============================== 2022-05-13 11:55:13.046402 | 4a1cd0d8-dde2-4aa4-8880-68e3dbe33074 ==============================
11:55:13.046402 [info ] [MainThread]: Running with dbt=1.0.1
11:55:13.046992 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
11:55:13.047122 [debug] [MainThread]: Tracking: tracking
11:55:13.047336 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1061b4e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1061b4a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1061b4d30>]}
11:55:13.091478 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
11:55:13.091793 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/my_first_dbt_model.sql
11:55:13.097322 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
11:55:13.117015 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4a1cd0d8-dde2-4aa4-8880-68e3dbe33074', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105202040>]}
11:55:13.120122 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4a1cd0d8-dde2-4aa4-8880-68e3dbe33074', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105778b20>]}
11:55:13.120257 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
11:55:13.120980 [info ] [MainThread]: 
11:55:13.121185 [debug] [MainThread]: Acquiring new snowflake connection "master"
11:55:13.121609 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytic_test"
11:55:13.127373 [debug] [ThreadPool]: Using snowflake connection "list_analytic_test"
11:55:13.127478 [debug] [ThreadPool]: On list_analytic_test: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytic_test"} */

    show terse schemas in database analytic_test
    limit 10000
11:55:13.127553 [debug] [ThreadPool]: Opening a new connection, currently in state init
11:55:14.006781 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01a43ceb-3201-9c86-0000-000120522de1
11:55:14.006983 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 002043 (02000): SQL compilation error:
Object does not exist, or operation cannot be performed.
11:55:14.007117 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro list_schemas
11:55:14.007179 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
11:55:14.007301 [debug] [ThreadPool]: On list_analytic_test: Close
11:55:14.174054 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
11:55:14.177918 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
11:55:14.178180 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
11:55:14.178379 [debug] [ThreadPool]: Opening a new connection, currently in state closed
11:55:14.867726 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 0.69 seconds
11:55:14.869731 [debug] [ThreadPool]: On list_analytics: Close
11:55:15.051358 [debug] [MainThread]: Connection 'master' was properly closed.
11:55:15.051840 [debug] [MainThread]: Connection 'list_analytics' was properly closed.
11:55:15.052281 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10507e160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10618cbe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106544a60>]}


============================== 2022-05-13 11:57:12.170548 | a36575dd-b926-424a-b1e6-231f1e866068 ==============================
11:57:12.170548 [info ] [MainThread]: Running with dbt=1.0.1
11:57:12.170916 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
11:57:12.171054 [debug] [MainThread]: Tracking: tracking
11:57:12.171259 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1104728b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110472b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110472610>]}
11:57:12.213961 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
11:57:12.214118 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
11:57:12.217400 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a36575dd-b926-424a-b1e6-231f1e866068', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11043e040>]}
11:57:12.220771 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a36575dd-b926-424a-b1e6-231f1e866068', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110454eb0>]}
11:57:12.220925 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
11:57:12.221764 [info ] [MainThread]: 
11:57:12.222092 [debug] [MainThread]: Acquiring new snowflake connection "master"
11:57:12.222560 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
11:57:12.228741 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
11:57:12.228901 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
11:57:12.228993 [debug] [ThreadPool]: Opening a new connection, currently in state init
11:57:13.051352 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 0.82 seconds
11:57:13.053220 [debug] [ThreadPool]: On list_analytics: Close
11:57:13.210249 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytic_test"
11:57:13.212883 [debug] [ThreadPool]: Using snowflake connection "list_analytic_test"
11:57:13.213121 [debug] [ThreadPool]: On list_analytic_test: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytic_test"} */

    show terse schemas in database analytic_test
    limit 10000
11:57:13.213278 [debug] [ThreadPool]: Opening a new connection, currently in state closed
11:57:13.724112 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01a43ced-3201-9c12-0000-000120521a85
11:57:13.724671 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 002043 (02000): SQL compilation error:
Object does not exist, or operation cannot be performed.
11:57:13.725167 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro list_schemas
11:57:13.725366 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
11:57:13.725648 [debug] [ThreadPool]: On list_analytic_test: Close
11:57:13.911271 [debug] [MainThread]: Connection 'master' was properly closed.
11:57:13.911779 [debug] [MainThread]: Connection 'list_analytic_test' was properly closed.
11:57:13.912093 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1071da130>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1071c7e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1109f1fa0>]}


============================== 2022-05-13 11:57:30.832906 | 655bf4f2-cea4-419e-9606-da9e1017f2fa ==============================
11:57:30.832906 [info ] [MainThread]: Running with dbt=1.0.1
11:57:30.833306 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
11:57:30.833429 [debug] [MainThread]: Tracking: tracking
11:57:30.833634 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a8bbf70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a8bbc40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a8bb8b0>]}
11:57:30.876228 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
11:57:30.876604 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/my_first_dbt_model.sql
11:57:30.881954 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
11:57:30.900986 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '655bf4f2-cea4-419e-9606-da9e1017f2fa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10969a460>]}
11:57:30.904213 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '655bf4f2-cea4-419e-9606-da9e1017f2fa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a8995e0>]}
11:57:30.904382 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
11:57:30.905251 [info ] [MainThread]: 
11:57:30.905500 [debug] [MainThread]: Acquiring new snowflake connection "master"
11:57:30.905993 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
11:57:30.912189 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
11:57:30.912331 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
11:57:30.912405 [debug] [ThreadPool]: Opening a new connection, currently in state init
11:57:31.656945 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 0.74 seconds
11:57:31.660308 [debug] [ThreadPool]: On list_analytics: Close
11:57:31.856970 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_test"
11:57:31.859938 [debug] [ThreadPool]: Using snowflake connection "list_analytics_test"
11:57:31.860195 [debug] [ThreadPool]: On list_analytics_test: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_test"} */

    show terse schemas in database analytics_test
    limit 10000
11:57:31.860383 [debug] [ThreadPool]: Opening a new connection, currently in state closed
11:57:32.663661 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.8 seconds
11:57:32.666342 [debug] [ThreadPool]: On list_analytics_test: Close
11:57:32.836155 [debug] [ThreadPool]: Acquiring new snowflake connection "create_analytics_test_dbt_nigel_test"
11:57:32.836708 [debug] [ThreadPool]: Acquiring new snowflake connection "create_analytics_test_dbt_nigel_test"
11:57:32.837017 [debug] [ThreadPool]: Creating schema "_ReferenceKey(database='analytics_test', schema='dbt_nigel_test', identifier=None)"
11:57:32.843771 [debug] [ThreadPool]: Using snowflake connection "create_analytics_test_dbt_nigel_test"
11:57:32.844088 [debug] [ThreadPool]: On create_analytics_test_dbt_nigel_test: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "create_analytics_test_dbt_nigel_test"} */
create schema if not exists analytics_test.dbt_nigel_test
11:57:32.844253 [debug] [ThreadPool]: Opening a new connection, currently in state closed
11:57:33.376355 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.53 seconds
11:57:33.378105 [debug] [ThreadPool]: On create_analytics_test_dbt_nigel_test: Close
11:57:33.538174 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
11:57:33.546674 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
11:57:33.546958 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
11:57:33.547118 [debug] [ThreadPool]: Opening a new connection, currently in state closed
11:57:34.145322 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 0.6 seconds
11:57:34.148156 [debug] [ThreadPool]: On list_analytics_dbt: Close
11:57:34.315119 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_test_dbt_nigel_test"
11:57:34.318341 [debug] [ThreadPool]: Using snowflake connection "list_analytics_test_dbt_nigel_test"
11:57:34.318699 [debug] [ThreadPool]: On list_analytics_test_dbt_nigel_test: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_test_dbt_nigel_test"} */

    show terse objects in analytics_test.dbt_nigel_test
11:57:34.318905 [debug] [ThreadPool]: Opening a new connection, currently in state closed
11:57:34.808187 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 0.49 seconds
11:57:34.811899 [debug] [ThreadPool]: On list_analytics_test_dbt_nigel_test: Close
11:57:34.983265 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
11:57:34.984194 [info ] [MainThread]: 
11:57:34.990120 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
11:57:34.990580 [info ] [Thread-1  ]: 1 of 6 START incremental model dbt.dates........................................ [RUN]
11:57:34.991137 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
11:57:34.991304 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
11:57:34.991831 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
11:57:34.997486 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
11:57:34.998915 [debug] [Thread-1  ]: finished collecting timing info
11:57:34.999143 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
11:57:35.030584 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
11:57:35.030782 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
11:57:35.030872 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:57:36.816052 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.79 seconds
11:57:36.829490 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
11:57:36.829874 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
11:57:36.935152 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.11 seconds
11:57:36.943064 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
11:57:36.943415 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
11:57:37.031500 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.09 seconds
11:57:37.042609 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
11:57:37.042885 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
11:57:37.140267 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.1 seconds
11:57:37.168414 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
11:57:37.170776 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
11:57:37.170906 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
11:57:37.298921 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.13 seconds
11:57:37.299593 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
11:57:37.299782 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
11:57:37.854477 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.55 seconds
11:57:37.855959 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
11:57:37.856193 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
11:57:38.050109 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.19 seconds
11:57:38.064838 [debug] [Thread-1  ]: finished collecting timing info
11:57:38.065220 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
11:57:38.261818 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '655bf4f2-cea4-419e-9606-da9e1017f2fa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ac39190>]}
11:57:38.262297 [info ] [Thread-1  ]: 1 of 6 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 3.27s]
11:57:38.262490 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
11:57:38.262582 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
11:57:38.262687 [info ] [Thread-1  ]: 2 of 6 START incremental model dbt.incremental_time............................. [RUN]
11:57:38.263044 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
11:57:38.263313 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
11:57:38.263447 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
11:57:38.267386 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
11:57:38.269513 [debug] [Thread-1  ]: finished collecting timing info
11:57:38.269706 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
11:57:38.273566 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
11:57:38.273774 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
11:57:38.273914 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:57:39.505424 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.23 seconds
11:57:39.512413 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
11:57:39.512774 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
11:57:39.630330 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.12 seconds
11:57:39.635896 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
11:57:39.636238 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
11:57:39.744926 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.11 seconds
11:57:39.748999 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
11:57:39.749249 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
11:57:39.850536 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
11:57:39.855532 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
11:57:39.857997 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
11:57:39.858232 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
11:57:39.989554 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.13 seconds
11:57:39.990858 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
11:57:39.991109 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
11:57:40.912614 [debug] [Thread-1  ]: SQL status: SUCCESS 1238 in 0.92 seconds
11:57:40.913443 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
11:57:40.913644 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
11:57:41.219812 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.31 seconds
11:57:41.223270 [debug] [Thread-1  ]: finished collecting timing info
11:57:41.223720 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
11:57:41.400280 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '655bf4f2-cea4-419e-9606-da9e1017f2fa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cf9a7f0>]}
11:57:41.401034 [info ] [Thread-1  ]: 2 of 6 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 3.14s]
11:57:41.401465 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
11:57:41.402274 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
11:57:41.402575 [info ] [Thread-1  ]: 3 of 6 START table model analytics_test.dbt_nigel_test.first_model.............. [RUN]
11:57:41.402974 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
11:57:41.403097 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
11:57:41.403215 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
11:57:41.405694 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
11:57:41.407352 [debug] [Thread-1  ]: finished collecting timing info
11:57:41.407584 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
11:57:41.415151 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
11:57:41.416501 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
11:57:41.416725 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics_test.dbt_nigel_test.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
11:57:41.416839 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:57:42.655372 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.24 seconds
11:57:42.657958 [debug] [Thread-1  ]: finished collecting timing info
11:57:42.658308 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
11:57:42.821467 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '655bf4f2-cea4-419e-9606-da9e1017f2fa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ad9c9a0>]}
11:57:42.822291 [info ] [Thread-1  ]: 3 of 6 OK created table model analytics_test.dbt_nigel_test.first_model......... [[32mSUCCESS 1[0m in 1.42s]
11:57:42.822836 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
11:57:42.823072 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
11:57:42.823284 [info ] [Thread-1  ]: 4 of 6 START table model dbt.snowflake_cumulative_sales......................... [RUN]
11:57:42.823611 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
11:57:42.823708 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
11:57:42.823781 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
11:57:42.824473 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
11:57:42.825964 [debug] [Thread-1  ]: finished collecting timing info
11:57:42.826103 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
11:57:42.827648 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
11:57:42.828229 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
11:57:42.828308 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
11:57:42.828376 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:57:44.467681 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.64 seconds
11:57:44.472236 [debug] [Thread-1  ]: finished collecting timing info
11:57:44.472658 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
11:57:44.644048 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '655bf4f2-cea4-419e-9606-da9e1017f2fa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ad9c9d0>]}
11:57:44.646472 [info ] [Thread-1  ]: 4 of 6 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 1.82s]
11:57:44.646943 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
11:57:44.647183 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
11:57:44.647525 [info ] [Thread-1  ]: 5 of 6 START table model dbt.snowflake_customer_purchases....................... [RUN]
11:57:44.648507 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
11:57:44.648750 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
11:57:44.648956 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
11:57:44.650712 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
11:57:44.652666 [debug] [Thread-1  ]: finished collecting timing info
11:57:44.652967 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
11:57:44.655568 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
11:57:44.656805 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
11:57:44.656983 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
11:57:44.657132 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:57:46.211158 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.55 seconds
11:57:46.217686 [debug] [Thread-1  ]: finished collecting timing info
11:57:46.218136 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
11:57:46.406388 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '655bf4f2-cea4-419e-9606-da9e1017f2fa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ae52cd0>]}
11:57:46.418141 [info ] [Thread-1  ]: 5 of 6 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 1.76s]
11:57:46.418662 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
11:57:46.418934 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
11:57:46.421526 [info ] [Thread-1  ]: 6 of 6 START table model dbt.my_second_dbt_model................................ [RUN]
11:57:46.422164 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
11:57:46.422304 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
11:57:46.422430 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
11:57:46.424553 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
11:57:46.425689 [debug] [Thread-1  ]: finished collecting timing info
11:57:46.425918 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
11:57:46.428188 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
11:57:46.429181 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
11:57:46.429402 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics_test.dbt_nigel_test.first_model
where id = 1
      );
11:57:46.429560 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:57:47.574917 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.15 seconds
11:57:47.577648 [debug] [Thread-1  ]: finished collecting timing info
11:57:47.577966 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
11:57:47.769230 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '655bf4f2-cea4-419e-9606-da9e1017f2fa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a8abe20>]}
11:57:47.770088 [info ] [Thread-1  ]: 6 of 6 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.35s]
11:57:47.770486 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
11:57:47.771450 [debug] [MainThread]: Acquiring new snowflake connection "master"
11:57:47.772048 [info ] [MainThread]: 
11:57:47.772405 [info ] [MainThread]: Finished running 2 incremental models, 4 table models in 16.87s.
11:57:47.772551 [debug] [MainThread]: Connection 'master' was properly closed.
11:57:47.772623 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
11:57:47.776911 [info ] [MainThread]: 
11:57:47.777139 [info ] [MainThread]: [32mCompleted successfully[0m
11:57:47.777309 [info ] [MainThread]: 
11:57:47.777431 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
11:57:47.777626 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cf0e520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a899670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cf03070>]}


============================== 2022-05-13 11:59:39.762097 | 90a0ec53-a580-4ed2-9c15-925b0818b325 ==============================
11:59:39.762097 [info ] [MainThread]: Running with dbt=1.0.1
11:59:39.762653 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
11:59:39.762779 [debug] [MainThread]: Tracking: tracking
11:59:39.762985 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105a431c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105a43dc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105a43c10>]}
11:59:39.806910 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
11:59:39.807214 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/my_first_dbt_model.sql
11:59:39.812736 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
11:59:39.814575 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102eaf9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059f6550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059f62e0>]}


============================== 2022-05-13 12:00:08.576998 | 9f8aed9a-d9cc-48c4-89b7-9898a7744598 ==============================
12:00:08.576998 [info ] [MainThread]: Running with dbt=1.0.1
12:00:08.577374 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
12:00:08.577516 [debug] [MainThread]: Tracking: tracking
12:00:08.577716 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1118c33a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1118c3370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1118c36d0>]}
12:00:08.619193 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
12:00:08.619492 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/my_first_dbt_model.sql
12:00:08.624380 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
12:00:08.625554 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1118ae5b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1119c4220>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1119c42b0>]}


============================== 2022-05-13 12:00:52.918224 | bcf5a11b-1ead-4170-872c-bc8fe39e6597 ==============================
12:00:52.918224 [info ] [MainThread]: Running with dbt=1.0.1
12:00:52.918561 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
12:00:52.918687 [debug] [MainThread]: Tracking: tracking
12:00:52.918927 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11137ce20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11137ca90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11137cd30>]}
12:00:52.959999 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
12:00:52.960362 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/my_first_dbt_model.sql
12:00:52.965328 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
12:00:52.966530 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1025f6940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111343490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111343550>]}


============================== 2022-05-13 12:01:35.442046 | 0802810b-e55c-4cd3-9bd9-bc83c8fdfd64 ==============================
12:01:35.442046 [info ] [MainThread]: Running with dbt=1.0.1
12:01:35.442711 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
12:01:35.442891 [debug] [MainThread]: Tracking: tracking
12:01:35.443166 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1121906a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1121905b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112190250>]}
12:01:35.484033 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
12:01:35.484385 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/my_first_dbt_model.sql
12:01:35.489877 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
12:01:35.510442 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0802810b-e55c-4cd3-9bd9-bc83c8fdfd64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1122d2430>]}
12:01:35.513614 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0802810b-e55c-4cd3-9bd9-bc83c8fdfd64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105392160>]}
12:01:35.513754 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
12:01:35.514526 [info ] [MainThread]: 
12:01:35.514749 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:01:35.515227 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
12:01:35.521218 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
12:01:35.521326 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
12:01:35.521394 [debug] [ThreadPool]: Opening a new connection, currently in state init
12:01:36.568209 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.05 seconds
12:01:36.570620 [debug] [ThreadPool]: On list_analytics: Close
12:01:36.761776 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
12:01:36.773348 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
12:01:36.773695 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
12:01:36.773869 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:01:37.815598 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1.04 seconds
12:01:37.817709 [debug] [ThreadPool]: On list_analytics_dbt: Close
12:01:38.091852 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
12:01:38.092372 [info ] [MainThread]: 
12:01:38.097742 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
12:01:38.098485 [info ] [Thread-1  ]: 1 of 6 START incremental model dbt.dates........................................ [RUN]
12:01:38.099026 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
12:01:38.099205 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
12:01:38.099394 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
12:01:38.109247 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
12:01:38.109870 [debug] [Thread-1  ]: finished collecting timing info
12:01:38.110017 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
12:01:38.138561 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:01:38.138752 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
12:01:38.138840 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:01:40.015616 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.88 seconds
12:01:40.029303 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:01:40.029666 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
12:01:40.221070 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.19 seconds
12:01:40.227041 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:01:40.227276 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
12:01:40.323556 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.1 seconds
12:01:40.336041 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:01:40.336337 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
12:01:40.435961 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.1 seconds
12:01:40.464698 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
12:01:40.466888 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:01:40.467021 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
12:01:40.619438 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.15 seconds
12:01:40.622018 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:01:40.622358 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
12:01:41.347187 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.72 seconds
12:01:41.347753 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:01:41.348050 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
12:01:41.547111 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.2 seconds
12:01:41.569738 [debug] [Thread-1  ]: finished collecting timing info
12:01:41.570215 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
12:01:41.813181 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0802810b-e55c-4cd3-9bd9-bc83c8fdfd64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110dcd3a0>]}
12:01:41.813963 [info ] [Thread-1  ]: 1 of 6 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 3.71s]
12:01:41.814421 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
12:01:41.814670 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
12:01:41.815160 [info ] [Thread-1  ]: 2 of 6 START incremental model dbt.incremental_time............................. [RUN]
12:01:41.815744 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
12:01:41.815936 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
12:01:41.816124 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
12:01:41.820116 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
12:01:41.820867 [debug] [Thread-1  ]: finished collecting timing info
12:01:41.821050 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
12:01:41.824977 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:01:41.825220 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
12:01:41.825366 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:01:45.384546 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 3.56 seconds
12:01:45.393154 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:01:45.393506 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
12:01:45.750848 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.36 seconds
12:01:45.756753 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:01:45.757086 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
12:01:45.860077 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
12:01:45.864000 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:01:45.864163 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
12:01:46.101898 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.24 seconds
12:01:46.112030 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
12:01:46.114194 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:01:46.114386 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
12:01:46.424368 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.31 seconds
12:01:46.425353 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:01:46.425805 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
12:01:47.186031 [debug] [Thread-1  ]: SQL status: SUCCESS 244 in 0.76 seconds
12:01:47.187115 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:01:47.187347 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
12:01:47.449055 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.26 seconds
12:01:47.451625 [debug] [Thread-1  ]: finished collecting timing info
12:01:47.451875 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
12:01:47.684329 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0802810b-e55c-4cd3-9bd9-bc83c8fdfd64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11680d820>]}
12:01:47.685099 [info ] [Thread-1  ]: 2 of 6 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 5.87s]
12:01:47.685556 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
12:01:47.685810 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
12:01:47.686109 [info ] [Thread-1  ]: 3 of 6 START table model dbt.first_model........................................ [RUN]
12:01:47.686815 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
12:01:47.687050 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
12:01:47.687258 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
12:01:47.690826 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
12:01:47.691448 [debug] [Thread-1  ]: finished collecting timing info
12:01:47.691623 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
12:01:47.700819 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
12:01:47.701943 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
12:01:47.702097 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
12:01:47.702221 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:01:49.342253 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.64 seconds
12:01:49.345192 [debug] [Thread-1  ]: finished collecting timing info
12:01:49.345498 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
12:01:49.525521 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0802810b-e55c-4cd3-9bd9-bc83c8fdfd64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1126e7af0>]}
12:01:49.526223 [info ] [Thread-1  ]: 3 of 6 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 1.84s]
12:01:49.526669 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
12:01:49.526923 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
12:01:49.527388 [info ] [Thread-1  ]: 4 of 6 START table model dbt.snowflake_cumulative_sales......................... [RUN]
12:01:49.528182 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
12:01:49.528411 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
12:01:49.528611 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
12:01:49.530068 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
12:01:49.530840 [debug] [Thread-1  ]: finished collecting timing info
12:01:49.531041 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
12:01:49.533892 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
12:01:49.535132 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
12:01:49.535288 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
12:01:49.535421 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:01:51.070503 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.54 seconds
12:01:51.074556 [debug] [Thread-1  ]: finished collecting timing info
12:01:51.074960 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
12:01:51.259367 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0802810b-e55c-4cd3-9bd9-bc83c8fdfd64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116850b80>]}
12:01:51.260166 [info ] [Thread-1  ]: 4 of 6 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 1.73s]
12:01:51.260836 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
12:01:51.261129 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
12:01:51.261580 [info ] [Thread-1  ]: 5 of 6 START table model dbt.snowflake_customer_purchases....................... [RUN]
12:01:51.262268 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
12:01:51.262519 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
12:01:51.262759 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
12:01:51.264707 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
12:01:51.265450 [debug] [Thread-1  ]: finished collecting timing info
12:01:51.265661 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
12:01:51.268331 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
12:01:51.269601 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
12:01:51.269766 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
12:01:51.269910 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:01:53.014116 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.74 seconds
12:01:53.016649 [debug] [Thread-1  ]: finished collecting timing info
12:01:53.016936 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
12:01:53.202040 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0802810b-e55c-4cd3-9bd9-bc83c8fdfd64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1126818e0>]}
12:01:53.202798 [info ] [Thread-1  ]: 5 of 6 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 1.94s]
12:01:53.203259 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
12:01:53.203527 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
12:01:53.203975 [info ] [Thread-1  ]: 6 of 6 START table model dbt.my_second_dbt_model................................ [RUN]
12:01:53.204637 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
12:01:53.204873 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
12:01:53.205084 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
12:01:53.208221 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
12:01:53.209094 [debug] [Thread-1  ]: finished collecting timing info
12:01:53.209289 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
12:01:53.211841 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
12:01:53.212719 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
12:01:53.212896 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
where id = 1
      );
12:01:53.213049 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:01:54.434514 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.22 seconds
12:01:54.437522 [debug] [Thread-1  ]: finished collecting timing info
12:01:54.437814 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
12:01:55.482036 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0802810b-e55c-4cd3-9bd9-bc83c8fdfd64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116859190>]}
12:01:55.482756 [info ] [Thread-1  ]: 6 of 6 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 2.28s]
12:01:55.483199 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
12:01:55.484506 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:01:55.485070 [info ] [MainThread]: 
12:01:55.485431 [info ] [MainThread]: Finished running 2 incremental models, 4 table models in 19.97s.
12:01:55.485736 [debug] [MainThread]: Connection 'master' was properly closed.
12:01:55.485900 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
12:01:55.492056 [info ] [MainThread]: 
12:01:55.492386 [info ] [MainThread]: [32mCompleted successfully[0m
12:01:55.492680 [info ] [MainThread]: 
12:01:55.492889 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
12:01:55.493175 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112355550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112558850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11685c0a0>]}


============================== 2022-05-13 12:08:25.563610 | ada402ae-839d-40c2-9280-37bfef28344f ==============================
12:08:25.563610 [info ] [MainThread]: Running with dbt=1.0.1
12:08:25.564053 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
12:08:25.564175 [debug] [MainThread]: Tracking: tracking
12:08:25.564374 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107132730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107132af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107132640>]}
12:08:25.598269 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
12:08:25.598484 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'ada402ae-839d-40c2-9280-37bfef28344f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107152c70>]}
12:08:25.606960 [debug] [MainThread]: Parsing macros/catalog.sql
12:08:25.608145 [debug] [MainThread]: Parsing macros/adapters.sql
12:08:25.627424 [debug] [MainThread]: Parsing macros/materializations/merge.sql
12:08:25.629214 [debug] [MainThread]: Parsing macros/materializations/seed.sql
12:08:25.631741 [debug] [MainThread]: Parsing macros/materializations/view.sql
12:08:25.632339 [debug] [MainThread]: Parsing macros/materializations/table.sql
12:08:25.633750 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
12:08:25.637767 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
12:08:25.638187 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
12:08:25.639906 [debug] [MainThread]: Parsing macros/materializations/configs.sql
12:08:25.640914 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
12:08:25.641658 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
12:08:25.649398 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
12:08:25.654923 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
12:08:25.660732 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
12:08:25.662828 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
12:08:25.663618 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
12:08:25.664407 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
12:08:25.666410 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
12:08:25.671781 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
12:08:25.672451 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
12:08:25.677319 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
12:08:25.684968 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
12:08:25.688601 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
12:08:25.689866 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
12:08:25.693336 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
12:08:25.693898 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
12:08:25.695102 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
12:08:25.696095 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
12:08:25.698924 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
12:08:25.706819 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
12:08:25.707467 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
12:08:25.708546 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
12:08:25.709224 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
12:08:25.709624 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
12:08:25.709856 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
12:08:25.710154 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
12:08:25.710754 [debug] [MainThread]: Parsing macros/etc/statement.sql
12:08:25.712756 [debug] [MainThread]: Parsing macros/etc/datetime.sql
12:08:25.716641 [debug] [MainThread]: Parsing macros/adapters/schema.sql
12:08:25.717576 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
12:08:25.718752 [debug] [MainThread]: Parsing macros/adapters/relation.sql
12:08:25.723235 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
12:08:25.724496 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
12:08:25.726450 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
12:08:25.729729 [debug] [MainThread]: Parsing macros/adapters/columns.sql
12:08:25.734224 [debug] [MainThread]: Parsing tests/generic/builtin.sql
12:08:25.823515 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
12:08:25.829645 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
12:08:25.830213 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_cumulative_sales.sql
12:08:25.831226 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
12:08:25.832206 [debug] [MainThread]: 1603: static parser failed on example/dates.sql
12:08:25.835498 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/dates.sql
12:08:25.835958 [debug] [MainThread]: 1603: static parser failed on example/incremental_time.sql
12:08:25.837593 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_time.sql
12:08:25.838048 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
12:08:25.863601 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.learn_dbt.example.vars

12:08:25.865970 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ada402ae-839d-40c2-9280-37bfef28344f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10724d370>]}
12:08:25.868854 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ada402ae-839d-40c2-9280-37bfef28344f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10724ddc0>]}
12:08:25.868989 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
12:08:25.869709 [info ] [MainThread]: 
12:08:25.869920 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:08:25.870334 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
12:08:25.876331 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
12:08:25.876537 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
12:08:25.876613 [debug] [ThreadPool]: Opening a new connection, currently in state init
12:08:26.708131 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.83 seconds
12:08:26.711878 [debug] [ThreadPool]: On list_analytics: Close
12:08:26.948184 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
12:08:26.957020 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
12:08:26.957238 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
12:08:26.957394 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:08:27.499888 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 0.54 seconds
12:08:27.503408 [debug] [ThreadPool]: On list_analytics_dbt: Close
12:08:27.674649 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
12:08:27.675273 [info ] [MainThread]: 
12:08:27.680194 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
12:08:27.680859 [info ] [Thread-1  ]: 1 of 6 START incremental model dbt.dates........................................ [RUN]
12:08:27.681357 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
12:08:27.681527 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
12:08:27.681686 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
12:08:27.687438 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
12:08:27.688091 [debug] [Thread-1  ]: finished collecting timing info
12:08:27.688257 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
12:08:27.718566 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:08:27.718787 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
12:08:27.718880 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:08:29.923871 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.2 seconds
12:08:29.937508 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:08:29.937843 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
12:08:30.061991 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.12 seconds
12:08:30.069077 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:08:30.069450 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
12:08:30.196914 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.13 seconds
12:08:30.210213 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:08:30.210578 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
12:08:30.328122 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.12 seconds
12:08:30.354577 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
12:08:30.357101 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:08:30.357231 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
12:08:30.511335 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.15 seconds
12:08:30.512206 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:08:30.512418 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
12:08:31.461368 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.95 seconds
12:08:31.462032 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:08:31.462303 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
12:08:31.657982 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.2 seconds
12:08:31.671112 [debug] [Thread-1  ]: finished collecting timing info
12:08:31.671650 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
12:08:31.851048 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ada402ae-839d-40c2-9280-37bfef28344f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107250f10>]}
12:08:31.851765 [info ] [Thread-1  ]: 1 of 6 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 4.17s]
12:08:31.852232 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
12:08:31.852515 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
12:08:31.852890 [info ] [Thread-1  ]: 2 of 6 START incremental model dbt.incremental_time............................. [RUN]
12:08:31.854082 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
12:08:31.854366 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
12:08:31.854581 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
12:08:31.858696 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
12:08:31.859362 [debug] [Thread-1  ]: finished collecting timing info
12:08:31.859536 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
12:08:31.863119 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:08:31.863303 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
12:08:31.863448 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:08:33.508187 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.64 seconds
12:08:33.513463 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:08:33.513799 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
12:08:33.623191 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.11 seconds
12:08:33.628249 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:08:33.628509 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
12:08:33.751011 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.12 seconds
12:08:33.756746 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:08:33.756912 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
12:08:33.861606 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
12:08:33.866759 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
12:08:33.869002 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:08:33.869186 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
12:08:34.063600 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.19 seconds
12:08:34.064519 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:08:34.064709 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
12:08:34.842089 [debug] [Thread-1  ]: SQL status: SUCCESS 410 in 0.78 seconds
12:08:34.842747 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:08:34.842962 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
12:08:35.350893 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.51 seconds
12:08:35.354663 [debug] [Thread-1  ]: finished collecting timing info
12:08:35.355076 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
12:08:35.561981 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ada402ae-839d-40c2-9280-37bfef28344f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1096d6d90>]}
12:08:35.562623 [info ] [Thread-1  ]: 2 of 6 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 3.71s]
12:08:35.563074 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
12:08:35.563326 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
12:08:35.563732 [info ] [Thread-1  ]: 3 of 6 START table model dbt.first_model........................................ [RUN]
12:08:35.564381 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
12:08:35.564604 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
12:08:35.564824 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
12:08:35.569775 [debug] [Thread-1  ]: finished collecting timing info
12:08:35.570173 [debug] [Thread-1  ]: Compilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  Required var 'my_first_variable' not found in config:
  Vars supplied to my_first_dbt_model = {}
  
  > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
12:08:35.570455 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ada402ae-839d-40c2-9280-37bfef28344f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1096b6610>]}
12:08:35.570771 [error] [Thread-1  ]: 3 of 6 ERROR creating table model dbt.first_model............................... [[31mERROR[0m in 0.01s]
12:08:35.571086 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
12:08:35.571282 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
12:08:35.571724 [info ] [Thread-1  ]: 4 of 6 START table model dbt.snowflake_cumulative_sales......................... [RUN]
12:08:35.572176 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
12:08:35.572335 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
12:08:35.572490 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
12:08:35.573676 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
12:08:35.574445 [debug] [Thread-1  ]: finished collecting timing info
12:08:35.574609 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
12:08:35.582893 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
12:08:35.583873 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
12:08:35.584008 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
12:08:35.584121 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:08:36.991739 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.41 seconds
12:08:36.995269 [debug] [Thread-1  ]: finished collecting timing info
12:08:36.995694 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
12:08:37.198950 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ada402ae-839d-40c2-9280-37bfef28344f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1096da220>]}
12:08:37.199661 [info ] [Thread-1  ]: 4 of 6 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 1.63s]
12:08:37.200105 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
12:08:37.200357 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
12:08:37.200762 [info ] [Thread-1  ]: 5 of 6 START table model dbt.snowflake_customer_purchases....................... [RUN]
12:08:37.201453 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
12:08:37.201673 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
12:08:37.201880 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
12:08:37.203955 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
12:08:37.204781 [debug] [Thread-1  ]: finished collecting timing info
12:08:37.204990 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
12:08:37.207819 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
12:08:37.209324 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
12:08:37.209517 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
12:08:37.209680 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:08:39.345102 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.14 seconds
12:08:39.348709 [debug] [Thread-1  ]: finished collecting timing info
12:08:39.349140 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
12:08:39.547748 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ada402ae-839d-40c2-9280-37bfef28344f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10762b400>]}
12:08:39.548454 [info ] [Thread-1  ]: 5 of 6 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.35s]
12:08:39.548902 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
12:08:39.549147 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
12:08:39.549487 [info ] [Thread-1  ]: 6 of 6 SKIP relation dbt.my_second_dbt_model.................................... [[33mSKIP[0m]
12:08:39.549970 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
12:08:39.551238 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:08:39.551728 [info ] [MainThread]: 
12:08:39.552062 [info ] [MainThread]: Finished running 2 incremental models, 4 table models in 13.68s.
12:08:39.552355 [debug] [MainThread]: Connection 'master' was properly closed.
12:08:39.552517 [debug] [MainThread]: Connection 'model.learn_dbt.snowflake_customer_purchases' was properly closed.
12:08:39.558834 [info ] [MainThread]: 
12:08:39.559099 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
12:08:39.559329 [info ] [MainThread]: 
12:08:39.559521 [error] [MainThread]: [33mCompilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)[0m
12:08:39.559713 [error] [MainThread]:   Required var 'my_first_variable' not found in config:
12:08:39.560165 [error] [MainThread]:   Vars supplied to my_first_dbt_model = {}
12:08:39.560381 [error] [MainThread]:   
12:08:39.560570 [error] [MainThread]:   > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
12:08:39.560754 [error] [MainThread]:   > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
12:08:39.561052 [info ] [MainThread]: 
12:08:39.561254 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=1 TOTAL=6
12:08:39.561536 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10762b400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10764dcd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1096b0eb0>]}


============================== 2022-05-13 12:09:39.024472 | 3b51c2fd-a781-47ee-acd6-95f4a57ebd50 ==============================
12:09:39.024472 [info ] [MainThread]: Running with dbt=1.0.1
12:09:39.024867 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
12:09:39.024994 [debug] [MainThread]: Tracking: tracking
12:09:39.025215 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109c82250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109c82ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109c82910>]}
12:09:39.058832 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
12:09:39.059054 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '3b51c2fd-a781-47ee-acd6-95f4a57ebd50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1091c6340>]}
12:09:39.067971 [debug] [MainThread]: Parsing macros/catalog.sql
12:09:39.069203 [debug] [MainThread]: Parsing macros/adapters.sql
12:09:39.088341 [debug] [MainThread]: Parsing macros/materializations/merge.sql
12:09:39.090136 [debug] [MainThread]: Parsing macros/materializations/seed.sql
12:09:39.092623 [debug] [MainThread]: Parsing macros/materializations/view.sql
12:09:39.093207 [debug] [MainThread]: Parsing macros/materializations/table.sql
12:09:39.094622 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
12:09:39.098591 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
12:09:39.099002 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
12:09:39.100711 [debug] [MainThread]: Parsing macros/materializations/configs.sql
12:09:39.101715 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
12:09:39.102457 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
12:09:39.110212 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
12:09:39.115708 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
12:09:39.121537 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
12:09:39.123627 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
12:09:39.124414 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
12:09:39.125213 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
12:09:39.127195 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
12:09:39.132532 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
12:09:39.133215 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
12:09:39.138132 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
12:09:39.145789 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
12:09:39.149445 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
12:09:39.150703 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
12:09:39.154211 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
12:09:39.154773 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
12:09:39.155983 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
12:09:39.156982 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
12:09:39.159784 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
12:09:39.167675 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
12:09:39.168325 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
12:09:39.169413 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
12:09:39.170110 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
12:09:39.170518 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
12:09:39.170747 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
12:09:39.171040 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
12:09:39.171649 [debug] [MainThread]: Parsing macros/etc/statement.sql
12:09:39.173650 [debug] [MainThread]: Parsing macros/etc/datetime.sql
12:09:39.177552 [debug] [MainThread]: Parsing macros/adapters/schema.sql
12:09:39.178487 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
12:09:39.179659 [debug] [MainThread]: Parsing macros/adapters/relation.sql
12:09:39.184136 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
12:09:39.185418 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
12:09:39.187388 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
12:09:39.190665 [debug] [MainThread]: Parsing macros/adapters/columns.sql
12:09:39.195192 [debug] [MainThread]: Parsing tests/generic/builtin.sql
12:09:39.285677 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
12:09:39.291807 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
12:09:39.292346 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_cumulative_sales.sql
12:09:39.293420 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
12:09:39.294405 [debug] [MainThread]: 1603: static parser failed on example/dates.sql
12:09:39.298226 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/dates.sql
12:09:39.298841 [debug] [MainThread]: 1603: static parser failed on example/incremental_time.sql
12:09:39.300670 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_time.sql
12:09:39.301136 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
12:09:39.327205 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.learn_dbt.example.vars

12:09:39.329601 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3b51c2fd-a781-47ee-acd6-95f4a57ebd50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109dbefa0>]}
12:09:39.332490 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3b51c2fd-a781-47ee-acd6-95f4a57ebd50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109dbe700>]}
12:09:39.332623 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
12:09:39.333346 [info ] [MainThread]: 
12:09:39.333559 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:09:39.334000 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
12:09:39.339776 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
12:09:39.339876 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
12:09:39.339941 [debug] [ThreadPool]: Opening a new connection, currently in state init
12:09:40.116369 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.78 seconds
12:09:40.118138 [debug] [ThreadPool]: On list_analytics: Close
12:09:40.279009 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
12:09:40.282473 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
12:09:40.282582 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
12:09:40.282648 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:09:40.783459 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 0.5 seconds
12:09:40.786103 [debug] [ThreadPool]: On list_analytics_dbt: Close
12:09:40.955408 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
12:09:40.956097 [info ] [MainThread]: 
12:09:40.960069 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
12:09:40.960597 [info ] [Thread-1  ]: 1 of 6 START incremental model dbt.dates........................................ [RUN]
12:09:40.960981 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
12:09:40.961119 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
12:09:40.961236 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
12:09:40.967130 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
12:09:40.967731 [debug] [Thread-1  ]: finished collecting timing info
12:09:40.967884 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
12:09:40.998416 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:09:40.998588 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
12:09:40.998676 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:09:42.806960 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.81 seconds
12:09:42.816707 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:09:42.816899 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
12:09:42.946564 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.13 seconds
12:09:42.952264 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:09:42.952466 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
12:09:43.066225 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.11 seconds
12:09:43.081238 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:09:43.081575 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
12:09:43.181693 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.1 seconds
12:09:43.208689 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
12:09:43.211058 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:09:43.211185 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
12:09:43.331036 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.12 seconds
12:09:43.331899 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:09:43.332140 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
12:09:43.683783 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.35 seconds
12:09:43.684304 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:09:43.684495 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
12:09:43.882110 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.2 seconds
12:09:43.896641 [debug] [Thread-1  ]: finished collecting timing info
12:09:43.896969 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
12:09:44.080702 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3b51c2fd-a781-47ee-acd6-95f4a57ebd50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109d18b50>]}
12:09:44.081405 [info ] [Thread-1  ]: 1 of 6 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 3.12s]
12:09:44.081841 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
12:09:44.082084 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
12:09:44.082482 [info ] [Thread-1  ]: 2 of 6 START incremental model dbt.incremental_time............................. [RUN]
12:09:44.083139 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
12:09:44.083350 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
12:09:44.083552 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
12:09:44.087564 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
12:09:44.088355 [debug] [Thread-1  ]: finished collecting timing info
12:09:44.088535 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
12:09:44.092262 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:09:44.092447 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
12:09:44.092578 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:09:45.762770 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.67 seconds
12:09:45.767209 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:09:45.767469 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
12:09:46.140424 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.37 seconds
12:09:46.148777 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:09:46.149147 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
12:09:46.262872 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.11 seconds
12:09:46.268483 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:09:46.268761 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
12:09:46.389145 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.12 seconds
12:09:46.394293 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
12:09:46.396812 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:09:46.397007 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
12:09:46.532433 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.14 seconds
12:09:46.533354 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:09:46.533585 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
12:09:47.545880 [debug] [Thread-1  ]: SQL status: SUCCESS 72 in 1.01 seconds
12:09:47.547386 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:09:47.547655 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
12:09:47.851990 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.3 seconds
12:09:47.855200 [debug] [Thread-1  ]: finished collecting timing info
12:09:47.855543 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
12:09:48.045822 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3b51c2fd-a781-47ee-acd6-95f4a57ebd50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a283ca0>]}
12:09:48.046802 [info ] [Thread-1  ]: 2 of 6 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 3.96s]
12:09:48.047321 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
12:09:48.047571 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
12:09:48.047981 [info ] [Thread-1  ]: 3 of 6 START table model dbt.first_model........................................ [RUN]
12:09:48.048644 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
12:09:48.048849 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
12:09:48.049040 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
12:09:48.056594 [debug] [Thread-1  ]: finished collecting timing info
12:09:48.057038 [debug] [Thread-1  ]: Compilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  Required var 'my_first_variable' not found in config:
  Vars supplied to my_first_dbt_model = {}
  
  > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
12:09:48.057374 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3b51c2fd-a781-47ee-acd6-95f4a57ebd50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a63f190>]}
12:09:48.057740 [error] [Thread-1  ]: 3 of 6 ERROR creating table model dbt.first_model............................... [[31mERROR[0m in 0.01s]
12:09:48.058088 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
12:09:48.058247 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
12:09:48.058604 [info ] [Thread-1  ]: 4 of 6 START table model dbt.snowflake_cumulative_sales......................... [RUN]
12:09:48.059056 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
12:09:48.059201 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
12:09:48.059344 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
12:09:48.060567 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
12:09:48.061215 [debug] [Thread-1  ]: finished collecting timing info
12:09:48.061367 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
12:09:48.069329 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
12:09:48.070261 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
12:09:48.070392 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
12:09:48.070501 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:09:49.316238 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.25 seconds
12:09:49.321483 [debug] [Thread-1  ]: finished collecting timing info
12:09:49.321891 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
12:09:49.528589 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3b51c2fd-a781-47ee-acd6-95f4a57ebd50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a283f70>]}
12:09:49.529709 [info ] [Thread-1  ]: 4 of 6 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 1.47s]
12:09:49.530322 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
12:09:49.530598 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
12:09:49.531021 [info ] [Thread-1  ]: 5 of 6 START table model dbt.snowflake_customer_purchases....................... [RUN]
12:09:49.531706 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
12:09:49.532129 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
12:09:49.532394 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
12:09:49.534282 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
12:09:49.534987 [debug] [Thread-1  ]: finished collecting timing info
12:09:49.535192 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
12:09:49.537789 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
12:09:49.538873 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
12:09:49.539043 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
12:09:49.539188 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:09:51.128325 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.59 seconds
12:09:51.131724 [debug] [Thread-1  ]: finished collecting timing info
12:09:51.132112 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
12:09:51.323260 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3b51c2fd-a781-47ee-acd6-95f4a57ebd50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a283370>]}
12:09:51.323615 [info ] [Thread-1  ]: 5 of 6 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 1.79s]
12:09:51.323821 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
12:09:51.323937 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
12:09:51.324094 [info ] [Thread-1  ]: 6 of 6 SKIP relation dbt.my_second_dbt_model.................................... [[33mSKIP[0m]
12:09:51.324304 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
12:09:51.324998 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:09:51.325284 [info ] [MainThread]: 
12:09:51.325444 [info ] [MainThread]: Finished running 2 incremental models, 4 table models in 11.99s.
12:09:51.325581 [debug] [MainThread]: Connection 'master' was properly closed.
12:09:51.325656 [debug] [MainThread]: Connection 'model.learn_dbt.snowflake_customer_purchases' was properly closed.
12:09:51.330620 [info ] [MainThread]: 
12:09:51.331063 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
12:09:51.331274 [info ] [MainThread]: 
12:09:51.331433 [error] [MainThread]: [33mCompilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)[0m
12:09:51.331594 [error] [MainThread]:   Required var 'my_first_variable' not found in config:
12:09:51.331737 [error] [MainThread]:   Vars supplied to my_first_dbt_model = {}
12:09:51.331876 [error] [MainThread]:   
12:09:51.332015 [error] [MainThread]:   > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
12:09:51.332151 [error] [MainThread]:   > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
12:09:51.332300 [info ] [MainThread]: 
12:09:51.332443 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=1 TOTAL=6
12:09:51.332660 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109c5a7c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109dbe6a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a28d700>]}


============================== 2022-05-13 12:11:30.620026 | c1a196fc-9ba5-4a5d-aeff-a41b37a15527 ==============================
12:11:30.620026 [info ] [MainThread]: Running with dbt=1.0.1
12:11:30.620603 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
12:11:30.620730 [debug] [MainThread]: Tracking: tracking
12:11:30.620965 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11193d850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11193d760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11193d400>]}
12:11:30.673494 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
12:11:30.673798 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/my_first_dbt_model.sql
12:11:30.679268 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
12:11:30.686326 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
12:11:30.697893 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.learn_dbt.example.vars

12:11:30.700297 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c1a196fc-9ba5-4a5d-aeff-a41b37a15527', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111934c70>]}
12:11:30.703174 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c1a196fc-9ba5-4a5d-aeff-a41b37a15527', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c90760>]}
12:11:30.703307 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
12:11:30.704064 [info ] [MainThread]: 
12:11:30.704273 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:11:30.704710 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
12:11:30.710565 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
12:11:30.710683 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
12:11:30.710750 [debug] [ThreadPool]: Opening a new connection, currently in state init
12:11:31.503427 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.79 seconds
12:11:31.504698 [debug] [ThreadPool]: On list_analytics: Close
12:11:31.678195 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
12:11:31.686688 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
12:11:31.686949 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
12:11:31.687106 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:11:32.411804 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 0.72 seconds
12:11:32.414174 [debug] [ThreadPool]: On list_analytics_dbt: Close
12:11:32.592504 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
12:11:32.593183 [info ] [MainThread]: 
12:11:32.598528 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
12:11:32.599352 [info ] [Thread-1  ]: 1 of 6 START incremental model dbt.dates........................................ [RUN]
12:11:32.599868 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
12:11:32.600041 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
12:11:32.600198 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
12:11:32.609497 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
12:11:32.610164 [debug] [Thread-1  ]: finished collecting timing info
12:11:32.610304 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
12:11:32.639605 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:11:32.639840 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
12:11:32.639932 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:11:34.348024 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.71 seconds
12:11:34.362017 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:11:34.362410 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
12:11:34.477054 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.11 seconds
12:11:34.483858 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:11:34.484163 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
12:11:34.602125 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.12 seconds
12:11:34.614274 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:11:34.614545 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
12:11:34.737402 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.12 seconds
12:11:34.768721 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
12:11:34.771316 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:11:34.771455 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
12:11:34.921900 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.15 seconds
12:11:34.922546 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:11:34.922737 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
12:11:35.269429 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.35 seconds
12:11:35.269979 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:11:35.270330 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
12:11:35.467496 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.2 seconds
12:11:35.481745 [debug] [Thread-1  ]: finished collecting timing info
12:11:35.482185 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
12:11:35.653942 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c1a196fc-9ba5-4a5d-aeff-a41b37a15527', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111902490>]}
12:11:35.654647 [info ] [Thread-1  ]: 1 of 6 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 3.05s]
12:11:35.655077 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
12:11:35.655332 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
12:11:35.655729 [info ] [Thread-1  ]: 2 of 6 START incremental model dbt.incremental_time............................. [RUN]
12:11:35.656393 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
12:11:35.656623 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
12:11:35.656797 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
12:11:35.660575 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
12:11:35.661270 [debug] [Thread-1  ]: finished collecting timing info
12:11:35.661446 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
12:11:35.664727 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:11:35.664908 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
12:11:35.665035 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:11:37.316610 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.65 seconds
12:11:37.321152 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:11:37.321437 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
12:11:37.451529 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.13 seconds
12:11:37.455701 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:11:37.455949 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
12:11:37.564244 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.11 seconds
12:11:37.570441 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:11:37.570717 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
12:11:37.670259 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
12:11:37.673004 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
12:11:37.673881 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:11:37.673963 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
12:11:37.809522 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.14 seconds
12:11:37.809970 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:11:37.810134 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
12:11:38.545657 [debug] [Thread-1  ]: SQL status: SUCCESS 112 in 0.74 seconds
12:11:38.546980 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:11:38.547383 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
12:11:38.791091 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.24 seconds
12:11:38.794464 [debug] [Thread-1  ]: finished collecting timing info
12:11:38.794679 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
12:11:38.963777 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c1a196fc-9ba5-4a5d-aeff-a41b37a15527', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11220acd0>]}
12:11:38.965028 [info ] [Thread-1  ]: 2 of 6 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 3.31s]
12:11:38.965575 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
12:11:38.966074 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
12:11:38.966452 [info ] [Thread-1  ]: 3 of 6 START table model dbt.first_model........................................ [RUN]
12:11:38.967203 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
12:11:38.967403 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
12:11:38.967583 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
12:11:38.973957 [debug] [Thread-1  ]: finished collecting timing info
12:11:38.974368 [debug] [Thread-1  ]: Compilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  Required var 'my_first_variable' not found in config:
  Vars supplied to my_first_dbt_model = {}
  
  > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
12:11:38.974665 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c1a196fc-9ba5-4a5d-aeff-a41b37a15527', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111edb310>]}
12:11:38.975011 [error] [Thread-1  ]: 3 of 6 ERROR creating table model dbt.first_model............................... [[31mERROR[0m in 0.01s]
12:11:38.975344 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
12:11:38.975526 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
12:11:38.975742 [info ] [Thread-1  ]: 4 of 6 START table model dbt.snowflake_cumulative_sales......................... [RUN]
12:11:38.976166 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
12:11:38.976524 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
12:11:38.977048 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
12:11:38.978377 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
12:11:38.978952 [debug] [Thread-1  ]: finished collecting timing info
12:11:38.979111 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
12:11:38.987416 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
12:11:38.988436 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
12:11:38.988572 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
12:11:38.988688 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:11:40.698379 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.71 seconds
12:11:40.701267 [debug] [Thread-1  ]: finished collecting timing info
12:11:40.701688 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
12:11:40.889778 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c1a196fc-9ba5-4a5d-aeff-a41b37a15527', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111eabb80>]}
12:11:40.890578 [info ] [Thread-1  ]: 4 of 6 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 1.91s]
12:11:40.891041 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
12:11:40.891302 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
12:11:40.891707 [info ] [Thread-1  ]: 5 of 6 START table model dbt.snowflake_customer_purchases....................... [RUN]
12:11:40.892373 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
12:11:40.892586 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
12:11:40.892785 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
12:11:40.894559 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
12:11:40.895405 [debug] [Thread-1  ]: finished collecting timing info
12:11:40.895599 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
12:11:40.898396 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
12:11:40.899833 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
12:11:40.900016 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
12:11:40.900169 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:11:42.436923 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.54 seconds
12:11:42.439673 [debug] [Thread-1  ]: finished collecting timing info
12:11:42.440069 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
12:11:42.600277 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c1a196fc-9ba5-4a5d-aeff-a41b37a15527', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111d45400>]}
12:11:42.601012 [info ] [Thread-1  ]: 5 of 6 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 1.71s]
12:11:42.601461 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
12:11:42.601709 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
12:11:42.602037 [info ] [Thread-1  ]: 6 of 6 SKIP relation dbt.my_second_dbt_model.................................... [[33mSKIP[0m]
12:11:42.602509 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
12:11:42.603820 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:11:42.604310 [info ] [MainThread]: 
12:11:42.604644 [info ] [MainThread]: Finished running 2 incremental models, 4 table models in 11.90s.
12:11:42.604934 [debug] [MainThread]: Connection 'master' was properly closed.
12:11:42.605095 [debug] [MainThread]: Connection 'model.learn_dbt.snowflake_customer_purchases' was properly closed.
12:11:42.611635 [info ] [MainThread]: 
12:11:42.611940 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
12:11:42.612194 [info ] [MainThread]: 
12:11:42.612386 [error] [MainThread]: [33mCompilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)[0m
12:11:42.612581 [error] [MainThread]:   Required var 'my_first_variable' not found in config:
12:11:42.612995 [error] [MainThread]:   Vars supplied to my_first_dbt_model = {}
12:11:42.613225 [error] [MainThread]:   
12:11:42.613479 [error] [MainThread]:   > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
12:11:42.613693 [error] [MainThread]:   > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
12:11:42.613889 [info ] [MainThread]: 
12:11:42.614074 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=1 TOTAL=6
12:11:42.614346 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110b281c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c90670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111e7a670>]}


============================== 2022-05-13 12:15:56.358089 | 16c5c4bd-0652-4541-83d5-5f31db294bfe ==============================
12:15:56.358089 [info ] [MainThread]: Running with dbt=1.0.1
12:15:56.358683 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
12:15:56.358803 [debug] [MainThread]: Tracking: tracking
12:15:56.359014 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c832b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c83eb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c83910>]}
12:15:56.392783 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
12:15:56.393012 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '16c5c4bd-0652-4541-83d5-5f31db294bfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1042baaf0>]}
12:15:56.405466 [debug] [MainThread]: Parsing macros/catalog.sql
12:15:56.406710 [debug] [MainThread]: Parsing macros/adapters.sql
12:15:56.425932 [debug] [MainThread]: Parsing macros/materializations/merge.sql
12:15:56.427691 [debug] [MainThread]: Parsing macros/materializations/seed.sql
12:15:56.430165 [debug] [MainThread]: Parsing macros/materializations/view.sql
12:15:56.430759 [debug] [MainThread]: Parsing macros/materializations/table.sql
12:15:56.432158 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
12:15:56.436115 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
12:15:56.436526 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
12:15:56.438224 [debug] [MainThread]: Parsing macros/materializations/configs.sql
12:15:56.439228 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
12:15:56.439970 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
12:15:56.447633 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
12:15:56.453102 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
12:15:56.458860 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
12:15:56.460917 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
12:15:56.461697 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
12:15:56.462485 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
12:15:56.464457 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
12:15:56.469810 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
12:15:56.470480 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
12:15:56.475302 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
12:15:56.482913 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
12:15:56.486540 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
12:15:56.487792 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
12:15:56.491245 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
12:15:56.491804 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
12:15:56.493009 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
12:15:56.493999 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
12:15:56.496763 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
12:15:56.504596 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
12:15:56.505245 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
12:15:56.506326 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
12:15:56.507002 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
12:15:56.507395 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
12:15:56.507627 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
12:15:56.507924 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
12:15:56.508516 [debug] [MainThread]: Parsing macros/etc/statement.sql
12:15:56.510501 [debug] [MainThread]: Parsing macros/etc/datetime.sql
12:15:56.514374 [debug] [MainThread]: Parsing macros/adapters/schema.sql
12:15:56.515297 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
12:15:56.516465 [debug] [MainThread]: Parsing macros/adapters/relation.sql
12:15:56.520896 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
12:15:56.522157 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
12:15:56.524130 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
12:15:56.527495 [debug] [MainThread]: Parsing macros/adapters/columns.sql
12:15:56.532106 [debug] [MainThread]: Parsing tests/generic/builtin.sql
12:15:56.621284 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
12:15:56.627708 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
12:15:56.628234 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_cumulative_sales.sql
12:15:56.629311 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
12:15:56.630308 [debug] [MainThread]: 1603: static parser failed on example/dates.sql
12:15:56.633725 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/dates.sql
12:15:56.634223 [debug] [MainThread]: 1603: static parser failed on example/incremental_time.sql
12:15:56.635850 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_time.sql
12:15:56.636283 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
12:15:56.664397 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '16c5c4bd-0652-4541-83d5-5f31db294bfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104dd0fa0>]}
12:15:56.667595 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '16c5c4bd-0652-4541-83d5-5f31db294bfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104dd00a0>]}
12:15:56.667735 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
12:15:56.668485 [info ] [MainThread]: 
12:15:56.668701 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:15:56.669139 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
12:15:56.674935 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
12:15:56.675032 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
12:15:56.675103 [debug] [ThreadPool]: Opening a new connection, currently in state init
12:15:57.502913 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.83 seconds
12:15:57.505111 [debug] [ThreadPool]: On list_analytics: Close
12:15:57.686009 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
12:15:57.694779 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
12:15:57.695120 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
12:15:57.695291 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:15:58.396457 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 0.7 seconds
12:15:58.400535 [debug] [ThreadPool]: On list_analytics_dbt: Close
12:15:58.586091 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
12:15:58.586618 [info ] [MainThread]: 
12:15:58.590594 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
12:15:58.591528 [info ] [Thread-1  ]: 1 of 6 START incremental model dbt.dates........................................ [RUN]
12:15:58.592094 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
12:15:58.592268 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
12:15:58.592448 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
12:15:58.597414 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
12:15:58.598569 [debug] [Thread-1  ]: finished collecting timing info
12:15:58.598796 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
12:15:58.630008 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:15:58.630258 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
12:15:58.630348 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:16:00.306216 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.68 seconds
12:16:00.324565 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:16:00.324979 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
12:16:00.447284 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.12 seconds
12:16:00.454662 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:16:00.455036 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
12:16:00.558499 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.1 seconds
12:16:00.573254 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:16:00.573549 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
12:16:00.684375 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.11 seconds
12:16:00.710819 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
12:16:00.713192 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:16:00.713319 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
12:16:00.879716 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.17 seconds
12:16:00.881007 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:16:00.881221 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
12:16:01.303081 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.42 seconds
12:16:01.303636 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:16:01.303849 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
12:16:01.471085 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.17 seconds
12:16:01.485319 [debug] [Thread-1  ]: finished collecting timing info
12:16:01.485629 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
12:16:01.667130 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '16c5c4bd-0652-4541-83d5-5f31db294bfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053bf070>]}
12:16:01.667759 [info ] [Thread-1  ]: 1 of 6 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 3.08s]
12:16:01.668126 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
12:16:01.668329 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
12:16:01.668681 [info ] [Thread-1  ]: 2 of 6 START incremental model dbt.incremental_time............................. [RUN]
12:16:01.669204 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
12:16:01.669375 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
12:16:01.669535 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
12:16:01.673158 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
12:16:01.675219 [debug] [Thread-1  ]: finished collecting timing info
12:16:01.675462 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
12:16:01.679317 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:16:01.679524 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
12:16:01.679655 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:16:03.351311 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.67 seconds
12:16:03.354264 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:16:03.354456 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
12:16:03.477259 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.12 seconds
12:16:03.482964 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:16:03.483335 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
12:16:03.612647 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.13 seconds
12:16:03.617107 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:16:03.617329 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
12:16:03.760417 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.14 seconds
12:16:03.766029 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
12:16:03.768454 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:16:03.768665 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
12:16:03.912453 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.14 seconds
12:16:03.913332 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:16:03.913578 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
12:16:05.111777 [debug] [Thread-1  ]: SQL status: SUCCESS 266 in 1.2 seconds
12:16:05.112820 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:16:05.113015 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
12:16:05.500082 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.39 seconds
12:16:05.503916 [debug] [Thread-1  ]: finished collecting timing info
12:16:05.504374 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
12:16:05.700967 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '16c5c4bd-0652-4541-83d5-5f31db294bfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105193220>]}
12:16:05.701448 [info ] [Thread-1  ]: 2 of 6 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 4.03s]
12:16:05.701708 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
12:16:05.701843 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
12:16:05.702073 [info ] [Thread-1  ]: 3 of 6 START table model dbt.first_model........................................ [RUN]
12:16:05.702639 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
12:16:05.702848 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
12:16:05.703048 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
12:16:05.708941 [debug] [Thread-1  ]: finished collecting timing info
12:16:05.709235 [debug] [Thread-1  ]: Compilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  Required var 'my_first_variable' not found in config:
  Vars supplied to my_first_dbt_model = {}
  
  > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
12:16:05.709445 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '16c5c4bd-0652-4541-83d5-5f31db294bfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107376d30>]}
12:16:05.709685 [error] [Thread-1  ]: 3 of 6 ERROR creating table model dbt.first_model............................... [[31mERROR[0m in 0.01s]
12:16:05.709923 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
12:16:05.710061 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
12:16:05.710745 [info ] [Thread-1  ]: 4 of 6 START table model dbt.snowflake_cumulative_sales......................... [RUN]
12:16:05.711311 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
12:16:05.711484 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
12:16:05.711645 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
12:16:05.712943 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
12:16:05.713803 [debug] [Thread-1  ]: finished collecting timing info
12:16:05.714021 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
12:16:05.722010 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
12:16:05.722814 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
12:16:05.722942 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
12:16:05.723051 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:16:07.244378 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.52 seconds
12:16:07.247306 [debug] [Thread-1  ]: finished collecting timing info
12:16:07.247715 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
12:16:07.420396 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '16c5c4bd-0652-4541-83d5-5f31db294bfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1073769a0>]}
12:16:07.421166 [info ] [Thread-1  ]: 4 of 6 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 1.71s]
12:16:07.421725 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
12:16:07.421982 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
12:16:07.422449 [info ] [Thread-1  ]: 5 of 6 START table model dbt.snowflake_customer_purchases....................... [RUN]
12:16:07.423243 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
12:16:07.423595 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
12:16:07.423832 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
12:16:07.425690 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
12:16:07.426355 [debug] [Thread-1  ]: finished collecting timing info
12:16:07.426549 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
12:16:07.429159 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
12:16:07.430236 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
12:16:07.430396 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
12:16:07.430536 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:16:09.187272 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.76 seconds
12:16:09.196664 [debug] [Thread-1  ]: finished collecting timing info
12:16:09.197418 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
12:16:09.365535 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '16c5c4bd-0652-4541-83d5-5f31db294bfe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10537eeb0>]}
12:16:09.366309 [info ] [Thread-1  ]: 5 of 6 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 1.94s]
12:16:09.366960 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
12:16:09.367348 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
12:16:09.367699 [info ] [Thread-1  ]: 6 of 6 SKIP relation dbt.my_second_dbt_model.................................... [[33mSKIP[0m]
12:16:09.368081 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
12:16:09.369345 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:16:09.369923 [info ] [MainThread]: 
12:16:09.370305 [info ] [MainThread]: Finished running 2 incremental models, 4 table models in 12.70s.
12:16:09.370606 [debug] [MainThread]: Connection 'master' was properly closed.
12:16:09.370780 [debug] [MainThread]: Connection 'model.learn_dbt.snowflake_customer_purchases' was properly closed.
12:16:09.377887 [info ] [MainThread]: 
12:16:09.378343 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
12:16:09.378753 [info ] [MainThread]: 
12:16:09.378981 [error] [MainThread]: [33mCompilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)[0m
12:16:09.379179 [error] [MainThread]:   Required var 'my_first_variable' not found in config:
12:16:09.379361 [error] [MainThread]:   Vars supplied to my_first_dbt_model = {}
12:16:09.379536 [error] [MainThread]:   
12:16:09.379709 [error] [MainThread]:   > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
12:16:09.379881 [error] [MainThread]:   > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
12:16:09.380071 [info ] [MainThread]: 
12:16:09.380253 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=1 TOTAL=6
12:16:09.380514 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10736e1f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1051955b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105193250>]}


============================== 2022-05-13 12:21:30.587276 | 9813d93a-c4ba-4b05-907f-e2a6574694bd ==============================
12:21:30.587276 [info ] [MainThread]: Running with dbt=1.0.1
12:21:30.587646 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
12:21:30.587771 [debug] [MainThread]: Tracking: tracking
12:21:30.588013 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1071907f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107190ca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107190d00>]}
12:21:30.622866 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
12:21:30.623092 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '9813d93a-c4ba-4b05-907f-e2a6574694bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10671c7f0>]}
12:21:30.634629 [debug] [MainThread]: Parsing macros/catalog.sql
12:21:30.635900 [debug] [MainThread]: Parsing macros/adapters.sql
12:21:30.656497 [debug] [MainThread]: Parsing macros/materializations/merge.sql
12:21:30.658424 [debug] [MainThread]: Parsing macros/materializations/seed.sql
12:21:30.661049 [debug] [MainThread]: Parsing macros/materializations/view.sql
12:21:30.661672 [debug] [MainThread]: Parsing macros/materializations/table.sql
12:21:30.663131 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
12:21:30.667221 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
12:21:30.667652 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
12:21:30.669414 [debug] [MainThread]: Parsing macros/materializations/configs.sql
12:21:30.670456 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
12:21:30.671221 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
12:21:30.679938 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
12:21:30.686013 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
12:21:30.692561 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
12:21:30.694985 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
12:21:30.695924 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
12:21:30.696750 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
12:21:30.698888 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
12:21:30.704546 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
12:21:30.705259 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
12:21:30.710600 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
12:21:30.718616 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
12:21:30.722439 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
12:21:30.723767 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
12:21:30.727371 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
12:21:30.727976 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
12:21:30.729234 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
12:21:30.730299 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
12:21:30.733211 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
12:21:30.741632 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
12:21:30.742387 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
12:21:30.743543 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
12:21:30.744258 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
12:21:30.744667 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
12:21:30.744905 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
12:21:30.745215 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
12:21:30.745834 [debug] [MainThread]: Parsing macros/etc/statement.sql
12:21:30.747905 [debug] [MainThread]: Parsing macros/etc/datetime.sql
12:21:30.752026 [debug] [MainThread]: Parsing macros/adapters/schema.sql
12:21:30.753036 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
12:21:30.754243 [debug] [MainThread]: Parsing macros/adapters/relation.sql
12:21:30.759107 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
12:21:30.760702 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
12:21:30.762783 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
12:21:30.766144 [debug] [MainThread]: Parsing macros/adapters/columns.sql
12:21:30.770956 [debug] [MainThread]: Parsing tests/generic/builtin.sql
12:21:30.862043 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
12:21:30.868407 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
12:21:30.868947 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_cumulative_sales.sql
12:21:30.870042 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
12:21:30.871022 [debug] [MainThread]: 1603: static parser failed on example/dates.sql
12:21:30.874366 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/dates.sql
12:21:30.874827 [debug] [MainThread]: 1603: static parser failed on example/incremental_time.sql
12:21:30.876453 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_time.sql
12:21:30.876899 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
12:21:30.902607 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.learn_dbt.example.vars

12:21:30.904998 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9813d93a-c4ba-4b05-907f-e2a6574694bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10722efa0>]}
12:21:30.907810 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9813d93a-c4ba-4b05-907f-e2a6574694bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10722efd0>]}
12:21:30.907951 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
12:21:30.908634 [info ] [MainThread]: 
12:21:30.908842 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:21:30.909318 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
12:21:30.915392 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
12:21:30.915517 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
12:21:30.915584 [debug] [ThreadPool]: Opening a new connection, currently in state init
12:21:31.728635 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.81 seconds
12:21:31.731128 [debug] [ThreadPool]: On list_analytics: Close
12:21:31.977975 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
12:21:31.983150 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
12:21:31.983303 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
12:21:31.983401 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:21:32.797659 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 0.81 seconds
12:21:32.801697 [debug] [ThreadPool]: On list_analytics_dbt: Close
12:21:33.139919 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
12:21:33.140601 [info ] [MainThread]: 
12:21:33.146295 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
12:21:33.147131 [info ] [Thread-1  ]: 1 of 6 START incremental model dbt.dates........................................ [RUN]
12:21:33.147629 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
12:21:33.147779 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
12:21:33.147917 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
12:21:33.153355 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
12:21:33.154286 [debug] [Thread-1  ]: finished collecting timing info
12:21:33.154551 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
12:21:33.184258 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:21:33.184447 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
12:21:33.184533 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:21:35.117822 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.93 seconds
12:21:35.124748 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:21:35.124881 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
12:21:35.277471 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.15 seconds
12:21:35.282293 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:21:35.282561 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
12:21:35.386619 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.1 seconds
12:21:35.400302 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:21:35.400639 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
12:21:35.516702 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.12 seconds
12:21:35.538665 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
12:21:35.540472 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:21:35.540613 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
12:21:35.663189 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.12 seconds
12:21:35.664195 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:21:35.664430 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
12:21:36.249476 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.58 seconds
12:21:36.249994 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:21:36.250175 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
12:21:36.444204 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.19 seconds
12:21:36.458139 [debug] [Thread-1  ]: finished collecting timing info
12:21:36.458475 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
12:21:36.658982 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9813d93a-c4ba-4b05-907f-e2a6574694bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10718a2e0>]}
12:21:36.659650 [info ] [Thread-1  ]: 1 of 6 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 3.51s]
12:21:36.660026 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
12:21:36.660183 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
12:21:36.660439 [info ] [Thread-1  ]: 2 of 6 START incremental model dbt.incremental_time............................. [RUN]
12:21:36.660847 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
12:21:36.660984 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
12:21:36.661115 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
12:21:36.663934 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
12:21:36.664573 [debug] [Thread-1  ]: finished collecting timing info
12:21:36.664705 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
12:21:36.667934 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:21:36.668106 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
12:21:36.668240 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:21:38.315056 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.65 seconds
12:21:38.319155 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:21:38.319364 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
12:21:38.434983 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.12 seconds
12:21:38.440613 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:21:38.440958 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
12:21:38.567731 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.13 seconds
12:21:38.575128 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:21:38.575448 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
12:21:38.767174 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.19 seconds
12:21:38.771272 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
12:21:38.773282 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:21:38.773506 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
12:21:38.900983 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.13 seconds
12:21:38.901978 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:21:38.902302 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
12:21:39.579874 [debug] [Thread-1  ]: SQL status: SUCCESS 335 in 0.68 seconds
12:21:39.580912 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:21:39.581137 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
12:21:39.862268 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.28 seconds
12:21:39.864607 [debug] [Thread-1  ]: finished collecting timing info
12:21:39.864749 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
12:21:40.059874 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9813d93a-c4ba-4b05-907f-e2a6574694bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076cc910>]}
12:21:40.060155 [info ] [Thread-1  ]: 2 of 6 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 3.40s]
12:21:40.060314 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
12:21:40.060405 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
12:21:40.060506 [info ] [Thread-1  ]: 3 of 6 START table model dbt.first_model........................................ [RUN]
12:21:40.060704 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
12:21:40.060777 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
12:21:40.060849 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
12:21:40.064063 [debug] [Thread-1  ]: finished collecting timing info
12:21:40.064288 [debug] [Thread-1  ]: Compilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  Required var 'my_first_variable' not found in config:
  Vars supplied to my_first_dbt_model = {}
  
  > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
12:21:40.064432 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9813d93a-c4ba-4b05-907f-e2a6574694bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a97ca0>]}
12:21:40.064589 [error] [Thread-1  ]: 3 of 6 ERROR creating table model dbt.first_model............................... [[31mERROR[0m in 0.00s]
12:21:40.064735 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
12:21:40.064820 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
12:21:40.065181 [info ] [Thread-1  ]: 4 of 6 START table model dbt.snowflake_cumulative_sales......................... [RUN]
12:21:40.065465 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
12:21:40.065545 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
12:21:40.065618 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
12:21:40.066276 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
12:21:40.066633 [debug] [Thread-1  ]: finished collecting timing info
12:21:40.066719 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
12:21:40.071310 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
12:21:40.071844 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
12:21:40.071925 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
12:21:40.071990 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:21:41.410697 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.34 seconds
12:21:41.414491 [debug] [Thread-1  ]: finished collecting timing info
12:21:41.414944 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
12:21:41.586205 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9813d93a-c4ba-4b05-907f-e2a6574694bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a97760>]}
12:21:41.586852 [info ] [Thread-1  ]: 4 of 6 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 1.52s]
12:21:41.587287 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
12:21:41.587530 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
12:21:41.587941 [info ] [Thread-1  ]: 5 of 6 START table model dbt.snowflake_customer_purchases....................... [RUN]
12:21:41.588604 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
12:21:41.588827 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
12:21:41.589040 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
12:21:41.591036 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
12:21:41.591647 [debug] [Thread-1  ]: finished collecting timing info
12:21:41.591814 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
12:21:41.594543 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
12:21:41.595948 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
12:21:41.596137 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
12:21:41.596294 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:21:43.215104 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.62 seconds
12:21:43.217347 [debug] [Thread-1  ]: finished collecting timing info
12:21:43.217528 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
12:21:43.750691 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9813d93a-c4ba-4b05-907f-e2a6574694bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074c0bb0>]}
12:21:43.751368 [info ] [Thread-1  ]: 5 of 6 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.16s]
12:21:43.751658 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
12:21:43.751784 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
12:21:43.751972 [info ] [Thread-1  ]: 6 of 6 SKIP relation dbt.my_second_dbt_model.................................... [[33mSKIP[0m]
12:21:43.752186 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
12:21:43.752851 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:21:43.753160 [info ] [MainThread]: 
12:21:43.753372 [info ] [MainThread]: Finished running 2 incremental models, 4 table models in 12.84s.
12:21:43.753523 [debug] [MainThread]: Connection 'master' was properly closed.
12:21:43.753636 [debug] [MainThread]: Connection 'model.learn_dbt.snowflake_customer_purchases' was properly closed.
12:21:43.757491 [info ] [MainThread]: 
12:21:43.757704 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
12:21:43.757887 [info ] [MainThread]: 
12:21:43.758019 [error] [MainThread]: [33mCompilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)[0m
12:21:43.758139 [error] [MainThread]:   Required var 'my_first_variable' not found in config:
12:21:43.758266 [error] [MainThread]:   Vars supplied to my_first_dbt_model = {}
12:21:43.758392 [error] [MainThread]:   
12:21:43.758516 [error] [MainThread]:   > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
12:21:43.758637 [error] [MainThread]:   > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
12:21:43.758876 [info ] [MainThread]: 
12:21:43.758995 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=1 TOTAL=6
12:21:43.759165 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107190e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076cc9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107375a30>]}


============================== 2022-05-13 12:22:46.414809 | a408b718-cf05-4808-8db3-16295bc429e0 ==============================
12:22:46.414809 [info ] [MainThread]: Running with dbt=1.0.1
12:22:46.415184 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
12:22:46.415313 [debug] [MainThread]: Tracking: tracking
12:22:46.415532 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104f92fa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104f928e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104f92910>]}
12:22:46.448389 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
12:22:46.448664 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'a408b718-cf05-4808-8db3-16295bc429e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104f98280>]}
12:22:46.459897 [debug] [MainThread]: Parsing macros/catalog.sql
12:22:46.461098 [debug] [MainThread]: Parsing macros/adapters.sql
12:22:46.480554 [debug] [MainThread]: Parsing macros/materializations/merge.sql
12:22:46.482337 [debug] [MainThread]: Parsing macros/materializations/seed.sql
12:22:46.484814 [debug] [MainThread]: Parsing macros/materializations/view.sql
12:22:46.485406 [debug] [MainThread]: Parsing macros/materializations/table.sql
12:22:46.486824 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
12:22:46.490786 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
12:22:46.491198 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
12:22:46.492918 [debug] [MainThread]: Parsing macros/materializations/configs.sql
12:22:46.493920 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
12:22:46.494665 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
12:22:46.502350 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
12:22:46.507851 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
12:22:46.513624 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
12:22:46.515690 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
12:22:46.516477 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
12:22:46.517274 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
12:22:46.519262 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
12:22:46.524633 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
12:22:46.525308 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
12:22:46.530138 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
12:22:46.537788 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
12:22:46.541391 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
12:22:46.542643 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
12:22:46.546099 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
12:22:46.546662 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
12:22:46.547877 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
12:22:46.548877 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
12:22:46.551665 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
12:22:46.559516 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
12:22:46.560157 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
12:22:46.561241 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
12:22:46.561921 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
12:22:46.562312 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
12:22:46.562541 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
12:22:46.562836 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
12:22:46.563438 [debug] [MainThread]: Parsing macros/etc/statement.sql
12:22:46.565424 [debug] [MainThread]: Parsing macros/etc/datetime.sql
12:22:46.569313 [debug] [MainThread]: Parsing macros/adapters/schema.sql
12:22:46.570238 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
12:22:46.571418 [debug] [MainThread]: Parsing macros/adapters/relation.sql
12:22:46.575888 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
12:22:46.577154 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
12:22:46.579094 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
12:22:46.582339 [debug] [MainThread]: Parsing macros/adapters/columns.sql
12:22:46.586831 [debug] [MainThread]: Parsing tests/generic/builtin.sql
12:22:46.677362 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
12:22:46.683570 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
12:22:46.684081 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_cumulative_sales.sql
12:22:46.685164 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
12:22:46.686155 [debug] [MainThread]: 1603: static parser failed on example/dates.sql
12:22:46.689495 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/dates.sql
12:22:46.689963 [debug] [MainThread]: 1603: static parser failed on example/incremental_time.sql
12:22:46.691616 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_time.sql
12:22:46.692060 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
12:22:46.717951 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.learn_dbt.example.vars

12:22:46.720321 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a408b718-cf05-4808-8db3-16295bc429e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1050838b0>]}
12:22:46.723170 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a408b718-cf05-4808-8db3-16295bc429e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105083160>]}
12:22:46.723299 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
12:22:46.723980 [info ] [MainThread]: 
12:22:46.724183 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:22:46.724631 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
12:22:46.730320 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
12:22:46.730444 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
12:22:46.730509 [debug] [ThreadPool]: Opening a new connection, currently in state init
12:22:48.111776 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.38 seconds
12:22:48.114152 [debug] [ThreadPool]: On list_analytics: Close
12:22:48.296457 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
12:22:48.305139 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
12:22:48.305409 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
12:22:48.305574 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:22:49.159950 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 0.85 seconds
12:22:49.163396 [debug] [ThreadPool]: On list_analytics_dbt: Close
12:22:49.347236 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
12:22:49.348899 [info ] [MainThread]: 
12:22:49.353971 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
12:22:49.354776 [info ] [Thread-1  ]: 1 of 6 START incremental model dbt.dates........................................ [RUN]
12:22:49.355281 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
12:22:49.355421 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
12:22:49.355558 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
12:22:49.360102 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
12:22:49.360718 [debug] [Thread-1  ]: finished collecting timing info
12:22:49.360898 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
12:22:49.389946 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:22:49.390151 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
12:22:49.390251 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:22:51.300869 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.91 seconds
12:22:51.313468 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:22:51.313827 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
12:22:51.460214 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.15 seconds
12:22:51.468824 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:22:51.469344 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
12:22:51.664109 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.19 seconds
12:22:51.676759 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:22:51.677078 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
12:22:51.804350 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.13 seconds
12:22:51.831307 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
12:22:51.833714 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:22:51.833848 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
12:22:51.965681 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.13 seconds
12:22:51.968254 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:22:51.968600 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
12:22:52.714187 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.75 seconds
12:22:52.714766 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:22:52.715101 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
12:22:52.922945 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.21 seconds
12:22:52.930922 [debug] [Thread-1  ]: finished collecting timing info
12:22:52.931303 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
12:22:53.212487 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a408b718-cf05-4808-8db3-16295bc429e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1050b33d0>]}
12:22:53.213246 [info ] [Thread-1  ]: 1 of 6 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 3.86s]
12:22:53.213714 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
12:22:53.213970 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
12:22:53.214406 [info ] [Thread-1  ]: 2 of 6 START incremental model dbt.incremental_time............................. [RUN]
12:22:53.215101 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
12:22:53.215339 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
12:22:53.215546 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
12:22:53.219537 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
12:22:53.220367 [debug] [Thread-1  ]: finished collecting timing info
12:22:53.220555 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
12:22:53.224351 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:22:53.224516 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
12:22:53.224643 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:22:54.809383 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.58 seconds
12:22:54.812979 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:22:54.813310 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
12:22:54.948397 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.13 seconds
12:22:54.954492 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:22:54.954923 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
12:22:55.066539 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.11 seconds
12:22:55.072123 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:22:55.072480 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
12:22:55.200821 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.13 seconds
12:22:55.205750 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
12:22:55.208201 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:22:55.208437 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
12:22:55.342044 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.13 seconds
12:22:55.342795 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:22:55.343758 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
12:22:56.124844 [debug] [Thread-1  ]: SQL status: SUCCESS 76 in 0.78 seconds
12:22:56.125702 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:22:56.125920 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
12:22:56.493899 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.37 seconds
12:22:56.498591 [debug] [Thread-1  ]: finished collecting timing info
12:22:56.498987 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
12:22:56.699911 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a408b718-cf05-4808-8db3-16295bc429e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10568e580>]}
12:22:56.700636 [info ] [Thread-1  ]: 2 of 6 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 3.48s]
12:22:56.701078 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
12:22:56.701329 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
12:22:56.701728 [info ] [Thread-1  ]: 3 of 6 START table model dbt.first_model........................................ [RUN]
12:22:56.702369 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
12:22:56.702583 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
12:22:56.702781 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
12:22:56.707833 [debug] [Thread-1  ]: finished collecting timing info
12:22:56.708220 [debug] [Thread-1  ]: Compilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  Required var 'my_first_variable' not found in config:
  Vars supplied to my_first_dbt_model = {}
  
  > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
12:22:56.708507 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a408b718-cf05-4808-8db3-16295bc429e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108d0b250>]}
12:22:56.708839 [error] [Thread-1  ]: 3 of 6 ERROR creating table model dbt.first_model............................... [[31mERROR[0m in 0.01s]
12:22:56.709343 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
12:22:56.709671 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
12:22:56.710174 [info ] [Thread-1  ]: 4 of 6 START table model dbt.snowflake_cumulative_sales......................... [RUN]
12:22:56.710739 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
12:22:56.710978 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
12:22:56.711140 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
12:22:56.712339 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
12:22:56.712829 [debug] [Thread-1  ]: finished collecting timing info
12:22:56.712972 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
12:22:56.721086 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
12:22:56.722053 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
12:22:56.722183 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
12:22:56.722299 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:22:58.511427 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.79 seconds
12:22:58.515249 [debug] [Thread-1  ]: finished collecting timing info
12:22:58.515627 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
12:22:58.683969 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a408b718-cf05-4808-8db3-16295bc429e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108d0bdf0>]}
12:22:58.684718 [info ] [Thread-1  ]: 4 of 6 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 1.97s]
12:22:58.685168 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
12:22:58.685413 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
12:22:58.685817 [info ] [Thread-1  ]: 5 of 6 START table model dbt.snowflake_customer_purchases....................... [RUN]
12:22:58.686442 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
12:22:58.686651 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
12:22:58.686843 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
12:22:58.688397 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
12:22:58.689028 [debug] [Thread-1  ]: finished collecting timing info
12:22:58.689174 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
12:22:58.691044 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
12:22:58.691770 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
12:22:58.691856 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
12:22:58.691932 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:23:00.720570 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.03 seconds
12:23:00.723462 [debug] [Thread-1  ]: finished collecting timing info
12:23:00.723787 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
12:23:00.915840 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a408b718-cf05-4808-8db3-16295bc429e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10563a370>]}
12:23:00.916869 [info ] [Thread-1  ]: 5 of 6 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.23s]
12:23:00.917439 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
12:23:00.917818 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
12:23:00.918057 [info ] [Thread-1  ]: 6 of 6 SKIP relation dbt.my_second_dbt_model.................................... [[33mSKIP[0m]
12:23:00.918439 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
12:23:00.919841 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:23:00.920344 [info ] [MainThread]: 
12:23:00.920665 [info ] [MainThread]: Finished running 2 incremental models, 4 table models in 14.20s.
12:23:00.920960 [debug] [MainThread]: Connection 'master' was properly closed.
12:23:00.921124 [debug] [MainThread]: Connection 'model.learn_dbt.snowflake_customer_purchases' was properly closed.
12:23:00.927368 [info ] [MainThread]: 
12:23:00.927602 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
12:23:00.927801 [info ] [MainThread]: 
12:23:00.927969 [error] [MainThread]: [33mCompilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)[0m
12:23:00.928135 [error] [MainThread]:   Required var 'my_first_variable' not found in config:
12:23:00.928292 [error] [MainThread]:   Vars supplied to my_first_dbt_model = {}
12:23:00.928469 [error] [MainThread]:   
12:23:00.928623 [error] [MainThread]:   > in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
12:23:00.928773 [error] [MainThread]:   > called by model my_first_dbt_model (models/example/my_first_dbt_model.sql)
12:23:00.928943 [info ] [MainThread]: 
12:23:00.929112 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=1 TOTAL=6
12:23:00.929388 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105681b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105681fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1057da670>]}


============================== 2022-05-13 12:24:06.416543 | cdc41580-7387-4ba3-b84c-fd72aa560133 ==============================
12:24:06.416543 [info ] [MainThread]: Running with dbt=1.0.1
12:24:06.416910 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
12:24:06.417043 [debug] [MainThread]: Tracking: tracking
12:24:06.417269 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074422b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107442b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107442910>]}
12:24:06.457225 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
12:24:06.457480 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/my_first_dbt_model.sql
12:24:06.462708 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
12:24:06.469230 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
12:24:06.481189 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.learn_dbt.example.vars

12:24:06.483733 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cdc41580-7387-4ba3-b84c-fd72aa560133', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10406fb20>]}
12:24:06.486850 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cdc41580-7387-4ba3-b84c-fd72aa560133', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10741bdf0>]}
12:24:06.487005 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
12:24:06.487773 [info ] [MainThread]: 
12:24:06.487991 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:24:06.488409 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
12:24:06.494434 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
12:24:06.494568 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
12:24:06.494663 [debug] [ThreadPool]: Opening a new connection, currently in state init
12:24:08.376961 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.88 seconds
12:24:08.379791 [debug] [ThreadPool]: On list_analytics: Close
12:24:08.613089 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
12:24:08.621569 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
12:24:08.621851 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
12:24:08.622015 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:24:09.255312 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 0.63 seconds
12:24:09.258588 [debug] [ThreadPool]: On list_analytics_dbt: Close
12:24:09.428080 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
12:24:09.428776 [info ] [MainThread]: 
12:24:09.432479 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
12:24:09.433247 [info ] [Thread-1  ]: 1 of 6 START incremental model dbt.dates........................................ [RUN]
12:24:09.433806 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
12:24:09.433986 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
12:24:09.434154 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
12:24:09.444182 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
12:24:09.444808 [debug] [Thread-1  ]: finished collecting timing info
12:24:09.444967 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
12:24:09.474301 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:24:09.474494 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
12:24:09.474584 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:24:11.492436 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.02 seconds
12:24:11.506060 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:24:11.506500 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
12:24:11.649465 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.14 seconds
12:24:11.656067 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:24:11.656280 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
12:24:11.870201 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.21 seconds
12:24:11.886057 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:24:11.886431 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
12:24:11.993415 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.11 seconds
12:24:12.020575 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
12:24:12.023047 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:24:12.023208 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
12:24:12.143523 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.12 seconds
12:24:12.145041 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:24:12.145385 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
12:24:12.685384 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.54 seconds
12:24:12.686165 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:24:12.686361 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
12:24:12.949994 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.26 seconds
12:24:12.962401 [debug] [Thread-1  ]: finished collecting timing info
12:24:12.962619 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
12:24:13.165037 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cdc41580-7387-4ba3-b84c-fd72aa560133', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10741b100>]}
12:24:13.166179 [info ] [Thread-1  ]: 1 of 6 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 3.73s]
12:24:13.166675 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
12:24:13.166954 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
12:24:13.167260 [info ] [Thread-1  ]: 2 of 6 START incremental model dbt.incremental_time............................. [RUN]
12:24:13.167974 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
12:24:13.168532 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
12:24:13.168808 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
12:24:13.171971 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
12:24:13.172736 [debug] [Thread-1  ]: finished collecting timing info
12:24:13.172899 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
12:24:13.176097 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:24:13.176333 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
12:24:13.176462 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:24:14.573221 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.4 seconds
12:24:14.582168 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:24:14.582549 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
12:24:14.691726 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.11 seconds
12:24:14.697258 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:24:14.697684 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
12:24:14.892650 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.19 seconds
12:24:14.898723 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:24:14.899087 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
12:24:15.021402 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.12 seconds
12:24:15.026163 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
12:24:15.028455 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:24:15.028687 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
12:24:15.149816 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.12 seconds
12:24:15.150442 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:24:15.150635 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
12:24:16.137086 [debug] [Thread-1  ]: SQL status: SUCCESS 80 in 0.99 seconds
12:24:16.139116 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:24:16.139435 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
12:24:16.396530 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.26 seconds
12:24:16.400039 [debug] [Thread-1  ]: finished collecting timing info
12:24:16.400409 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
12:24:16.768990 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cdc41580-7387-4ba3-b84c-fd72aa560133', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1104fcee0>]}
12:24:16.769776 [info ] [Thread-1  ]: 2 of 6 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 3.60s]
12:24:16.770222 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
12:24:16.770469 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
12:24:16.770871 [info ] [Thread-1  ]: 3 of 6 START table model dbt.first_model........................................ [RUN]
12:24:16.771510 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
12:24:16.771728 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
12:24:16.771937 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
12:24:16.778319 [debug] [Thread-1  ]: finished collecting timing info
12:24:16.778711 [debug] [Thread-1  ]: Compilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  'vars' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
12:24:16.778992 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cdc41580-7387-4ba3-b84c-fd72aa560133', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1104b1e80>]}
12:24:16.779319 [error] [Thread-1  ]: 3 of 6 ERROR creating table model dbt.first_model............................... [[31mERROR[0m in 0.01s]
12:24:16.779633 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
12:24:16.779807 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
12:24:16.780267 [info ] [Thread-1  ]: 4 of 6 START table model dbt.snowflake_cumulative_sales......................... [RUN]
12:24:16.780702 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
12:24:16.780856 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
12:24:16.780990 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
12:24:16.782326 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
12:24:16.782919 [debug] [Thread-1  ]: finished collecting timing info
12:24:16.783079 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
12:24:16.791050 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
12:24:16.791996 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
12:24:16.792126 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
12:24:16.792241 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:24:18.458073 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.67 seconds
12:24:18.460543 [debug] [Thread-1  ]: finished collecting timing info
12:24:18.460852 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
12:24:18.867965 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cdc41580-7387-4ba3-b84c-fd72aa560133', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1104fcdc0>]}
12:24:18.868982 [info ] [Thread-1  ]: 4 of 6 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 2.09s]
12:24:18.869599 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
12:24:18.869870 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
12:24:18.870294 [info ] [Thread-1  ]: 5 of 6 START table model dbt.snowflake_customer_purchases....................... [RUN]
12:24:18.870969 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
12:24:18.871194 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
12:24:18.871402 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
12:24:18.873327 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
12:24:18.874266 [debug] [Thread-1  ]: finished collecting timing info
12:24:18.874488 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
12:24:18.877406 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
12:24:18.878803 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
12:24:18.878994 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
12:24:18.879149 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:24:20.601058 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.72 seconds
12:24:20.604583 [debug] [Thread-1  ]: finished collecting timing info
12:24:20.605021 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
12:24:20.891667 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cdc41580-7387-4ba3-b84c-fd72aa560133', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1103ebd00>]}
12:24:20.892329 [info ] [Thread-1  ]: 5 of 6 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.02s]
12:24:20.892818 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
12:24:20.893091 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
12:24:20.893489 [info ] [Thread-1  ]: 6 of 6 SKIP relation dbt.my_second_dbt_model.................................... [[33mSKIP[0m]
12:24:20.894058 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
12:24:20.895465 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:24:20.896084 [info ] [MainThread]: 
12:24:20.896478 [info ] [MainThread]: Finished running 2 incremental models, 4 table models in 14.41s.
12:24:20.896841 [debug] [MainThread]: Connection 'master' was properly closed.
12:24:20.897063 [debug] [MainThread]: Connection 'model.learn_dbt.snowflake_customer_purchases' was properly closed.
12:24:20.903250 [info ] [MainThread]: 
12:24:20.903545 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
12:24:20.903777 [info ] [MainThread]: 
12:24:20.903974 [error] [MainThread]: [33mCompilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)[0m
12:24:20.904170 [error] [MainThread]:   'vars' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
12:24:20.904368 [info ] [MainThread]: 
12:24:20.904558 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=1 TOTAL=6
12:24:20.904848 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10741b130>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110340100>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110343460>]}


============================== 2022-05-13 12:26:29.577501 | efd946a2-9ac2-45ad-8f24-2edf6aa4e979 ==============================
12:26:29.577501 [info ] [MainThread]: Running with dbt=1.0.1
12:26:29.579364 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
12:26:29.579543 [debug] [MainThread]: Tracking: tracking
12:26:29.580190 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108267730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108267640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1082679d0>]}
12:26:29.616423 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
12:26:29.616666 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'efd946a2-9ac2-45ad-8f24-2edf6aa4e979', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108287f10>]}
12:26:29.628376 [debug] [MainThread]: Parsing macros/catalog.sql
12:26:29.629606 [debug] [MainThread]: Parsing macros/adapters.sql
12:26:29.648908 [debug] [MainThread]: Parsing macros/materializations/merge.sql
12:26:29.650675 [debug] [MainThread]: Parsing macros/materializations/seed.sql
12:26:29.653167 [debug] [MainThread]: Parsing macros/materializations/view.sql
12:26:29.653751 [debug] [MainThread]: Parsing macros/materializations/table.sql
12:26:29.655146 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
12:26:29.659087 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
12:26:29.659501 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
12:26:29.661201 [debug] [MainThread]: Parsing macros/materializations/configs.sql
12:26:29.662203 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
12:26:29.662939 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
12:26:29.670595 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
12:26:29.676069 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
12:26:29.681827 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
12:26:29.683899 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
12:26:29.684693 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
12:26:29.685478 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
12:26:29.687438 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
12:26:29.692786 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
12:26:29.693453 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
12:26:29.698270 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
12:26:29.705876 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
12:26:29.709486 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
12:26:29.710728 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
12:26:29.714170 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
12:26:29.714728 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
12:26:29.715931 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
12:26:29.716913 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
12:26:29.719692 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
12:26:29.727918 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
12:26:29.728686 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
12:26:29.729819 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
12:26:29.730522 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
12:26:29.730929 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
12:26:29.731166 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
12:26:29.731479 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
12:26:29.732099 [debug] [MainThread]: Parsing macros/etc/statement.sql
12:26:29.734183 [debug] [MainThread]: Parsing macros/etc/datetime.sql
12:26:29.738488 [debug] [MainThread]: Parsing macros/adapters/schema.sql
12:26:29.739570 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
12:26:29.740812 [debug] [MainThread]: Parsing macros/adapters/relation.sql
12:26:29.745495 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
12:26:29.746768 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
12:26:29.748784 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
12:26:29.752168 [debug] [MainThread]: Parsing macros/adapters/columns.sql
12:26:29.757207 [debug] [MainThread]: Parsing tests/generic/builtin.sql
12:26:29.849198 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
12:26:29.856304 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
12:26:29.856908 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_cumulative_sales.sql
12:26:29.857977 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
12:26:29.858969 [debug] [MainThread]: 1603: static parser failed on example/dates.sql
12:26:29.862312 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/dates.sql
12:26:29.862772 [debug] [MainThread]: 1603: static parser failed on example/incremental_time.sql
12:26:29.864403 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/incremental_time.sql
12:26:29.864836 [debug] [MainThread]: 1699: static parser successfully parsed example/snowflake_customer_purchases.sql
12:26:29.892766 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'efd946a2-9ac2-45ad-8f24-2edf6aa4e979', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1083a0550>]}
12:26:29.897326 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'efd946a2-9ac2-45ad-8f24-2edf6aa4e979', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1083a0a30>]}
12:26:29.897498 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
12:26:29.898310 [info ] [MainThread]: 
12:26:29.898560 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:26:29.899079 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
12:26:29.905102 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
12:26:29.905214 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
12:26:29.905284 [debug] [ThreadPool]: Opening a new connection, currently in state init
12:26:30.931095 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.03 seconds
12:26:30.933537 [debug] [ThreadPool]: On list_analytics: Close
12:26:31.203994 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
12:26:31.212463 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
12:26:31.212746 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
12:26:31.212909 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:26:31.856574 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 0.64 seconds
12:26:31.859716 [debug] [ThreadPool]: On list_analytics_dbt: Close
12:26:32.051479 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
12:26:32.051900 [info ] [MainThread]: 
12:26:32.057201 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
12:26:32.057970 [info ] [Thread-1  ]: 1 of 6 START incremental model dbt.dates........................................ [RUN]
12:26:32.058466 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
12:26:32.058628 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
12:26:32.058785 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
12:26:32.065113 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
12:26:32.065836 [debug] [Thread-1  ]: finished collecting timing info
12:26:32.066059 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
12:26:32.095665 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:26:32.095882 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
12:26:32.096007 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:26:34.504588 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.41 seconds
12:26:34.518728 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:26:34.519112 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
12:26:34.643786 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.12 seconds
12:26:34.653840 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:26:34.654237 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
12:26:34.769005 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.11 seconds
12:26:34.781710 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:26:34.782014 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
12:26:35.001269 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.22 seconds
12:26:35.028936 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
12:26:35.031328 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:26:35.031463 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
12:26:35.181652 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.15 seconds
12:26:35.182669 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:26:35.182856 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
12:26:35.498951 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.32 seconds
12:26:35.499504 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:26:35.499689 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
12:26:35.667870 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.17 seconds
12:26:35.682310 [debug] [Thread-1  ]: finished collecting timing info
12:26:35.682660 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
12:26:35.857502 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'efd946a2-9ac2-45ad-8f24-2edf6aa4e979', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108345c40>]}
12:26:35.858122 [info ] [Thread-1  ]: 1 of 6 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 3.80s]
12:26:35.858594 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
12:26:35.858863 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
12:26:35.859324 [info ] [Thread-1  ]: 2 of 6 START incremental model dbt.incremental_time............................. [RUN]
12:26:35.859958 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
12:26:35.860180 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
12:26:35.860399 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
12:26:35.864425 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
12:26:35.865192 [debug] [Thread-1  ]: finished collecting timing info
12:26:35.865364 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
12:26:35.868952 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:26:35.869148 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
12:26:35.869282 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:26:37.400587 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.53 seconds
12:26:37.405814 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:26:37.406159 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
12:26:37.602913 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.19 seconds
12:26:37.607863 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:26:37.608224 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
12:26:37.740220 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.13 seconds
12:26:37.745540 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:26:37.745826 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
12:26:37.844286 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
12:26:37.853091 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
12:26:37.855259 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:26:37.855468 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
12:26:37.982747 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.13 seconds
12:26:37.983527 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:26:37.983728 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
12:26:38.713961 [debug] [Thread-1  ]: SQL status: SUCCESS 143 in 0.73 seconds
12:26:38.715146 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:26:38.715265 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
12:26:38.970525 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.26 seconds
12:26:38.973600 [debug] [Thread-1  ]: finished collecting timing info
12:26:38.974033 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
12:26:39.304288 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'efd946a2-9ac2-45ad-8f24-2edf6aa4e979', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108679520>]}
12:26:39.305563 [info ] [Thread-1  ]: 2 of 6 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 3.44s]
12:26:39.306146 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
12:26:39.306397 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
12:26:39.306685 [info ] [Thread-1  ]: 3 of 6 START table model dbt.first_model........................................ [RUN]
12:26:39.307403 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
12:26:39.307658 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
12:26:39.307866 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
12:26:39.314626 [debug] [Thread-1  ]: finished collecting timing info
12:26:39.315134 [debug] [Thread-1  ]: Compilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  'vars' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
12:26:39.315575 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'efd946a2-9ac2-45ad-8f24-2edf6aa4e979', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10830a6a0>]}
12:26:39.315950 [error] [Thread-1  ]: 3 of 6 ERROR creating table model dbt.first_model............................... [[31mERROR[0m in 0.01s]
12:26:39.316170 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
12:26:39.316284 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
12:26:39.316411 [info ] [Thread-1  ]: 4 of 6 START table model dbt.snowflake_cumulative_sales......................... [RUN]
12:26:39.316676 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
12:26:39.316912 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
12:26:39.317216 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
12:26:39.318522 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
12:26:39.319160 [debug] [Thread-1  ]: finished collecting timing info
12:26:39.319317 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
12:26:39.326423 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
12:26:39.327306 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
12:26:39.327448 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
12:26:39.327563 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:26:40.847225 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.52 seconds
12:26:40.851156 [debug] [Thread-1  ]: finished collecting timing info
12:26:40.851594 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
12:26:41.007812 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'efd946a2-9ac2-45ad-8f24-2edf6aa4e979', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a4d13a0>]}
12:26:41.008188 [info ] [Thread-1  ]: 4 of 6 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 1.69s]
12:26:41.008394 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
12:26:41.008510 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
12:26:41.008701 [info ] [Thread-1  ]: 5 of 6 START table model dbt.snowflake_customer_purchases....................... [RUN]
12:26:41.008992 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
12:26:41.009095 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
12:26:41.009191 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
12:26:41.010215 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
12:26:41.010744 [debug] [Thread-1  ]: finished collecting timing info
12:26:41.010961 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
12:26:41.013802 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
12:26:41.015142 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
12:26:41.015331 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
12:26:41.015485 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:26:42.768965 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.75 seconds
12:26:42.772814 [debug] [Thread-1  ]: finished collecting timing info
12:26:42.773200 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
12:26:42.926796 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'efd946a2-9ac2-45ad-8f24-2edf6aa4e979', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a4dcd60>]}
12:26:42.927693 [info ] [Thread-1  ]: 5 of 6 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 1.92s]
12:26:42.928140 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
12:26:42.928511 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
12:26:42.928811 [info ] [Thread-1  ]: 6 of 6 SKIP relation dbt.my_second_dbt_model.................................... [[33mSKIP[0m]
12:26:42.929082 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
12:26:42.930105 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:26:42.930625 [info ] [MainThread]: 
12:26:42.930928 [info ] [MainThread]: Finished running 2 incremental models, 4 table models in 13.03s.
12:26:42.931195 [debug] [MainThread]: Connection 'master' was properly closed.
12:26:42.931336 [debug] [MainThread]: Connection 'model.learn_dbt.snowflake_customer_purchases' was properly closed.
12:26:42.937390 [info ] [MainThread]: 
12:26:42.937707 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
12:26:42.937976 [info ] [MainThread]: 
12:26:42.938318 [error] [MainThread]: [33mCompilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)[0m
12:26:42.938584 [error] [MainThread]:   'vars' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
12:26:42.938823 [info ] [MainThread]: 
12:26:42.939046 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=1 TOTAL=6
12:26:42.939359 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108383e80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1083a0a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108729970>]}


============================== 2022-05-13 12:27:24.772339 | cfb3548c-7fc4-44b4-ac1f-4b22bd1c07e7 ==============================
12:27:24.772339 [info ] [MainThread]: Running with dbt=1.0.1
12:27:24.773069 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
12:27:24.773298 [debug] [MainThread]: Tracking: tracking
12:27:24.773546 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10430fe80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10430f4f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10430f9d0>]}
12:27:24.821928 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
12:27:24.822218 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/my_first_dbt_model.sql
12:27:24.827643 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
12:27:24.834534 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
12:27:24.848048 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cfb3548c-7fc4-44b4-ac1f-4b22bd1c07e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1032e3280>]}
12:27:24.851034 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cfb3548c-7fc4-44b4-ac1f-4b22bd1c07e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1042f8e50>]}
12:27:24.851165 [info ] [MainThread]: Found 6 models, 8 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
12:27:24.851900 [info ] [MainThread]: 
12:27:24.852104 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:27:24.852544 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
12:27:24.858344 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
12:27:24.858442 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
12:27:24.858503 [debug] [ThreadPool]: Opening a new connection, currently in state init
12:27:25.823156 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.96 seconds
12:27:25.825636 [debug] [ThreadPool]: On list_analytics: Close
12:27:26.009967 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
12:27:26.016716 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
12:27:26.016911 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
12:27:26.017029 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:27:26.774149 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 0.76 seconds
12:27:26.777794 [debug] [ThreadPool]: On list_analytics_dbt: Close
12:27:26.942887 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
12:27:26.957196 [info ] [MainThread]: 
12:27:26.962564 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
12:27:26.963250 [info ] [Thread-1  ]: 1 of 6 START incremental model dbt.dates........................................ [RUN]
12:27:26.963799 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
12:27:26.964015 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
12:27:26.964226 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
12:27:26.973501 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
12:27:26.974144 [debug] [Thread-1  ]: finished collecting timing info
12:27:26.974302 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
12:27:27.003361 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:27:27.003512 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
12:27:27.003575 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:27:29.368266 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.36 seconds
12:27:29.379235 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:27:29.379585 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
12:27:29.659133 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.28 seconds
12:27:29.666996 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:27:29.667316 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
12:27:29.765279 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.1 seconds
12:27:29.778243 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:27:29.778637 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
12:27:29.917451 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.14 seconds
12:27:29.940972 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
12:27:29.943345 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:27:29.943470 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
12:27:30.062777 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.12 seconds
12:27:30.063852 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:27:30.064354 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
12:27:30.575623 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.51 seconds
12:27:30.576414 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:27:30.576687 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
12:27:30.839535 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.26 seconds
12:27:30.854618 [debug] [Thread-1  ]: finished collecting timing info
12:27:30.854995 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
12:27:31.302170 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cfb3548c-7fc4-44b4-ac1f-4b22bd1c07e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1042fc460>]}
12:27:31.302962 [info ] [Thread-1  ]: 1 of 6 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 4.34s]
12:27:31.303407 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
12:27:31.303649 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
12:27:31.304058 [info ] [Thread-1  ]: 2 of 6 START incremental model dbt.incremental_time............................. [RUN]
12:27:31.304703 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
12:27:31.304914 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
12:27:31.305111 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
12:27:31.308885 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
12:27:31.309693 [debug] [Thread-1  ]: finished collecting timing info
12:27:31.309882 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
12:27:31.313560 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:27:31.313734 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
12:27:31.313855 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:27:33.197672 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.88 seconds
12:27:33.202821 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:27:33.203183 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
12:27:33.344688 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.14 seconds
12:27:33.348260 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:27:33.348459 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
12:27:33.457790 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.11 seconds
12:27:33.463920 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:27:33.464294 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
12:27:33.717681 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.25 seconds
12:27:33.723149 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
12:27:33.726468 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:27:33.726692 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
12:27:33.892393 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.17 seconds
12:27:33.893276 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:27:33.893558 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
12:27:34.517501 [debug] [Thread-1  ]: SQL status: SUCCESS 56 in 0.62 seconds
12:27:34.518390 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:27:34.518689 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
12:27:34.833085 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.31 seconds
12:27:34.835061 [debug] [Thread-1  ]: finished collecting timing info
12:27:34.835254 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
12:27:35.021760 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cfb3548c-7fc4-44b4-ac1f-4b22bd1c07e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1047a5f40>]}
12:27:35.023227 [info ] [Thread-1  ]: 2 of 6 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 3.72s]
12:27:35.023874 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
12:27:35.024355 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
12:27:35.024741 [info ] [Thread-1  ]: 3 of 6 START table model dbt.first_model........................................ [RUN]
12:27:35.025144 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
12:27:35.025246 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
12:27:35.025342 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
12:27:35.029405 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
12:27:35.030164 [debug] [Thread-1  ]: finished collecting timing info
12:27:35.030345 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
12:27:35.039339 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
12:27:35.040532 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
12:27:35.040686 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *, True as first_variable
from source_data
where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
12:27:35.040813 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:27:36.442793 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.4 seconds
12:27:36.446339 [debug] [Thread-1  ]: finished collecting timing info
12:27:36.446816 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
12:27:36.649254 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cfb3548c-7fc4-44b4-ac1f-4b22bd1c07e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106581af0>]}
12:27:36.649676 [info ] [Thread-1  ]: 3 of 6 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 1.62s]
12:27:36.649905 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
12:27:36.650036 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
12:27:36.650171 [info ] [Thread-1  ]: 4 of 6 START table model dbt.snowflake_cumulative_sales......................... [RUN]
12:27:36.650460 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
12:27:36.650873 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
12:27:36.651127 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
12:27:36.652649 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
12:27:36.653207 [debug] [Thread-1  ]: finished collecting timing info
12:27:36.653378 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
12:27:36.655773 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
12:27:36.656754 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
12:27:36.656914 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
12:27:36.657054 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:27:38.068117 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.41 seconds
12:27:38.072219 [debug] [Thread-1  ]: finished collecting timing info
12:27:38.072778 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
12:27:38.470947 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cfb3548c-7fc4-44b4-ac1f-4b22bd1c07e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10655a4f0>]}
12:27:38.471572 [info ] [Thread-1  ]: 4 of 6 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 1.82s]
12:27:38.472150 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
12:27:38.472493 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
12:27:38.472829 [info ] [Thread-1  ]: 5 of 6 START table model dbt.snowflake_customer_purchases....................... [RUN]
12:27:38.473624 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
12:27:38.473902 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
12:27:38.474118 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
12:27:38.475966 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
12:27:38.476639 [debug] [Thread-1  ]: finished collecting timing info
12:27:38.476814 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
12:27:38.479411 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
12:27:38.480649 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
12:27:38.480815 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
12:27:38.480953 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:27:40.045389 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.56 seconds
12:27:40.048616 [debug] [Thread-1  ]: finished collecting timing info
12:27:40.048989 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
12:27:40.212032 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cfb3548c-7fc4-44b4-ac1f-4b22bd1c07e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10670bb80>]}
12:27:40.212738 [info ] [Thread-1  ]: 5 of 6 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 1.74s]
12:27:40.213180 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
12:27:40.213419 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
12:27:40.213808 [info ] [Thread-1  ]: 6 of 6 START table model dbt.my_second_dbt_model................................ [RUN]
12:27:40.214421 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
12:27:40.214622 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
12:27:40.214811 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
12:27:40.216249 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
12:27:40.217951 [debug] [Thread-1  ]: finished collecting timing info
12:27:40.218162 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
12:27:40.220838 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
12:27:40.222215 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
12:27:40.222455 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
where id = 1
      );
12:27:40.222612 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:27:42.546951 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.32 seconds
12:27:42.551442 [debug] [Thread-1  ]: finished collecting timing info
12:27:42.551850 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
12:27:42.739613 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cfb3548c-7fc4-44b4-ac1f-4b22bd1c07e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103624b20>]}
12:27:42.740260 [info ] [Thread-1  ]: 6 of 6 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 2.53s]
12:27:42.740692 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
12:27:42.742029 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:27:42.742595 [info ] [MainThread]: 
12:27:42.742958 [info ] [MainThread]: Finished running 2 incremental models, 4 table models in 17.89s.
12:27:42.743259 [debug] [MainThread]: Connection 'master' was properly closed.
12:27:42.743419 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
12:27:42.749995 [info ] [MainThread]: 
12:27:42.750318 [info ] [MainThread]: [32mCompleted successfully[0m
12:27:42.750579 [info ] [MainThread]: 
12:27:42.750766 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
12:27:42.751050 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10652df10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10655a880>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1046f8220>]}


============================== 2022-05-13 12:31:46.164409 | b06540f9-edcb-4312-a480-a7d7396aa90b ==============================
12:31:46.164409 [info ] [MainThread]: Running with dbt=1.0.1
12:31:46.165016 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
12:31:46.165133 [debug] [MainThread]: Tracking: tracking
12:31:46.165355 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1081a7e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1081a7a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1081a7d30>]}
12:31:46.201810 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108184490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1081844f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108184760>]}


============================== 2022-05-13 12:46:51.990580 | fee484f3-62b8-4d42-89ca-e8d63cfaed01 ==============================
12:46:51.990580 [info ] [MainThread]: Running with dbt=1.0.1
12:46:51.991178 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
12:46:51.991298 [debug] [MainThread]: Tracking: tracking
12:46:51.991534 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d1b8b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d1bb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d1b610>]}
12:46:52.028926 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d55b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d55520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1072079d0>]}


============================== 2022-05-13 12:48:32.965345 | a1cabe6d-e60f-497f-99d8-988dd970e14b ==============================
12:48:32.965345 [info ] [MainThread]: Running with dbt=1.0.1
12:48:32.965899 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
12:48:32.966048 [debug] [MainThread]: Tracking: tracking
12:48:32.966334 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113333eb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113333b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1133333a0>]}
12:48:33.014435 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
12:48:33.014790 [debug] [MainThread]: Partial parsing: update schema file: learn_dbt://models/example/schema.yml
12:48:33.022030 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
12:48:33.047461 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a1cabe6d-e60f-497f-99d8-988dd970e14b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1115a50d0>]}
12:48:33.050508 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a1cabe6d-e60f-497f-99d8-988dd970e14b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113310b80>]}
12:48:33.050645 [info ] [MainThread]: Found 6 models, 9 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
12:48:33.051378 [info ] [MainThread]: 
12:48:33.051581 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:48:33.052003 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
12:48:33.058023 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
12:48:33.058151 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
12:48:33.058216 [debug] [ThreadPool]: Opening a new connection, currently in state init
12:48:34.182983 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.12 seconds
12:48:34.186212 [debug] [ThreadPool]: On list_analytics: Close
12:48:34.561635 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
12:48:34.570501 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
12:48:34.570769 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
12:48:34.570931 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:48:35.301218 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 0.73 seconds
12:48:35.303403 [debug] [ThreadPool]: On list_analytics_dbt: Close
12:48:35.840426 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
12:48:35.841071 [info ] [MainThread]: 
12:48:35.845623 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
12:48:35.846321 [info ] [Thread-1  ]: 1 of 6 START incremental model dbt.dates........................................ [RUN]
12:48:35.846765 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
12:48:35.846904 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
12:48:35.847054 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
12:48:35.856852 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
12:48:35.858286 [debug] [Thread-1  ]: finished collecting timing info
12:48:35.858434 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
12:48:35.886907 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:48:35.887076 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
12:48:35.887165 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:48:38.386394 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.5 seconds
12:48:38.399216 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:48:38.399625 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
12:48:38.528355 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.13 seconds
12:48:38.535558 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:48:38.535891 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
12:48:38.727699 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.19 seconds
12:48:38.740458 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:48:38.740853 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
12:48:38.879998 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.14 seconds
12:48:38.901323 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
12:48:38.904541 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:48:38.904695 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
12:48:39.281001 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.38 seconds
12:48:39.281655 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:48:39.281841 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
12:48:39.891898 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.61 seconds
12:48:39.893357 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:48:39.893577 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
12:48:40.391717 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.5 seconds
12:48:40.405675 [debug] [Thread-1  ]: finished collecting timing info
12:48:40.406028 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
12:48:40.916897 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a1cabe6d-e60f-497f-99d8-988dd970e14b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106cd3040>]}
12:48:40.917751 [info ] [Thread-1  ]: 1 of 6 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 5.07s]
12:48:40.918223 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
12:48:40.918472 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
12:48:40.918883 [info ] [Thread-1  ]: 2 of 6 START incremental model dbt.incremental_time............................. [RUN]
12:48:40.919566 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
12:48:40.919791 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
12:48:40.919995 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
12:48:40.923988 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
12:48:40.925979 [debug] [Thread-1  ]: finished collecting timing info
12:48:40.926232 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
12:48:40.929847 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:48:40.930049 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
12:48:40.930187 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:48:42.422086 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.49 seconds
12:48:42.429011 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:48:42.429469 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
12:48:42.569884 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.14 seconds
12:48:42.573240 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:48:42.573421 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
12:48:42.679878 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.11 seconds
12:48:42.686171 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:48:42.686417 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
12:48:42.949804 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.26 seconds
12:48:42.955308 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
12:48:42.958926 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:48:42.959181 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
12:48:43.102930 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.14 seconds
12:48:43.103300 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:48:43.103431 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
12:48:43.996441 [debug] [Thread-1  ]: SQL status: SUCCESS 1269 in 0.89 seconds
12:48:43.997584 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:48:43.997830 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
12:48:44.336896 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.34 seconds
12:48:44.339681 [debug] [Thread-1  ]: finished collecting timing info
12:48:44.340029 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
12:48:44.711722 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a1cabe6d-e60f-497f-99d8-988dd970e14b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116913610>]}
12:48:44.712967 [info ] [Thread-1  ]: 2 of 6 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 3.79s]
12:48:44.713521 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
12:48:44.713698 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
12:48:44.714001 [info ] [Thread-1  ]: 3 of 6 START table model dbt.first_model........................................ [RUN]
12:48:44.714416 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
12:48:44.714552 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
12:48:44.714675 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
12:48:44.717916 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
12:48:44.718752 [debug] [Thread-1  ]: finished collecting timing info
12:48:44.718906 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
12:48:44.726683 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
12:48:44.727741 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
12:48:44.727880 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *, True as first_variable
from source_data
where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
12:48:44.727993 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:48:46.169233 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.44 seconds
12:48:46.172960 [debug] [Thread-1  ]: finished collecting timing info
12:48:46.173350 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
12:48:46.401985 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a1cabe6d-e60f-497f-99d8-988dd970e14b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116878ac0>]}
12:48:46.402702 [info ] [Thread-1  ]: 3 of 6 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 1.69s]
12:48:46.403419 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
12:48:46.403942 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
12:48:46.404465 [info ] [Thread-1  ]: 4 of 6 START table model dbt.snowflake_cumulative_sales......................... [RUN]
12:48:46.405254 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
12:48:46.405496 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
12:48:46.405699 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
12:48:46.407416 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
12:48:46.408506 [debug] [Thread-1  ]: finished collecting timing info
12:48:46.408730 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
12:48:46.411540 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
12:48:46.412740 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
12:48:46.412925 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
12:48:46.413078 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:48:48.231434 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.82 seconds
12:48:48.234692 [debug] [Thread-1  ]: finished collecting timing info
12:48:48.234981 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
12:48:48.434170 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a1cabe6d-e60f-497f-99d8-988dd970e14b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114954e20>]}
12:48:48.435234 [info ] [Thread-1  ]: 4 of 6 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 2.03s]
12:48:48.435697 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
12:48:48.436184 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
12:48:48.436647 [info ] [Thread-1  ]: 5 of 6 START table model dbt.snowflake_customer_purchases....................... [RUN]
12:48:48.437260 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
12:48:48.437459 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
12:48:48.437650 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
12:48:48.444600 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
12:48:48.446266 [debug] [Thread-1  ]: finished collecting timing info
12:48:48.446513 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
12:48:48.449139 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
12:48:48.450265 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
12:48:48.450407 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
12:48:48.450523 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:48:51.424871 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.97 seconds
12:48:51.428495 [debug] [Thread-1  ]: finished collecting timing info
12:48:51.428920 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
12:48:51.590752 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a1cabe6d-e60f-497f-99d8-988dd970e14b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11491af70>]}
12:48:51.591514 [info ] [Thread-1  ]: 5 of 6 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 3.15s]
12:48:51.591978 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
12:48:51.592247 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
12:48:51.592544 [info ] [Thread-1  ]: 6 of 6 START table model dbt.my_second_dbt_model................................ [RUN]
12:48:51.593246 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
12:48:51.593491 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
12:48:51.593692 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
12:48:51.596876 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
12:48:51.599049 [debug] [Thread-1  ]: finished collecting timing info
12:48:51.599242 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
12:48:51.601764 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
12:48:51.602797 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
12:48:51.602971 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
where id = 1
      );
12:48:51.603098 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:48:52.909509 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.31 seconds
12:48:52.913485 [debug] [Thread-1  ]: finished collecting timing info
12:48:52.913794 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
12:48:53.136745 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a1cabe6d-e60f-497f-99d8-988dd970e14b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11693a520>]}
12:48:53.137500 [info ] [Thread-1  ]: 6 of 6 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.54s]
12:48:53.137956 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
12:48:53.139587 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:48:53.140176 [info ] [MainThread]: 
12:48:53.140479 [info ] [MainThread]: Finished running 2 incremental models, 4 table models in 20.09s.
12:48:53.140731 [debug] [MainThread]: Connection 'master' was properly closed.
12:48:53.140865 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
12:48:53.147566 [info ] [MainThread]: 
12:48:53.147860 [info ] [MainThread]: [32mCompleted successfully[0m
12:48:53.148129 [info ] [MainThread]: 
12:48:53.148321 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
12:48:53.148584 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1149f7520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113310190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114959a90>]}


============================== 2022-05-13 12:48:59.703144 | 66bd61e9-63f4-4e5e-a7ae-cbcfd97032d9 ==============================
12:48:59.703144 [info ] [MainThread]: Running with dbt=1.0.1
12:48:59.703568 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, store_failures=False, indirect_selection='eager', threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.test.TestTask'>, which='test', rpc_method='test')
12:48:59.703716 [debug] [MainThread]: Tracking: tracking
12:48:59.703987 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11374b3d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11374b790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11374b850>]}
12:48:59.750225 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
12:48:59.750366 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
12:48:59.753515 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '66bd61e9-63f4-4e5e-a7ae-cbcfd97032d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113712220>]}
12:48:59.756666 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '66bd61e9-63f4-4e5e-a7ae-cbcfd97032d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111cb7970>]}
12:48:59.756807 [info ] [MainThread]: Found 6 models, 9 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
12:48:59.757575 [info ] [MainThread]: 
12:48:59.757785 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:48:59.758258 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
12:48:59.764217 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
12:48:59.764331 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
12:48:59.764396 [debug] [ThreadPool]: Opening a new connection, currently in state init
12:49:00.981936 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1.22 seconds
12:49:00.984645 [debug] [ThreadPool]: On list_analytics_dbt: Close
12:49:01.366194 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
12:49:01.366847 [info ] [MainThread]: 
12:49:01.373144 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_my_first_dbt_model_id.5fb22c2710
12:49:01.373531 [info ] [Thread-1  ]: 1 of 9 START test not_null_my_first_dbt_model_id................................ [RUN]
12:49:01.374175 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_my_first_dbt_model_id.5fb22c2710"
12:49:01.374349 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_my_first_dbt_model_id.5fb22c2710
12:49:01.374514 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_my_first_dbt_model_id.5fb22c2710
12:49:01.385302 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_my_first_dbt_model_id.5fb22c2710"
12:49:01.385979 [debug] [Thread-1  ]: finished collecting timing info
12:49:01.386129 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_my_first_dbt_model_id.5fb22c2710
12:49:01.398727 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_my_first_dbt_model_id.5fb22c2710"
12:49:01.399523 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_my_first_dbt_model_id.5fb22c2710"
12:49:01.399630 [debug] [Thread-1  ]: On test.learn_dbt.not_null_my_first_dbt_model_id.5fb22c2710: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_my_first_dbt_model_id.5fb22c2710"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.first_model
where id is null



      
    ) dbt_internal_test
12:49:01.399721 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:49:02.869431 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.47 seconds
12:49:02.872932 [debug] [Thread-1  ]: finished collecting timing info
12:49:02.873370 [debug] [Thread-1  ]: On test.learn_dbt.not_null_my_first_dbt_model_id.5fb22c2710: Close
12:49:03.398864 [info ] [Thread-1  ]: 1 of 9 PASS not_null_my_first_dbt_model_id...................................... [[32mPASS[0m in 2.02s]
12:49:03.399611 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_my_first_dbt_model_id.5fb22c2710
12:49:03.399877 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
12:49:03.400258 [info ] [Thread-1  ]: 2 of 9 START test not_null_my_second_dbt_model_id............................... [RUN]
12:49:03.400897 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"
12:49:03.401113 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
12:49:03.401306 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
12:49:03.406147 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"
12:49:03.406692 [debug] [Thread-1  ]: finished collecting timing info
12:49:03.406831 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
12:49:03.408267 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"
12:49:03.408946 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"
12:49:03.409065 [debug] [Thread-1  ]: On test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.my_second_dbt_model
where id is null



      
    ) dbt_internal_test
12:49:03.409174 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:49:04.445988 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.04 seconds
12:49:04.448328 [debug] [Thread-1  ]: finished collecting timing info
12:49:04.448530 [debug] [Thread-1  ]: On test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778: Close
12:49:04.716614 [info ] [Thread-1  ]: 2 of 9 PASS not_null_my_second_dbt_model_id..................................... [[32mPASS[0m in 1.32s]
12:49:04.717774 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
12:49:04.718125 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
12:49:04.718544 [info ] [Thread-1  ]: 3 of 9 START test not_null_snowflake_cumulative_sales_o_orderdate............... [RUN]
12:49:04.719335 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
12:49:04.719556 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
12:49:04.719766 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
12:49:04.724386 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
12:49:04.725383 [debug] [Thread-1  ]: finished collecting timing info
12:49:04.725665 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
12:49:04.728105 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
12:49:04.729328 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
12:49:04.729590 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.snowflake_cumulative_sales
where o_orderdate is null



      
    ) dbt_internal_test
12:49:04.729753 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:49:06.299165 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.57 seconds
12:49:06.302670 [debug] [Thread-1  ]: finished collecting timing info
12:49:06.303082 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856: Close
12:49:06.635216 [info ] [Thread-1  ]: 3 of 9 PASS not_null_snowflake_cumulative_sales_o_orderdate..................... [[32mPASS[0m in 1.92s]
12:49:06.635790 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
12:49:06.636035 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
12:49:06.636233 [info ] [Thread-1  ]: 4 of 9 START test not_null_snowflake_customer_purchases_c_custkey............... [RUN]
12:49:06.636954 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
12:49:06.637184 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
12:49:06.637382 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
12:49:06.642273 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
12:49:06.643004 [debug] [Thread-1  ]: finished collecting timing info
12:49:06.643211 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
12:49:06.645652 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
12:49:06.646711 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
12:49:06.646884 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.snowflake_customer_purchases
where c_custkey is null



      
    ) dbt_internal_test
12:49:06.647031 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:49:07.592704 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.95 seconds
12:49:07.599195 [debug] [Thread-1  ]: finished collecting timing info
12:49:07.599500 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502: Close
12:49:07.766919 [info ] [Thread-1  ]: 4 of 9 PASS not_null_snowflake_customer_purchases_c_custkey..................... [[32mPASS[0m in 1.13s]
12:49:07.767381 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
12:49:07.767592 [debug] [Thread-1  ]: Began running node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
12:49:07.767851 [info ] [Thread-1  ]: 5 of 9 START test relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ [RUN]
12:49:07.768364 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
12:49:07.768531 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
12:49:07.768688 [debug] [Thread-1  ]: Compiling test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
12:49:07.778303 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
12:49:07.778754 [debug] [Thread-1  ]: finished collecting timing info
12:49:07.778849 [debug] [Thread-1  ]: Began executing node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
12:49:07.779894 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
12:49:07.780680 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
12:49:07.780783 [debug] [Thread-1  ]: On test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select id as from_field
    from analytics.dbt.my_second_dbt_model
    where id is not null
),

parent as (
    select id as to_field
    from analytics.dbt.first_model
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
12:49:07.780849 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:49:08.669402 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.89 seconds
12:49:08.672595 [debug] [Thread-1  ]: finished collecting timing info
12:49:08.673046 [debug] [Thread-1  ]: On test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: Close
12:49:08.861041 [info ] [Thread-1  ]: 5 of 9 PASS relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_... [[32mPASS[0m in 1.09s]
12:49:08.861777 [debug] [Thread-1  ]: Finished running node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
12:49:08.862041 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
12:49:08.862236 [info ] [Thread-1  ]: 6 of 9 START test unique_my_first_dbt_model_id.................................. [RUN]
12:49:08.862873 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
12:49:08.863060 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
12:49:08.863229 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
12:49:08.869151 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
12:49:08.869734 [debug] [Thread-1  ]: finished collecting timing info
12:49:08.869883 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
12:49:08.871441 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
12:49:08.872323 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
12:49:08.872481 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.first_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
12:49:08.872779 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:49:09.851130 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.98 seconds
12:49:09.853176 [debug] [Thread-1  ]: finished collecting timing info
12:49:09.853425 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_first_dbt_model_id.16e066b321: Close
12:49:10.215049 [info ] [Thread-1  ]: 6 of 9 PASS unique_my_first_dbt_model_id........................................ [[32mPASS[0m in 1.35s]
12:49:10.215834 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
12:49:10.216091 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
12:49:10.216296 [info ] [Thread-1  ]: 7 of 9 START test unique_my_second_dbt_model_id................................. [RUN]
12:49:10.217013 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
12:49:10.217264 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
12:49:10.217480 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
12:49:10.221772 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
12:49:10.222515 [debug] [Thread-1  ]: finished collecting timing info
12:49:10.222690 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
12:49:10.224942 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
12:49:10.226184 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
12:49:10.226416 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.my_second_dbt_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
12:49:10.226555 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:49:11.260736 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.03 seconds
12:49:11.263474 [debug] [Thread-1  ]: finished collecting timing info
12:49:11.263904 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493: Close
12:49:11.421502 [info ] [Thread-1  ]: 7 of 9 PASS unique_my_second_dbt_model_id....................................... [[32mPASS[0m in 1.20s]
12:49:11.422368 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
12:49:11.422630 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
12:49:11.422832 [info ] [Thread-1  ]: 8 of 9 START test unique_snowflake_cumulative_sales_o_orderdate................. [RUN]
12:49:11.423567 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
12:49:11.423809 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
12:49:11.424018 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
12:49:11.428729 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
12:49:11.429576 [debug] [Thread-1  ]: finished collecting timing info
12:49:11.429762 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
12:49:11.432395 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
12:49:11.433823 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
12:49:11.434058 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    o_orderdate as unique_field,
    count(*) as n_records

from analytics.dbt.snowflake_cumulative_sales
where o_orderdate is not null
group by o_orderdate
having count(*) > 1



      
    ) dbt_internal_test
12:49:11.434193 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:49:12.176031 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.74 seconds
12:49:12.179507 [debug] [Thread-1  ]: finished collecting timing info
12:49:12.179898 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed: Close
12:49:12.339246 [info ] [Thread-1  ]: 8 of 9 PASS unique_snowflake_cumulative_sales_o_orderdate....................... [[32mPASS[0m in 0.92s]
12:49:12.340028 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
12:49:12.340239 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
12:49:12.340401 [info ] [Thread-1  ]: 9 of 9 START test unique_snowflake_customer_purchases_c_custkey................. [RUN]
12:49:12.340652 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
12:49:12.340727 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
12:49:12.340801 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
12:49:12.342848 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
12:49:12.343294 [debug] [Thread-1  ]: finished collecting timing info
12:49:12.343378 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
12:49:12.344522 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
12:49:12.345061 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
12:49:12.345132 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    c_custkey as unique_field,
    count(*) as n_records

from analytics.dbt.snowflake_customer_purchases
where c_custkey is not null
group by c_custkey
having count(*) > 1



      
    ) dbt_internal_test
12:49:12.345193 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:49:13.133123 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.79 seconds
12:49:13.136512 [debug] [Thread-1  ]: finished collecting timing info
12:49:13.136980 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f: Close
12:49:13.411942 [info ] [Thread-1  ]: 9 of 9 PASS unique_snowflake_customer_purchases_c_custkey....................... [[32mPASS[0m in 1.07s]
12:49:13.412807 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
12:49:13.414245 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:49:13.414710 [info ] [MainThread]: 
12:49:13.415040 [info ] [MainThread]: Finished running 9 tests in 13.66s.
12:49:13.415335 [debug] [MainThread]: Connection 'master' was properly closed.
12:49:13.415495 [debug] [MainThread]: Connection 'test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f' was properly closed.
12:49:13.422425 [info ] [MainThread]: 
12:49:13.422777 [info ] [MainThread]: [32mCompleted successfully[0m
12:49:13.423073 [info ] [MainThread]: 
12:49:13.423268 [info ] [MainThread]: Done. PASS=9 WARN=0 ERROR=0 SKIP=0 TOTAL=9
12:49:13.423542 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1139dc3a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107f223d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113f4ed60>]}


============================== 2022-05-13 12:50:19.774998 | c70dbfd4-d9be-495a-b9d0-78fd417eee6c ==============================
12:50:19.774998 [info ] [MainThread]: Running with dbt=1.0.1
12:50:19.775722 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
12:50:19.775953 [debug] [MainThread]: Tracking: tracking
12:50:19.776271 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110e43e80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110e43d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110e439d0>]}
12:50:19.822400 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
12:50:19.822733 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/my_second_dbt_model.sql
12:50:19.830192 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
12:50:19.856659 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c70dbfd4-d9be-495a-b9d0-78fd417eee6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110004ca0>]}
12:50:19.859602 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c70dbfd4-d9be-495a-b9d0-78fd417eee6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053821c0>]}
12:50:19.859741 [info ] [MainThread]: Found 6 models, 9 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
12:50:19.860561 [info ] [MainThread]: 
12:50:19.860837 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:50:19.861321 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
12:50:19.867637 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
12:50:19.867778 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
12:50:19.867846 [debug] [ThreadPool]: Opening a new connection, currently in state init
12:50:20.766303 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.9 seconds
12:50:20.768675 [debug] [ThreadPool]: On list_analytics: Close
12:50:21.081093 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
12:50:21.088948 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
12:50:21.089228 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
12:50:21.089377 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:50:21.651587 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 0.56 seconds
12:50:21.655311 [debug] [ThreadPool]: On list_analytics_dbt: Close
12:50:21.846358 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
12:50:21.847519 [info ] [MainThread]: 
12:50:21.852364 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
12:50:21.853110 [info ] [Thread-1  ]: 1 of 6 START incremental model dbt.dates........................................ [RUN]
12:50:21.853663 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
12:50:21.853847 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
12:50:21.854007 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
12:50:21.860863 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
12:50:21.861559 [debug] [Thread-1  ]: finished collecting timing info
12:50:21.861709 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
12:50:21.891699 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:50:21.891922 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
12:50:21.892014 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:50:24.130226 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.24 seconds
12:50:24.142821 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:50:24.143134 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
12:50:24.301365 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.16 seconds
12:50:24.309603 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:50:24.309896 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
12:50:24.418825 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.11 seconds
12:50:24.427789 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:50:24.428031 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
12:50:24.913828 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.49 seconds
12:50:24.937284 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
12:50:24.939636 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:50:24.939773 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
12:50:25.182711 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.24 seconds
12:50:25.183427 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:50:25.183633 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
12:50:25.798900 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.62 seconds
12:50:25.799649 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:50:25.799938 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
12:50:25.968948 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.17 seconds
12:50:25.982302 [debug] [Thread-1  ]: finished collecting timing info
12:50:25.982672 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
12:50:26.233782 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c70dbfd4-d9be-495a-b9d0-78fd417eee6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107f66a90>]}
12:50:26.234507 [info ] [Thread-1  ]: 1 of 6 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 4.38s]
12:50:26.235075 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
12:50:26.235396 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
12:50:26.235674 [info ] [Thread-1  ]: 2 of 6 START incremental model dbt.incremental_time............................. [RUN]
12:50:26.235952 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
12:50:26.236035 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
12:50:26.236119 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
12:50:26.237705 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
12:50:26.238073 [debug] [Thread-1  ]: finished collecting timing info
12:50:26.238157 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
12:50:26.240090 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:50:26.240435 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
12:50:26.240639 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:50:27.731614 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.49 seconds
12:50:27.736834 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:50:27.737165 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
12:50:29.016732 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 1.28 seconds
12:50:29.022047 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:50:29.022460 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
12:50:29.191814 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.17 seconds
12:50:29.196299 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:50:29.196567 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
12:50:29.375273 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.18 seconds
12:50:29.380184 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
12:50:29.382625 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:50:29.382850 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
12:50:29.525660 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.14 seconds
12:50:29.526788 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:50:29.527013 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
12:50:30.485822 [debug] [Thread-1  ]: SQL status: SUCCESS 105 in 0.96 seconds
12:50:30.486291 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:50:30.486479 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
12:50:31.012969 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.53 seconds
12:50:31.016903 [debug] [Thread-1  ]: finished collecting timing info
12:50:31.017149 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
12:50:31.189306 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c70dbfd4-d9be-495a-b9d0-78fd417eee6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1116d0430>]}
12:50:31.190113 [info ] [Thread-1  ]: 2 of 6 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 4.95s]
12:50:31.190564 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
12:50:31.190776 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
12:50:31.191118 [info ] [Thread-1  ]: 3 of 6 START table model dbt.first_model........................................ [RUN]
12:50:31.191691 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
12:50:31.191894 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
12:50:31.192058 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
12:50:31.195213 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
12:50:31.195802 [debug] [Thread-1  ]: finished collecting timing info
12:50:31.195928 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
12:50:31.202542 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
12:50:31.203195 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
12:50:31.203274 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *, True as first_variable
from source_data
where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
12:50:31.203337 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:50:32.667343 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.46 seconds
12:50:32.670654 [debug] [Thread-1  ]: finished collecting timing info
12:50:32.671073 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
12:50:33.044304 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c70dbfd4-d9be-495a-b9d0-78fd417eee6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1110f09d0>]}
12:50:33.045215 [info ] [Thread-1  ]: 3 of 6 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 1.85s]
12:50:33.045656 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
12:50:33.045778 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
12:50:33.046058 [info ] [Thread-1  ]: 4 of 6 START table model dbt.snowflake_cumulative_sales......................... [RUN]
12:50:33.046330 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
12:50:33.046417 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
12:50:33.046501 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
12:50:33.047287 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
12:50:33.047741 [debug] [Thread-1  ]: finished collecting timing info
12:50:33.047853 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
12:50:33.049642 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
12:50:33.050413 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
12:50:33.050524 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
12:50:33.050616 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:50:34.642762 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.59 seconds
12:50:34.646238 [debug] [Thread-1  ]: finished collecting timing info
12:50:34.646575 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
12:50:34.819159 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c70dbfd4-d9be-495a-b9d0-78fd417eee6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113d0a1c0>]}
12:50:34.819991 [info ] [Thread-1  ]: 4 of 6 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 1.77s]
12:50:34.820444 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
12:50:34.820694 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
12:50:34.821097 [info ] [Thread-1  ]: 5 of 6 START table model dbt.snowflake_customer_purchases....................... [RUN]
12:50:34.821748 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
12:50:34.821964 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
12:50:34.822175 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
12:50:34.823844 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
12:50:34.824525 [debug] [Thread-1  ]: finished collecting timing info
12:50:34.824692 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
12:50:34.826824 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
12:50:34.827685 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
12:50:34.827807 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
12:50:34.827907 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:50:37.000402 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.17 seconds
12:50:37.004176 [debug] [Thread-1  ]: finished collecting timing info
12:50:37.004510 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
12:50:37.337555 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c70dbfd4-d9be-495a-b9d0-78fd417eee6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1116a8250>]}
12:50:37.338428 [info ] [Thread-1  ]: 5 of 6 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.52s]
12:50:37.338889 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
12:50:37.339142 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
12:50:37.339559 [info ] [Thread-1  ]: 6 of 6 START table model dbt.my_second_dbt_model................................ [RUN]
12:50:37.340220 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
12:50:37.340455 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
12:50:37.340659 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
12:50:37.343146 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
12:50:37.343616 [debug] [Thread-1  ]: finished collecting timing info
12:50:37.343733 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
12:50:37.345198 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
12:50:37.345704 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
12:50:37.345802 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
union all
select 7 as id
      );
12:50:37.345888 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:50:38.054407 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a43d22-3201-9c86-0000-000120527171
12:50:38.054841 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 001789 (42601): SQL compilation error:
invalid number of result columns for set operator input branches, expected 2, got 1 in branch 2
12:50:38.055164 [debug] [Thread-1  ]: finished collecting timing info
12:50:38.055373 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
12:50:38.330522 [debug] [Thread-1  ]: Database Error in model my_second_dbt_model (models/example/my_second_dbt_model.sql)
  001789 (42601): SQL compilation error:
  invalid number of result columns for set operator input branches, expected 2, got 1 in branch 2
  compiled SQL at target/run/learn_dbt/models/example/my_second_dbt_model.sql
12:50:38.331337 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c70dbfd4-d9be-495a-b9d0-78fd417eee6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113d1b130>]}
12:50:38.331916 [error] [Thread-1  ]: 6 of 6 ERROR creating table model dbt.my_second_dbt_model....................... [[31mERROR[0m in 0.99s]
12:50:38.332531 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
12:50:38.333867 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:50:38.334367 [info ] [MainThread]: 
12:50:38.334699 [info ] [MainThread]: Finished running 2 incremental models, 4 table models in 18.47s.
12:50:38.334992 [debug] [MainThread]: Connection 'master' was properly closed.
12:50:38.335155 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
12:50:38.341941 [info ] [MainThread]: 
12:50:38.342274 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
12:50:38.342544 [info ] [MainThread]: 
12:50:38.342775 [error] [MainThread]: [33mDatabase Error in model my_second_dbt_model (models/example/my_second_dbt_model.sql)[0m
12:50:38.343002 [error] [MainThread]:   001789 (42601): SQL compilation error:
12:50:38.343221 [error] [MainThread]:   invalid number of result columns for set operator input branches, expected 2, got 1 in branch 2
12:50:38.343432 [error] [MainThread]:   compiled SQL at target/run/learn_dbt/models/example/my_second_dbt_model.sql
12:50:38.343626 [info ] [MainThread]: 
12:50:38.343814 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=1 SKIP=0 TOTAL=6
12:50:38.344091 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11154e5e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1101fd220>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1116d9790>]}


============================== 2022-05-13 12:52:22.827838 | d389c04d-7681-4f44-b5e3-cce5d7612073 ==============================
12:52:22.827838 [info ] [MainThread]: Running with dbt=1.0.1
12:52:22.828474 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
12:52:22.828608 [debug] [MainThread]: Tracking: tracking
12:52:22.828810 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107543370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107543be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075439d0>]}
12:52:22.873642 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
12:52:22.873967 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/my_second_dbt_model.sql
12:52:22.879670 [debug] [MainThread]: 1603: static parser failed on example/my_second_dbt_model.sql
12:52:22.886177 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_second_dbt_model.sql
12:52:22.905764 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd389c04d-7681-4f44-b5e3-cce5d7612073', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076c1ac0>]}
12:52:22.908763 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd389c04d-7681-4f44-b5e3-cce5d7612073', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105cbc430>]}
12:52:22.908898 [info ] [MainThread]: Found 6 models, 9 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
12:52:22.909645 [info ] [MainThread]: 
12:52:22.909845 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:52:22.910282 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
12:52:22.916228 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
12:52:22.916356 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
12:52:22.916418 [debug] [ThreadPool]: Opening a new connection, currently in state init
12:52:23.847243 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.93 seconds
12:52:23.850284 [debug] [ThreadPool]: On list_analytics: Close
12:52:24.060138 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
12:52:24.068554 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
12:52:24.068834 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
12:52:24.068997 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:52:24.714706 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 0.65 seconds
12:52:24.718470 [debug] [ThreadPool]: On list_analytics_dbt: Close
12:52:24.891068 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
12:52:24.891625 [info ] [MainThread]: 
12:52:24.897320 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
12:52:24.898251 [info ] [Thread-1  ]: 1 of 6 START incremental model dbt.dates........................................ [RUN]
12:52:24.898826 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
12:52:24.898994 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
12:52:24.899159 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
12:52:24.908756 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
12:52:24.909709 [debug] [Thread-1  ]: finished collecting timing info
12:52:24.909883 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
12:52:24.938128 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:52:24.938301 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
12:52:24.938388 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:52:26.643749 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.71 seconds
12:52:26.651936 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:52:26.652076 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
12:52:26.921792 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.27 seconds
12:52:26.927759 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:52:26.927961 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
12:52:27.026111 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.1 seconds
12:52:27.033250 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:52:27.033452 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
12:52:27.202454 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.17 seconds
12:52:27.229133 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
12:52:27.232342 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:52:27.232470 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
12:52:27.351722 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.12 seconds
12:52:27.353770 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:52:27.354128 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
12:52:28.010824 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.66 seconds
12:52:28.015390 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:52:28.015648 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
12:52:28.250236 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.23 seconds
12:52:28.264408 [debug] [Thread-1  ]: finished collecting timing info
12:52:28.264799 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
12:52:28.535300 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd389c04d-7681-4f44-b5e3-cce5d7612073', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059746a0>]}
12:52:28.535808 [info ] [Thread-1  ]: 1 of 6 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 3.64s]
12:52:28.536115 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
12:52:28.536289 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
12:52:28.536598 [info ] [Thread-1  ]: 2 of 6 START incremental model dbt.incremental_time............................. [RUN]
12:52:28.537083 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
12:52:28.537254 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
12:52:28.537416 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
12:52:28.540939 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
12:52:28.542445 [debug] [Thread-1  ]: finished collecting timing info
12:52:28.542612 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
12:52:28.546655 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:52:28.546964 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
12:52:28.547108 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:52:30.115990 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.57 seconds
12:52:30.121206 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:52:30.121560 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
12:52:30.546817 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.42 seconds
12:52:30.552452 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:52:30.552782 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
12:52:30.667653 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.11 seconds
12:52:30.672617 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:52:30.672853 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
12:52:30.791414 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.12 seconds
12:52:30.796966 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
12:52:30.799410 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:52:30.799627 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
12:52:31.067673 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.27 seconds
12:52:31.068239 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:52:31.068417 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
12:52:32.117046 [debug] [Thread-1  ]: SQL status: SUCCESS 123 in 1.05 seconds
12:52:32.118145 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:52:32.118357 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
12:52:32.641195 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.52 seconds
12:52:32.649863 [debug] [Thread-1  ]: finished collecting timing info
12:52:32.650500 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
12:52:32.820370 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd389c04d-7681-4f44-b5e3-cce5d7612073', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107c97e80>]}
12:52:32.821169 [info ] [Thread-1  ]: 2 of 6 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 4.28s]
12:52:32.821608 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
12:52:32.821835 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
12:52:32.822251 [info ] [Thread-1  ]: 3 of 6 START table model dbt.first_model........................................ [RUN]
12:52:32.822882 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
12:52:32.823060 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
12:52:32.823222 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
12:52:32.826981 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
12:52:32.828799 [debug] [Thread-1  ]: finished collecting timing info
12:52:32.829053 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
12:52:32.838152 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
12:52:32.839209 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
12:52:32.839355 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *, True as first_variable
from source_data
where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
12:52:32.839470 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:52:34.149356 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.31 seconds
12:52:34.151577 [debug] [Thread-1  ]: finished collecting timing info
12:52:34.151780 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
12:52:34.324904 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd389c04d-7681-4f44-b5e3-cce5d7612073', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d16f10>]}
12:52:34.325845 [info ] [Thread-1  ]: 3 of 6 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 1.50s]
12:52:34.326318 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
12:52:34.326583 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
12:52:34.327056 [info ] [Thread-1  ]: 4 of 6 START table model dbt.snowflake_cumulative_sales......................... [RUN]
12:52:34.327978 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
12:52:34.328381 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
12:52:34.328621 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
12:52:34.330407 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
12:52:34.332478 [debug] [Thread-1  ]: finished collecting timing info
12:52:34.332765 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
12:52:34.335297 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
12:52:34.336428 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
12:52:34.336604 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
12:52:34.336783 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:52:36.245824 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.91 seconds
12:52:36.249069 [debug] [Thread-1  ]: finished collecting timing info
12:52:36.249471 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
12:52:36.437459 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd389c04d-7681-4f44-b5e3-cce5d7612073', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107aead60>]}
12:52:36.438175 [info ] [Thread-1  ]: 4 of 6 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 2.11s]
12:52:36.438620 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
12:52:36.438861 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
12:52:36.439281 [info ] [Thread-1  ]: 5 of 6 START table model dbt.snowflake_customer_purchases....................... [RUN]
12:52:36.439988 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
12:52:36.440196 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
12:52:36.440394 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
12:52:36.442062 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
12:52:36.442876 [debug] [Thread-1  ]: finished collecting timing info
12:52:36.443074 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
12:52:36.445545 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
12:52:36.446805 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
12:52:36.446981 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
12:52:36.447124 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:52:38.500606 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.05 seconds
12:52:38.504013 [debug] [Thread-1  ]: finished collecting timing info
12:52:38.504461 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
12:52:38.739077 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd389c04d-7681-4f44-b5e3-cce5d7612073', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d4e9a0>]}
12:52:38.739690 [info ] [Thread-1  ]: 5 of 6 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.30s]
12:52:38.740106 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
12:52:38.740345 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
12:52:38.740741 [info ] [Thread-1  ]: 6 of 6 START table model dbt.my_second_dbt_model................................ [RUN]
12:52:38.741409 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
12:52:38.741642 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
12:52:38.741847 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
12:52:38.745423 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
12:52:38.747215 [debug] [Thread-1  ]: finished collecting timing info
12:52:38.747423 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
12:52:38.750146 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
12:52:38.751044 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
12:52:38.751377 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
union all
select 7 as id, , True as first_variable
      );
12:52:38.751561 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:52:39.404893 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a43d24-3201-9c86-0000-000120527199
12:52:39.405327 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 7 at position 16 unexpected ','.
12:52:39.405701 [debug] [Thread-1  ]: finished collecting timing info
12:52:39.405936 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
12:52:39.568358 [debug] [Thread-1  ]: Database Error in model my_second_dbt_model (models/example/my_second_dbt_model.sql)
  001003 (42000): SQL compilation error:
  syntax error line 7 at position 16 unexpected ','.
  compiled SQL at target/run/learn_dbt/models/example/my_second_dbt_model.sql
12:52:39.569028 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd389c04d-7681-4f44-b5e3-cce5d7612073', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d683a0>]}
12:52:39.569459 [error] [Thread-1  ]: 6 of 6 ERROR creating table model dbt.my_second_dbt_model....................... [[31mERROR[0m in 0.83s]
12:52:39.569853 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
12:52:39.571031 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:52:39.571389 [info ] [MainThread]: 
12:52:39.571620 [info ] [MainThread]: Finished running 2 incremental models, 4 table models in 16.66s.
12:52:39.571828 [debug] [MainThread]: Connection 'master' was properly closed.
12:52:39.571951 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
12:52:39.577392 [info ] [MainThread]: 
12:52:39.577633 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
12:52:39.577827 [info ] [MainThread]: 
12:52:39.577992 [error] [MainThread]: [33mDatabase Error in model my_second_dbt_model (models/example/my_second_dbt_model.sql)[0m
12:52:39.578161 [error] [MainThread]:   001003 (42000): SQL compilation error:
12:52:39.578318 [error] [MainThread]:   syntax error line 7 at position 16 unexpected ','.
12:52:39.578470 [error] [MainThread]:   compiled SQL at target/run/learn_dbt/models/example/my_second_dbt_model.sql
12:52:39.578635 [info ] [MainThread]: 
12:52:39.578793 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=1 SKIP=0 TOTAL=6
12:52:39.579037 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076e38b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076e35e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b34d90>]}


============================== 2022-05-13 12:53:09.438040 | da8ed36b-cc12-49f7-8fa7-df42e439473f ==============================
12:53:09.438040 [info ] [MainThread]: Running with dbt=1.0.1
12:53:09.438468 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
12:53:09.438606 [debug] [MainThread]: Tracking: tracking
12:53:09.438847 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1091eb250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1091ebb80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1091eb910>]}
12:53:09.480364 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
12:53:09.480673 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/my_second_dbt_model.sql
12:53:09.489052 [debug] [MainThread]: 1603: static parser failed on example/my_second_dbt_model.sql
12:53:09.495431 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_second_dbt_model.sql
12:53:09.516752 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'da8ed36b-cc12-49f7-8fa7-df42e439473f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108301700>]}
12:53:09.520098 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'da8ed36b-cc12-49f7-8fa7-df42e439473f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10565f610>]}
12:53:09.520241 [info ] [MainThread]: Found 6 models, 9 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
12:53:09.520950 [info ] [MainThread]: 
12:53:09.521153 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:53:09.521665 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
12:53:09.528058 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
12:53:09.528200 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
12:53:09.528272 [debug] [ThreadPool]: Opening a new connection, currently in state init
12:53:10.588507 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.06 seconds
12:53:10.590681 [debug] [ThreadPool]: On list_analytics: Close
12:53:12.737243 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
12:53:12.746375 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
12:53:12.746646 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
12:53:12.746813 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:53:13.617452 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 0.87 seconds
12:53:13.620420 [debug] [ThreadPool]: On list_analytics_dbt: Close
12:53:13.819872 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
12:53:13.823115 [info ] [MainThread]: 
12:53:13.826511 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
12:53:13.827089 [info ] [Thread-1  ]: 1 of 6 START incremental model dbt.dates........................................ [RUN]
12:53:13.827597 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
12:53:13.827724 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
12:53:13.827897 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
12:53:13.833534 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
12:53:13.834007 [debug] [Thread-1  ]: finished collecting timing info
12:53:13.834114 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
12:53:13.862950 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:53:13.863189 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
12:53:13.863296 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:53:15.134268 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.27 seconds
12:53:15.146604 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:53:15.146954 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
12:53:15.270624 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.12 seconds
12:53:15.277274 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:53:15.277564 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
12:53:15.567202 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.29 seconds
12:53:15.579842 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:53:15.580147 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
12:53:15.678496 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.1 seconds
12:53:15.704432 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
12:53:15.707233 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:53:15.707472 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
12:53:15.882052 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.17 seconds
12:53:15.882778 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:53:15.883571 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
12:53:16.222143 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.34 seconds
12:53:16.222824 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:53:16.223436 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
12:53:16.614707 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.39 seconds
12:53:16.624646 [debug] [Thread-1  ]: finished collecting timing info
12:53:16.624958 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
12:53:16.826344 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'da8ed36b-cc12-49f7-8fa7-df42e439473f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106d3eee0>]}
12:53:16.827073 [info ] [Thread-1  ]: 1 of 6 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 3.00s]
12:53:16.827531 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
12:53:16.827782 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
12:53:16.828177 [info ] [Thread-1  ]: 2 of 6 START incremental model dbt.incremental_time............................. [RUN]
12:53:16.828799 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
12:53:16.829026 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
12:53:16.829228 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
12:53:16.833037 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
12:53:16.833777 [debug] [Thread-1  ]: finished collecting timing info
12:53:16.833985 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
12:53:16.837669 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:53:16.837856 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
12:53:16.837987 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:53:18.194592 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.36 seconds
12:53:18.199632 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:53:18.200007 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
12:53:18.352551 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.15 seconds
12:53:18.357860 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:53:18.358304 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
12:53:18.475695 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.12 seconds
12:53:18.483638 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:53:18.484040 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
12:53:18.715383 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.23 seconds
12:53:18.720252 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
12:53:18.722624 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:53:18.722813 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
12:53:18.857796 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.13 seconds
12:53:18.858348 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:53:18.858461 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
12:53:19.627893 [debug] [Thread-1  ]: SQL status: SUCCESS 48 in 0.77 seconds
12:53:19.628665 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:53:19.628867 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
12:53:19.897705 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.27 seconds
12:53:19.900839 [debug] [Thread-1  ]: finished collecting timing info
12:53:19.901076 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
12:53:20.103694 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'da8ed36b-cc12-49f7-8fa7-df42e439473f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ab4da00>]}
12:53:20.104193 [info ] [Thread-1  ]: 2 of 6 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 3.28s]
12:53:20.104518 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
12:53:20.104694 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
12:53:20.104984 [info ] [Thread-1  ]: 3 of 6 START table model dbt.first_model........................................ [RUN]
12:53:20.105494 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
12:53:20.105646 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
12:53:20.105789 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
12:53:20.109174 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
12:53:20.109920 [debug] [Thread-1  ]: finished collecting timing info
12:53:20.110105 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
12:53:20.119010 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
12:53:20.120069 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
12:53:20.120211 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *, True as first_variable
from source_data
where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
12:53:20.120330 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:53:21.881709 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.76 seconds
12:53:21.885268 [debug] [Thread-1  ]: finished collecting timing info
12:53:21.885729 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
12:53:22.122921 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'da8ed36b-cc12-49f7-8fa7-df42e439473f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aa16340>]}
12:53:22.123575 [info ] [Thread-1  ]: 3 of 6 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 2.02s]
12:53:22.123993 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
12:53:22.124276 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
12:53:22.124591 [info ] [Thread-1  ]: 4 of 6 START table model dbt.snowflake_cumulative_sales......................... [RUN]
12:53:22.125080 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
12:53:22.125389 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
12:53:22.125778 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
12:53:22.127848 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
12:53:22.128669 [debug] [Thread-1  ]: finished collecting timing info
12:53:22.128867 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
12:53:22.131371 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
12:53:22.132328 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
12:53:22.132498 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
12:53:22.132643 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:53:23.701730 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.57 seconds
12:53:23.705156 [debug] [Thread-1  ]: finished collecting timing info
12:53:23.705412 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
12:53:23.924966 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'da8ed36b-cc12-49f7-8fa7-df42e439473f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ac0fd30>]}
12:53:23.925919 [info ] [Thread-1  ]: 4 of 6 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 1.80s]
12:53:23.926221 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
12:53:23.926338 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
12:53:23.926452 [info ] [Thread-1  ]: 5 of 6 START table model dbt.snowflake_customer_purchases....................... [RUN]
12:53:23.926702 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
12:53:23.926781 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
12:53:23.926860 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
12:53:23.927650 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
12:53:23.928397 [debug] [Thread-1  ]: finished collecting timing info
12:53:23.928680 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
12:53:23.931851 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
12:53:23.933173 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
12:53:23.933367 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
12:53:23.933525 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:53:25.828813 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.9 seconds
12:53:25.831548 [debug] [Thread-1  ]: finished collecting timing info
12:53:25.832011 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
12:53:26.077021 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'da8ed36b-cc12-49f7-8fa7-df42e439473f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ac12b50>]}
12:53:26.077774 [info ] [Thread-1  ]: 5 of 6 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.15s]
12:53:26.078181 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
12:53:26.078433 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
12:53:26.078902 [info ] [Thread-1  ]: 6 of 6 START table model dbt.my_second_dbt_model................................ [RUN]
12:53:26.079437 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
12:53:26.079620 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
12:53:26.079789 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
12:53:26.082788 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
12:53:26.083416 [debug] [Thread-1  ]: finished collecting timing info
12:53:26.083598 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
12:53:26.086111 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
12:53:26.087002 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
12:53:26.087168 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
union all
select 7 as id, True as first_variable
      );
12:53:26.087321 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:53:27.385385 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.3 seconds
12:53:27.388204 [debug] [Thread-1  ]: finished collecting timing info
12:53:27.388670 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
12:53:27.626164 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'da8ed36b-cc12-49f7-8fa7-df42e439473f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ac0ff70>]}
12:53:27.626946 [info ] [Thread-1  ]: 6 of 6 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.55s]
12:53:27.627409 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
12:53:27.628821 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:53:27.629401 [info ] [MainThread]: 
12:53:27.629769 [info ] [MainThread]: Finished running 2 incremental models, 4 table models in 18.11s.
12:53:27.630084 [debug] [MainThread]: Connection 'master' was properly closed.
12:53:27.630254 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
12:53:27.636984 [info ] [MainThread]: 
12:53:27.637392 [info ] [MainThread]: [32mCompleted successfully[0m
12:53:27.637711 [info ] [MainThread]: 
12:53:27.637946 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
12:53:27.638262 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a8f3b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a8f8f40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10abcf280>]}


============================== 2022-05-13 12:53:31.690788 | f5f5cdad-3550-4e7b-b3ab-70463e0bcb5f ==============================
12:53:31.690788 [info ] [MainThread]: Running with dbt=1.0.1
12:53:31.691185 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, store_failures=False, indirect_selection='eager', threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.test.TestTask'>, which='test', rpc_method='test')
12:53:31.691333 [debug] [MainThread]: Tracking: tracking
12:53:31.691557 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1134d3070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1134d31c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1134d3d60>]}
12:53:31.735060 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
12:53:31.735209 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
12:53:31.738439 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f5f5cdad-3550-4e7b-b3ab-70463e0bcb5f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11348f100>]}
12:53:31.741841 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f5f5cdad-3550-4e7b-b3ab-70463e0bcb5f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1129b4dc0>]}
12:53:31.741977 [info ] [MainThread]: Found 6 models, 9 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
12:53:31.742772 [info ] [MainThread]: 
12:53:31.742980 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:53:31.743476 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
12:53:31.749428 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
12:53:31.749544 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
12:53:31.749613 [debug] [ThreadPool]: Opening a new connection, currently in state init
12:53:32.637155 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 0.89 seconds
12:53:32.639830 [debug] [ThreadPool]: On list_analytics_dbt: Close
12:53:32.959954 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
12:53:32.960678 [info ] [MainThread]: 
12:53:32.965043 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_my_first_dbt_model_id.5fb22c2710
12:53:32.965405 [info ] [Thread-1  ]: 1 of 9 START test not_null_my_first_dbt_model_id................................ [RUN]
12:53:32.965933 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_my_first_dbt_model_id.5fb22c2710"
12:53:32.966104 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_my_first_dbt_model_id.5fb22c2710
12:53:32.966273 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_my_first_dbt_model_id.5fb22c2710
12:53:32.977628 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_my_first_dbt_model_id.5fb22c2710"
12:53:32.979193 [debug] [Thread-1  ]: finished collecting timing info
12:53:32.979348 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_my_first_dbt_model_id.5fb22c2710
12:53:32.992515 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_my_first_dbt_model_id.5fb22c2710"
12:53:32.993316 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_my_first_dbt_model_id.5fb22c2710"
12:53:32.993452 [debug] [Thread-1  ]: On test.learn_dbt.not_null_my_first_dbt_model_id.5fb22c2710: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_my_first_dbt_model_id.5fb22c2710"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.first_model
where id is null



      
    ) dbt_internal_test
12:53:32.993551 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:53:33.915858 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.92 seconds
12:53:33.919959 [debug] [Thread-1  ]: finished collecting timing info
12:53:33.920369 [debug] [Thread-1  ]: On test.learn_dbt.not_null_my_first_dbt_model_id.5fb22c2710: Close
12:53:34.098869 [info ] [Thread-1  ]: 1 of 9 PASS not_null_my_first_dbt_model_id...................................... [[32mPASS[0m in 1.13s]
12:53:34.099481 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_my_first_dbt_model_id.5fb22c2710
12:53:34.099757 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
12:53:34.100079 [info ] [Thread-1  ]: 2 of 9 START test not_null_my_second_dbt_model_id............................... [RUN]
12:53:34.100724 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"
12:53:34.101016 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
12:53:34.101234 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
12:53:34.104677 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"
12:53:34.105269 [debug] [Thread-1  ]: finished collecting timing info
12:53:34.105402 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
12:53:34.106700 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"
12:53:34.107402 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"
12:53:34.107524 [debug] [Thread-1  ]: On test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.my_second_dbt_model
where id is null



      
    ) dbt_internal_test
12:53:34.107636 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:53:35.199460 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.09 seconds
12:53:35.202309 [debug] [Thread-1  ]: finished collecting timing info
12:53:35.202731 [debug] [Thread-1  ]: On test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778: Close
12:53:35.593528 [info ] [Thread-1  ]: 2 of 9 PASS not_null_my_second_dbt_model_id..................................... [[32mPASS[0m in 1.49s]
12:53:35.594513 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
12:53:35.595039 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
12:53:35.595475 [info ] [Thread-1  ]: 3 of 9 START test not_null_snowflake_cumulative_sales_o_orderdate............... [RUN]
12:53:35.596165 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
12:53:35.596420 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
12:53:35.596650 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
12:53:35.601534 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
12:53:35.602404 [debug] [Thread-1  ]: finished collecting timing info
12:53:35.602618 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
12:53:35.605010 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
12:53:35.606011 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
12:53:35.606176 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.snowflake_cumulative_sales
where o_orderdate is null



      
    ) dbt_internal_test
12:53:35.606320 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:53:36.766409 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.16 seconds
12:53:36.772325 [debug] [Thread-1  ]: finished collecting timing info
12:53:36.772859 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856: Close
12:53:37.061716 [info ] [Thread-1  ]: 3 of 9 PASS not_null_snowflake_cumulative_sales_o_orderdate..................... [[32mPASS[0m in 1.47s]
12:53:37.062930 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
12:53:37.063275 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
12:53:37.063619 [info ] [Thread-1  ]: 4 of 9 START test not_null_snowflake_customer_purchases_c_custkey............... [RUN]
12:53:37.064297 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
12:53:37.064508 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
12:53:37.064708 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
12:53:37.069506 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
12:53:37.070278 [debug] [Thread-1  ]: finished collecting timing info
12:53:37.070460 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
12:53:37.072715 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
12:53:37.073728 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
12:53:37.073891 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.snowflake_customer_purchases
where c_custkey is null



      
    ) dbt_internal_test
12:53:37.074033 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:53:37.924046 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.85 seconds
12:53:37.926814 [debug] [Thread-1  ]: finished collecting timing info
12:53:37.927130 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502: Close
12:53:38.216511 [info ] [Thread-1  ]: 4 of 9 PASS not_null_snowflake_customer_purchases_c_custkey..................... [[32mPASS[0m in 1.15s]
12:53:38.217119 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
12:53:38.217379 [debug] [Thread-1  ]: Began running node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
12:53:38.217694 [info ] [Thread-1  ]: 5 of 9 START test relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ [RUN]
12:53:38.218334 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
12:53:38.218544 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
12:53:38.218737 [debug] [Thread-1  ]: Compiling test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
12:53:38.229352 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
12:53:38.230123 [debug] [Thread-1  ]: finished collecting timing info
12:53:38.230292 [debug] [Thread-1  ]: Began executing node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
12:53:38.232178 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
12:53:38.233382 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
12:53:38.233579 [debug] [Thread-1  ]: On test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select id as from_field
    from analytics.dbt.my_second_dbt_model
    where id is not null
),

parent as (
    select id as to_field
    from analytics.dbt.first_model
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
12:53:38.233726 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:53:39.157012 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.92 seconds
12:53:39.159469 [debug] [Thread-1  ]: finished collecting timing info
12:53:39.159821 [debug] [Thread-1  ]: On test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: Close
12:53:39.347609 [error] [Thread-1  ]: 5 of 9 FAIL 1 relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_. [[31mFAIL 1[0m in 1.13s]
12:53:39.348102 [debug] [Thread-1  ]: Finished running node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
12:53:39.348258 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
12:53:39.348478 [info ] [Thread-1  ]: 6 of 9 START test unique_my_first_dbt_model_id.................................. [RUN]
12:53:39.348843 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
12:53:39.348975 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
12:53:39.349097 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
12:53:39.355424 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
12:53:39.356016 [debug] [Thread-1  ]: finished collecting timing info
12:53:39.356171 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
12:53:39.357952 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
12:53:39.359065 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
12:53:39.359359 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.first_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
12:53:39.359511 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:53:39.989008 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.63 seconds
12:53:39.992280 [debug] [Thread-1  ]: finished collecting timing info
12:53:39.992684 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_first_dbt_model_id.16e066b321: Close
12:53:40.361342 [info ] [Thread-1  ]: 6 of 9 PASS unique_my_first_dbt_model_id........................................ [[32mPASS[0m in 1.01s]
12:53:40.361983 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
12:53:40.362203 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
12:53:40.362609 [info ] [Thread-1  ]: 7 of 9 START test unique_my_second_dbt_model_id................................. [RUN]
12:53:40.363145 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
12:53:40.363313 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
12:53:40.363473 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
12:53:40.367727 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
12:53:40.368365 [debug] [Thread-1  ]: finished collecting timing info
12:53:40.368532 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
12:53:40.370715 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
12:53:40.371804 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
12:53:40.371971 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.my_second_dbt_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
12:53:40.372117 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:53:41.320565 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.95 seconds
12:53:41.324352 [debug] [Thread-1  ]: finished collecting timing info
12:53:41.324666 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493: Close
12:53:41.500391 [info ] [Thread-1  ]: 7 of 9 PASS unique_my_second_dbt_model_id....................................... [[32mPASS[0m in 1.14s]
12:53:41.501530 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
12:53:41.501865 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
12:53:41.502198 [info ] [Thread-1  ]: 8 of 9 START test unique_snowflake_cumulative_sales_o_orderdate................. [RUN]
12:53:41.502763 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
12:53:41.502973 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
12:53:41.503170 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
12:53:41.508021 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
12:53:41.508609 [debug] [Thread-1  ]: finished collecting timing info
12:53:41.508783 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
12:53:41.511008 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
12:53:41.512198 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
12:53:41.512431 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    o_orderdate as unique_field,
    count(*) as n_records

from analytics.dbt.snowflake_cumulative_sales
where o_orderdate is not null
group by o_orderdate
having count(*) > 1



      
    ) dbt_internal_test
12:53:41.512630 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:53:43.056064 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.54 seconds
12:53:43.058775 [debug] [Thread-1  ]: finished collecting timing info
12:53:43.059139 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed: Close
12:53:43.351762 [info ] [Thread-1  ]: 8 of 9 PASS unique_snowflake_cumulative_sales_o_orderdate....................... [[32mPASS[0m in 1.85s]
12:53:43.353454 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
12:53:43.353713 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
12:53:43.353907 [info ] [Thread-1  ]: 9 of 9 START test unique_snowflake_customer_purchases_c_custkey................. [RUN]
12:53:43.354464 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
12:53:43.354667 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
12:53:43.355254 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
12:53:43.360382 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
12:53:43.361087 [debug] [Thread-1  ]: finished collecting timing info
12:53:43.361273 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
12:53:43.363412 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
12:53:43.364516 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
12:53:43.364681 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    c_custkey as unique_field,
    count(*) as n_records

from analytics.dbt.snowflake_customer_purchases
where c_custkey is not null
group by c_custkey
having count(*) > 1



      
    ) dbt_internal_test
12:53:43.364827 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:53:44.181606 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.82 seconds
12:53:44.185440 [debug] [Thread-1  ]: finished collecting timing info
12:53:44.185736 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f: Close
12:53:44.490884 [info ] [Thread-1  ]: 9 of 9 PASS unique_snowflake_customer_purchases_c_custkey....................... [[32mPASS[0m in 1.14s]
12:53:44.491884 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
12:53:44.494118 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:53:44.494763 [info ] [MainThread]: 
12:53:44.495139 [info ] [MainThread]: Finished running 9 tests in 12.75s.
12:53:44.495450 [debug] [MainThread]: Connection 'master' was properly closed.
12:53:44.495616 [debug] [MainThread]: Connection 'test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f' was properly closed.
12:53:44.502621 [info ] [MainThread]: 
12:53:44.502978 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
12:53:44.503271 [info ] [MainThread]: 
12:53:44.503506 [error] [MainThread]: [31mFailure in test relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ (models/example/schema.yml)[0m
12:53:44.504020 [error] [MainThread]:   Got 1 result, configured to fail if != 0
12:53:44.504429 [info ] [MainThread]: 
12:53:44.504693 [info ] [MainThread]:   compiled SQL at target/compiled/learn_dbt/models/example/schema.yml/relationships_my_second_dbt_mo_160f86f0431c50a9f09003e4d3e6dceb.sql
12:53:44.504952 [info ] [MainThread]: 
12:53:44.505172 [info ] [MainThread]: Done. PASS=8 WARN=0 ERROR=1 SKIP=0 TOTAL=9
12:53:44.505450 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11499de50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1134b0970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1168c7340>]}


============================== 2022-05-13 13:05:49.834436 | 469b18c5-b0f8-4334-a76f-246ce3fdd2fe ==============================
13:05:49.834436 [info ] [MainThread]: Running with dbt=1.0.1
13:05:49.834947 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
13:05:49.835084 [debug] [MainThread]: Tracking: tracking
13:05:49.835347 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1118896a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1118895b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111889250>]}
13:05:49.883933 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 2 files changed.
13:05:49.884269 [debug] [MainThread]: Partial parsing: added file: learn_dbt://tests/assert_under_10_percent_null.sql
13:05:49.884483 [debug] [MainThread]: Partial parsing: update schema file: learn_dbt://models/example/schema.yml
13:05:49.884578 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/my_first_dbt_model.sql
13:05:49.890596 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
13:05:49.897774 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
13:05:49.916011 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '469b18c5-b0f8-4334-a76f-246ce3fdd2fe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111af5fa0>]}
13:05:49.919045 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '469b18c5-b0f8-4334-a76f-246ce3fdd2fe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b2a580>]}
13:05:49.919184 [info ] [MainThread]: Found 6 models, 9 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
13:05:49.919918 [info ] [MainThread]: 
13:05:49.920117 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:05:49.920545 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
13:05:49.926492 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
13:05:49.926591 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
13:05:49.926653 [debug] [ThreadPool]: Opening a new connection, currently in state init
13:05:51.034014 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.11 seconds
13:05:51.036399 [debug] [ThreadPool]: On list_analytics: Close
13:05:51.229914 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
13:05:51.238546 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
13:05:51.238806 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
13:05:51.238941 [debug] [ThreadPool]: Opening a new connection, currently in state closed
13:05:52.238878 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1.0 seconds
13:05:52.241811 [debug] [ThreadPool]: On list_analytics_dbt: Close
13:05:52.475735 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
13:05:52.476253 [info ] [MainThread]: 
13:05:52.480632 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
13:05:52.481388 [info ] [Thread-1  ]: 1 of 6 START incremental model dbt.dates........................................ [RUN]
13:05:52.481910 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
13:05:52.482067 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
13:05:52.482222 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
13:05:52.492489 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
13:05:52.493483 [debug] [Thread-1  ]: finished collecting timing info
13:05:52.493682 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
13:05:52.525158 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:05:52.525356 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
13:05:52.525441 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:05:54.176758 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.65 seconds
13:05:54.189045 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:05:54.189312 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
13:05:54.292377 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.1 seconds
13:05:54.300579 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:05:54.300896 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
13:05:54.445705 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.14 seconds
13:05:54.456223 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:05:54.456489 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
13:05:54.610735 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.15 seconds
13:05:54.636013 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
13:05:54.638316 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:05:54.638448 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
13:05:54.768611 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.13 seconds
13:05:54.769583 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:05:54.769810 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
13:05:55.056013 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.29 seconds
13:05:55.056621 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:05:55.056807 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
13:05:55.397468 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.34 seconds
13:05:55.406641 [debug] [Thread-1  ]: finished collecting timing info
13:05:55.406898 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
13:05:55.622071 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '469b18c5-b0f8-4334-a76f-246ce3fdd2fe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b2a520>]}
13:05:55.622415 [info ] [Thread-1  ]: 1 of 6 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 3.14s]
13:05:55.622632 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
13:05:55.622754 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
13:05:55.623004 [info ] [Thread-1  ]: 2 of 6 START incremental model dbt.incremental_time............................. [RUN]
13:05:55.623359 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
13:05:55.623469 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
13:05:55.623569 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
13:05:55.626323 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
13:05:55.627152 [debug] [Thread-1  ]: finished collecting timing info
13:05:55.627316 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
13:05:55.629626 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:05:55.629742 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
13:05:55.629822 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:05:57.115483 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.49 seconds
13:05:57.117569 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:05:57.117679 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
13:05:57.321961 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.2 seconds
13:05:57.327507 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:05:57.327846 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
13:05:57.431484 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
13:05:57.434304 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:05:57.434455 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
13:05:57.588450 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.15 seconds
13:05:57.594617 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
13:05:57.597066 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:05:57.597272 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
13:05:57.732831 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.14 seconds
13:05:57.733541 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:05:57.734392 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
13:05:58.459723 [debug] [Thread-1  ]: SQL status: SUCCESS 759 in 0.72 seconds
13:05:58.460524 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:05:58.461015 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
13:05:58.766910 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.31 seconds
13:05:58.768671 [debug] [Thread-1  ]: finished collecting timing info
13:05:58.768888 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
13:05:58.970122 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '469b18c5-b0f8-4334-a76f-246ce3fdd2fe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112a50220>]}
13:05:58.971084 [info ] [Thread-1  ]: 2 of 6 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 3.35s]
13:05:58.971710 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
13:05:58.971967 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
13:05:58.972393 [info ] [Thread-1  ]: 3 of 6 START table model dbt.first_model........................................ [RUN]
13:05:58.973320 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
13:05:58.973550 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
13:05:58.973749 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
13:05:58.978064 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
13:05:58.978858 [debug] [Thread-1  ]: finished collecting timing info
13:05:58.979030 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
13:05:58.988064 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
13:05:58.989007 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
13:05:58.989139 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id

)

select *, True as first_variable
from source_data
where id >= 1

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
13:05:58.989248 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:06:00.084650 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.1 seconds
13:06:00.088253 [debug] [Thread-1  ]: finished collecting timing info
13:06:00.088558 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
13:06:00.273159 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '469b18c5-b0f8-4334-a76f-246ce3fdd2fe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112a62790>]}
13:06:00.273764 [info ] [Thread-1  ]: 3 of 6 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 1.30s]
13:06:00.274137 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
13:06:00.274327 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
13:06:00.274793 [info ] [Thread-1  ]: 4 of 6 START table model dbt.snowflake_cumulative_sales......................... [RUN]
13:06:00.275668 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
13:06:00.275852 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
13:06:00.276001 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
13:06:00.277436 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
13:06:00.278057 [debug] [Thread-1  ]: finished collecting timing info
13:06:00.278222 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
13:06:00.280574 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
13:06:00.281585 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
13:06:00.281748 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
13:06:00.281880 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:06:02.104617 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.82 seconds
13:06:02.107080 [debug] [Thread-1  ]: finished collecting timing info
13:06:02.107380 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
13:06:02.297276 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '469b18c5-b0f8-4334-a76f-246ce3fdd2fe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111f373a0>]}
13:06:02.298655 [info ] [Thread-1  ]: 4 of 6 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 2.02s]
13:06:02.299031 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
13:06:02.299223 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
13:06:02.299579 [info ] [Thread-1  ]: 5 of 6 START table model dbt.snowflake_customer_purchases....................... [RUN]
13:06:02.300135 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
13:06:02.300318 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
13:06:02.300486 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
13:06:02.302092 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
13:06:02.302783 [debug] [Thread-1  ]: finished collecting timing info
13:06:02.302939 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
13:06:02.306007 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
13:06:02.306669 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
13:06:02.306765 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
13:06:02.306850 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:06:04.373365 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.07 seconds
13:06:04.377045 [debug] [Thread-1  ]: finished collecting timing info
13:06:04.377409 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
13:06:04.666534 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '469b18c5-b0f8-4334-a76f-246ce3fdd2fe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112adce20>]}
13:06:04.667184 [info ] [Thread-1  ]: 5 of 6 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.37s]
13:06:04.667609 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
13:06:04.667843 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
13:06:04.668251 [info ] [Thread-1  ]: 6 of 6 START table model dbt.my_second_dbt_model................................ [RUN]
13:06:04.668958 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
13:06:04.669217 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
13:06:04.669430 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
13:06:04.672739 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
13:06:04.673596 [debug] [Thread-1  ]: finished collecting timing info
13:06:04.673780 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
13:06:04.676378 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
13:06:04.677338 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
13:06:04.677505 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
union all
select 7 as id, True as first_variable
      );
13:06:04.677635 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:06:06.233876 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.56 seconds
13:06:06.235795 [debug] [Thread-1  ]: finished collecting timing info
13:06:06.236030 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
13:06:06.391025 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '469b18c5-b0f8-4334-a76f-246ce3fdd2fe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111f379a0>]}
13:06:06.394313 [info ] [Thread-1  ]: 6 of 6 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.72s]
13:06:06.394995 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
13:06:06.396375 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:06:06.396885 [info ] [MainThread]: 
13:06:06.397186 [info ] [MainThread]: Finished running 2 incremental models, 4 table models in 16.48s.
13:06:06.397437 [debug] [MainThread]: Connection 'master' was properly closed.
13:06:06.397567 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
13:06:06.403800 [info ] [MainThread]: 
13:06:06.404026 [info ] [MainThread]: [32mCompleted successfully[0m
13:06:06.404193 [info ] [MainThread]: 
13:06:06.404317 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
13:06:06.404511 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110428970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10542b610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111f71760>]}


============================== 2022-05-13 13:06:16.684992 | c1490610-309a-4928-87a9-0aeb4bb34692 ==============================
13:06:16.684992 [info ] [MainThread]: Running with dbt=1.0.1
13:06:16.685385 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, store_failures=False, indirect_selection='eager', threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.test.TestTask'>, which='test', rpc_method='test')
13:06:16.685516 [debug] [MainThread]: Tracking: tracking
13:06:16.685752 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1084d30a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1084d3b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1084d33a0>]}
13:06:16.731736 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
13:06:16.731912 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
13:06:16.735521 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c1490610-309a-4928-87a9-0aeb4bb34692', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10849d100>]}
13:06:16.739132 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c1490610-309a-4928-87a9-0aeb4bb34692', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106100070>]}
13:06:16.739291 [info ] [MainThread]: Found 6 models, 9 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
13:06:16.740097 [info ] [MainThread]: 
13:06:16.740317 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:06:16.740809 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
13:06:16.747036 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
13:06:16.747186 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
13:06:16.747252 [debug] [ThreadPool]: Opening a new connection, currently in state init
13:06:17.752612 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1.01 seconds
13:06:17.756065 [debug] [ThreadPool]: On list_analytics_dbt: Close
13:06:17.956293 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
13:06:17.957042 [info ] [MainThread]: 
13:06:17.968617 [debug] [Thread-1  ]: Began running node test.learn_dbt.assert_under_10_percent_null
13:06:17.968895 [info ] [Thread-1  ]: 1 of 9 START test assert_under_10_percent_null.................................. [RUN]
13:06:17.969332 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.assert_under_10_percent_null"
13:06:17.969439 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.assert_under_10_percent_null
13:06:17.969535 [debug] [Thread-1  ]: Compiling test.learn_dbt.assert_under_10_percent_null
13:06:17.971177 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.assert_under_10_percent_null"
13:06:17.971599 [debug] [Thread-1  ]: finished collecting timing info
13:06:17.971696 [debug] [Thread-1  ]: Began executing node test.learn_dbt.assert_under_10_percent_null
13:06:17.981883 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.assert_under_10_percent_null"
13:06:17.982625 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.assert_under_10_percent_null"
13:06:17.982724 [debug] [Thread-1  ]: On test.learn_dbt.assert_under_10_percent_null: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.assert_under_10_percent_null"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      select sum (case when id is null then 1 else 0 end) / count(*) as total_nulls
from analytics.dbt.first_model
having sum (case when id is null then 1 else 0 end) / count(*) > .1
      
    ) dbt_internal_test
13:06:17.982835 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:06:18.766693 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.78 seconds
13:06:18.771596 [debug] [Thread-1  ]: finished collecting timing info
13:06:18.771996 [debug] [Thread-1  ]: On test.learn_dbt.assert_under_10_percent_null: Close
13:06:18.957477 [info ] [Thread-1  ]: 1 of 9 PASS assert_under_10_percent_null........................................ [[32mPASS[0m in 0.99s]
13:06:18.958563 [debug] [Thread-1  ]: Finished running node test.learn_dbt.assert_under_10_percent_null
13:06:18.958877 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
13:06:18.959076 [info ] [Thread-1  ]: 2 of 9 START test not_null_my_second_dbt_model_id............................... [RUN]
13:06:18.959637 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"
13:06:18.959833 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
13:06:18.960127 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
13:06:18.978261 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"
13:06:18.979723 [debug] [Thread-1  ]: finished collecting timing info
13:06:18.979906 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
13:06:18.981334 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"
13:06:18.982092 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"
13:06:18.982203 [debug] [Thread-1  ]: On test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.my_second_dbt_model
where id is null



      
    ) dbt_internal_test
13:06:18.982292 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:06:19.737069 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.75 seconds
13:06:19.739752 [debug] [Thread-1  ]: finished collecting timing info
13:06:19.740076 [debug] [Thread-1  ]: On test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778: Close
13:06:19.963577 [info ] [Thread-1  ]: 2 of 9 PASS not_null_my_second_dbt_model_id..................................... [[32mPASS[0m in 1.00s]
13:06:19.964422 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
13:06:19.964688 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
13:06:19.965259 [info ] [Thread-1  ]: 3 of 9 START test not_null_snowflake_cumulative_sales_o_orderdate............... [RUN]
13:06:19.966582 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
13:06:19.967516 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
13:06:19.967882 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
13:06:19.977071 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
13:06:19.977661 [debug] [Thread-1  ]: finished collecting timing info
13:06:19.977799 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
13:06:19.979106 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
13:06:19.979628 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
13:06:19.979714 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.snowflake_cumulative_sales
where o_orderdate is null



      
    ) dbt_internal_test
13:06:19.979791 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:06:20.676035 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.7 seconds
13:06:20.682440 [debug] [Thread-1  ]: finished collecting timing info
13:06:20.683659 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856: Close
13:06:20.948637 [info ] [Thread-1  ]: 3 of 9 PASS not_null_snowflake_cumulative_sales_o_orderdate..................... [[32mPASS[0m in 0.98s]
13:06:20.949809 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
13:06:20.950121 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
13:06:20.951089 [info ] [Thread-1  ]: 4 of 9 START test not_null_snowflake_customer_purchases_c_custkey............... [RUN]
13:06:20.952101 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
13:06:20.952534 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
13:06:20.952856 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
13:06:20.963667 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
13:06:20.964364 [debug] [Thread-1  ]: finished collecting timing info
13:06:20.964512 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
13:06:20.965783 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
13:06:20.966349 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
13:06:20.966438 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.snowflake_customer_purchases
where c_custkey is null



      
    ) dbt_internal_test
13:06:20.966518 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:06:21.951583 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.99 seconds
13:06:21.955587 [debug] [Thread-1  ]: finished collecting timing info
13:06:21.956010 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502: Close
13:06:22.155223 [info ] [Thread-1  ]: 4 of 9 PASS not_null_snowflake_customer_purchases_c_custkey..................... [[32mPASS[0m in 1.20s]
13:06:22.156174 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
13:06:22.156466 [debug] [Thread-1  ]: Began running node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
13:06:22.156697 [info ] [Thread-1  ]: 5 of 9 START test relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ [RUN]
13:06:22.158873 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
13:06:22.159568 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
13:06:22.159925 [debug] [Thread-1  ]: Compiling test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
13:06:22.177643 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
13:06:22.178178 [debug] [Thread-1  ]: finished collecting timing info
13:06:22.178282 [debug] [Thread-1  ]: Began executing node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
13:06:22.179392 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
13:06:22.180161 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
13:06:22.180255 [debug] [Thread-1  ]: On test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select id as from_field
    from analytics.dbt.my_second_dbt_model
    where id is not null
),

parent as (
    select id as to_field
    from analytics.dbt.first_model
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
13:06:22.180332 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:06:23.180359 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.0 seconds
13:06:23.184726 [debug] [Thread-1  ]: finished collecting timing info
13:06:23.185703 [debug] [Thread-1  ]: On test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: Close
13:06:23.537006 [error] [Thread-1  ]: 5 of 9 FAIL 1 relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_. [[31mFAIL 1[0m in 1.38s]
13:06:23.537941 [debug] [Thread-1  ]: Finished running node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
13:06:23.538830 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
13:06:23.539088 [info ] [Thread-1  ]: 6 of 9 START test unique_my_first_dbt_model_id.................................. [RUN]
13:06:23.539704 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
13:06:23.540017 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
13:06:23.540474 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
13:06:23.555396 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
13:06:23.557159 [debug] [Thread-1  ]: finished collecting timing info
13:06:23.557281 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
13:06:23.558893 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
13:06:23.560204 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
13:06:23.560408 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.first_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
13:06:23.560596 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:06:24.204014 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.64 seconds
13:06:24.207492 [debug] [Thread-1  ]: finished collecting timing info
13:06:24.207987 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_first_dbt_model_id.16e066b321: Close
13:06:24.422261 [info ] [Thread-1  ]: 6 of 9 PASS unique_my_first_dbt_model_id........................................ [[32mPASS[0m in 0.88s]
13:06:24.423266 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
13:06:24.440637 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:06:24.441062 [info ] [Thread-1  ]: 7 of 9 START test unique_my_second_dbt_model_id................................. [RUN]
13:06:24.442290 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
13:06:24.442584 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:06:24.442809 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:06:24.446392 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
13:06:24.447224 [debug] [Thread-1  ]: finished collecting timing info
13:06:24.447362 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:06:24.448547 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
13:06:24.449367 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
13:06:24.449466 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.my_second_dbt_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
13:06:24.449551 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:06:26.679550 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.23 seconds
13:06:26.682564 [debug] [Thread-1  ]: finished collecting timing info
13:06:26.683014 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493: Close
13:06:27.083417 [info ] [Thread-1  ]: 7 of 9 PASS unique_my_second_dbt_model_id....................................... [[32mPASS[0m in 2.64s]
13:06:27.086376 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:06:27.086853 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
13:06:27.087060 [info ] [Thread-1  ]: 8 of 9 START test unique_snowflake_cumulative_sales_o_orderdate................. [RUN]
13:06:27.087743 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
13:06:27.087959 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
13:06:27.088215 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
13:06:27.099576 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
13:06:27.100271 [debug] [Thread-1  ]: finished collecting timing info
13:06:27.100461 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
13:06:27.101936 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
13:06:27.102688 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
13:06:27.102804 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    o_orderdate as unique_field,
    count(*) as n_records

from analytics.dbt.snowflake_cumulative_sales
where o_orderdate is not null
group by o_orderdate
having count(*) > 1



      
    ) dbt_internal_test
13:06:27.102893 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:06:27.943085 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.84 seconds
13:06:27.946874 [debug] [Thread-1  ]: finished collecting timing info
13:06:27.947463 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed: Close
13:06:28.291853 [info ] [Thread-1  ]: 8 of 9 PASS unique_snowflake_cumulative_sales_o_orderdate....................... [[32mPASS[0m in 1.20s]
13:06:28.292806 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
13:06:28.293074 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
13:06:28.293580 [info ] [Thread-1  ]: 9 of 9 START test unique_snowflake_customer_purchases_c_custkey................. [RUN]
13:06:28.294309 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
13:06:28.294684 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
13:06:28.295066 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
13:06:28.306691 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
13:06:28.307190 [debug] [Thread-1  ]: finished collecting timing info
13:06:28.307296 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
13:06:28.308442 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
13:06:28.309164 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
13:06:28.309261 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    c_custkey as unique_field,
    count(*) as n_records

from analytics.dbt.snowflake_customer_purchases
where c_custkey is not null
group by c_custkey
having count(*) > 1



      
    ) dbt_internal_test
13:06:28.309348 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:06:29.294701 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.99 seconds
13:06:29.297615 [debug] [Thread-1  ]: finished collecting timing info
13:06:29.298574 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f: Close
13:06:29.509774 [info ] [Thread-1  ]: 9 of 9 PASS unique_snowflake_customer_purchases_c_custkey....................... [[32mPASS[0m in 1.22s]
13:06:29.511173 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
13:06:29.515487 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:06:29.516230 [info ] [MainThread]: 
13:06:29.517018 [info ] [MainThread]: Finished running 9 tests in 12.78s.
13:06:29.517376 [debug] [MainThread]: Connection 'master' was properly closed.
13:06:29.517552 [debug] [MainThread]: Connection 'test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f' was properly closed.
13:06:29.526934 [info ] [MainThread]: 
13:06:29.527242 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
13:06:29.527431 [info ] [MainThread]: 
13:06:29.527578 [error] [MainThread]: [31mFailure in test relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ (models/example/schema.yml)[0m
13:06:29.527739 [error] [MainThread]:   Got 1 result, configured to fail if != 0
13:06:29.527873 [info ] [MainThread]: 
13:06:29.528006 [info ] [MainThread]:   compiled SQL at target/compiled/learn_dbt/models/example/schema.yml/relationships_my_second_dbt_mo_160f86f0431c50a9f09003e4d3e6dceb.sql
13:06:29.528157 [info ] [MainThread]: 
13:06:29.528288 [info ] [MainThread]: Done. PASS=8 WARN=0 ERROR=1 SKIP=0 TOTAL=9
13:06:29.528505 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107268040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10866f6a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108828670>]}


============================== 2022-05-13 13:09:30.153515 | a9c9256d-98b7-4ece-89c9-af85175eb0a8 ==============================
13:09:30.153515 [info ] [MainThread]: Running with dbt=1.0.1
13:09:30.154135 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
13:09:30.154247 [debug] [MainThread]: Tracking: tracking
13:09:30.154478 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1085b73a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1085b7370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1085b76d0>]}
13:09:30.200906 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
13:09:30.201246 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/my_first_dbt_model.sql
13:09:30.207409 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
13:09:30.214422 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
13:09:30.227852 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a9c9256d-98b7-4ece-89c9-af85175eb0a8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108562130>]}
13:09:30.230958 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a9c9256d-98b7-4ece-89c9-af85175eb0a8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107577ee0>]}
13:09:30.231101 [info ] [MainThread]: Found 6 models, 9 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
13:09:30.231856 [info ] [MainThread]: 
13:09:30.232061 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:09:30.232499 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
13:09:30.238274 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
13:09:30.238382 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
13:09:30.238451 [debug] [ThreadPool]: Opening a new connection, currently in state init
13:09:31.315273 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.08 seconds
13:09:31.317245 [debug] [ThreadPool]: On list_analytics: Close
13:09:31.506094 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
13:09:31.514973 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
13:09:31.515196 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
13:09:31.515349 [debug] [ThreadPool]: Opening a new connection, currently in state closed
13:09:32.471047 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 0.96 seconds
13:09:32.474374 [debug] [ThreadPool]: On list_analytics_dbt: Close
13:09:32.820087 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
13:09:32.820690 [info ] [MainThread]: 
13:09:32.825736 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
13:09:32.826379 [info ] [Thread-1  ]: 1 of 6 START incremental model dbt.dates........................................ [RUN]
13:09:32.826868 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
13:09:32.827034 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
13:09:32.827201 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
13:09:32.836441 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
13:09:32.837398 [debug] [Thread-1  ]: finished collecting timing info
13:09:32.837547 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
13:09:32.865913 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:09:32.866096 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
13:09:32.866180 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:09:34.911699 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.05 seconds
13:09:34.928674 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:09:34.929004 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
13:09:35.051971 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.12 seconds
13:09:35.059005 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:09:35.059328 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
13:09:35.182040 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.12 seconds
13:09:35.194490 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:09:35.194770 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
13:09:35.436535 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.24 seconds
13:09:35.463231 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
13:09:35.465671 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:09:35.465795 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
13:09:35.622327 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.16 seconds
13:09:35.622945 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:09:35.623148 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
13:09:36.007849 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.38 seconds
13:09:36.008428 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:09:36.008655 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
13:09:36.235935 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.23 seconds
13:09:36.250206 [debug] [Thread-1  ]: finished collecting timing info
13:09:36.250616 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
13:09:36.614969 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a9c9256d-98b7-4ece-89c9-af85175eb0a8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1073f4cd0>]}
13:09:36.615884 [info ] [Thread-1  ]: 1 of 6 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 3.79s]
13:09:36.616410 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
13:09:36.616812 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
13:09:36.617292 [info ] [Thread-1  ]: 2 of 6 START incremental model dbt.incremental_time............................. [RUN]
13:09:36.617893 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
13:09:36.618102 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
13:09:36.618308 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
13:09:36.622390 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
13:09:36.623946 [debug] [Thread-1  ]: finished collecting timing info
13:09:36.624140 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
13:09:36.627839 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:09:36.628122 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
13:09:36.628269 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:09:38.308029 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.68 seconds
13:09:38.311614 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:09:38.311861 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
13:09:38.418166 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.11 seconds
13:09:38.424272 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:09:38.424619 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
13:09:38.665037 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.24 seconds
13:09:38.671342 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:09:38.671588 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
13:09:38.769544 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
13:09:38.774419 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
13:09:38.776554 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:09:38.776794 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
13:09:38.974860 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.2 seconds
13:09:38.975596 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:09:38.975906 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
13:09:39.685899 [debug] [Thread-1  ]: SQL status: SUCCESS 221 in 0.71 seconds
13:09:39.686864 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:09:39.687093 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
13:09:40.025157 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.34 seconds
13:09:40.028022 [debug] [Thread-1  ]: finished collecting timing info
13:09:40.028477 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
13:09:40.237312 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a9c9256d-98b7-4ece-89c9-af85175eb0a8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1089a5b80>]}
13:09:40.238113 [info ] [Thread-1  ]: 2 of 6 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 3.62s]
13:09:40.238565 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
13:09:40.238805 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
13:09:40.239202 [info ] [Thread-1  ]: 3 of 6 START table model dbt.first_model........................................ [RUN]
13:09:40.239830 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
13:09:40.240046 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
13:09:40.240209 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
13:09:40.243922 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
13:09:40.244661 [debug] [Thread-1  ]: finished collecting timing info
13:09:40.244840 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
13:09:40.253793 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
13:09:40.254790 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
13:09:40.254920 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id

)

select * 
from source_data


/*
select *, True as first_variable
from source_data
where id >= 1
*/
      );
13:09:40.255027 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:09:41.988485 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.73 seconds
13:09:41.991457 [debug] [Thread-1  ]: finished collecting timing info
13:09:41.991902 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
13:09:42.461773 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a9c9256d-98b7-4ece-89c9-af85175eb0a8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1089a5fa0>]}
13:09:42.462553 [info ] [Thread-1  ]: 3 of 6 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 2.22s]
13:09:42.462997 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
13:09:42.463239 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
13:09:42.463523 [info ] [Thread-1  ]: 4 of 6 START table model dbt.snowflake_cumulative_sales......................... [RUN]
13:09:42.464099 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
13:09:42.464304 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
13:09:42.464979 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
13:09:42.466811 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
13:09:42.468291 [debug] [Thread-1  ]: finished collecting timing info
13:09:42.468482 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
13:09:42.470046 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
13:09:42.470769 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
13:09:42.470915 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
13:09:42.471002 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:09:44.074853 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.6 seconds
13:09:44.079311 [debug] [Thread-1  ]: finished collecting timing info
13:09:44.079687 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
13:09:44.461649 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a9c9256d-98b7-4ece-89c9-af85175eb0a8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108959070>]}
13:09:44.462475 [info ] [Thread-1  ]: 4 of 6 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 2.00s]
13:09:44.463037 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
13:09:44.463283 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
13:09:44.463691 [info ] [Thread-1  ]: 5 of 6 START table model dbt.snowflake_customer_purchases....................... [RUN]
13:09:44.464371 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
13:09:44.464586 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
13:09:44.464776 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
13:09:44.466506 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
13:09:44.467279 [debug] [Thread-1  ]: finished collecting timing info
13:09:44.467427 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
13:09:44.470006 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
13:09:44.471382 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
13:09:44.471557 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
13:09:44.471708 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:09:46.447410 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.98 seconds
13:09:46.450641 [debug] [Thread-1  ]: finished collecting timing info
13:09:46.451051 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
13:09:46.630663 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a9c9256d-98b7-4ece-89c9-af85175eb0a8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a7ff3d0>]}
13:09:46.631713 [info ] [Thread-1  ]: 5 of 6 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.17s]
13:09:46.632256 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
13:09:46.632521 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
13:09:46.633068 [info ] [Thread-1  ]: 6 of 6 START table model dbt.my_second_dbt_model................................ [RUN]
13:09:46.634019 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
13:09:46.634234 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
13:09:46.634413 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
13:09:46.637661 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
13:09:46.639502 [debug] [Thread-1  ]: finished collecting timing info
13:09:46.639775 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
13:09:46.642668 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
13:09:46.643521 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
13:09:46.643728 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
union all
select 7 as id, True as first_variable
      );
13:09:46.643822 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:09:47.670429 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a43d35-3201-9c86-0000-000120527279
13:09:47.670741 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 001789 (42601): SQL compilation error:
invalid number of result columns for set operator input branches, expected 1, got 2 in branch 2
13:09:47.670976 [debug] [Thread-1  ]: finished collecting timing info
13:09:47.671091 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
13:09:48.021432 [debug] [Thread-1  ]: Database Error in model my_second_dbt_model (models/example/my_second_dbt_model.sql)
  001789 (42601): SQL compilation error:
  invalid number of result columns for set operator input branches, expected 1, got 2 in branch 2
  compiled SQL at target/run/learn_dbt/models/example/my_second_dbt_model.sql
13:09:48.023936 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a9c9256d-98b7-4ece-89c9-af85175eb0a8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1088b4be0>]}
13:09:48.024637 [error] [Thread-1  ]: 6 of 6 ERROR creating table model dbt.my_second_dbt_model....................... [[31mERROR[0m in 1.39s]
13:09:48.025230 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
13:09:48.026694 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:09:48.027292 [info ] [MainThread]: 
13:09:48.027637 [info ] [MainThread]: Finished running 2 incremental models, 4 table models in 17.80s.
13:09:48.027934 [debug] [MainThread]: Connection 'master' was properly closed.
13:09:48.028092 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
13:09:48.035120 [info ] [MainThread]: 
13:09:48.035603 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
13:09:48.035901 [info ] [MainThread]: 
13:09:48.036099 [error] [MainThread]: [33mDatabase Error in model my_second_dbt_model (models/example/my_second_dbt_model.sql)[0m
13:09:48.036292 [error] [MainThread]:   001789 (42601): SQL compilation error:
13:09:48.036474 [error] [MainThread]:   invalid number of result columns for set operator input branches, expected 1, got 2 in branch 2
13:09:48.036652 [error] [MainThread]:   compiled SQL at target/run/learn_dbt/models/example/my_second_dbt_model.sql
13:09:48.036842 [info ] [MainThread]: 
13:09:48.037025 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=1 SKIP=0 TOTAL=6
13:09:48.037302 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10634e6a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1078b51c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1089a53a0>]}


============================== 2022-05-13 13:10:18.933707 | 7e577291-569d-4211-a3e2-bc6ce2548906 ==============================
13:10:18.933707 [info ] [MainThread]: Running with dbt=1.0.1
13:10:18.934076 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
13:10:18.934206 [debug] [MainThread]: Tracking: tracking
13:10:18.934446 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1066d3f70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1066d3c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1066d38b0>]}
13:10:18.975300 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
13:10:18.975626 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/my_second_dbt_model.sql
13:10:18.980791 [debug] [MainThread]: 1603: static parser failed on example/my_second_dbt_model.sql
13:10:18.987103 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_second_dbt_model.sql
13:10:19.008488 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7e577291-569d-4211-a3e2-bc6ce2548906', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106862f40>]}
13:10:19.011583 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7e577291-569d-4211-a3e2-bc6ce2548906', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1010ea160>]}
13:10:19.011725 [info ] [MainThread]: Found 6 models, 9 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
13:10:19.012485 [info ] [MainThread]: 
13:10:19.012695 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:10:19.013129 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
13:10:19.019015 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
13:10:19.019116 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
13:10:19.019179 [debug] [ThreadPool]: Opening a new connection, currently in state init
13:10:20.152815 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.13 seconds
13:10:20.155888 [debug] [ThreadPool]: On list_analytics: Close
13:10:20.361833 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
13:10:20.370439 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
13:10:20.370705 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
13:10:20.370869 [debug] [ThreadPool]: Opening a new connection, currently in state closed
13:10:21.159046 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 0.79 seconds
13:10:21.161784 [debug] [ThreadPool]: On list_analytics_dbt: Close
13:10:21.359053 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
13:10:21.359498 [info ] [MainThread]: 
13:10:21.362207 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
13:10:21.362817 [info ] [Thread-1  ]: 1 of 6 START incremental model dbt.dates........................................ [RUN]
13:10:21.363258 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
13:10:21.363405 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
13:10:21.363549 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
13:10:21.374119 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
13:10:21.374782 [debug] [Thread-1  ]: finished collecting timing info
13:10:21.374951 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
13:10:21.405174 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:10:21.405326 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
13:10:21.405411 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:10:23.026304 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.62 seconds
13:10:23.036745 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:10:23.037041 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
13:10:23.195778 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.16 seconds
13:10:23.204830 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:10:23.205217 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
13:10:23.295040 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.09 seconds
13:10:23.306026 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:10:23.306416 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
13:10:23.408620 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.1 seconds
13:10:23.432066 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
13:10:23.434387 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:10:23.434529 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
13:10:23.669540 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.23 seconds
13:10:23.672305 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:10:23.672650 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
13:10:24.920697 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 1.25 seconds
13:10:24.921925 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:10:24.922445 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
13:10:25.192907 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.27 seconds
13:10:25.202047 [debug] [Thread-1  ]: finished collecting timing info
13:10:25.202319 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
13:10:25.415295 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7e577291-569d-4211-a3e2-bc6ce2548906', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102d4e850>]}
13:10:25.416114 [info ] [Thread-1  ]: 1 of 6 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 4.05s]
13:10:25.416593 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
13:10:25.416872 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
13:10:25.417452 [info ] [Thread-1  ]: 2 of 6 START incremental model dbt.incremental_time............................. [RUN]
13:10:25.418179 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
13:10:25.418392 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
13:10:25.418583 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
13:10:25.422521 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
13:10:25.423215 [debug] [Thread-1  ]: finished collecting timing info
13:10:25.423393 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
13:10:25.427073 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:10:25.427261 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
13:10:25.427419 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:10:26.815051 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.39 seconds
13:10:26.820010 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:10:26.820390 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
13:10:26.931508 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.11 seconds
13:10:26.937431 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:10:26.937760 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
13:10:27.036029 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
13:10:27.040924 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:10:27.041139 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
13:10:27.869046 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.83 seconds
13:10:27.871653 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
13:10:27.872746 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:10:27.872845 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
13:10:28.067591 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.19 seconds
13:10:28.068184 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:10:28.068369 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
13:10:28.910775 [debug] [Thread-1  ]: SQL status: SUCCESS 49 in 0.84 seconds
13:10:28.911904 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:10:28.912235 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
13:10:29.306404 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.39 seconds
13:10:29.310299 [debug] [Thread-1  ]: finished collecting timing info
13:10:29.310707 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
13:10:30.084536 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7e577291-569d-4211-a3e2-bc6ce2548906', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106885070>]}
13:10:30.085527 [info ] [Thread-1  ]: 2 of 6 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 4.67s]
13:10:30.086096 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
13:10:30.086356 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
13:10:30.086646 [info ] [Thread-1  ]: 3 of 6 START table model dbt.first_model........................................ [RUN]
13:10:30.087433 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
13:10:30.087708 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
13:10:30.087929 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
13:10:30.092214 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
13:10:30.093020 [debug] [Thread-1  ]: finished collecting timing info
13:10:30.093204 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
13:10:30.102122 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
13:10:30.103118 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
13:10:30.103248 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id

)

select * 
from source_data


/*
select *, True as first_variable
from source_data
where id >= 1
*/
      );
13:10:30.103363 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:10:31.811630 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.71 seconds
13:10:31.815068 [debug] [Thread-1  ]: finished collecting timing info
13:10:31.815442 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
13:10:33.194705 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7e577291-569d-4211-a3e2-bc6ce2548906', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f85e80>]}
13:10:33.195868 [info ] [Thread-1  ]: 3 of 6 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 3.11s]
13:10:33.196418 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
13:10:33.196681 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
13:10:33.197124 [info ] [Thread-1  ]: 4 of 6 START table model dbt.snowflake_cumulative_sales......................... [RUN]
13:10:33.198121 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
13:10:33.198437 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
13:10:33.198806 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
13:10:33.200683 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
13:10:33.201327 [debug] [Thread-1  ]: finished collecting timing info
13:10:33.201495 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
13:10:33.203972 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
13:10:33.204914 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
13:10:33.205076 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
13:10:33.205218 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:10:34.680830 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.48 seconds
13:10:34.684306 [debug] [Thread-1  ]: finished collecting timing info
13:10:34.684680 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
13:10:34.935878 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7e577291-569d-4211-a3e2-bc6ce2548906', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106aa1340>]}
13:10:34.936635 [info ] [Thread-1  ]: 4 of 6 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 1.74s]
13:10:34.937084 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
13:10:34.937324 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
13:10:34.937727 [info ] [Thread-1  ]: 5 of 6 START table model dbt.snowflake_customer_purchases....................... [RUN]
13:10:34.938350 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
13:10:34.938572 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
13:10:34.938768 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
13:10:34.939975 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
13:10:34.940489 [debug] [Thread-1  ]: finished collecting timing info
13:10:34.940637 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
13:10:34.943132 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
13:10:34.944477 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
13:10:34.944662 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
13:10:34.944812 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:10:37.824218 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.88 seconds
13:10:37.828638 [debug] [Thread-1  ]: finished collecting timing info
13:10:37.829023 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
13:10:38.039063 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7e577291-569d-4211-a3e2-bc6ce2548906', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106fc5220>]}
13:10:38.039887 [info ] [Thread-1  ]: 5 of 6 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 3.10s]
13:10:38.040365 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
13:10:38.040610 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
13:10:38.041045 [info ] [Thread-1  ]: 6 of 6 START table model dbt.my_second_dbt_model................................ [RUN]
13:10:38.041675 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
13:10:38.041870 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
13:10:38.042059 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
13:10:38.045472 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
13:10:38.046100 [debug] [Thread-1  ]: finished collecting timing info
13:10:38.046265 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
13:10:38.048767 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
13:10:38.049606 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
13:10:38.049772 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
/*
union all
select 7 as id, True as first_variable
*/
      );
13:10:38.049922 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:10:39.636041 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.59 seconds
13:10:39.637207 [debug] [Thread-1  ]: finished collecting timing info
13:10:39.637348 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
13:10:39.931319 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7e577291-569d-4211-a3e2-bc6ce2548906', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106fdbdc0>]}
13:10:39.931860 [info ] [Thread-1  ]: 6 of 6 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.89s]
13:10:39.932127 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
13:10:39.933200 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:10:39.933764 [info ] [MainThread]: 
13:10:39.934109 [info ] [MainThread]: Finished running 2 incremental models, 4 table models in 20.92s.
13:10:39.934404 [debug] [MainThread]: Connection 'master' was properly closed.
13:10:39.934561 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
13:10:39.940875 [info ] [MainThread]: 
13:10:39.941168 [info ] [MainThread]: [32mCompleted successfully[0m
13:10:39.941449 [info ] [MainThread]: 
13:10:39.941680 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
13:10:39.941986 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106aa3df0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068cff70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f8e6d0>]}


============================== 2022-05-13 13:10:45.150973 | 0eeebcfc-7927-4ab9-a084-4dc7581caf98 ==============================
13:10:45.150973 [info ] [MainThread]: Running with dbt=1.0.1
13:10:45.151341 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, store_failures=False, indirect_selection='eager', threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.test.TestTask'>, which='test', rpc_method='test')
13:10:45.151487 [debug] [MainThread]: Tracking: tracking
13:10:45.151714 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1082d31c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1082d3dc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1082d3c10>]}
13:10:45.194320 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
13:10:45.194459 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
13:10:45.197547 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0eeebcfc-7927-4ab9-a084-4dc7581caf98', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10829d040>]}
13:10:45.201136 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0eeebcfc-7927-4ab9-a084-4dc7581caf98', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1071284c0>]}
13:10:45.201309 [info ] [MainThread]: Found 6 models, 9 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
13:10:45.202114 [info ] [MainThread]: 
13:10:45.202340 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:10:45.202857 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
13:10:45.208844 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
13:10:45.208959 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
13:10:45.209025 [debug] [ThreadPool]: Opening a new connection, currently in state init
13:10:46.424624 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1.22 seconds
13:10:46.427457 [debug] [ThreadPool]: On list_analytics_dbt: Close
13:10:47.021280 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
13:10:47.021567 [info ] [MainThread]: 
13:10:47.024644 [debug] [Thread-1  ]: Began running node test.learn_dbt.assert_under_10_percent_null
13:10:47.024813 [info ] [Thread-1  ]: 1 of 9 START test assert_under_10_percent_null.................................. [RUN]
13:10:47.025099 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.assert_under_10_percent_null"
13:10:47.025195 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.assert_under_10_percent_null
13:10:47.025281 [debug] [Thread-1  ]: Compiling test.learn_dbt.assert_under_10_percent_null
13:10:47.027521 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.assert_under_10_percent_null"
13:10:47.028200 [debug] [Thread-1  ]: finished collecting timing info
13:10:47.028397 [debug] [Thread-1  ]: Began executing node test.learn_dbt.assert_under_10_percent_null
13:10:47.044131 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.assert_under_10_percent_null"
13:10:47.045255 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.assert_under_10_percent_null"
13:10:47.045388 [debug] [Thread-1  ]: On test.learn_dbt.assert_under_10_percent_null: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.assert_under_10_percent_null"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      select sum (case when id is null then 1 else 0 end) / count(*) as total_nulls
from analytics.dbt.first_model
having sum (case when id is null then 1 else 0 end) / count(*) > .1
      
    ) dbt_internal_test
13:10:47.045498 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:10:48.315498 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.27 seconds
13:10:48.318732 [debug] [Thread-1  ]: finished collecting timing info
13:10:48.319057 [debug] [Thread-1  ]: On test.learn_dbt.assert_under_10_percent_null: Close
13:10:48.539020 [error] [Thread-1  ]: 1 of 9 FAIL 1 assert_under_10_percent_null...................................... [[31mFAIL 1[0m in 1.51s]
13:10:48.539621 [debug] [Thread-1  ]: Finished running node test.learn_dbt.assert_under_10_percent_null
13:10:48.539897 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
13:10:48.540117 [info ] [Thread-1  ]: 2 of 9 START test not_null_my_second_dbt_model_id............................... [RUN]
13:10:48.540625 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"
13:10:48.540819 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
13:10:48.541126 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
13:10:48.553348 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"
13:10:48.554993 [debug] [Thread-1  ]: finished collecting timing info
13:10:48.555246 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
13:10:48.557043 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"
13:10:48.557812 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"
13:10:48.557933 [debug] [Thread-1  ]: On test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.my_second_dbt_model
where id is null



      
    ) dbt_internal_test
13:10:48.558044 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:10:49.566695 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.01 seconds
13:10:49.569856 [debug] [Thread-1  ]: finished collecting timing info
13:10:49.570251 [debug] [Thread-1  ]: On test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778: Close
13:10:49.886885 [error] [Thread-1  ]: 2 of 9 FAIL 1 not_null_my_second_dbt_model_id................................... [[31mFAIL 1[0m in 1.35s]
13:10:49.887571 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
13:10:49.887828 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
13:10:49.888146 [info ] [Thread-1  ]: 3 of 9 START test not_null_snowflake_cumulative_sales_o_orderdate............... [RUN]
13:10:49.888828 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
13:10:49.889046 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
13:10:49.889252 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
13:10:49.893955 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
13:10:49.894627 [debug] [Thread-1  ]: finished collecting timing info
13:10:49.894813 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
13:10:49.897005 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
13:10:49.897999 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
13:10:49.898360 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.snowflake_cumulative_sales
where o_orderdate is null



      
    ) dbt_internal_test
13:10:49.898590 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:10:50.573016 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.67 seconds
13:10:50.575828 [debug] [Thread-1  ]: finished collecting timing info
13:10:50.576145 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856: Close
13:10:50.936103 [info ] [Thread-1  ]: 3 of 9 PASS not_null_snowflake_cumulative_sales_o_orderdate..................... [[32mPASS[0m in 1.05s]
13:10:50.936941 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
13:10:50.937205 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
13:10:50.937550 [info ] [Thread-1  ]: 4 of 9 START test not_null_snowflake_customer_purchases_c_custkey............... [RUN]
13:10:50.938204 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
13:10:50.938421 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
13:10:50.938635 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
13:10:50.943870 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
13:10:50.944680 [debug] [Thread-1  ]: finished collecting timing info
13:10:50.944861 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
13:10:50.946745 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
13:10:50.947607 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
13:10:50.947849 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.snowflake_customer_purchases
where c_custkey is null



      
    ) dbt_internal_test
13:10:50.947985 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:10:51.806615 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.86 seconds
13:10:51.809157 [debug] [Thread-1  ]: finished collecting timing info
13:10:51.809482 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502: Close
13:10:52.228403 [info ] [Thread-1  ]: 4 of 9 PASS not_null_snowflake_customer_purchases_c_custkey..................... [[32mPASS[0m in 1.29s]
13:10:52.229199 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
13:10:52.229472 [debug] [Thread-1  ]: Began running node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
13:10:52.229815 [info ] [Thread-1  ]: 5 of 9 START test relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ [RUN]
13:10:52.230475 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
13:10:52.230690 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
13:10:52.230894 [debug] [Thread-1  ]: Compiling test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
13:10:52.241529 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
13:10:52.242288 [debug] [Thread-1  ]: finished collecting timing info
13:10:52.242441 [debug] [Thread-1  ]: Began executing node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
13:10:52.244330 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
13:10:52.245476 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
13:10:52.245601 [debug] [Thread-1  ]: On test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select id as from_field
    from analytics.dbt.my_second_dbt_model
    where id is not null
),

parent as (
    select id as to_field
    from analytics.dbt.first_model
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
13:10:52.245713 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:10:53.055839 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.81 seconds
13:10:53.059421 [debug] [Thread-1  ]: finished collecting timing info
13:10:53.059851 [debug] [Thread-1  ]: On test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: Close
13:10:53.310489 [info ] [Thread-1  ]: 5 of 9 PASS relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_... [[32mPASS[0m in 1.08s]
13:10:53.310979 [debug] [Thread-1  ]: Finished running node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
13:10:53.311148 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
13:10:53.311375 [info ] [Thread-1  ]: 6 of 9 START test unique_my_first_dbt_model_id.................................. [RUN]
13:10:53.311796 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
13:10:53.311929 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
13:10:53.312062 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
13:10:53.319785 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
13:10:53.320516 [debug] [Thread-1  ]: finished collecting timing info
13:10:53.320705 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
13:10:53.322540 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
13:10:53.323676 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
13:10:53.323827 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.first_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
13:10:53.323954 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:10:54.172730 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.85 seconds
13:10:54.176075 [debug] [Thread-1  ]: finished collecting timing info
13:10:54.176651 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_first_dbt_model_id.16e066b321: Close
13:10:54.472020 [info ] [Thread-1  ]: 6 of 9 PASS unique_my_first_dbt_model_id........................................ [[32mPASS[0m in 1.16s]
13:10:54.472956 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
13:10:54.473254 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:10:54.473474 [info ] [Thread-1  ]: 7 of 9 START test unique_my_second_dbt_model_id................................. [RUN]
13:10:54.474250 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
13:10:54.474515 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:10:54.474744 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:10:54.479597 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
13:10:54.480454 [debug] [Thread-1  ]: finished collecting timing info
13:10:54.480710 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:10:54.483126 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
13:10:54.484197 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
13:10:54.484348 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.my_second_dbt_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
13:10:54.484471 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:10:55.131925 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.65 seconds
13:10:55.137027 [debug] [Thread-1  ]: finished collecting timing info
13:10:55.137454 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493: Close
13:10:55.803945 [info ] [Thread-1  ]: 7 of 9 PASS unique_my_second_dbt_model_id....................................... [[32mPASS[0m in 1.33s]
13:10:55.804741 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:10:55.805011 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
13:10:55.805391 [info ] [Thread-1  ]: 8 of 9 START test unique_snowflake_cumulative_sales_o_orderdate................. [RUN]
13:10:55.806028 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
13:10:55.806238 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
13:10:55.806438 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
13:10:55.811138 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
13:10:55.811943 [debug] [Thread-1  ]: finished collecting timing info
13:10:55.812121 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
13:10:55.814328 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
13:10:55.815383 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
13:10:55.815711 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    o_orderdate as unique_field,
    count(*) as n_records

from analytics.dbt.snowflake_cumulative_sales
where o_orderdate is not null
group by o_orderdate
having count(*) > 1



      
    ) dbt_internal_test
13:10:55.815894 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:10:56.798675 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.98 seconds
13:10:56.802356 [debug] [Thread-1  ]: finished collecting timing info
13:10:56.802718 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed: Close
13:10:57.009948 [info ] [Thread-1  ]: 8 of 9 PASS unique_snowflake_cumulative_sales_o_orderdate....................... [[32mPASS[0m in 1.20s]
13:10:57.010746 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
13:10:57.011033 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
13:10:57.011344 [info ] [Thread-1  ]: 9 of 9 START test unique_snowflake_customer_purchases_c_custkey................. [RUN]
13:10:57.011948 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
13:10:57.012103 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
13:10:57.012259 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
13:10:57.016157 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
13:10:57.016823 [debug] [Thread-1  ]: finished collecting timing info
13:10:57.017030 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
13:10:57.018906 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
13:10:57.019646 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
13:10:57.019740 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    c_custkey as unique_field,
    count(*) as n_records

from analytics.dbt.snowflake_customer_purchases
where c_custkey is not null
group by c_custkey
having count(*) > 1



      
    ) dbt_internal_test
13:10:57.019828 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:10:58.667255 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.65 seconds
13:10:58.671778 [debug] [Thread-1  ]: finished collecting timing info
13:10:58.672216 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f: Close
13:10:58.874813 [info ] [Thread-1  ]: 9 of 9 PASS unique_snowflake_customer_purchases_c_custkey....................... [[32mPASS[0m in 1.86s]
13:10:58.875857 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
13:10:58.877526 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:10:58.878100 [info ] [MainThread]: 
13:10:58.878459 [info ] [MainThread]: Finished running 9 tests in 13.68s.
13:10:58.878763 [debug] [MainThread]: Connection 'master' was properly closed.
13:10:58.878928 [debug] [MainThread]: Connection 'test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f' was properly closed.
13:10:58.885657 [info ] [MainThread]: 
13:10:58.885986 [info ] [MainThread]: [31mCompleted with 2 errors and 0 warnings:[0m
13:10:58.886245 [info ] [MainThread]: 
13:10:58.886447 [error] [MainThread]: [31mFailure in test assert_under_10_percent_null (tests/assert_under_10_percent_null.sql)[0m
13:10:58.886683 [error] [MainThread]:   Got 1 result, configured to fail if != 0
13:10:58.886872 [info ] [MainThread]: 
13:10:58.887056 [info ] [MainThread]:   compiled SQL at target/compiled/learn_dbt/tests/assert_under_10_percent_null.sql
13:10:58.887245 [info ] [MainThread]: 
13:10:58.887421 [error] [MainThread]: [31mFailure in test not_null_my_second_dbt_model_id (models/example/schema.yml)[0m
13:10:58.887602 [error] [MainThread]:   Got 1 result, configured to fail if != 0
13:10:58.887775 [info ] [MainThread]: 
13:10:58.887947 [info ] [MainThread]:   compiled SQL at target/compiled/learn_dbt/models/example/schema.yml/not_null_my_second_dbt_model_id.sql
13:10:58.888141 [info ] [MainThread]: 
13:10:58.888316 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=2 SKIP=0 TOTAL=9
13:10:58.888582 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10874b1c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10293f940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108742460>]}


============================== 2022-05-13 13:11:15.826648 | 20efd4b4-7b8a-4b69-88be-4a716b54521d ==============================
13:11:15.826648 [info ] [MainThread]: Running with dbt=1.0.1
13:11:15.827036 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
13:11:15.827174 [debug] [MainThread]: Tracking: tracking
13:11:15.827374 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c9432b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c943eb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c9439a0>]}
13:11:15.869709 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
13:11:15.870046 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://tests/assert_under_10_percent_null.sql
13:11:15.885863 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '20efd4b4-7b8a-4b69-88be-4a716b54521d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11ca9f0d0>]}
13:11:15.889978 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '20efd4b4-7b8a-4b69-88be-4a716b54521d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c8ff4f0>]}
13:11:15.890158 [info ] [MainThread]: Found 6 models, 9 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
13:11:15.890937 [info ] [MainThread]: 
13:11:15.891184 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:11:15.891649 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
13:11:15.897687 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
13:11:15.897790 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
13:11:15.897865 [debug] [ThreadPool]: Opening a new connection, currently in state init
13:11:17.148753 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.25 seconds
13:11:17.150768 [debug] [ThreadPool]: On list_analytics: Close
13:11:17.380423 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
13:11:17.389317 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
13:11:17.389574 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
13:11:17.389731 [debug] [ThreadPool]: Opening a new connection, currently in state closed
13:11:18.373193 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 0.98 seconds
13:11:18.375668 [debug] [ThreadPool]: On list_analytics_dbt: Close
13:11:18.590388 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
13:11:18.591013 [info ] [MainThread]: 
13:11:18.594514 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
13:11:18.595362 [info ] [Thread-1  ]: 1 of 6 START incremental model dbt.dates........................................ [RUN]
13:11:18.595892 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
13:11:18.596062 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
13:11:18.596235 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
13:11:18.606243 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
13:11:18.606889 [debug] [Thread-1  ]: finished collecting timing info
13:11:18.607056 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
13:11:18.636916 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:11:18.637137 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
13:11:18.637230 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:11:20.907952 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.27 seconds
13:11:20.921388 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:11:20.921833 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
13:11:21.075767 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.15 seconds
13:11:21.087617 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:11:21.088079 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
13:11:21.338313 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.25 seconds
13:11:21.350721 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:11:21.351051 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
13:11:21.478633 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.13 seconds
13:11:21.503893 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
13:11:21.505914 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:11:21.506035 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
13:11:21.638090 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.13 seconds
13:11:21.639154 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:11:21.639373 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
13:11:22.099291 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.46 seconds
13:11:22.100116 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:11:22.100391 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
13:11:22.492806 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.39 seconds
13:11:22.507968 [debug] [Thread-1  ]: finished collecting timing info
13:11:22.508326 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
13:11:22.782443 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '20efd4b4-7b8a-4b69-88be-4a716b54521d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c8ffac0>]}
13:11:22.783353 [info ] [Thread-1  ]: 1 of 6 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 4.19s]
13:11:22.783851 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
13:11:22.784334 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
13:11:22.784843 [info ] [Thread-1  ]: 2 of 6 START incremental model dbt.incremental_time............................. [RUN]
13:11:22.785485 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
13:11:22.785696 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
13:11:22.785885 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
13:11:22.789885 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
13:11:22.790482 [debug] [Thread-1  ]: finished collecting timing info
13:11:22.790666 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
13:11:22.794227 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:11:22.794340 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
13:11:22.794419 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:11:24.177608 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.38 seconds
13:11:24.183504 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:11:24.183843 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
13:11:24.318466 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.13 seconds
13:11:24.321695 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:11:24.321866 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
13:11:24.601024 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.28 seconds
13:11:24.606772 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:11:24.607095 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
13:11:24.876863 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.27 seconds
13:11:24.881962 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
13:11:24.884272 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:11:24.884501 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
13:11:25.011909 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.13 seconds
13:11:25.013188 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:11:25.013390 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
13:11:25.756702 [debug] [Thread-1  ]: SQL status: SUCCESS 57 in 0.74 seconds
13:11:25.757872 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:11:25.758258 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
13:11:26.162300 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.4 seconds
13:11:26.165388 [debug] [Thread-1  ]: finished collecting timing info
13:11:26.165781 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
13:11:26.589468 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '20efd4b4-7b8a-4b69-88be-4a716b54521d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11cefa310>]}
13:11:26.590232 [info ] [Thread-1  ]: 2 of 6 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 3.80s]
13:11:26.590652 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
13:11:26.590918 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
13:11:26.591300 [info ] [Thread-1  ]: 3 of 6 START table model dbt.first_model........................................ [RUN]
13:11:26.591732 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
13:11:26.591860 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
13:11:26.591988 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
13:11:26.595035 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
13:11:26.595717 [debug] [Thread-1  ]: finished collecting timing info
13:11:26.595901 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
13:11:26.605586 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
13:11:26.606774 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
13:11:26.606940 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id

)

select * 
from source_data


/*
select *, True as first_variable
from source_data
where id >= 1
*/
      );
13:11:26.607055 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:11:28.355955 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.75 seconds
13:11:28.359960 [debug] [Thread-1  ]: finished collecting timing info
13:11:28.360354 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
13:11:28.682318 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '20efd4b4-7b8a-4b69-88be-4a716b54521d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11cefa040>]}
13:11:28.683073 [info ] [Thread-1  ]: 3 of 6 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 2.09s]
13:11:28.683526 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
13:11:28.683767 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
13:11:28.684160 [info ] [Thread-1  ]: 4 of 6 START table model dbt.snowflake_cumulative_sales......................... [RUN]
13:11:28.684855 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
13:11:28.685047 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
13:11:28.685242 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
13:11:28.687003 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
13:11:28.687714 [debug] [Thread-1  ]: finished collecting timing info
13:11:28.687876 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
13:11:28.690342 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
13:11:28.691387 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
13:11:28.691559 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
13:11:28.691704 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:11:30.842351 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.15 seconds
13:11:30.845137 [debug] [Thread-1  ]: finished collecting timing info
13:11:30.845510 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
13:11:31.071471 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '20efd4b4-7b8a-4b69-88be-4a716b54521d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11cefa160>]}
13:11:31.072394 [info ] [Thread-1  ]: 4 of 6 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 2.39s]
13:11:31.072848 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
13:11:31.073099 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
13:11:31.073483 [info ] [Thread-1  ]: 5 of 6 START table model dbt.snowflake_customer_purchases....................... [RUN]
13:11:31.074131 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
13:11:31.074352 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
13:11:31.074562 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
13:11:31.076353 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
13:11:31.077179 [debug] [Thread-1  ]: finished collecting timing info
13:11:31.077399 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
13:11:31.079938 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
13:11:31.081178 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
13:11:31.081341 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
13:11:31.081487 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:11:32.985974 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.9 seconds
13:11:32.989528 [debug] [Thread-1  ]: finished collecting timing info
13:11:32.989924 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
13:11:33.400079 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '20efd4b4-7b8a-4b69-88be-4a716b54521d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11fd81790>]}
13:11:33.400640 [info ] [Thread-1  ]: 5 of 6 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.33s]
13:11:33.401051 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
13:11:33.401277 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
13:11:33.401699 [info ] [Thread-1  ]: 6 of 6 START table model dbt.my_second_dbt_model................................ [RUN]
13:11:33.402176 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
13:11:33.402343 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
13:11:33.402514 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
13:11:33.405648 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
13:11:33.406307 [debug] [Thread-1  ]: finished collecting timing info
13:11:33.406493 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
13:11:33.408674 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
13:11:33.409426 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
13:11:33.409567 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
/*
union all
select 7 as id, True as first_variable
*/
      );
13:11:33.409693 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:11:34.625194 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.22 seconds
13:11:34.631759 [debug] [Thread-1  ]: finished collecting timing info
13:11:34.632180 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
13:11:34.793532 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '20efd4b4-7b8a-4b69-88be-4a716b54521d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11fd625b0>]}
13:11:34.794314 [info ] [Thread-1  ]: 6 of 6 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.39s]
13:11:34.794769 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
13:11:34.796136 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:11:34.796722 [info ] [MainThread]: 
13:11:34.797077 [info ] [MainThread]: Finished running 2 incremental models, 4 table models in 18.91s.
13:11:34.797377 [debug] [MainThread]: Connection 'master' was properly closed.
13:11:34.797547 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
13:11:34.804227 [info ] [MainThread]: 
13:11:34.804557 [info ] [MainThread]: [32mCompleted successfully[0m
13:11:34.804812 [info ] [MainThread]: 
13:11:34.805005 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
13:11:34.805266 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11cefeb80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11cefe7c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11fda4d90>]}


============================== 2022-05-13 13:12:06.309087 | 74571314-53b4-45d8-80fb-5aefefc907bb ==============================
13:12:06.309087 [info ] [MainThread]: Running with dbt=1.0.1
13:12:06.309451 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, store_failures=False, indirect_selection='eager', threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.test.TestTask'>, which='test', rpc_method='test')
13:12:06.309574 [debug] [MainThread]: Tracking: tracking
13:12:06.309806 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111d835b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111d83eb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111d83dc0>]}
13:12:06.351652 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
13:12:06.351786 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
13:12:06.354750 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '74571314-53b4-45d8-80fb-5aefefc907bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111d4d100>]}
13:12:06.357870 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '74571314-53b4-45d8-80fb-5aefefc907bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1109f6940>]}
13:12:06.358005 [info ] [MainThread]: Found 6 models, 9 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
13:12:06.358756 [info ] [MainThread]: 
13:12:06.358959 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:12:06.359404 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
13:12:06.365221 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
13:12:06.365332 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
13:12:06.365401 [debug] [ThreadPool]: Opening a new connection, currently in state init
13:12:07.684950 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1.32 seconds
13:12:07.688112 [debug] [ThreadPool]: On list_analytics_dbt: Close
13:12:07.921941 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
13:12:07.922612 [info ] [MainThread]: 
13:12:07.926481 [debug] [Thread-1  ]: Began running node test.learn_dbt.assert_under_10_percent_null
13:12:07.926737 [info ] [Thread-1  ]: 1 of 9 START test assert_under_10_percent_null.................................. [RUN]
13:12:07.927226 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.assert_under_10_percent_null"
13:12:07.927391 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.assert_under_10_percent_null
13:12:07.927552 [debug] [Thread-1  ]: Compiling test.learn_dbt.assert_under_10_percent_null
13:12:07.930633 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.assert_under_10_percent_null"
13:12:07.947372 [debug] [Thread-1  ]: finished collecting timing info
13:12:07.947665 [debug] [Thread-1  ]: Began executing node test.learn_dbt.assert_under_10_percent_null
13:12:07.962475 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.assert_under_10_percent_null"
13:12:07.963299 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.assert_under_10_percent_null"
13:12:07.963421 [debug] [Thread-1  ]: On test.learn_dbt.assert_under_10_percent_null: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.assert_under_10_percent_null"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      select sum (case when id is null then 1 else 0 end) / count(*) as total_nulls
from analytics.dbt.first_model
having sum (case when id is null then 1 else 0 end) / count(*) > .4
      
    ) dbt_internal_test
13:12:07.963522 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:12:08.996516 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.03 seconds
13:12:09.000089 [debug] [Thread-1  ]: finished collecting timing info
13:12:09.000445 [debug] [Thread-1  ]: On test.learn_dbt.assert_under_10_percent_null: Close
13:12:09.223113 [info ] [Thread-1  ]: 1 of 9 PASS assert_under_10_percent_null........................................ [[32mPASS[0m in 1.30s]
13:12:09.223621 [debug] [Thread-1  ]: Finished running node test.learn_dbt.assert_under_10_percent_null
13:12:09.223767 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
13:12:09.223994 [info ] [Thread-1  ]: 2 of 9 START test not_null_my_second_dbt_model_id............................... [RUN]
13:12:09.224396 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"
13:12:09.224510 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
13:12:09.224606 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
13:12:09.235048 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"
13:12:09.235475 [debug] [Thread-1  ]: finished collecting timing info
13:12:09.235577 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
13:12:09.236814 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"
13:12:09.237366 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"
13:12:09.237452 [debug] [Thread-1  ]: On test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.my_second_dbt_model
where id is null



      
    ) dbt_internal_test
13:12:09.237531 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:12:10.058615 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.82 seconds
13:12:10.062063 [debug] [Thread-1  ]: finished collecting timing info
13:12:10.062467 [debug] [Thread-1  ]: On test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778: Close
13:12:10.242181 [error] [Thread-1  ]: 2 of 9 FAIL 1 not_null_my_second_dbt_model_id................................... [[31mFAIL 1[0m in 1.02s]
13:12:10.242904 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
13:12:10.243164 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
13:12:10.243512 [info ] [Thread-1  ]: 3 of 9 START test not_null_snowflake_cumulative_sales_o_orderdate............... [RUN]
13:12:10.244209 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
13:12:10.244439 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
13:12:10.244637 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
13:12:10.249807 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
13:12:10.250737 [debug] [Thread-1  ]: finished collecting timing info
13:12:10.250951 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
13:12:10.252897 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
13:12:10.253873 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
13:12:10.254115 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.snowflake_cumulative_sales
where o_orderdate is null



      
    ) dbt_internal_test
13:12:10.254252 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:12:11.209676 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.96 seconds
13:12:11.212266 [debug] [Thread-1  ]: finished collecting timing info
13:12:11.212698 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856: Close
13:12:11.418272 [info ] [Thread-1  ]: 3 of 9 PASS not_null_snowflake_cumulative_sales_o_orderdate..................... [[32mPASS[0m in 1.17s]
13:12:11.419194 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
13:12:11.419564 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
13:12:11.419814 [info ] [Thread-1  ]: 4 of 9 START test not_null_snowflake_customer_purchases_c_custkey............... [RUN]
13:12:11.420577 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
13:12:11.420837 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
13:12:11.421057 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
13:12:11.426042 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
13:12:11.426897 [debug] [Thread-1  ]: finished collecting timing info
13:12:11.427090 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
13:12:11.429388 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
13:12:11.430425 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
13:12:11.430626 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.snowflake_customer_purchases
where c_custkey is null



      
    ) dbt_internal_test
13:12:11.430829 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:12:12.550825 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.12 seconds
13:12:12.552890 [debug] [Thread-1  ]: finished collecting timing info
13:12:12.553126 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502: Close
13:12:12.976425 [info ] [Thread-1  ]: 4 of 9 PASS not_null_snowflake_customer_purchases_c_custkey..................... [[32mPASS[0m in 1.56s]
13:12:12.977573 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
13:12:12.977996 [debug] [Thread-1  ]: Began running node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
13:12:12.978242 [info ] [Thread-1  ]: 5 of 9 START test relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ [RUN]
13:12:12.979025 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
13:12:12.979279 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
13:12:12.979489 [debug] [Thread-1  ]: Compiling test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
13:12:12.990385 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
13:12:12.991039 [debug] [Thread-1  ]: finished collecting timing info
13:12:12.991200 [debug] [Thread-1  ]: Began executing node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
13:12:12.993064 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
13:12:12.994222 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
13:12:12.994367 [debug] [Thread-1  ]: On test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select id as from_field
    from analytics.dbt.my_second_dbt_model
    where id is not null
),

parent as (
    select id as to_field
    from analytics.dbt.first_model
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
13:12:12.994495 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:12:14.288563 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.29 seconds
13:12:14.291820 [debug] [Thread-1  ]: finished collecting timing info
13:12:14.292086 [debug] [Thread-1  ]: On test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: Close
13:12:14.485133 [info ] [Thread-1  ]: 5 of 9 PASS relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_... [[32mPASS[0m in 1.51s]
13:12:14.486088 [debug] [Thread-1  ]: Finished running node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
13:12:14.486379 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
13:12:14.486718 [info ] [Thread-1  ]: 6 of 9 START test unique_my_first_dbt_model_id.................................. [RUN]
13:12:14.487427 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
13:12:14.487660 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
13:12:14.487865 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
13:12:14.496007 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
13:12:14.496801 [debug] [Thread-1  ]: finished collecting timing info
13:12:14.496987 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
13:12:14.498821 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
13:12:14.499974 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
13:12:14.500138 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.first_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
13:12:14.500272 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:12:15.439207 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.94 seconds
13:12:15.441933 [debug] [Thread-1  ]: finished collecting timing info
13:12:15.442435 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_first_dbt_model_id.16e066b321: Close
13:12:15.671297 [info ] [Thread-1  ]: 6 of 9 PASS unique_my_first_dbt_model_id........................................ [[32mPASS[0m in 1.18s]
13:12:15.672125 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
13:12:15.672391 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:12:15.672731 [info ] [Thread-1  ]: 7 of 9 START test unique_my_second_dbt_model_id................................. [RUN]
13:12:15.673385 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
13:12:15.673607 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:12:15.673817 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:12:15.678376 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
13:12:15.679070 [debug] [Thread-1  ]: finished collecting timing info
13:12:15.679265 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:12:15.681502 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
13:12:15.682489 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
13:12:15.682627 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.my_second_dbt_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
13:12:15.682875 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:12:16.691546 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.01 seconds
13:12:16.694938 [debug] [Thread-1  ]: finished collecting timing info
13:12:16.695396 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493: Close
13:12:17.056043 [info ] [Thread-1  ]: 7 of 9 PASS unique_my_second_dbt_model_id....................................... [[32mPASS[0m in 1.38s]
13:12:17.056744 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:12:17.057120 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
13:12:17.057495 [info ] [Thread-1  ]: 8 of 9 START test unique_snowflake_cumulative_sales_o_orderdate................. [RUN]
13:12:17.058137 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
13:12:17.058349 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
13:12:17.058543 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
13:12:17.063308 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
13:12:17.064099 [debug] [Thread-1  ]: finished collecting timing info
13:12:17.064342 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
13:12:17.066711 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
13:12:17.067941 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
13:12:17.068168 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    o_orderdate as unique_field,
    count(*) as n_records

from analytics.dbt.snowflake_cumulative_sales
where o_orderdate is not null
group by o_orderdate
having count(*) > 1



      
    ) dbt_internal_test
13:12:17.068365 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:12:17.959272 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.89 seconds
13:12:17.962584 [debug] [Thread-1  ]: finished collecting timing info
13:12:17.962996 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed: Close
13:12:18.142481 [info ] [Thread-1  ]: 8 of 9 PASS unique_snowflake_cumulative_sales_o_orderdate....................... [[32mPASS[0m in 1.08s]
13:12:18.143575 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
13:12:18.144000 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
13:12:18.144249 [info ] [Thread-1  ]: 9 of 9 START test unique_snowflake_customer_purchases_c_custkey................. [RUN]
13:12:18.145082 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
13:12:18.145345 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
13:12:18.145572 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
13:12:18.150386 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
13:12:18.150882 [debug] [Thread-1  ]: finished collecting timing info
13:12:18.151013 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
13:12:18.152741 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
13:12:18.153726 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
13:12:18.153884 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    c_custkey as unique_field,
    count(*) as n_records

from analytics.dbt.snowflake_customer_purchases
where c_custkey is not null
group by c_custkey
having count(*) > 1



      
    ) dbt_internal_test
13:12:18.154026 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:12:19.008363 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.85 seconds
13:12:19.011419 [debug] [Thread-1  ]: finished collecting timing info
13:12:19.011833 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f: Close
13:12:19.198778 [info ] [Thread-1  ]: 9 of 9 PASS unique_snowflake_customer_purchases_c_custkey....................... [[32mPASS[0m in 1.05s]
13:12:19.199823 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
13:12:19.201029 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:12:19.201552 [info ] [MainThread]: 
13:12:19.201864 [info ] [MainThread]: Finished running 9 tests in 12.84s.
13:12:19.202166 [debug] [MainThread]: Connection 'master' was properly closed.
13:12:19.202292 [debug] [MainThread]: Connection 'test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f' was properly closed.
13:12:19.208608 [info ] [MainThread]: 
13:12:19.209026 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
13:12:19.209320 [info ] [MainThread]: 
13:12:19.209550 [error] [MainThread]: [31mFailure in test not_null_my_second_dbt_model_id (models/example/schema.yml)[0m
13:12:19.209934 [error] [MainThread]:   Got 1 result, configured to fail if != 0
13:12:19.210184 [info ] [MainThread]: 
13:12:19.210415 [info ] [MainThread]:   compiled SQL at target/compiled/learn_dbt/models/example/schema.yml/not_null_my_second_dbt_model_id.sql
13:12:19.210812 [info ] [MainThread]: 
13:12:19.211071 [info ] [MainThread]: Done. PASS=8 WARN=0 ERROR=1 SKIP=0 TOTAL=9
13:12:19.211407 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112529be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11096c4f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112200550>]}


============================== 2022-05-13 13:14:36.838307 | b70a7687-eac6-4c4e-a241-d577c63bb9cd ==============================
13:14:36.838307 [info ] [MainThread]: Running with dbt=1.0.1
13:14:36.838705 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
13:14:36.838840 [debug] [MainThread]: Tracking: tracking
13:14:36.839081 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112891610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112891ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112891b20>]}
13:14:36.880799 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
13:14:36.881063 [debug] [MainThread]: Partial parsing: added file: learn_dbt://models/example/playing_with_tests.sql
13:14:36.886088 [debug] [MainThread]: 1699: static parser successfully parsed example/playing_with_tests.sql
13:14:36.895544 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b70a7687-eac6-4c4e-a241-d577c63bb9cd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1129d90d0>]}
13:14:36.898913 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b70a7687-eac6-4c4e-a241-d577c63bb9cd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112861be0>]}
13:14:36.899056 [info ] [MainThread]: Found 7 models, 9 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
13:14:36.899819 [info ] [MainThread]: 
13:14:36.900020 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:14:36.900501 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
13:14:36.906389 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
13:14:36.906500 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
13:14:36.906566 [debug] [ThreadPool]: Opening a new connection, currently in state init
13:14:38.091378 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.18 seconds
13:14:38.093912 [debug] [ThreadPool]: On list_analytics: Close
13:14:38.288991 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
13:14:38.297641 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
13:14:38.297896 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
13:14:38.298063 [debug] [ThreadPool]: Opening a new connection, currently in state closed
13:14:39.276962 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 0.98 seconds
13:14:39.280331 [debug] [ThreadPool]: On list_analytics_dbt: Close
13:14:39.594815 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
13:14:39.595962 [info ] [MainThread]: 
13:14:39.600763 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
13:14:39.601355 [info ] [Thread-1  ]: 1 of 7 START incremental model dbt.dates........................................ [RUN]
13:14:39.601975 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
13:14:39.602155 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
13:14:39.602338 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
13:14:39.612789 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
13:14:39.613436 [debug] [Thread-1  ]: finished collecting timing info
13:14:39.613592 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
13:14:39.642310 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:14:39.642491 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
13:14:39.642578 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:14:42.724546 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 3.08 seconds
13:14:42.737519 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:14:42.737848 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
13:14:42.873530 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.14 seconds
13:14:42.880637 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:14:42.880969 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
13:14:43.187702 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.31 seconds
13:14:43.198694 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:14:43.199012 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
13:14:43.305929 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.11 seconds
13:14:43.332770 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
13:14:43.335095 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:14:43.335220 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
13:14:43.811762 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.48 seconds
13:14:43.813017 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:14:43.813528 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
13:14:44.449235 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.64 seconds
13:14:44.449715 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:14:44.449924 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
13:14:44.756158 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.31 seconds
13:14:44.772434 [debug] [Thread-1  ]: finished collecting timing info
13:14:44.772856 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
13:14:44.983630 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b70a7687-eac6-4c4e-a241-d577c63bb9cd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1116ac6d0>]}
13:14:44.984292 [info ] [Thread-1  ]: 1 of 7 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 5.38s]
13:14:44.984748 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
13:14:44.984991 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
13:14:44.985398 [info ] [Thread-1  ]: 2 of 7 START incremental model dbt.incremental_time............................. [RUN]
13:14:44.986043 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
13:14:44.986265 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
13:14:44.986477 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
13:14:44.990466 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
13:14:44.992208 [debug] [Thread-1  ]: finished collecting timing info
13:14:44.992488 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
13:14:44.996207 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:14:44.996410 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
13:14:44.996552 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:14:46.853187 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.86 seconds
13:14:46.857912 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:14:46.858304 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
13:14:46.976714 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.12 seconds
13:14:46.985726 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:14:46.986105 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
13:14:47.082718 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
13:14:47.088071 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:14:47.088376 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
13:14:47.376727 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.29 seconds
13:14:47.382364 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
13:14:47.383501 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:14:47.383580 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
13:14:47.499969 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.12 seconds
13:14:47.502348 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:14:47.502662 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
13:14:48.292911 [debug] [Thread-1  ]: SQL status: SUCCESS 202 in 0.79 seconds
13:14:48.293767 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:14:48.294057 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
13:14:48.544230 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.25 seconds
13:14:48.549641 [debug] [Thread-1  ]: finished collecting timing info
13:14:48.550070 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
13:14:48.722394 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b70a7687-eac6-4c4e-a241-d577c63bb9cd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112db3fd0>]}
13:14:48.723222 [info ] [Thread-1  ]: 2 of 7 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 3.74s]
13:14:48.723677 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
13:14:48.723937 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
13:14:48.724355 [info ] [Thread-1  ]: 3 of 7 START table model dbt.first_model........................................ [RUN]
13:14:48.724985 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
13:14:48.725200 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
13:14:48.725397 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
13:14:48.729278 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
13:14:48.730027 [debug] [Thread-1  ]: finished collecting timing info
13:14:48.730210 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
13:14:48.739210 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
13:14:48.740255 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
13:14:48.740395 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id

)

select * 
from source_data


/*
select *, True as first_variable
from source_data
where id >= 1
*/
      );
13:14:48.740527 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:14:50.190088 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.45 seconds
13:14:50.193115 [debug] [Thread-1  ]: finished collecting timing info
13:14:50.193516 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
13:14:51.825593 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b70a7687-eac6-4c4e-a241-d577c63bb9cd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114d78df0>]}
13:14:51.826400 [info ] [Thread-1  ]: 3 of 7 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 3.10s]
13:14:51.826875 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
13:14:51.827127 [debug] [Thread-1  ]: Began running node model.learn_dbt.playing_with_tests
13:14:51.827531 [info ] [Thread-1  ]: 4 of 7 START table model dbt.playing_with_tests................................. [RUN]
13:14:51.828271 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.playing_with_tests"
13:14:51.828543 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.playing_with_tests
13:14:51.828764 [debug] [Thread-1  ]: Compiling model.learn_dbt.playing_with_tests
13:14:51.830512 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.playing_with_tests"
13:14:51.831224 [debug] [Thread-1  ]: finished collecting timing info
13:14:51.831407 [debug] [Thread-1  ]: Began executing node model.learn_dbt.playing_with_tests
13:14:51.833924 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.playing_with_tests"
13:14:51.834822 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
13:14:51.834988 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */


      create or replace transient table analytics.dbt.playing_with_tests  as
      (select * 
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF001"."CUSTOMER"
      );
13:14:51.835133 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:14:52.511399 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a43d3a-3201-9d36-0000-000120528345
13:14:52.511685 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 002003 (02000): SQL compilation error:
Schema 'SNOWFLAKE_SAMPLE_DATA.TPCH_SF001' does not exist or not authorized.
13:14:52.511917 [debug] [Thread-1  ]: finished collecting timing info
13:14:52.512034 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: Close
13:14:52.692330 [debug] [Thread-1  ]: Database Error in model playing_with_tests (models/example/playing_with_tests.sql)
  002003 (02000): SQL compilation error:
  Schema 'SNOWFLAKE_SAMPLE_DATA.TPCH_SF001' does not exist or not authorized.
  compiled SQL at target/run/learn_dbt/models/example/playing_with_tests.sql
13:14:52.692592 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b70a7687-eac6-4c4e-a241-d577c63bb9cd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114d81370>]}
13:14:52.692781 [error] [Thread-1  ]: 4 of 7 ERROR creating table model dbt.playing_with_tests........................ [[31mERROR[0m in 0.86s]
13:14:52.692940 [debug] [Thread-1  ]: Finished running node model.learn_dbt.playing_with_tests
13:14:52.693033 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
13:14:52.693129 [info ] [Thread-1  ]: 5 of 7 START table model dbt.snowflake_cumulative_sales......................... [RUN]
13:14:52.693332 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
13:14:52.693400 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
13:14:52.693469 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
13:14:52.694112 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
13:14:52.694572 [debug] [Thread-1  ]: finished collecting timing info
13:14:52.694678 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
13:14:52.695903 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
13:14:52.696401 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
13:14:52.696474 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
13:14:52.696539 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:14:54.587018 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.89 seconds
13:14:54.590013 [debug] [Thread-1  ]: finished collecting timing info
13:14:54.590370 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
13:14:54.801785 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b70a7687-eac6-4c4e-a241-d577c63bb9cd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114d60280>]}
13:14:54.803166 [info ] [Thread-1  ]: 5 of 7 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 2.11s]
13:14:54.803679 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
13:14:54.804048 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
13:14:54.804589 [info ] [Thread-1  ]: 6 of 7 START table model dbt.snowflake_customer_purchases....................... [RUN]
13:14:54.805609 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
13:14:54.805854 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
13:14:54.806065 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
13:14:54.807890 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
13:14:54.808658 [debug] [Thread-1  ]: finished collecting timing info
13:14:54.808835 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
13:14:54.811540 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
13:14:54.812849 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
13:14:54.813033 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
13:14:54.813207 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:14:56.532003 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.72 seconds
13:14:56.534941 [debug] [Thread-1  ]: finished collecting timing info
13:14:56.535485 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
13:14:56.819185 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b70a7687-eac6-4c4e-a241-d577c63bb9cd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114d6c550>]}
13:14:56.819923 [info ] [Thread-1  ]: 6 of 7 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.01s]
13:14:56.820373 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
13:14:56.820628 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
13:14:56.821026 [info ] [Thread-1  ]: 7 of 7 START table model dbt.my_second_dbt_model................................ [RUN]
13:14:56.821661 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
13:14:56.821886 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
13:14:56.822091 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
13:14:56.825384 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
13:14:56.826078 [debug] [Thread-1  ]: finished collecting timing info
13:14:56.826259 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
13:14:56.829019 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
13:14:56.830009 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
13:14:56.830173 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
/*
union all
select 7 as id, True as first_variable
*/
      );
13:14:56.830308 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:14:58.385224 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.55 seconds
13:14:58.388540 [debug] [Thread-1  ]: finished collecting timing info
13:14:58.388948 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
13:14:58.569223 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b70a7687-eac6-4c4e-a241-d577c63bb9cd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114f62070>]}
13:14:58.570023 [info ] [Thread-1  ]: 7 of 7 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.75s]
13:14:58.570481 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
13:14:58.571871 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:14:58.572438 [info ] [MainThread]: 
13:14:58.572785 [info ] [MainThread]: Finished running 2 incremental models, 5 table models in 21.67s.
13:14:58.573079 [debug] [MainThread]: Connection 'master' was properly closed.
13:14:58.573241 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
13:14:58.580826 [info ] [MainThread]: 
13:14:58.581205 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
13:14:58.581550 [info ] [MainThread]: 
13:14:58.581760 [error] [MainThread]: [33mDatabase Error in model playing_with_tests (models/example/playing_with_tests.sql)[0m
13:14:58.581958 [error] [MainThread]:   002003 (02000): SQL compilation error:
13:14:58.582144 [error] [MainThread]:   Schema 'SNOWFLAKE_SAMPLE_DATA.TPCH_SF001' does not exist or not authorized.
13:14:58.582326 [error] [MainThread]:   compiled SQL at target/run/learn_dbt/models/example/playing_with_tests.sql
13:14:58.582523 [info ] [MainThread]: 
13:14:58.582711 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=1 SKIP=0 TOTAL=7
13:14:58.582971 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112c2dbe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112c2de20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112c80550>]}


============================== 2022-05-13 13:16:26.080857 | bf9b6ca7-1f78-4b0b-8641-a38773cf924e ==============================
13:16:26.080857 [info ] [MainThread]: Running with dbt=1.0.1
13:16:26.081263 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
13:16:26.081437 [debug] [MainThread]: Tracking: tracking
13:16:26.081671 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f33370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f33be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f339d0>]}
13:16:26.123883 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
13:16:26.124192 [debug] [MainThread]: Partial parsing: update schema file: learn_dbt://models/example/schema.yml
13:16:26.142499 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'bf9b6ca7-1f78-4b0b-8641-a38773cf924e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107092040>]}
13:16:26.145575 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'bf9b6ca7-1f78-4b0b-8641-a38773cf924e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105a96670>]}
13:16:26.145707 [info ] [MainThread]: Found 7 models, 11 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
13:16:26.146502 [info ] [MainThread]: 
13:16:26.146708 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:16:26.147183 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
13:16:26.153058 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
13:16:26.153167 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
13:16:26.153235 [debug] [ThreadPool]: Opening a new connection, currently in state init
13:16:27.186035 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.03 seconds
13:16:27.188353 [debug] [ThreadPool]: On list_analytics: Close
13:16:27.518879 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
13:16:27.527810 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
13:16:27.528093 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
13:16:27.528255 [debug] [ThreadPool]: Opening a new connection, currently in state closed
13:16:28.232300 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 0.7 seconds
13:16:28.234984 [debug] [ThreadPool]: On list_analytics_dbt: Close
13:16:28.564109 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
13:16:28.564566 [info ] [MainThread]: 
13:16:28.566570 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
13:16:28.566815 [info ] [Thread-1  ]: 1 of 7 START incremental model dbt.dates........................................ [RUN]
13:16:28.567104 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
13:16:28.567199 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
13:16:28.567297 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
13:16:28.576939 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
13:16:28.577564 [debug] [Thread-1  ]: finished collecting timing info
13:16:28.577726 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
13:16:28.607583 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:16:28.607777 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
13:16:28.607862 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:16:30.290987 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.68 seconds
13:16:30.300446 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:16:30.300577 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
13:16:30.455238 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.15 seconds
13:16:30.464822 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:16:30.465157 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
13:16:30.725282 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.26 seconds
13:16:30.737999 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:16:30.738304 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
13:16:30.866639 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.13 seconds
13:16:30.889170 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
13:16:30.891505 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:16:30.891648 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
13:16:31.252080 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.36 seconds
13:16:31.252814 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:16:31.253021 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
13:16:31.771933 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.52 seconds
13:16:31.772414 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:16:31.772670 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
13:16:31.952683 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.18 seconds
13:16:31.967676 [debug] [Thread-1  ]: finished collecting timing info
13:16:31.968098 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
13:16:32.418841 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf9b6ca7-1f78-4b0b-8641-a38773cf924e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105c2cb50>]}
13:16:32.419599 [info ] [Thread-1  ]: 1 of 7 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 3.85s]
13:16:32.420050 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
13:16:32.420258 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
13:16:32.420614 [info ] [Thread-1  ]: 2 of 7 START incremental model dbt.incremental_time............................. [RUN]
13:16:32.421175 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
13:16:32.421364 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
13:16:32.421534 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
13:16:32.424994 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
13:16:32.425840 [debug] [Thread-1  ]: finished collecting timing info
13:16:32.426027 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
13:16:32.429708 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:16:32.429894 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
13:16:32.430023 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:16:34.996011 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.57 seconds
13:16:35.000048 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:16:35.000234 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
13:16:35.126321 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.13 seconds
13:16:35.131053 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:16:35.131301 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
13:16:35.505368 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.37 seconds
13:16:35.510030 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:16:35.510378 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
13:16:35.615938 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.11 seconds
13:16:35.621800 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
13:16:35.624209 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:16:35.624444 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
13:16:35.899929 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.28 seconds
13:16:35.900891 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:16:35.901082 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
13:16:36.948418 [debug] [Thread-1  ]: SQL status: SUCCESS 108 in 1.05 seconds
13:16:36.949180 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:16:36.949379 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
13:16:37.473351 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.52 seconds
13:16:37.476894 [debug] [Thread-1  ]: finished collecting timing info
13:16:37.477280 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
13:16:37.671791 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf9b6ca7-1f78-4b0b-8641-a38773cf924e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107542460>]}
13:16:37.672331 [info ] [Thread-1  ]: 2 of 7 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 5.25s]
13:16:37.672536 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
13:16:37.672630 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
13:16:37.672814 [info ] [Thread-1  ]: 3 of 7 START table model dbt.first_model........................................ [RUN]
13:16:37.673059 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
13:16:37.673136 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
13:16:37.673209 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
13:16:37.674912 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
13:16:37.675265 [debug] [Thread-1  ]: finished collecting timing info
13:16:37.675346 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
13:16:37.680632 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
13:16:37.681282 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
13:16:37.681362 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id

)

select * 
from source_data


/*
select *, True as first_variable
from source_data
where id >= 1
*/
      );
13:16:37.681429 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:16:39.046252 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.36 seconds
13:16:39.049689 [debug] [Thread-1  ]: finished collecting timing info
13:16:39.050054 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
13:16:39.219809 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf9b6ca7-1f78-4b0b-8641-a38773cf924e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107542130>]}
13:16:39.220379 [info ] [Thread-1  ]: 3 of 7 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 1.55s]
13:16:39.220676 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
13:16:39.220848 [debug] [Thread-1  ]: Began running node model.learn_dbt.playing_with_tests
13:16:39.221021 [info ] [Thread-1  ]: 4 of 7 START table model dbt.playing_with_tests................................. [RUN]
13:16:39.221512 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.playing_with_tests"
13:16:39.221732 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.playing_with_tests
13:16:39.221874 [debug] [Thread-1  ]: Compiling model.learn_dbt.playing_with_tests
13:16:39.223027 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.playing_with_tests"
13:16:39.223487 [debug] [Thread-1  ]: finished collecting timing info
13:16:39.223599 [debug] [Thread-1  ]: Began executing node model.learn_dbt.playing_with_tests
13:16:39.225392 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.playing_with_tests"
13:16:39.226133 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
13:16:39.226258 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */


      create or replace transient table analytics.dbt.playing_with_tests  as
      (select * 
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF001"."CUSTOMER"
      );
13:16:39.226360 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:16:39.850518 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a43d3c-3201-9d36-0000-000120528361
13:16:39.851115 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 002003 (02000): SQL compilation error:
Schema 'SNOWFLAKE_SAMPLE_DATA.TPCH_SF001' does not exist or not authorized.
13:16:39.851607 [debug] [Thread-1  ]: finished collecting timing info
13:16:39.851886 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: Close
13:16:40.094156 [debug] [Thread-1  ]: Database Error in model playing_with_tests (models/example/playing_with_tests.sql)
  002003 (02000): SQL compilation error:
  Schema 'SNOWFLAKE_SAMPLE_DATA.TPCH_SF001' does not exist or not authorized.
  compiled SQL at target/run/learn_dbt/models/example/playing_with_tests.sql
13:16:40.095745 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf9b6ca7-1f78-4b0b-8641-a38773cf924e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076c7af0>]}
13:16:40.096832 [error] [Thread-1  ]: 4 of 7 ERROR creating table model dbt.playing_with_tests........................ [[31mERROR[0m in 0.87s]
13:16:40.097372 [debug] [Thread-1  ]: Finished running node model.learn_dbt.playing_with_tests
13:16:40.097783 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
13:16:40.098395 [info ] [Thread-1  ]: 5 of 7 START table model dbt.snowflake_cumulative_sales......................... [RUN]
13:16:40.099099 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
13:16:40.099327 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
13:16:40.099533 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
13:16:40.101456 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
13:16:40.102326 [debug] [Thread-1  ]: finished collecting timing info
13:16:40.102525 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
13:16:40.105443 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
13:16:40.106685 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
13:16:40.106884 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
13:16:40.107030 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:16:41.842786 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.74 seconds
13:16:41.846019 [debug] [Thread-1  ]: finished collecting timing info
13:16:41.846480 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
13:16:42.259614 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf9b6ca7-1f78-4b0b-8641-a38773cf924e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107542ee0>]}
13:16:42.260162 [info ] [Thread-1  ]: 5 of 7 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 2.16s]
13:16:42.260448 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
13:16:42.260600 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
13:16:42.260893 [info ] [Thread-1  ]: 6 of 7 START table model dbt.snowflake_customer_purchases....................... [RUN]
13:16:42.261424 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
13:16:42.261715 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
13:16:42.261866 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
13:16:42.262957 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
13:16:42.263400 [debug] [Thread-1  ]: finished collecting timing info
13:16:42.263513 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
13:16:42.265243 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
13:16:42.266341 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
13:16:42.266504 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
13:16:42.266646 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:16:44.074876 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.81 seconds
13:16:44.077436 [debug] [Thread-1  ]: finished collecting timing info
13:16:44.077725 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
13:16:44.487145 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf9b6ca7-1f78-4b0b-8641-a38773cf924e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076bc100>]}
13:16:44.488296 [info ] [Thread-1  ]: 6 of 7 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.23s]
13:16:44.488870 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
13:16:44.489137 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
13:16:44.489576 [info ] [Thread-1  ]: 7 of 7 START table model dbt.my_second_dbt_model................................ [RUN]
13:16:44.490246 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
13:16:44.490468 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
13:16:44.490671 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
13:16:44.494183 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
13:16:44.494934 [debug] [Thread-1  ]: finished collecting timing info
13:16:44.495108 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
13:16:44.497581 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
13:16:44.498452 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
13:16:44.498612 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
/*
union all
select 7 as id, True as first_variable
*/
      );
13:16:44.498754 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:16:49.823588 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 5.32 seconds
13:16:49.826502 [debug] [Thread-1  ]: finished collecting timing info
13:16:49.826903 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
13:16:50.425476 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf9b6ca7-1f78-4b0b-8641-a38773cf924e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109d2b3a0>]}
13:16:50.426322 [info ] [Thread-1  ]: 7 of 7 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 5.94s]
13:16:50.426845 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
13:16:50.428210 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:16:50.428717 [info ] [MainThread]: 
13:16:50.429050 [info ] [MainThread]: Finished running 2 incremental models, 5 table models in 24.28s.
13:16:50.429342 [debug] [MainThread]: Connection 'master' was properly closed.
13:16:50.429505 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
13:16:50.436209 [info ] [MainThread]: 
13:16:50.436752 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
13:16:50.437107 [info ] [MainThread]: 
13:16:50.437361 [error] [MainThread]: [33mDatabase Error in model playing_with_tests (models/example/playing_with_tests.sql)[0m
13:16:50.437717 [error] [MainThread]:   002003 (02000): SQL compilation error:
13:16:50.437922 [error] [MainThread]:   Schema 'SNOWFLAKE_SAMPLE_DATA.TPCH_SF001' does not exist or not authorized.
13:16:50.438116 [error] [MainThread]:   compiled SQL at target/run/learn_dbt/models/example/playing_with_tests.sql
13:16:50.438316 [info ] [MainThread]: 
13:16:50.438504 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=1 SKIP=0 TOTAL=7
13:16:50.438767 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104f201f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104f2de80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075e6bb0>]}


============================== 2022-05-13 13:17:56.039052 | e4eab860-f552-4aee-bcda-6701c337849d ==============================
13:17:56.039052 [info ] [MainThread]: Running with dbt=1.0.1
13:17:56.039456 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
13:17:56.039741 [debug] [MainThread]: Tracking: tracking
13:17:56.040043 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e371c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e37dc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e37c10>]}
13:17:56.082054 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
13:17:56.082331 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/playing_with_tests.sql
13:17:56.087514 [debug] [MainThread]: 1699: static parser successfully parsed example/playing_with_tests.sql
13:17:56.106467 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e4eab860-f552-4aee-bcda-6701c337849d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104df20d0>]}
13:17:56.109476 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e4eab860-f552-4aee-bcda-6701c337849d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104103820>]}
13:17:56.109613 [info ] [MainThread]: Found 7 models, 11 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
13:17:56.110402 [info ] [MainThread]: 
13:17:56.110603 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:17:56.111068 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
13:17:56.117046 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
13:17:56.117157 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
13:17:56.117220 [debug] [ThreadPool]: Opening a new connection, currently in state init
13:17:57.140767 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.02 seconds
13:17:57.143617 [debug] [ThreadPool]: On list_analytics: Close
13:17:57.375760 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
13:17:57.384714 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
13:17:57.385004 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
13:17:57.385168 [debug] [ThreadPool]: Opening a new connection, currently in state closed
13:17:58.084868 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 0.7 seconds
13:17:58.088156 [debug] [ThreadPool]: On list_analytics_dbt: Close
13:17:58.251940 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
13:17:58.252716 [info ] [MainThread]: 
13:17:58.257112 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
13:17:58.257544 [info ] [Thread-1  ]: 1 of 7 START incremental model dbt.dates........................................ [RUN]
13:17:58.258065 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
13:17:58.258237 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
13:17:58.258397 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
13:17:58.267333 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
13:17:58.268035 [debug] [Thread-1  ]: finished collecting timing info
13:17:58.268166 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
13:17:58.297218 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:17:58.297444 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
13:17:58.297534 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:18:00.584194 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.29 seconds
13:18:00.597270 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:18:00.597611 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
13:18:00.895996 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.3 seconds
13:18:00.905109 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:18:00.905459 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
13:18:01.072070 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.17 seconds
13:18:01.082415 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:18:01.082755 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
13:18:01.422773 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.34 seconds
13:18:01.448279 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
13:18:01.451038 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:18:01.451205 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
13:18:01.639882 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.19 seconds
13:18:01.640572 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:18:01.640758 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
13:18:02.470849 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.83 seconds
13:18:02.471773 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:18:02.472089 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
13:18:02.652460 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.18 seconds
13:18:02.663688 [debug] [Thread-1  ]: finished collecting timing info
13:18:02.663998 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
13:18:02.995843 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4eab860-f552-4aee-bcda-6701c337849d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107468a30>]}
13:18:02.996733 [info ] [Thread-1  ]: 1 of 7 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 4.74s]
13:18:02.997075 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
13:18:02.997233 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
13:18:02.997478 [info ] [Thread-1  ]: 2 of 7 START incremental model dbt.incremental_time............................. [RUN]
13:18:02.997859 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
13:18:02.997989 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
13:18:02.998106 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
13:18:03.001924 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
13:18:03.002772 [debug] [Thread-1  ]: finished collecting timing info
13:18:03.002958 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
13:18:03.006159 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:18:03.006361 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
13:18:03.006478 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:18:04.502427 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.5 seconds
13:18:04.510075 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:18:04.510443 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
13:18:04.703175 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.19 seconds
13:18:04.711595 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:18:04.711964 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
13:18:04.808122 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
13:18:04.810904 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:18:04.811083 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
13:18:05.024076 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.21 seconds
13:18:05.028771 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
13:18:05.030532 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:18:05.030687 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
13:18:05.183150 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.15 seconds
13:18:05.184158 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:18:05.184383 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
13:18:06.072811 [debug] [Thread-1  ]: SQL status: SUCCESS 90 in 0.89 seconds
13:18:06.073777 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:18:06.074077 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
13:18:06.352241 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.28 seconds
13:18:06.354554 [debug] [Thread-1  ]: finished collecting timing info
13:18:06.354764 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
13:18:06.755324 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4eab860-f552-4aee-bcda-6701c337849d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074f66d0>]}
13:18:06.756054 [info ] [Thread-1  ]: 2 of 7 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 3.76s]
13:18:06.756497 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
13:18:06.756764 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
13:18:06.757188 [info ] [Thread-1  ]: 3 of 7 START table model dbt.first_model........................................ [RUN]
13:18:06.757900 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
13:18:06.758120 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
13:18:06.758322 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
13:18:06.762508 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
13:18:06.763362 [debug] [Thread-1  ]: finished collecting timing info
13:18:06.763538 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
13:18:06.770658 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
13:18:06.771758 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
13:18:06.771904 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id

)

select * 
from source_data


/*
select *, True as first_variable
from source_data
where id >= 1
*/
      );
13:18:06.772031 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:18:07.815602 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.04 seconds
13:18:07.818613 [debug] [Thread-1  ]: finished collecting timing info
13:18:07.819050 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
13:18:08.008921 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4eab860-f552-4aee-bcda-6701c337849d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10745d190>]}
13:18:08.009344 [info ] [Thread-1  ]: 3 of 7 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 1.25s]
13:18:08.009618 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
13:18:08.009766 [debug] [Thread-1  ]: Began running node model.learn_dbt.playing_with_tests
13:18:08.010044 [info ] [Thread-1  ]: 4 of 7 START table model dbt.playing_with_tests................................. [RUN]
13:18:08.010500 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.playing_with_tests"
13:18:08.010624 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.playing_with_tests
13:18:08.010745 [debug] [Thread-1  ]: Compiling model.learn_dbt.playing_with_tests
13:18:08.011793 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.playing_with_tests"
13:18:08.012311 [debug] [Thread-1  ]: finished collecting timing info
13:18:08.012437 [debug] [Thread-1  ]: Began executing node model.learn_dbt.playing_with_tests
13:18:08.014544 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.playing_with_tests"
13:18:08.015293 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
13:18:08.015419 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */


      create or replace transient table analytics.dbt.playing_with_tests  as
      (select * 
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER"
      );
13:18:08.015526 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:18:10.104686 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.09 seconds
13:18:10.108386 [debug] [Thread-1  ]: finished collecting timing info
13:18:10.108708 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: Close
13:18:10.442444 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4eab860-f552-4aee-bcda-6701c337849d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105135700>]}
13:18:10.443004 [info ] [Thread-1  ]: 4 of 7 OK created table model dbt.playing_with_tests............................ [[32mSUCCESS 1[0m in 2.43s]
13:18:10.443312 [debug] [Thread-1  ]: Finished running node model.learn_dbt.playing_with_tests
13:18:10.443576 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
13:18:10.443878 [info ] [Thread-1  ]: 5 of 7 START table model dbt.snowflake_cumulative_sales......................... [RUN]
13:18:10.444241 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
13:18:10.444368 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
13:18:10.444486 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
13:18:10.445603 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
13:18:10.446238 [debug] [Thread-1  ]: finished collecting timing info
13:18:10.446376 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
13:18:10.448589 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
13:18:10.449651 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
13:18:10.449850 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
13:18:10.449997 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:18:12.432997 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.98 seconds
13:18:12.435751 [debug] [Thread-1  ]: finished collecting timing info
13:18:12.436160 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
13:18:12.659364 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4eab860-f552-4aee-bcda-6701c337849d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053f1040>]}
13:18:12.660073 [info ] [Thread-1  ]: 5 of 7 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 2.22s]
13:18:12.660526 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
13:18:12.660786 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
13:18:12.661071 [info ] [Thread-1  ]: 6 of 7 START table model dbt.snowflake_customer_purchases....................... [RUN]
13:18:12.661793 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
13:18:12.662037 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
13:18:12.662248 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
13:18:12.663775 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
13:18:12.664339 [debug] [Thread-1  ]: finished collecting timing info
13:18:12.664503 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
13:18:12.667102 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
13:18:12.668528 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
13:18:12.668840 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
13:18:12.669010 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:18:14.463657 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.79 seconds
13:18:14.465387 [debug] [Thread-1  ]: finished collecting timing info
13:18:14.465613 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
13:18:14.625555 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4eab860-f552-4aee-bcda-6701c337849d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107518580>]}
13:18:14.626193 [info ] [Thread-1  ]: 6 of 7 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 1.96s]
13:18:14.626630 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
13:18:14.626868 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
13:18:14.627261 [info ] [Thread-1  ]: 7 of 7 START table model dbt.my_second_dbt_model................................ [RUN]
13:18:14.627890 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
13:18:14.628101 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
13:18:14.628296 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
13:18:14.631426 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
13:18:14.632043 [debug] [Thread-1  ]: finished collecting timing info
13:18:14.632214 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
13:18:14.634902 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
13:18:14.635962 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
13:18:14.636124 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
/*
union all
select 7 as id, True as first_variable
*/
      );
13:18:14.636265 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:18:16.038032 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.4 seconds
13:18:16.040946 [debug] [Thread-1  ]: finished collecting timing info
13:18:16.041175 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
13:18:16.210809 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4eab860-f552-4aee-bcda-6701c337849d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105350310>]}
13:18:16.211536 [info ] [Thread-1  ]: 7 of 7 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.58s]
13:18:16.212017 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
13:18:16.213339 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:18:16.213874 [info ] [MainThread]: 
13:18:16.214248 [info ] [MainThread]: Finished running 2 incremental models, 5 table models in 20.10s.
13:18:16.214548 [debug] [MainThread]: Connection 'master' was properly closed.
13:18:16.214711 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
13:18:16.221576 [info ] [MainThread]: 
13:18:16.221896 [info ] [MainThread]: [32mCompleted successfully[0m
13:18:16.222195 [info ] [MainThread]: 
13:18:16.222417 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
13:18:16.222641 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103a828e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103a82f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105356820>]}


============================== 2022-05-13 13:18:23.116920 | 06c1f92f-12a3-4f61-88b7-0ede0df80620 ==============================
13:18:23.116920 [info ] [MainThread]: Running with dbt=1.0.1
13:18:23.117281 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, store_failures=False, indirect_selection='eager', threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.test.TestTask'>, which='test', rpc_method='test')
13:18:23.117413 [debug] [MainThread]: Tracking: tracking
13:18:23.117627 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e1b1c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e1bf10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e1b460>]}
13:18:23.160182 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
13:18:23.160315 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
13:18:23.163399 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '06c1f92f-12a3-4f61-88b7-0ede0df80620', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106de7e20>]}
13:18:23.166800 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '06c1f92f-12a3-4f61-88b7-0ede0df80620', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104585d90>]}
13:18:23.166989 [info ] [MainThread]: Found 7 models, 11 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
13:18:23.168083 [info ] [MainThread]: 
13:18:23.168387 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:18:23.169008 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
13:18:23.175316 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
13:18:23.175425 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
13:18:23.175493 [debug] [ThreadPool]: Opening a new connection, currently in state init
13:18:24.016230 [debug] [ThreadPool]: SQL status: SUCCESS 7 in 0.84 seconds
13:18:24.019263 [debug] [ThreadPool]: On list_analytics_dbt: Close
13:18:24.296750 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
13:18:24.297309 [info ] [MainThread]: 
13:18:24.301339 [debug] [Thread-1  ]: Began running node test.learn_dbt.assert_under_10_percent_null
13:18:24.301569 [info ] [Thread-1  ]: 1 of 11 START test assert_under_10_percent_null................................. [RUN]
13:18:24.302031 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.assert_under_10_percent_null"
13:18:24.302191 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.assert_under_10_percent_null
13:18:24.302359 [debug] [Thread-1  ]: Compiling test.learn_dbt.assert_under_10_percent_null
13:18:24.305442 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.assert_under_10_percent_null"
13:18:24.306147 [debug] [Thread-1  ]: finished collecting timing info
13:18:24.306332 [debug] [Thread-1  ]: Began executing node test.learn_dbt.assert_under_10_percent_null
13:18:24.321121 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.assert_under_10_percent_null"
13:18:24.322074 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.assert_under_10_percent_null"
13:18:24.322204 [debug] [Thread-1  ]: On test.learn_dbt.assert_under_10_percent_null: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.assert_under_10_percent_null"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      select sum (case when id is null then 1 else 0 end) / count(*) as total_nulls
from analytics.dbt.first_model
having sum (case when id is null then 1 else 0 end) / count(*) > .4
      
    ) dbt_internal_test
13:18:24.322305 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:18:25.182065 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.86 seconds
13:18:25.186277 [debug] [Thread-1  ]: finished collecting timing info
13:18:25.186683 [debug] [Thread-1  ]: On test.learn_dbt.assert_under_10_percent_null: Close
13:18:25.459287 [info ] [Thread-1  ]: 1 of 11 PASS assert_under_10_percent_null....................................... [[32mPASS[0m in 1.16s]
13:18:25.459958 [debug] [Thread-1  ]: Finished running node test.learn_dbt.assert_under_10_percent_null
13:18:25.460223 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
13:18:25.460552 [info ] [Thread-1  ]: 2 of 11 START test not_null_my_second_dbt_model_id.............................. [RUN]
13:18:25.461242 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"
13:18:25.461398 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
13:18:25.461677 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
13:18:25.472920 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"
13:18:25.473817 [debug] [Thread-1  ]: finished collecting timing info
13:18:25.473976 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
13:18:25.476932 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"
13:18:25.477712 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"
13:18:25.477840 [debug] [Thread-1  ]: On test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.my_second_dbt_model
where id is null



      
    ) dbt_internal_test
13:18:25.477955 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:18:26.249343 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.77 seconds
13:18:26.258481 [debug] [Thread-1  ]: finished collecting timing info
13:18:26.258988 [debug] [Thread-1  ]: On test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778: Close
13:18:26.497352 [error] [Thread-1  ]: 2 of 11 FAIL 1 not_null_my_second_dbt_model_id.................................. [[31mFAIL 1[0m in 1.04s]
13:18:26.497851 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
13:18:26.498058 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4
13:18:26.498537 [info ] [Thread-1  ]: 3 of 11 START test not_null_playing_with_tests_c_custkey........................ [RUN]
13:18:26.498983 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4"
13:18:26.499119 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4
13:18:26.499454 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4
13:18:26.504843 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4"
13:18:26.505447 [debug] [Thread-1  ]: finished collecting timing info
13:18:26.505624 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4
13:18:26.507379 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4"
13:18:26.508332 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4"
13:18:26.508496 [debug] [Thread-1  ]: On test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.playing_with_tests
where c_custkey is null



      
    ) dbt_internal_test
13:18:26.508919 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:18:27.270438 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.76 seconds
13:18:27.273878 [debug] [Thread-1  ]: finished collecting timing info
13:18:27.274310 [debug] [Thread-1  ]: On test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4: Close
13:18:27.539904 [info ] [Thread-1  ]: 3 of 11 PASS not_null_playing_with_tests_c_custkey.............................. [[32mPASS[0m in 1.04s]
13:18:27.540669 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4
13:18:27.540962 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
13:18:27.541323 [info ] [Thread-1  ]: 4 of 11 START test not_null_snowflake_cumulative_sales_o_orderdate.............. [RUN]
13:18:27.542015 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
13:18:27.542223 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
13:18:27.542413 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
13:18:27.546715 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
13:18:27.547245 [debug] [Thread-1  ]: finished collecting timing info
13:18:27.547412 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
13:18:27.549554 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
13:18:27.550487 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
13:18:27.550630 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.snowflake_cumulative_sales
where o_orderdate is null



      
    ) dbt_internal_test
13:18:27.550754 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:18:28.337976 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.79 seconds
13:18:28.340914 [debug] [Thread-1  ]: finished collecting timing info
13:18:28.341255 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856: Close
13:18:28.602282 [info ] [Thread-1  ]: 4 of 11 PASS not_null_snowflake_cumulative_sales_o_orderdate.................... [[32mPASS[0m in 1.06s]
13:18:28.602899 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
13:18:28.603114 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
13:18:28.603385 [info ] [Thread-1  ]: 5 of 11 START test not_null_snowflake_customer_purchases_c_custkey.............. [RUN]
13:18:28.604007 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
13:18:28.604220 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
13:18:28.604421 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
13:18:28.609277 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
13:18:28.610028 [debug] [Thread-1  ]: finished collecting timing info
13:18:28.610209 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
13:18:28.612396 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
13:18:28.613375 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
13:18:28.613658 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.snowflake_customer_purchases
where c_custkey is null



      
    ) dbt_internal_test
13:18:28.613793 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:18:29.373779 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.76 seconds
13:18:29.377301 [debug] [Thread-1  ]: finished collecting timing info
13:18:29.377633 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502: Close
13:18:29.627766 [info ] [Thread-1  ]: 5 of 11 PASS not_null_snowflake_customer_purchases_c_custkey.................... [[32mPASS[0m in 1.02s]
13:18:29.628193 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
13:18:29.628315 [debug] [Thread-1  ]: Began running node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
13:18:29.628470 [info ] [Thread-1  ]: 6 of 11 START test relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ [RUN]
13:18:29.628756 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
13:18:29.628849 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
13:18:29.628937 [debug] [Thread-1  ]: Compiling test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
13:18:29.634505 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
13:18:29.634931 [debug] [Thread-1  ]: finished collecting timing info
13:18:29.635037 [debug] [Thread-1  ]: Began executing node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
13:18:29.636176 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
13:18:29.636890 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
13:18:29.636981 [debug] [Thread-1  ]: On test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select id as from_field
    from analytics.dbt.my_second_dbt_model
    where id is not null
),

parent as (
    select id as to_field
    from analytics.dbt.first_model
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
13:18:29.637059 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:18:30.485951 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.85 seconds
13:18:30.489788 [debug] [Thread-1  ]: finished collecting timing info
13:18:30.490270 [debug] [Thread-1  ]: On test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: Close
13:18:30.934899 [info ] [Thread-1  ]: 6 of 11 PASS relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.. [[32mPASS[0m in 1.31s]
13:18:30.935594 [debug] [Thread-1  ]: Finished running node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
13:18:30.935849 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
13:18:30.936169 [info ] [Thread-1  ]: 7 of 11 START test unique_my_first_dbt_model_id................................. [RUN]
13:18:30.936878 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
13:18:30.937093 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
13:18:30.937293 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
13:18:30.945813 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
13:18:30.946602 [debug] [Thread-1  ]: finished collecting timing info
13:18:30.946839 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
13:18:30.948675 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
13:18:30.949737 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
13:18:30.949885 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.first_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
13:18:30.950013 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:18:32.105562 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.16 seconds
13:18:32.108682 [debug] [Thread-1  ]: finished collecting timing info
13:18:32.109093 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_first_dbt_model_id.16e066b321: Close
13:18:32.459262 [info ] [Thread-1  ]: 7 of 11 PASS unique_my_first_dbt_model_id....................................... [[32mPASS[0m in 1.52s]
13:18:32.459964 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
13:18:32.460228 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:18:32.460431 [info ] [Thread-1  ]: 8 of 11 START test unique_my_second_dbt_model_id................................ [RUN]
13:18:32.461156 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
13:18:32.461405 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:18:32.461612 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:18:32.466520 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
13:18:32.467411 [debug] [Thread-1  ]: finished collecting timing info
13:18:32.467596 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:18:32.469862 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
13:18:32.470949 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
13:18:32.471103 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.my_second_dbt_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
13:18:32.471242 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:18:33.457228 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.99 seconds
13:18:33.459881 [debug] [Thread-1  ]: finished collecting timing info
13:18:33.460186 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493: Close
13:18:33.861912 [info ] [Thread-1  ]: 8 of 11 PASS unique_my_second_dbt_model_id...................................... [[32mPASS[0m in 1.40s]
13:18:33.862635 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:18:33.862920 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550
13:18:33.863202 [info ] [Thread-1  ]: 9 of 11 START test unique_playing_with_tests_c_custkey.......................... [RUN]
13:18:33.863780 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550"
13:18:33.864009 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550
13:18:33.864119 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550
13:18:33.867176 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550"
13:18:33.867625 [debug] [Thread-1  ]: finished collecting timing info
13:18:33.867850 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550
13:18:33.870404 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550"
13:18:33.871534 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550"
13:18:33.871703 [debug] [Thread-1  ]: On test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    c_custkey as unique_field,
    count(*) as n_records

from analytics.dbt.playing_with_tests
where c_custkey is not null
group by c_custkey
having count(*) > 1



      
    ) dbt_internal_test
13:18:33.871846 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:18:34.907938 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.04 seconds
13:18:34.910461 [debug] [Thread-1  ]: finished collecting timing info
13:18:34.910921 [debug] [Thread-1  ]: On test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550: Close
13:18:35.090164 [info ] [Thread-1  ]: 9 of 11 PASS unique_playing_with_tests_c_custkey................................ [[32mPASS[0m in 1.23s]
13:18:35.090801 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550
13:18:35.090969 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
13:18:35.091129 [info ] [Thread-1  ]: 10 of 11 START test unique_snowflake_cumulative_sales_o_orderdate............... [RUN]
13:18:35.091473 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
13:18:35.091569 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
13:18:35.091663 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
13:18:35.094294 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
13:18:35.095002 [debug] [Thread-1  ]: finished collecting timing info
13:18:35.095226 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
13:18:35.097209 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
13:18:35.097850 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
13:18:35.097943 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    o_orderdate as unique_field,
    count(*) as n_records

from analytics.dbt.snowflake_cumulative_sales
where o_orderdate is not null
group by o_orderdate
having count(*) > 1



      
    ) dbt_internal_test
13:18:35.098021 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:18:36.130183 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.03 seconds
13:18:36.132378 [debug] [Thread-1  ]: finished collecting timing info
13:18:36.132667 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed: Close
13:18:36.321550 [info ] [Thread-1  ]: 10 of 11 PASS unique_snowflake_cumulative_sales_o_orderdate..................... [[32mPASS[0m in 1.23s]
13:18:36.321960 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
13:18:36.322141 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
13:18:36.322401 [info ] [Thread-1  ]: 11 of 11 START test unique_snowflake_customer_purchases_c_custkey............... [RUN]
13:18:36.323159 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
13:18:36.323373 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
13:18:36.323579 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
13:18:36.328479 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
13:18:36.329154 [debug] [Thread-1  ]: finished collecting timing info
13:18:36.329319 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
13:18:36.331609 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
13:18:36.332797 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
13:18:36.333082 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    c_custkey as unique_field,
    count(*) as n_records

from analytics.dbt.snowflake_customer_purchases
where c_custkey is not null
group by c_custkey
having count(*) > 1



      
    ) dbt_internal_test
13:18:36.333269 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:18:37.296369 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.96 seconds
13:18:37.298597 [debug] [Thread-1  ]: finished collecting timing info
13:18:37.298845 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f: Close
13:18:37.616919 [info ] [Thread-1  ]: 11 of 11 PASS unique_snowflake_customer_purchases_c_custkey..................... [[32mPASS[0m in 1.29s]
13:18:37.617236 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
13:18:37.618007 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:18:37.618228 [info ] [MainThread]: 
13:18:37.618366 [info ] [MainThread]: Finished running 11 tests in 14.45s.
13:18:37.618486 [debug] [MainThread]: Connection 'master' was properly closed.
13:18:37.618554 [debug] [MainThread]: Connection 'test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f' was properly closed.
13:18:37.622075 [info ] [MainThread]: 
13:18:37.622257 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
13:18:37.622425 [info ] [MainThread]: 
13:18:37.622544 [error] [MainThread]: [31mFailure in test not_null_my_second_dbt_model_id (models/example/schema.yml)[0m
13:18:37.622673 [error] [MainThread]:   Got 1 result, configured to fail if != 0
13:18:37.622787 [info ] [MainThread]: 
13:18:37.622897 [info ] [MainThread]:   compiled SQL at target/compiled/learn_dbt/models/example/schema.yml/not_null_my_second_dbt_model_id.sql
13:18:37.623018 [info ] [MainThread]: 
13:18:37.623123 [info ] [MainThread]: Done. PASS=10 WARN=0 ERROR=1 SKIP=0 TOTAL=11
13:18:37.623291 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105b68e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106fc20a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110387820>]}


============================== 2022-05-13 13:23:52.923322 | 8f146740-bd48-4a2d-88c0-cd4adc3151f7 ==============================
13:23:52.923322 [info ] [MainThread]: Running with dbt=1.0.1
13:23:52.923863 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
13:23:52.923998 [debug] [MainThread]: Tracking: tracking
13:23:52.924210 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e8f850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e8f1c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e8fd60>]}
13:23:52.963929 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104fa68e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104fa6a60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104fa6dc0>]}


============================== 2022-05-13 13:25:11.319135 | 498dd6f5-7794-425a-a323-8ffd0a37be54 ==============================
13:25:11.319135 [info ] [MainThread]: Running with dbt=1.0.1
13:25:11.319458 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
13:25:11.319594 [debug] [MainThread]: Tracking: tracking
13:25:11.319823 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1113ff6a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1113ff7c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1113ffa90>]}
13:25:11.357651 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1114b5d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1114b5d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1114b5df0>]}


============================== 2022-05-13 13:25:51.164615 | c061952e-2467-423a-8f8b-c216d0a8d54a ==============================
13:25:51.164615 [info ] [MainThread]: Running with dbt=1.0.1
13:25:51.165099 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
13:25:51.165244 [debug] [MainThread]: Tracking: tracking
13:25:51.165461 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1050d31c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1050d3f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1050d3460>]}
13:25:51.213818 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
13:25:51.214167 [debug] [MainThread]: Partial parsing: update schema file: learn_dbt://models/example/schema.yml
13:25:51.219983 [debug] [MainThread]: 1699: static parser successfully parsed example/playing_with_tests.sql
13:25:51.246740 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c061952e-2467-423a-8f8b-c216d0a8d54a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1050c0700>]}
13:25:51.249852 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c061952e-2467-423a-8f8b-c216d0a8d54a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104263970>]}
13:25:51.249987 [info ] [MainThread]: Found 7 models, 12 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
13:25:51.250783 [info ] [MainThread]: 
13:25:51.250982 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:25:51.251437 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
13:25:51.257354 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
13:25:51.257490 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
13:25:51.257558 [debug] [ThreadPool]: Opening a new connection, currently in state init
13:25:52.246136 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.99 seconds
13:25:52.247693 [debug] [ThreadPool]: On list_analytics: Close
13:25:52.456085 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
13:25:52.465009 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
13:25:52.465294 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
13:25:52.465464 [debug] [ThreadPool]: Opening a new connection, currently in state closed
13:25:53.248496 [debug] [ThreadPool]: SQL status: SUCCESS 7 in 0.78 seconds
13:25:53.252051 [debug] [ThreadPool]: On list_analytics_dbt: Close
13:25:53.465603 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
13:25:53.466424 [info ] [MainThread]: 
13:25:53.472054 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
13:25:53.472510 [info ] [Thread-1  ]: 1 of 7 START incremental model dbt.dates........................................ [RUN]
13:25:53.473092 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
13:25:53.473272 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
13:25:53.473444 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
13:25:53.483194 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
13:25:53.484375 [debug] [Thread-1  ]: finished collecting timing info
13:25:53.484539 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
13:25:53.513376 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:25:53.513578 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
13:25:53.513669 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:25:55.163175 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.65 seconds
13:25:55.173299 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:25:55.173470 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
13:25:55.272622 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.1 seconds
13:25:55.279093 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:25:55.279391 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
13:25:55.379690 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.1 seconds
13:25:55.392895 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:25:55.393190 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
13:25:55.506992 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.11 seconds
13:25:55.528457 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
13:25:55.530837 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:25:55.530986 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
13:25:55.818923 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.29 seconds
13:25:55.820537 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:25:55.820808 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
13:25:56.394585 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.57 seconds
13:25:56.395041 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:25:56.395223 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
13:25:56.576680 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.18 seconds
13:25:56.590401 [debug] [Thread-1  ]: finished collecting timing info
13:25:56.590869 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
13:25:56.867947 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c061952e-2467-423a-8f8b-c216d0a8d54a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108544a60>]}
13:25:56.868831 [info ] [Thread-1  ]: 1 of 7 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 3.39s]
13:25:56.869272 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
13:25:56.869527 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
13:25:56.869922 [info ] [Thread-1  ]: 2 of 7 START incremental model dbt.incremental_time............................. [RUN]
13:25:56.870545 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
13:25:56.870761 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
13:25:56.870975 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
13:25:56.875072 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
13:25:56.877111 [debug] [Thread-1  ]: finished collecting timing info
13:25:56.877327 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
13:25:56.880934 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:25:56.881136 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
13:25:56.881266 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:25:58.154885 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.27 seconds
13:25:58.159963 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:25:58.160284 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
13:25:58.306830 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.15 seconds
13:25:58.309383 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:25:58.309512 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
13:25:58.402705 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.09 seconds
13:25:58.407734 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:25:58.408053 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
13:25:58.509681 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.1 seconds
13:25:58.515081 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
13:25:58.518513 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:25:58.518741 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
13:25:58.656580 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.14 seconds
13:25:58.657185 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:25:58.657389 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
13:25:59.221060 [debug] [Thread-1  ]: SQL status: SUCCESS 474 in 0.56 seconds
13:25:59.221788 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:25:59.221984 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
13:25:59.438369 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.22 seconds
13:25:59.441331 [debug] [Thread-1  ]: finished collecting timing info
13:25:59.441700 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
13:25:59.680916 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c061952e-2467-423a-8f8b-c216d0a8d54a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1056b4520>]}
13:25:59.681676 [info ] [Thread-1  ]: 2 of 7 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 2.81s]
13:25:59.682124 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
13:25:59.682373 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
13:25:59.682660 [info ] [Thread-1  ]: 3 of 7 START table model dbt.first_model........................................ [RUN]
13:25:59.683370 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
13:25:59.683624 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
13:25:59.683829 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
13:25:59.687989 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
13:25:59.690041 [debug] [Thread-1  ]: finished collecting timing info
13:25:59.690229 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
13:25:59.699336 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
13:25:59.700403 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
13:25:59.700545 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id

)

select * 
from source_data


/*
select *, True as first_variable
from source_data
where id >= 1
*/
      );
13:25:59.700677 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:26:00.838096 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.14 seconds
13:26:00.840886 [debug] [Thread-1  ]: finished collecting timing info
13:26:00.841210 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
13:26:01.153684 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c061952e-2467-423a-8f8b-c216d0a8d54a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1056b4d00>]}
13:26:01.154325 [info ] [Thread-1  ]: 3 of 7 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 1.47s]
13:26:01.154788 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
13:26:01.155043 [debug] [Thread-1  ]: Began running node model.learn_dbt.playing_with_tests
13:26:01.155534 [info ] [Thread-1  ]: 4 of 7 START table model dbt.playing_with_tests................................. [RUN]
13:26:01.156515 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.playing_with_tests"
13:26:01.156752 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.playing_with_tests
13:26:01.156951 [debug] [Thread-1  ]: Compiling model.learn_dbt.playing_with_tests
13:26:01.158609 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.playing_with_tests"
13:26:01.159349 [debug] [Thread-1  ]: finished collecting timing info
13:26:01.159520 [debug] [Thread-1  ]: Began executing node model.learn_dbt.playing_with_tests
13:26:01.161874 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.playing_with_tests"
13:26:01.162657 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
13:26:01.162823 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */


      create or replace transient table analytics.dbt.playing_with_tests  as
      (select * 
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER"
      );
13:26:01.162970 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:26:03.158282 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.0 seconds
13:26:03.160944 [debug] [Thread-1  ]: finished collecting timing info
13:26:03.161292 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: Close
13:26:03.329641 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c061952e-2467-423a-8f8b-c216d0a8d54a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1056b4940>]}
13:26:03.330130 [info ] [Thread-1  ]: 4 of 7 OK created table model dbt.playing_with_tests............................ [[32mSUCCESS 1[0m in 2.17s]
13:26:03.330373 [debug] [Thread-1  ]: Finished running node model.learn_dbt.playing_with_tests
13:26:03.330518 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
13:26:03.330754 [info ] [Thread-1  ]: 5 of 7 START table model dbt.snowflake_cumulative_sales......................... [RUN]
13:26:03.331118 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
13:26:03.331238 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
13:26:03.331349 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
13:26:03.332292 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
13:26:03.334011 [debug] [Thread-1  ]: finished collecting timing info
13:26:03.334149 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
13:26:03.335836 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
13:26:03.336506 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
13:26:03.336623 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
13:26:03.336719 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:26:06.366961 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 3.03 seconds
13:26:06.369736 [debug] [Thread-1  ]: finished collecting timing info
13:26:06.370077 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
13:26:06.532218 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c061952e-2467-423a-8f8b-c216d0a8d54a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108608490>]}
13:26:06.535655 [info ] [Thread-1  ]: 5 of 7 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 3.20s]
13:26:06.536170 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
13:26:06.536427 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
13:26:06.536931 [info ] [Thread-1  ]: 6 of 7 START table model dbt.snowflake_customer_purchases....................... [RUN]
13:26:06.537689 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
13:26:06.537916 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
13:26:06.538122 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
13:26:06.539930 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
13:26:06.541671 [debug] [Thread-1  ]: finished collecting timing info
13:26:06.541954 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
13:26:06.544746 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
13:26:06.546153 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
13:26:06.546363 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
13:26:06.546526 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:26:08.429156 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.88 seconds
13:26:08.432047 [debug] [Thread-1  ]: finished collecting timing info
13:26:08.432745 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
13:26:08.610077 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c061952e-2467-423a-8f8b-c216d0a8d54a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1057016a0>]}
13:26:08.610825 [info ] [Thread-1  ]: 6 of 7 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.07s]
13:26:08.611266 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
13:26:08.611506 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
13:26:08.611779 [info ] [Thread-1  ]: 7 of 7 START table model dbt.my_second_dbt_model................................ [RUN]
13:26:08.612485 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
13:26:08.612747 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
13:26:08.612961 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
13:26:08.616133 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
13:26:08.618235 [debug] [Thread-1  ]: finished collecting timing info
13:26:08.618431 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
13:26:08.620878 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
13:26:08.621916 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
13:26:08.622169 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
/*
union all
select 7 as id, True as first_variable
*/
      );
13:26:08.622459 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:26:10.022127 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.4 seconds
13:26:10.025789 [debug] [Thread-1  ]: finished collecting timing info
13:26:10.026186 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
13:26:10.192797 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c061952e-2467-423a-8f8b-c216d0a8d54a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1056f29a0>]}
13:26:10.194147 [info ] [Thread-1  ]: 7 of 7 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.58s]
13:26:10.194994 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
13:26:10.196922 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:26:10.197625 [info ] [MainThread]: 
13:26:10.198006 [info ] [MainThread]: Finished running 2 incremental models, 5 table models in 18.95s.
13:26:10.198314 [debug] [MainThread]: Connection 'master' was properly closed.
13:26:10.198483 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
13:26:10.207127 [info ] [MainThread]: 
13:26:10.207586 [info ] [MainThread]: [32mCompleted successfully[0m
13:26:10.207858 [info ] [MainThread]: 
13:26:10.208157 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
13:26:10.208465 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103c1d7f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105244640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1056dbc70>]}


============================== 2022-05-13 13:26:14.807225 | e1742851-5b6f-4231-aca0-63ec3ecc8c89 ==============================
13:26:14.807225 [info ] [MainThread]: Running with dbt=1.0.1
13:26:14.807658 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, store_failures=False, indirect_selection='eager', threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.test.TestTask'>, which='test', rpc_method='test')
13:26:14.807817 [debug] [MainThread]: Tracking: tracking
13:26:14.808039 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108ca7160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108ca7070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108ca7400>]}
13:26:14.852533 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
13:26:14.852686 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
13:26:14.855721 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e1742851-5b6f-4231-aca0-63ec3ecc8c89', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c91130>]}
13:26:14.859005 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e1742851-5b6f-4231-aca0-63ec3ecc8c89', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107aa7a90>]}
13:26:14.859138 [info ] [MainThread]: Found 7 models, 12 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
13:26:14.859983 [info ] [MainThread]: 
13:26:14.860187 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:26:14.860675 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
13:26:14.866526 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
13:26:14.866662 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
13:26:14.866729 [debug] [ThreadPool]: Opening a new connection, currently in state init
13:26:15.522955 [debug] [ThreadPool]: SQL status: SUCCESS 7 in 0.66 seconds
13:26:15.525348 [debug] [ThreadPool]: On list_analytics_dbt: Close
13:26:15.947547 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
13:26:15.948310 [info ] [MainThread]: 
13:26:15.952532 [debug] [Thread-1  ]: Began running node test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
13:26:15.952799 [info ] [Thread-1  ]: 1 of 12 START test accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE [RUN]
13:26:15.953145 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
13:26:15.953232 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
13:26:15.953310 [debug] [Thread-1  ]: Compiling test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
13:26:15.967844 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
13:26:15.968460 [debug] [Thread-1  ]: finished collecting timing info
13:26:15.968600 [debug] [Thread-1  ]: Began executing node test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
13:26:15.981026 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
13:26:15.982237 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
13:26:15.982370 [debug] [Thread-1  ]: On test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        c_mktsegment as value_field,
        count(*) as n_records

    from analytics.dbt.playing_with_tests
    group by c_mktsegment

)

select *
from all_values
where value_field not in (
    'BUILDING','AUTOMOBILE','MACHINERY','HOUSEHOLD','FURNITURE'
)



      
    ) dbt_internal_test
13:26:15.982473 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:26:17.377078 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.39 seconds
13:26:17.380719 [debug] [Thread-1  ]: finished collecting timing info
13:26:17.381122 [debug] [Thread-1  ]: On test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3: Close
13:26:17.556467 [info ] [Thread-1  ]: 1 of 12 PASS accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE [[32mPASS[0m in 1.60s]
13:26:17.557219 [debug] [Thread-1  ]: Finished running node test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
13:26:17.557490 [debug] [Thread-1  ]: Began running node test.learn_dbt.assert_under_10_percent_null
13:26:17.557700 [info ] [Thread-1  ]: 2 of 12 START test assert_under_10_percent_null................................. [RUN]
13:26:17.558427 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.assert_under_10_percent_null"
13:26:17.558686 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.assert_under_10_percent_null
13:26:17.558916 [debug] [Thread-1  ]: Compiling test.learn_dbt.assert_under_10_percent_null
13:26:17.561985 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.assert_under_10_percent_null"
13:26:17.563897 [debug] [Thread-1  ]: finished collecting timing info
13:26:17.564150 [debug] [Thread-1  ]: Began executing node test.learn_dbt.assert_under_10_percent_null
13:26:17.566646 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.assert_under_10_percent_null"
13:26:17.567967 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.assert_under_10_percent_null"
13:26:17.568181 [debug] [Thread-1  ]: On test.learn_dbt.assert_under_10_percent_null: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.assert_under_10_percent_null"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      select sum (case when id is null then 1 else 0 end) / count(*) as total_nulls
from analytics.dbt.first_model
having sum (case when id is null then 1 else 0 end) / count(*) > .4
      
    ) dbt_internal_test
13:26:17.568319 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:26:18.611465 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.04 seconds
13:26:18.614522 [debug] [Thread-1  ]: finished collecting timing info
13:26:18.614872 [debug] [Thread-1  ]: On test.learn_dbt.assert_under_10_percent_null: Close
13:26:18.887977 [info ] [Thread-1  ]: 2 of 12 PASS assert_under_10_percent_null....................................... [[32mPASS[0m in 1.33s]
13:26:18.888800 [debug] [Thread-1  ]: Finished running node test.learn_dbt.assert_under_10_percent_null
13:26:18.889081 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
13:26:18.889417 [info ] [Thread-1  ]: 3 of 12 START test not_null_my_second_dbt_model_id.............................. [RUN]
13:26:18.890145 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"
13:26:18.890446 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
13:26:18.890679 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
13:26:18.898668 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"
13:26:18.899537 [debug] [Thread-1  ]: finished collecting timing info
13:26:18.899811 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
13:26:18.901479 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"
13:26:18.902330 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"
13:26:18.902482 [debug] [Thread-1  ]: On test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.my_second_dbt_model
where id is null



      
    ) dbt_internal_test
13:26:18.902611 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:26:19.935706 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.03 seconds
13:26:19.938629 [debug] [Thread-1  ]: finished collecting timing info
13:26:19.938952 [debug] [Thread-1  ]: On test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778: Close
13:26:20.128235 [error] [Thread-1  ]: 3 of 12 FAIL 1 not_null_my_second_dbt_model_id.................................. [[31mFAIL 1[0m in 1.24s]
13:26:20.128797 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
13:26:20.129012 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4
13:26:20.129266 [info ] [Thread-1  ]: 4 of 12 START test not_null_playing_with_tests_c_custkey........................ [RUN]
13:26:20.129770 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4"
13:26:20.129944 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4
13:26:20.130041 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4
13:26:20.132755 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4"
13:26:20.133187 [debug] [Thread-1  ]: finished collecting timing info
13:26:20.133287 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4
13:26:20.134332 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4"
13:26:20.134856 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4"
13:26:20.134946 [debug] [Thread-1  ]: On test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.playing_with_tests
where c_custkey is null



      
    ) dbt_internal_test
13:26:20.135025 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:26:20.982257 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.85 seconds
13:26:20.985762 [debug] [Thread-1  ]: finished collecting timing info
13:26:20.986149 [debug] [Thread-1  ]: On test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4: Close
13:26:21.153861 [info ] [Thread-1  ]: 4 of 12 PASS not_null_playing_with_tests_c_custkey.............................. [[32mPASS[0m in 1.02s]
13:26:21.154475 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4
13:26:21.154744 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
13:26:21.155137 [info ] [Thread-1  ]: 5 of 12 START test not_null_snowflake_cumulative_sales_o_orderdate.............. [RUN]
13:26:21.156001 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
13:26:21.156245 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
13:26:21.156445 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
13:26:21.160931 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
13:26:21.161528 [debug] [Thread-1  ]: finished collecting timing info
13:26:21.161696 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
13:26:21.163858 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
13:26:21.164843 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
13:26:21.165006 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.snowflake_cumulative_sales
where o_orderdate is null



      
    ) dbt_internal_test
13:26:21.165352 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:26:22.030784 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.87 seconds
13:26:22.034803 [debug] [Thread-1  ]: finished collecting timing info
13:26:22.035234 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856: Close
13:26:22.205733 [info ] [Thread-1  ]: 5 of 12 PASS not_null_snowflake_cumulative_sales_o_orderdate.................... [[32mPASS[0m in 1.05s]
13:26:22.206308 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
13:26:22.206696 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
13:26:22.206940 [info ] [Thread-1  ]: 6 of 12 START test not_null_snowflake_customer_purchases_c_custkey.............. [RUN]
13:26:22.207583 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
13:26:22.207798 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
13:26:22.207992 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
13:26:22.212679 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
13:26:22.213284 [debug] [Thread-1  ]: finished collecting timing info
13:26:22.213460 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
13:26:22.215588 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
13:26:22.216520 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
13:26:22.216680 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.snowflake_customer_purchases
where c_custkey is null



      
    ) dbt_internal_test
13:26:22.216817 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:26:23.297176 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.08 seconds
13:26:23.300320 [debug] [Thread-1  ]: finished collecting timing info
13:26:23.300734 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502: Close
13:26:23.587542 [info ] [Thread-1  ]: 6 of 12 PASS not_null_snowflake_customer_purchases_c_custkey.................... [[32mPASS[0m in 1.38s]
13:26:23.588496 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
13:26:23.589003 [debug] [Thread-1  ]: Began running node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
13:26:23.589449 [info ] [Thread-1  ]: 7 of 12 START test relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ [RUN]
13:26:23.590113 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
13:26:23.590336 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
13:26:23.590548 [debug] [Thread-1  ]: Compiling test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
13:26:23.601392 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
13:26:23.602211 [debug] [Thread-1  ]: finished collecting timing info
13:26:23.602376 [debug] [Thread-1  ]: Began executing node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
13:26:23.604216 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
13:26:23.605446 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
13:26:23.605598 [debug] [Thread-1  ]: On test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select id as from_field
    from analytics.dbt.my_second_dbt_model
    where id is not null
),

parent as (
    select id as to_field
    from analytics.dbt.first_model
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
13:26:23.605730 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:26:24.523911 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.92 seconds
13:26:24.526185 [debug] [Thread-1  ]: finished collecting timing info
13:26:24.526401 [debug] [Thread-1  ]: On test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: Close
13:26:24.718941 [info ] [Thread-1  ]: 7 of 12 PASS relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.. [[32mPASS[0m in 1.13s]
13:26:24.723157 [debug] [Thread-1  ]: Finished running node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
13:26:24.724625 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
13:26:24.725785 [info ] [Thread-1  ]: 8 of 12 START test unique_my_first_dbt_model_id................................. [RUN]
13:26:24.726795 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
13:26:24.727043 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
13:26:24.727258 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
13:26:24.735385 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
13:26:24.736193 [debug] [Thread-1  ]: finished collecting timing info
13:26:24.736537 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
13:26:24.738486 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
13:26:24.739669 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
13:26:24.739826 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.first_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
13:26:24.739959 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:26:25.439419 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.7 seconds
13:26:25.441355 [debug] [Thread-1  ]: finished collecting timing info
13:26:25.441558 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_first_dbt_model_id.16e066b321: Close
13:26:25.662223 [info ] [Thread-1  ]: 8 of 12 PASS unique_my_first_dbt_model_id....................................... [[32mPASS[0m in 0.94s]
13:26:25.663072 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
13:26:25.663574 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:26:25.664025 [info ] [Thread-1  ]: 9 of 12 START test unique_my_second_dbt_model_id................................ [RUN]
13:26:25.664694 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
13:26:25.664884 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:26:25.665054 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:26:25.669359 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
13:26:25.669999 [debug] [Thread-1  ]: finished collecting timing info
13:26:25.670185 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:26:25.672523 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
13:26:25.673639 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
13:26:25.673816 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.my_second_dbt_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
13:26:25.673960 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:26:26.410090 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.74 seconds
13:26:26.413465 [debug] [Thread-1  ]: finished collecting timing info
13:26:26.413868 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493: Close
13:26:26.624937 [info ] [Thread-1  ]: 9 of 12 PASS unique_my_second_dbt_model_id...................................... [[32mPASS[0m in 0.96s]
13:26:26.625471 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:26:26.625691 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550
13:26:26.625944 [info ] [Thread-1  ]: 10 of 12 START test unique_playing_with_tests_c_custkey......................... [RUN]
13:26:26.626523 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550"
13:26:26.626700 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550
13:26:26.626872 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550
13:26:26.631051 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550"
13:26:26.632078 [debug] [Thread-1  ]: finished collecting timing info
13:26:26.632265 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550
13:26:26.634607 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550"
13:26:26.635962 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550"
13:26:26.636197 [debug] [Thread-1  ]: On test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    c_custkey as unique_field,
    count(*) as n_records

from analytics.dbt.playing_with_tests
where c_custkey is not null
group by c_custkey
having count(*) > 1



      
    ) dbt_internal_test
13:26:26.636358 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:26:27.529421 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.89 seconds
13:26:27.532657 [debug] [Thread-1  ]: finished collecting timing info
13:26:27.533058 [debug] [Thread-1  ]: On test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550: Close
13:26:27.798419 [info ] [Thread-1  ]: 10 of 12 PASS unique_playing_with_tests_c_custkey............................... [[32mPASS[0m in 1.17s]
13:26:27.799006 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550
13:26:27.799262 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
13:26:27.799575 [info ] [Thread-1  ]: 11 of 12 START test unique_snowflake_cumulative_sales_o_orderdate............... [RUN]
13:26:27.800282 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
13:26:27.800628 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
13:26:27.800844 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
13:26:27.805746 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
13:26:27.806511 [debug] [Thread-1  ]: finished collecting timing info
13:26:27.806700 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
13:26:27.808979 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
13:26:27.810132 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
13:26:27.810378 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    o_orderdate as unique_field,
    count(*) as n_records

from analytics.dbt.snowflake_cumulative_sales
where o_orderdate is not null
group by o_orderdate
having count(*) > 1



      
    ) dbt_internal_test
13:26:27.810514 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:26:28.714931 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.9 seconds
13:26:28.718013 [debug] [Thread-1  ]: finished collecting timing info
13:26:28.718451 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed: Close
13:26:28.920070 [info ] [Thread-1  ]: 11 of 12 PASS unique_snowflake_cumulative_sales_o_orderdate..................... [[32mPASS[0m in 1.12s]
13:26:28.920875 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
13:26:28.921296 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
13:26:28.921688 [info ] [Thread-1  ]: 12 of 12 START test unique_snowflake_customer_purchases_c_custkey............... [RUN]
13:26:28.922315 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
13:26:28.922531 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
13:26:28.922737 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
13:26:28.927847 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
13:26:28.928405 [debug] [Thread-1  ]: finished collecting timing info
13:26:28.928583 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
13:26:28.930804 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
13:26:28.932041 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
13:26:28.932381 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    c_custkey as unique_field,
    count(*) as n_records

from analytics.dbt.snowflake_customer_purchases
where c_custkey is not null
group by c_custkey
having count(*) > 1



      
    ) dbt_internal_test
13:26:28.932575 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:26:29.788039 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.86 seconds
13:26:29.791626 [debug] [Thread-1  ]: finished collecting timing info
13:26:29.792063 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f: Close
13:26:29.951009 [info ] [Thread-1  ]: 12 of 12 PASS unique_snowflake_customer_purchases_c_custkey..................... [[32mPASS[0m in 1.03s]
13:26:29.952182 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
13:26:29.953813 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:26:29.954337 [info ] [MainThread]: 
13:26:29.954681 [info ] [MainThread]: Finished running 12 tests in 15.09s.
13:26:29.954984 [debug] [MainThread]: Connection 'master' was properly closed.
13:26:29.955152 [debug] [MainThread]: Connection 'test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f' was properly closed.
13:26:29.962369 [info ] [MainThread]: 
13:26:29.962697 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
13:26:29.962971 [info ] [MainThread]: 
13:26:29.963199 [error] [MainThread]: [31mFailure in test not_null_my_second_dbt_model_id (models/example/schema.yml)[0m
13:26:29.963451 [error] [MainThread]:   Got 1 result, configured to fail if != 0
13:26:29.963914 [info ] [MainThread]: 
13:26:29.964159 [info ] [MainThread]:   compiled SQL at target/compiled/learn_dbt/models/example/schema.yml/not_null_my_second_dbt_model_id.sql
13:26:29.964391 [info ] [MainThread]: 
13:26:29.964581 [info ] [MainThread]: Done. PASS=11 WARN=0 ERROR=1 SKIP=0 TOTAL=12
13:26:29.964857 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109d75520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108e310d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1099d75b0>]}


============================== 2022-05-13 13:35:59.767368 | b3356159-50d4-4610-b128-871c8a9cb7af ==============================
13:35:59.767368 [info ] [MainThread]: Running with dbt=1.0.1
13:35:59.767733 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
13:35:59.767865 [debug] [MainThread]: Tracking: tracking
13:35:59.768084 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1056a2850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1056a2760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1056a2400>]}
13:35:59.810589 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
13:35:59.810827 [debug] [MainThread]: Partial parsing: added file: learn_dbt://tests/assert_accbal_less_than_100m.sql
13:35:59.825647 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b3356159-50d4-4610-b128-871c8a9cb7af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10592a0d0>]}
13:35:59.829141 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b3356159-50d4-4610-b128-871c8a9cb7af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10568db80>]}
13:35:59.829286 [info ] [MainThread]: Found 7 models, 13 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
13:35:59.830090 [info ] [MainThread]: 
13:35:59.830294 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:35:59.830764 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
13:35:59.836518 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
13:35:59.836617 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
13:35:59.836689 [debug] [ThreadPool]: Opening a new connection, currently in state init
13:36:00.922116 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.09 seconds
13:36:00.924327 [debug] [ThreadPool]: On list_analytics: Close
13:36:01.141676 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
13:36:01.147888 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
13:36:01.148101 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
13:36:01.148243 [debug] [ThreadPool]: Opening a new connection, currently in state closed
13:36:02.620277 [debug] [ThreadPool]: SQL status: SUCCESS 7 in 1.47 seconds
13:36:02.623177 [debug] [ThreadPool]: On list_analytics_dbt: Close
13:36:02.954753 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
13:36:02.955290 [info ] [MainThread]: 
13:36:02.957424 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
13:36:02.957643 [info ] [Thread-1  ]: 1 of 7 START incremental model dbt.dates........................................ [RUN]
13:36:02.957930 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
13:36:02.958022 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
13:36:02.958116 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
13:36:02.964157 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
13:36:02.964673 [debug] [Thread-1  ]: finished collecting timing info
13:36:02.964786 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
13:36:02.996403 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:36:02.996650 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
13:36:02.996752 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:36:05.126363 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.13 seconds
13:36:05.138188 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:36:05.138413 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
13:36:05.256851 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.12 seconds
13:36:05.264014 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:36:05.264392 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
13:36:05.570355 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.31 seconds
13:36:05.584953 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:36:05.585295 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
13:36:05.679333 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.09 seconds
13:36:05.705771 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
13:36:05.708180 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:36:05.708311 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
13:36:05.872694 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.16 seconds
13:36:05.873444 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:36:05.873594 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
13:36:06.373363 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.5 seconds
13:36:06.373832 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
13:36:06.374040 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
13:36:06.621891 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.25 seconds
13:36:06.634498 [debug] [Thread-1  ]: finished collecting timing info
13:36:06.634835 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
13:36:06.839723 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b3356159-50d4-4610-b128-871c8a9cb7af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105b4e460>]}
13:36:06.840458 [info ] [Thread-1  ]: 1 of 7 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 3.88s]
13:36:06.840920 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
13:36:06.841167 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
13:36:06.841598 [info ] [Thread-1  ]: 2 of 7 START incremental model dbt.incremental_time............................. [RUN]
13:36:06.842293 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
13:36:06.842526 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
13:36:06.842745 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
13:36:06.846768 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
13:36:06.847604 [debug] [Thread-1  ]: finished collecting timing info
13:36:06.847800 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
13:36:06.851640 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:36:06.851888 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
13:36:06.852037 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:36:08.338842 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.49 seconds
13:36:08.343103 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:36:08.343372 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
13:36:08.469989 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.13 seconds
13:36:08.475438 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:36:08.475778 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
13:36:08.587524 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.11 seconds
13:36:08.592612 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:36:08.592880 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
13:36:08.679988 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.09 seconds
13:36:08.685717 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
13:36:08.688297 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:36:08.688589 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
13:36:08.809164 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.12 seconds
13:36:08.809924 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:36:08.810295 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
13:36:09.708687 [debug] [Thread-1  ]: SQL status: SUCCESS 610 in 0.9 seconds
13:36:09.709527 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
13:36:09.709816 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
13:36:09.947838 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.24 seconds
13:36:09.952151 [debug] [Thread-1  ]: finished collecting timing info
13:36:09.952785 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
13:36:10.133456 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b3356159-50d4-4610-b128-871c8a9cb7af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105b9a5b0>]}
13:36:10.134594 [info ] [Thread-1  ]: 2 of 7 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 3.29s]
13:36:10.135376 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
13:36:10.135652 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
13:36:10.136091 [info ] [Thread-1  ]: 3 of 7 START table model dbt.first_model........................................ [RUN]
13:36:10.136758 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
13:36:10.136976 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
13:36:10.137183 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
13:36:10.141604 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
13:36:10.142408 [debug] [Thread-1  ]: finished collecting timing info
13:36:10.142625 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
13:36:10.152104 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
13:36:10.153248 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
13:36:10.153430 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id

)

select * 
from source_data


/*
select *, True as first_variable
from source_data
where id >= 1
*/
      );
13:36:10.153575 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:36:11.454034 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.3 seconds
13:36:11.457085 [debug] [Thread-1  ]: finished collecting timing info
13:36:11.457477 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
13:36:11.628435 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b3356159-50d4-4610-b128-871c8a9cb7af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107c9b190>]}
13:36:11.629058 [info ] [Thread-1  ]: 3 of 7 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 1.49s]
13:36:11.629332 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
13:36:11.629486 [debug] [Thread-1  ]: Began running node model.learn_dbt.playing_with_tests
13:36:11.629838 [info ] [Thread-1  ]: 4 of 7 START table model dbt.playing_with_tests................................. [RUN]
13:36:11.630222 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.playing_with_tests"
13:36:11.630342 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.playing_with_tests
13:36:11.630465 [debug] [Thread-1  ]: Compiling model.learn_dbt.playing_with_tests
13:36:11.631632 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.playing_with_tests"
13:36:11.632203 [debug] [Thread-1  ]: finished collecting timing info
13:36:11.632316 [debug] [Thread-1  ]: Began executing node model.learn_dbt.playing_with_tests
13:36:11.634259 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.playing_with_tests"
13:36:11.635047 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
13:36:11.635187 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */


      create or replace transient table analytics.dbt.playing_with_tests  as
      (select * 
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER"
      );
13:36:11.635298 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:36:13.554433 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.92 seconds
13:36:13.559569 [debug] [Thread-1  ]: finished collecting timing info
13:36:13.559948 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: Close
13:36:15.072928 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b3356159-50d4-4610-b128-871c8a9cb7af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105cd8c70>]}
13:36:15.073721 [info ] [Thread-1  ]: 4 of 7 OK created table model dbt.playing_with_tests............................ [[32mSUCCESS 1[0m in 3.44s]
13:36:15.074079 [debug] [Thread-1  ]: Finished running node model.learn_dbt.playing_with_tests
13:36:15.074337 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
13:36:15.074803 [info ] [Thread-1  ]: 5 of 7 START table model dbt.snowflake_cumulative_sales......................... [RUN]
13:36:15.075482 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
13:36:15.075733 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
13:36:15.075959 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
13:36:15.077374 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
13:36:15.078039 [debug] [Thread-1  ]: finished collecting timing info
13:36:15.078226 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
13:36:15.080661 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
13:36:15.081647 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
13:36:15.081819 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
13:36:15.081969 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:36:16.578660 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.5 seconds
13:36:16.583377 [debug] [Thread-1  ]: finished collecting timing info
13:36:16.583779 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
13:36:16.741462 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b3356159-50d4-4610-b128-871c8a9cb7af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107c83130>]}
13:36:16.742074 [info ] [Thread-1  ]: 5 of 7 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 1.67s]
13:36:16.742422 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
13:36:16.742886 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
13:36:16.743344 [info ] [Thread-1  ]: 6 of 7 START table model dbt.snowflake_customer_purchases....................... [RUN]
13:36:16.744013 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
13:36:16.744218 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
13:36:16.744417 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
13:36:16.746223 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
13:36:16.746969 [debug] [Thread-1  ]: finished collecting timing info
13:36:16.747162 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
13:36:16.749630 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
13:36:16.750741 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
13:36:16.750905 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
13:36:16.751053 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:36:18.729400 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.98 seconds
13:36:18.736503 [debug] [Thread-1  ]: finished collecting timing info
13:36:18.736993 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
13:36:18.895896 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b3356159-50d4-4610-b128-871c8a9cb7af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107c3bac0>]}
13:36:18.896960 [info ] [Thread-1  ]: 6 of 7 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.15s]
13:36:18.897468 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
13:36:18.897743 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
13:36:18.898022 [info ] [Thread-1  ]: 7 of 7 START table model dbt.my_second_dbt_model................................ [RUN]
13:36:18.901412 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
13:36:18.901852 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
13:36:18.902077 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
13:36:18.905159 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
13:36:18.905738 [debug] [Thread-1  ]: finished collecting timing info
13:36:18.905876 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
13:36:18.907657 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
13:36:18.908207 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
13:36:18.908309 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
/*
union all
select 7 as id, True as first_variable
*/
      );
13:36:18.908401 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:36:20.119530 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.21 seconds
13:36:20.123797 [debug] [Thread-1  ]: finished collecting timing info
13:36:20.124194 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
13:36:20.315887 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b3356159-50d4-4610-b128-871c8a9cb7af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107c3bfd0>]}
13:36:20.316793 [info ] [Thread-1  ]: 7 of 7 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.41s]
13:36:20.317291 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
13:36:20.318632 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:36:20.319060 [info ] [MainThread]: 
13:36:20.319317 [info ] [MainThread]: Finished running 2 incremental models, 5 table models in 20.49s.
13:36:20.319508 [debug] [MainThread]: Connection 'master' was properly closed.
13:36:20.319610 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
13:36:20.325989 [info ] [MainThread]: 
13:36:20.326358 [info ] [MainThread]: [32mCompleted successfully[0m
13:36:20.326625 [info ] [MainThread]: 
13:36:20.326824 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
13:36:20.327093 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10568d9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10567beb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107c15af0>]}


============================== 2022-05-13 13:36:25.414263 | b3c81fb8-37ec-4c6e-8891-24bfc41b5c24 ==============================
13:36:25.414263 [info ] [MainThread]: Running with dbt=1.0.1
13:36:25.414627 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, store_failures=False, indirect_selection='eager', threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.test.TestTask'>, which='test', rpc_method='test')
13:36:25.414772 [debug] [MainThread]: Tracking: tracking
13:36:25.415007 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c035b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c03eb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c03ca0>]}
13:36:25.458105 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
13:36:25.458271 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
13:36:25.461412 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b3c81fb8-37ec-4c6e-8891-24bfc41b5c24', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108bcd100>]}
13:36:25.464960 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b3c81fb8-37ec-4c6e-8891-24bfc41b5c24', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d2cc10>]}
13:36:25.465155 [info ] [MainThread]: Found 7 models, 13 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
13:36:25.466366 [info ] [MainThread]: 
13:36:25.466639 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:36:25.467304 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
13:36:25.473582 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
13:36:25.473703 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
13:36:25.473775 [debug] [ThreadPool]: Opening a new connection, currently in state init
13:36:26.189272 [debug] [ThreadPool]: SQL status: SUCCESS 7 in 0.72 seconds
13:36:26.191870 [debug] [ThreadPool]: On list_analytics_dbt: Close
13:36:26.410102 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
13:36:26.410678 [info ] [MainThread]: 
13:36:26.414620 [debug] [Thread-1  ]: Began running node test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
13:36:26.414891 [info ] [Thread-1  ]: 1 of 13 START test accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE [RUN]
13:36:26.415427 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
13:36:26.415601 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
13:36:26.415757 [debug] [Thread-1  ]: Compiling test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
13:36:26.430251 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
13:36:26.430896 [debug] [Thread-1  ]: finished collecting timing info
13:36:26.431036 [debug] [Thread-1  ]: Began executing node test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
13:36:26.443303 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
13:36:26.444181 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"
13:36:26.444286 [debug] [Thread-1  ]: On test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        c_mktsegment as value_field,
        count(*) as n_records

    from analytics.dbt.playing_with_tests
    group by c_mktsegment

)

select *
from all_values
where value_field not in (
    'BUILDING','AUTOMOBILE','MACHINERY','HOUSEHOLD','FURNITURE'
)



      
    ) dbt_internal_test
13:36:26.444376 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:36:27.093933 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.65 seconds
13:36:27.098031 [debug] [Thread-1  ]: finished collecting timing info
13:36:27.098481 [debug] [Thread-1  ]: On test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3: Close
13:36:27.298480 [info ] [Thread-1  ]: 1 of 13 PASS accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE [[32mPASS[0m in 0.88s]
13:36:27.303250 [debug] [Thread-1  ]: Finished running node test.learn_dbt.accepted_values_playing_with_tests_c_mktsegment__BUILDING__AUTOMOBILE__MACHINERY__HOUSEHOLD__FURNITURE.22353b7cb3
13:36:27.303561 [debug] [Thread-1  ]: Began running node test.learn_dbt.assert_accbal_less_than_100m
13:36:27.304025 [info ] [Thread-1  ]: 2 of 13 START test assert_accbal_less_than_100m................................. [RUN]
13:36:27.304932 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.assert_accbal_less_than_100m"
13:36:27.306011 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.assert_accbal_less_than_100m
13:36:27.306306 [debug] [Thread-1  ]: Compiling test.learn_dbt.assert_accbal_less_than_100m
13:36:27.309524 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.assert_accbal_less_than_100m"
13:36:27.310226 [debug] [Thread-1  ]: finished collecting timing info
13:36:27.310395 [debug] [Thread-1  ]: Began executing node test.learn_dbt.assert_accbal_less_than_100m
13:36:27.312396 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.assert_accbal_less_than_100m"
13:36:27.313302 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.assert_accbal_less_than_100m"
13:36:27.313440 [debug] [Thread-1  ]: On test.learn_dbt.assert_accbal_less_than_100m: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.assert_accbal_less_than_100m"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      select sum(c_acctbal) as sum
from analytics.dbt.playing_with_tests
having sum > 100000000
      
    ) dbt_internal_test
13:36:27.313575 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:36:27.955184 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.64 seconds
13:36:27.957711 [debug] [Thread-1  ]: finished collecting timing info
13:36:27.958024 [debug] [Thread-1  ]: On test.learn_dbt.assert_accbal_less_than_100m: Close
13:36:28.289965 [error] [Thread-1  ]: 2 of 13 FAIL 1 assert_accbal_less_than_100m..................................... [[31mFAIL 1[0m in 0.99s]
13:36:28.290697 [debug] [Thread-1  ]: Finished running node test.learn_dbt.assert_accbal_less_than_100m
13:36:28.290966 [debug] [Thread-1  ]: Began running node test.learn_dbt.assert_under_10_percent_null
13:36:28.291284 [info ] [Thread-1  ]: 3 of 13 START test assert_under_10_percent_null................................. [RUN]
13:36:28.291921 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.assert_under_10_percent_null"
13:36:28.292133 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.assert_under_10_percent_null
13:36:28.292328 [debug] [Thread-1  ]: Compiling test.learn_dbt.assert_under_10_percent_null
13:36:28.295302 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.assert_under_10_percent_null"
13:36:28.296048 [debug] [Thread-1  ]: finished collecting timing info
13:36:28.296237 [debug] [Thread-1  ]: Began executing node test.learn_dbt.assert_under_10_percent_null
13:36:28.298674 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.assert_under_10_percent_null"
13:36:28.300003 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.assert_under_10_percent_null"
13:36:28.300187 [debug] [Thread-1  ]: On test.learn_dbt.assert_under_10_percent_null: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.assert_under_10_percent_null"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      select sum (case when id is null then 1 else 0 end) / count(*) as total_nulls
from analytics.dbt.first_model
having sum (case when id is null then 1 else 0 end) / count(*) > .4
      
    ) dbt_internal_test
13:36:28.300347 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:36:29.381661 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.08 seconds
13:36:29.386787 [debug] [Thread-1  ]: finished collecting timing info
13:36:29.387199 [debug] [Thread-1  ]: On test.learn_dbt.assert_under_10_percent_null: Close
13:36:29.644274 [info ] [Thread-1  ]: 3 of 13 PASS assert_under_10_percent_null....................................... [[32mPASS[0m in 1.35s]
13:36:29.645164 [debug] [Thread-1  ]: Finished running node test.learn_dbt.assert_under_10_percent_null
13:36:29.645642 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
13:36:29.646047 [info ] [Thread-1  ]: 4 of 13 START test not_null_my_second_dbt_model_id.............................. [RUN]
13:36:29.646693 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"
13:36:29.646904 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
13:36:29.647124 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
13:36:29.655355 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"
13:36:29.656191 [debug] [Thread-1  ]: finished collecting timing info
13:36:29.656371 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
13:36:29.658291 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"
13:36:29.659361 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"
13:36:29.659523 [debug] [Thread-1  ]: On test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.my_second_dbt_model
where id is null



      
    ) dbt_internal_test
13:36:29.659656 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:36:30.464061 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.8 seconds
13:36:30.472532 [debug] [Thread-1  ]: finished collecting timing info
13:36:30.472916 [debug] [Thread-1  ]: On test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778: Close
13:36:30.924523 [error] [Thread-1  ]: 4 of 13 FAIL 1 not_null_my_second_dbt_model_id.................................. [[31mFAIL 1[0m in 1.28s]
13:36:30.925193 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_my_second_dbt_model_id.151b76d778
13:36:30.925447 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4
13:36:30.925772 [info ] [Thread-1  ]: 5 of 13 START test not_null_playing_with_tests_c_custkey........................ [RUN]
13:36:30.926405 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4"
13:36:30.926630 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4
13:36:30.926838 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4
13:36:30.931541 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4"
13:36:30.932392 [debug] [Thread-1  ]: finished collecting timing info
13:36:30.932582 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4
13:36:30.934902 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4"
13:36:30.936009 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4"
13:36:30.936262 [debug] [Thread-1  ]: On test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.playing_with_tests
where c_custkey is null



      
    ) dbt_internal_test
13:36:30.936431 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:36:32.054640 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.12 seconds
13:36:32.059095 [debug] [Thread-1  ]: finished collecting timing info
13:36:32.059672 [debug] [Thread-1  ]: On test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4: Close
13:36:32.453033 [info ] [Thread-1  ]: 5 of 13 PASS not_null_playing_with_tests_c_custkey.............................. [[32mPASS[0m in 1.53s]
13:36:32.453752 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_playing_with_tests_c_custkey.8de0306ae4
13:36:32.454001 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
13:36:32.454202 [info ] [Thread-1  ]: 6 of 13 START test not_null_snowflake_cumulative_sales_o_orderdate.............. [RUN]
13:36:32.454953 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
13:36:32.455177 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
13:36:32.455375 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
13:36:32.460346 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
13:36:32.460988 [debug] [Thread-1  ]: finished collecting timing info
13:36:32.461166 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
13:36:32.463371 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
13:36:32.464330 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"
13:36:32.464515 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.snowflake_cumulative_sales
where o_orderdate is null



      
    ) dbt_internal_test
13:36:32.464822 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:36:33.354086 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.89 seconds
13:36:33.356438 [debug] [Thread-1  ]: finished collecting timing info
13:36:33.356777 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856: Close
13:36:33.544153 [info ] [Thread-1  ]: 6 of 13 PASS not_null_snowflake_cumulative_sales_o_orderdate.................... [[32mPASS[0m in 1.09s]
13:36:33.544796 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_snowflake_cumulative_sales_o_orderdate.931c839856
13:36:33.545057 [debug] [Thread-1  ]: Began running node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
13:36:33.545266 [info ] [Thread-1  ]: 7 of 13 START test not_null_snowflake_customer_purchases_c_custkey.............. [RUN]
13:36:33.545985 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
13:36:33.546237 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
13:36:33.546443 [debug] [Thread-1  ]: Compiling test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
13:36:33.551571 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
13:36:33.552483 [debug] [Thread-1  ]: finished collecting timing info
13:36:33.552677 [debug] [Thread-1  ]: Began executing node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
13:36:33.555021 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
13:36:33.556069 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"
13:36:33.556310 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from analytics.dbt.snowflake_customer_purchases
where c_custkey is null



      
    ) dbt_internal_test
13:36:33.556455 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:36:34.408810 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.85 seconds
13:36:34.411983 [debug] [Thread-1  ]: finished collecting timing info
13:36:34.412411 [debug] [Thread-1  ]: On test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502: Close
13:36:34.579199 [info ] [Thread-1  ]: 7 of 13 PASS not_null_snowflake_customer_purchases_c_custkey.................... [[32mPASS[0m in 1.03s]
13:36:34.579978 [debug] [Thread-1  ]: Finished running node test.learn_dbt.not_null_snowflake_customer_purchases_c_custkey.482188c502
13:36:34.580250 [debug] [Thread-1  ]: Began running node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
13:36:34.580579 [info ] [Thread-1  ]: 8 of 13 START test relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_ [RUN]
13:36:34.581228 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
13:36:34.581441 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
13:36:34.581644 [debug] [Thread-1  ]: Compiling test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
13:36:34.592393 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
13:36:34.593203 [debug] [Thread-1  ]: finished collecting timing info
13:36:34.593368 [debug] [Thread-1  ]: Began executing node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
13:36:34.596007 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
13:36:34.597108 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"
13:36:34.597236 [debug] [Thread-1  ]: On test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select id as from_field
    from analytics.dbt.my_second_dbt_model
    where id is not null
),

parent as (
    select id as to_field
    from analytics.dbt.first_model
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
13:36:34.597349 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:36:36.800159 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.2 seconds
13:36:36.803226 [debug] [Thread-1  ]: finished collecting timing info
13:36:36.803641 [debug] [Thread-1  ]: On test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9: Close
13:36:37.214629 [info ] [Thread-1  ]: 8 of 13 PASS relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.. [[32mPASS[0m in 2.63s]
13:36:37.215555 [debug] [Thread-1  ]: Finished running node test.learn_dbt.relationships_my_second_dbt_model_id__id__ref_my_first_dbt_model_.e73b057dc9
13:36:37.215856 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
13:36:37.216142 [info ] [Thread-1  ]: 9 of 13 START test unique_my_first_dbt_model_id................................. [RUN]
13:36:37.216705 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
13:36:37.216886 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
13:36:37.217053 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
13:36:37.224348 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
13:36:37.225027 [debug] [Thread-1  ]: finished collecting timing info
13:36:37.225192 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
13:36:37.226858 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
13:36:37.227845 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"
13:36:37.228034 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.first_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
13:36:37.228153 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:36:37.954048 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.73 seconds
13:36:37.956833 [debug] [Thread-1  ]: finished collecting timing info
13:36:37.957169 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_first_dbt_model_id.16e066b321: Close
13:36:38.156332 [info ] [Thread-1  ]: 9 of 13 PASS unique_my_first_dbt_model_id....................................... [[32mPASS[0m in 0.94s]
13:36:38.156678 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_my_first_dbt_model_id.16e066b321
13:36:38.156810 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:36:38.156962 [info ] [Thread-1  ]: 10 of 13 START test unique_my_second_dbt_model_id............................... [RUN]
13:36:38.157237 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
13:36:38.157337 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:36:38.157428 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:36:38.159968 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
13:36:38.160404 [debug] [Thread-1  ]: finished collecting timing info
13:36:38.160497 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:36:38.161658 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
13:36:38.162266 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"
13:36:38.162356 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from analytics.dbt.my_second_dbt_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
13:36:38.162433 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:36:38.871213 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.71 seconds
13:36:38.874808 [debug] [Thread-1  ]: finished collecting timing info
13:36:38.875358 [debug] [Thread-1  ]: On test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493: Close
13:36:39.084376 [info ] [Thread-1  ]: 10 of 13 PASS unique_my_second_dbt_model_id..................................... [[32mPASS[0m in 0.93s]
13:36:39.084998 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:36:39.085239 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550
13:36:39.085543 [info ] [Thread-1  ]: 11 of 13 START test unique_playing_with_tests_c_custkey......................... [RUN]
13:36:39.086098 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550"
13:36:39.086277 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550
13:36:39.086447 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550
13:36:39.091117 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550"
13:36:39.091805 [debug] [Thread-1  ]: finished collecting timing info
13:36:39.091985 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550
13:36:39.094265 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550"
13:36:39.095369 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550"
13:36:39.095604 [debug] [Thread-1  ]: On test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    c_custkey as unique_field,
    count(*) as n_records

from analytics.dbt.playing_with_tests
where c_custkey is not null
group by c_custkey
having count(*) > 1



      
    ) dbt_internal_test
13:36:39.095882 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:36:39.869788 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.77 seconds
13:36:39.872671 [debug] [Thread-1  ]: finished collecting timing info
13:36:39.873053 [debug] [Thread-1  ]: On test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550: Close
13:36:40.208083 [info ] [Thread-1  ]: 11 of 13 PASS unique_playing_with_tests_c_custkey............................... [[32mPASS[0m in 1.12s]
13:36:40.208742 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_playing_with_tests_c_custkey.b4337ce550
13:36:40.209087 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
13:36:40.209671 [info ] [Thread-1  ]: 12 of 13 START test unique_snowflake_cumulative_sales_o_orderdate............... [RUN]
13:36:40.210615 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
13:36:40.214203 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
13:36:40.214492 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
13:36:40.224815 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
13:36:40.225276 [debug] [Thread-1  ]: finished collecting timing info
13:36:40.225379 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
13:36:40.226613 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
13:36:40.227251 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"
13:36:40.227338 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    o_orderdate as unique_field,
    count(*) as n_records

from analytics.dbt.snowflake_cumulative_sales
where o_orderdate is not null
group by o_orderdate
having count(*) > 1



      
    ) dbt_internal_test
13:36:40.227418 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:36:41.290648 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.06 seconds
13:36:41.293272 [debug] [Thread-1  ]: finished collecting timing info
13:36:41.293546 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed: Close
13:36:41.475328 [info ] [Thread-1  ]: 12 of 13 PASS unique_snowflake_cumulative_sales_o_orderdate..................... [[32mPASS[0m in 1.27s]
13:36:41.475635 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_snowflake_cumulative_sales_o_orderdate.e6791ce0ed
13:36:41.475908 [debug] [Thread-1  ]: Began running node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
13:36:41.476117 [info ] [Thread-1  ]: 13 of 13 START test unique_snowflake_customer_purchases_c_custkey............... [RUN]
13:36:41.476433 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
13:36:41.476531 [debug] [Thread-1  ]: Began compiling node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
13:36:41.476621 [debug] [Thread-1  ]: Compiling test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
13:36:41.479229 [debug] [Thread-1  ]: Writing injected SQL for node "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
13:36:41.479729 [debug] [Thread-1  ]: finished collecting timing info
13:36:41.479864 [debug] [Thread-1  ]: Began executing node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
13:36:41.481399 [debug] [Thread-1  ]: Writing runtime SQL for node "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
13:36:41.482248 [debug] [Thread-1  ]: Using snowflake connection "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"
13:36:41.482371 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    c_custkey as unique_field,
    count(*) as n_records

from analytics.dbt.snowflake_customer_purchases
where c_custkey is not null
group by c_custkey
having count(*) > 1



      
    ) dbt_internal_test
13:36:41.482479 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:36:42.608758 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.13 seconds
13:36:42.611942 [debug] [Thread-1  ]: finished collecting timing info
13:36:42.612362 [debug] [Thread-1  ]: On test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f: Close
13:36:42.954066 [info ] [Thread-1  ]: 13 of 13 PASS unique_snowflake_customer_purchases_c_custkey..................... [[32mPASS[0m in 1.48s]
13:36:42.954759 [debug] [Thread-1  ]: Finished running node test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f
13:36:42.957131 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:36:42.959784 [info ] [MainThread]: 
13:36:42.960377 [info ] [MainThread]: Finished running 13 tests in 17.49s.
13:36:42.962276 [debug] [MainThread]: Connection 'master' was properly closed.
13:36:42.962491 [debug] [MainThread]: Connection 'test.learn_dbt.unique_snowflake_customer_purchases_c_custkey.fea628232f' was properly closed.
13:36:42.972687 [info ] [MainThread]: 
13:36:42.972948 [info ] [MainThread]: [31mCompleted with 2 errors and 0 warnings:[0m
13:36:42.973143 [info ] [MainThread]: 
13:36:42.973311 [error] [MainThread]: [31mFailure in test assert_accbal_less_than_100m (tests/assert_accbal_less_than_100m.sql)[0m
13:36:42.973503 [error] [MainThread]:   Got 1 result, configured to fail if != 0
13:36:42.973669 [info ] [MainThread]: 
13:36:42.973830 [info ] [MainThread]:   compiled SQL at target/compiled/learn_dbt/tests/assert_accbal_less_than_100m.sql
13:36:42.973999 [info ] [MainThread]: 
13:36:42.974158 [error] [MainThread]: [31mFailure in test not_null_my_second_dbt_model_id (models/example/schema.yml)[0m
13:36:42.974321 [error] [MainThread]:   Got 1 result, configured to fail if != 0
13:36:42.974477 [info ] [MainThread]: 
13:36:42.974631 [info ] [MainThread]:   compiled SQL at target/compiled/learn_dbt/models/example/schema.yml/not_null_my_second_dbt_model_id.sql
13:36:42.974806 [info ] [MainThread]: 
13:36:42.974962 [info ] [MainThread]: Done. PASS=11 WARN=0 ERROR=2 SKIP=0 TOTAL=13
13:36:42.975205 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108d5b0a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079eb580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b0bb550>]}


============================== 2022-05-16 12:03:05.570429 | 8e6273ec-b6f3-44db-9654-d210cdb3b580 ==============================
12:03:05.570429 [info ] [MainThread]: Running with dbt=1.0.1
12:03:05.570961 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['example'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
12:03:05.571128 [debug] [MainThread]: Tracking: tracking
12:03:05.571347 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11274fe20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11274f8e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11274feb0>]}
12:03:05.620459 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
12:03:05.620592 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
12:03:05.623784 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8e6273ec-b6f3-44db-9654-d210cdb3b580', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112719130>]}
12:03:05.627700 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8e6273ec-b6f3-44db-9654-d210cdb3b580', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11286ba90>]}
12:03:05.627843 [info ] [MainThread]: Found 7 models, 13 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
12:03:05.628636 [info ] [MainThread]: 
12:03:05.628846 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:03:05.629309 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
12:03:05.635161 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
12:03:05.635250 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
12:03:05.635324 [debug] [ThreadPool]: Opening a new connection, currently in state init
12:03:06.736389 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.1 seconds
12:03:06.739011 [debug] [ThreadPool]: On list_analytics: Close
12:03:06.922243 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
12:03:06.931128 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
12:03:06.931356 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
12:03:06.931517 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:03:07.495342 [debug] [ThreadPool]: SQL status: SUCCESS 7 in 0.56 seconds
12:03:07.498916 [debug] [ThreadPool]: On list_analytics_dbt: Close
12:03:07.719728 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
12:03:07.720166 [info ] [MainThread]: 
12:03:07.724992 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
12:03:07.725497 [info ] [Thread-1  ]: 1 of 7 START incremental model dbt.dates........................................ [RUN]
12:03:07.725779 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
12:03:07.725873 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
12:03:07.725969 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
12:03:07.731608 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
12:03:07.732767 [debug] [Thread-1  ]: finished collecting timing info
12:03:07.732929 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
12:03:07.761578 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:03:07.761797 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
12:03:07.761899 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:03:10.888675 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 3.13 seconds
12:03:10.901875 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:03:10.902266 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
12:03:11.052022 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.15 seconds
12:03:11.058983 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:03:11.059290 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
12:03:11.210681 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.15 seconds
12:03:11.220736 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:03:11.221002 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
12:03:11.370965 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.15 seconds
12:03:11.396875 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
12:03:11.399353 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:03:11.399485 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
12:03:11.532118 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.13 seconds
12:03:11.533448 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:03:11.533859 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
12:03:12.332856 [debug] [Thread-1  ]: SQL status: SUCCESS 3 in 0.8 seconds
12:03:12.334064 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:03:12.334272 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
12:03:12.590310 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.26 seconds
12:03:12.603540 [debug] [Thread-1  ]: finished collecting timing info
12:03:12.603795 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
12:03:12.798399 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8e6273ec-b6f3-44db-9654-d210cdb3b580', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104b11d30>]}
12:03:12.799314 [info ] [Thread-1  ]: 1 of 7 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 5.07s]
12:03:12.799768 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
12:03:12.800018 [debug] [Thread-1  ]: Began running node model.learn_dbt.incremental_time
12:03:12.800451 [info ] [Thread-1  ]: 2 of 7 START incremental model dbt.incremental_time............................. [RUN]
12:03:12.801104 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.incremental_time"
12:03:12.801317 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.incremental_time
12:03:12.801528 [debug] [Thread-1  ]: Compiling model.learn_dbt.incremental_time
12:03:12.805520 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.incremental_time"
12:03:12.807527 [debug] [Thread-1  ]: finished collecting timing info
12:03:12.807733 [debug] [Thread-1  ]: Began executing node model.learn_dbt.incremental_time
12:03:12.811190 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:03:12.811419 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    

      create or replace temporary table analytics.dbt.incremental_time__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."TIME_DIM"
where to_time(concat(T_HOUR::varchar, ':', T_MINUTE::varchar, ':', T_SECOND::varchar)) <= current_time


	and t_time > (select max(t_time) from analytics.dbt.incremental_time)

      );
12:03:12.811549 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:03:14.861281 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.05 seconds
12:03:14.866533 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:03:14.866889 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time__dbt_tmp
12:03:14.991690 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.12 seconds
12:03:14.997085 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:03:14.997305 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table analytics.dbt.incremental_time
12:03:15.118300 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.12 seconds
12:03:15.123205 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:03:15.123459 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */

    describe table "ANALYTICS"."DBT"."INCREMENTAL_TIME"
12:03:15.254944 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.13 seconds
12:03:15.260130 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.incremental_time"
12:03:15.262502 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:03:15.262674 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.incremental_time"} */
begin;
12:03:15.407096 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.14 seconds
12:03:15.408158 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:03:15.408378 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: merge into analytics.dbt.incremental_time as DBT_INTERNAL_DEST
        using analytics.dbt.incremental_time__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.t_time = DBT_INTERNAL_DEST.t_time
        

    
    when matched then update set
        "T_TIME_SK" = DBT_INTERNAL_SOURCE."T_TIME_SK","T_TIME_ID" = DBT_INTERNAL_SOURCE."T_TIME_ID","T_TIME" = DBT_INTERNAL_SOURCE."T_TIME","T_HOUR" = DBT_INTERNAL_SOURCE."T_HOUR","T_MINUTE" = DBT_INTERNAL_SOURCE."T_MINUTE","T_SECOND" = DBT_INTERNAL_SOURCE."T_SECOND","T_AM_PM" = DBT_INTERNAL_SOURCE."T_AM_PM","T_SHIFT" = DBT_INTERNAL_SOURCE."T_SHIFT","T_SUB_SHIFT" = DBT_INTERNAL_SOURCE."T_SUB_SHIFT","T_MEAL_TIME" = DBT_INTERNAL_SOURCE."T_MEAL_TIME"
    

    when not matched then insert
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")
    values
        ("T_TIME_SK", "T_TIME_ID", "T_TIME", "T_HOUR", "T_MINUTE", "T_SECOND", "T_AM_PM", "T_SHIFT", "T_SUB_SHIFT", "T_MEAL_TIME")

;
12:03:16.554095 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 1.15 seconds
12:03:16.554546 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.incremental_time"
12:03:16.554722 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: commit;
12:03:16.736015 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.18 seconds
12:03:16.740048 [debug] [Thread-1  ]: finished collecting timing info
12:03:16.740429 [debug] [Thread-1  ]: On model.learn_dbt.incremental_time: Close
12:03:16.927332 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8e6273ec-b6f3-44db-9654-d210cdb3b580', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112c3f4f0>]}
12:03:16.928161 [info ] [Thread-1  ]: 2 of 7 OK created incremental model dbt.incremental_time........................ [[32mSUCCESS 1[0m in 4.13s]
12:03:16.928617 [debug] [Thread-1  ]: Finished running node model.learn_dbt.incremental_time
12:03:16.928866 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
12:03:16.929140 [info ] [Thread-1  ]: 3 of 7 START table model dbt.first_model........................................ [RUN]
12:03:16.929958 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
12:03:16.930220 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
12:03:16.930399 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
12:03:16.934353 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
12:03:16.935014 [debug] [Thread-1  ]: finished collecting timing info
12:03:16.935184 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
12:03:16.943922 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
12:03:16.945020 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
12:03:16.945155 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id

)

select * 
from source_data


/*
select *, True as first_variable
from source_data
where id >= 1
*/
      );
12:03:16.945272 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:03:18.783785 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.84 seconds
12:03:18.787567 [debug] [Thread-1  ]: finished collecting timing info
12:03:18.788010 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
12:03:18.955367 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8e6273ec-b6f3-44db-9654-d210cdb3b580', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112c3fb20>]}
12:03:18.955692 [info ] [Thread-1  ]: 3 of 7 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 2.03s]
12:03:18.955886 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
12:03:18.955995 [debug] [Thread-1  ]: Began running node model.learn_dbt.playing_with_tests
12:03:18.956216 [info ] [Thread-1  ]: 4 of 7 START table model dbt.playing_with_tests................................. [RUN]
12:03:18.956459 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.playing_with_tests"
12:03:18.956540 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.playing_with_tests
12:03:18.956619 [debug] [Thread-1  ]: Compiling model.learn_dbt.playing_with_tests
12:03:18.957415 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.playing_with_tests"
12:03:18.957900 [debug] [Thread-1  ]: finished collecting timing info
12:03:18.957993 [debug] [Thread-1  ]: Began executing node model.learn_dbt.playing_with_tests
12:03:18.959355 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.playing_with_tests"
12:03:18.959874 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.playing_with_tests"
12:03:18.959962 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.playing_with_tests"} */


      create or replace transient table analytics.dbt.playing_with_tests  as
      (select * 
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER"
      );
12:03:18.960036 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:03:20.705721 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.75 seconds
12:03:20.709430 [debug] [Thread-1  ]: finished collecting timing info
12:03:20.709812 [debug] [Thread-1  ]: On model.learn_dbt.playing_with_tests: Close
12:03:20.920724 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8e6273ec-b6f3-44db-9654-d210cdb3b580', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114e9f610>]}
12:03:20.921471 [info ] [Thread-1  ]: 4 of 7 OK created table model dbt.playing_with_tests............................ [[32mSUCCESS 1[0m in 1.96s]
12:03:20.921918 [debug] [Thread-1  ]: Finished running node model.learn_dbt.playing_with_tests
12:03:20.922161 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_cumulative_sales
12:03:20.922421 [info ] [Thread-1  ]: 5 of 7 START table model dbt.snowflake_cumulative_sales......................... [RUN]
12:03:20.923097 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
12:03:20.923329 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_cumulative_sales
12:03:20.923784 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_cumulative_sales
12:03:20.925675 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_cumulative_sales"
12:03:20.929215 [debug] [Thread-1  ]: finished collecting timing info
12:03:20.929451 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_cumulative_sales
12:03:20.933638 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_cumulative_sales"
12:03:20.934695 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_cumulative_sales"
12:03:20.934836 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_cumulative_sales"} */


      create or replace transient table analytics.dbt.snowflake_cumulative_sales  as
      (select distinct o_orderdate 
       , sum(o_totalprice) over (order by o_orderdate) cumulative_sales
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS"
order by o_orderdate
      );
12:03:20.934963 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:03:22.404249 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.47 seconds
12:03:22.407203 [debug] [Thread-1  ]: finished collecting timing info
12:03:22.407535 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_cumulative_sales: Close
12:03:22.623167 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8e6273ec-b6f3-44db-9654-d210cdb3b580', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112c3f0d0>]}
12:03:22.623501 [info ] [Thread-1  ]: 5 of 7 OK created table model dbt.snowflake_cumulative_sales.................... [[32mSUCCESS 1[0m in 1.70s]
12:03:22.623885 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_cumulative_sales
12:03:22.624210 [debug] [Thread-1  ]: Began running node model.learn_dbt.snowflake_customer_purchases
12:03:22.624482 [info ] [Thread-1  ]: 6 of 7 START table model dbt.snowflake_customer_purchases....................... [RUN]
12:03:22.624932 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.snowflake_customer_purchases"
12:03:22.625048 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.snowflake_customer_purchases
12:03:22.625150 [debug] [Thread-1  ]: Compiling model.learn_dbt.snowflake_customer_purchases
12:03:22.625989 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.snowflake_customer_purchases"
12:03:22.626717 [debug] [Thread-1  ]: finished collecting timing info
12:03:22.626852 [debug] [Thread-1  ]: Began executing node model.learn_dbt.snowflake_customer_purchases
12:03:22.629214 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.snowflake_customer_purchases"
12:03:22.630508 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.snowflake_customer_purchases"
12:03:22.630687 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.snowflake_customer_purchases"} */


      create or replace transient table analytics.dbt.snowflake_customer_purchases  as
      (select c.c_custkey
     , c.c_name
     , c.c_nationkey as nation
     , sum(o.o_totalprice) as total_order_price
from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."CUSTOMER" c
left join "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1"."ORDERS" o
on c.c_custkey = o.o_custkey
group by 
  c.c_custkey
, c.c_name
, c.c_nationkey
      );
12:03:22.630834 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:03:24.629478 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.0 seconds
12:03:24.632533 [debug] [Thread-1  ]: finished collecting timing info
12:03:24.632853 [debug] [Thread-1  ]: On model.learn_dbt.snowflake_customer_purchases: Close
12:03:24.857074 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8e6273ec-b6f3-44db-9654-d210cdb3b580', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114e6a430>]}
12:03:24.857805 [info ] [Thread-1  ]: 6 of 7 OK created table model dbt.snowflake_customer_purchases.................. [[32mSUCCESS 1[0m in 2.23s]
12:03:24.858251 [debug] [Thread-1  ]: Finished running node model.learn_dbt.snowflake_customer_purchases
12:03:24.858499 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_second_dbt_model
12:03:24.858905 [info ] [Thread-1  ]: 7 of 7 START table model dbt.my_second_dbt_model................................ [RUN]
12:03:24.859538 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_second_dbt_model"
12:03:24.859749 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_second_dbt_model
12:03:24.860113 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_second_dbt_model
12:03:24.863682 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_second_dbt_model"
12:03:24.864470 [debug] [Thread-1  ]: finished collecting timing info
12:03:24.864648 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_second_dbt_model
12:03:24.867191 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_second_dbt_model"
12:03:24.868045 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_second_dbt_model"
12:03:24.868194 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_second_dbt_model"} */


      create or replace transient table analytics.dbt.my_second_dbt_model  as
      (-- Use the `ref` function to select from other models

select *
from analytics.dbt.first_model
/*
union all
select 7 as id, True as first_variable
*/
      );
12:03:24.868319 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:03:26.359748 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.49 seconds
12:03:26.363410 [debug] [Thread-1  ]: finished collecting timing info
12:03:26.363849 [debug] [Thread-1  ]: On model.learn_dbt.my_second_dbt_model: Close
12:03:26.546155 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8e6273ec-b6f3-44db-9654-d210cdb3b580', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114e33430>]}
12:03:26.546778 [info ] [Thread-1  ]: 7 of 7 OK created table model dbt.my_second_dbt_model........................... [[32mSUCCESS 1[0m in 1.69s]
12:03:26.547076 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_second_dbt_model
12:03:26.548060 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:03:26.548421 [info ] [MainThread]: 
12:03:26.548620 [info ] [MainThread]: Finished running 2 incremental models, 5 table models in 20.92s.
12:03:26.548785 [debug] [MainThread]: Connection 'master' was properly closed.
12:03:26.548877 [debug] [MainThread]: Connection 'model.learn_dbt.my_second_dbt_model' was properly closed.
12:03:26.554813 [info ] [MainThread]: 
12:03:26.555083 [info ] [MainThread]: [32mCompleted successfully[0m
12:03:26.555301 [info ] [MainThread]: 
12:03:26.555468 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
12:03:26.555708 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107becc10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11286b400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112d2fbb0>]}


============================== 2022-05-16 12:03:36.395805 | ec5ce9e7-519f-4010-b3fa-2e3186a56152 ==============================
12:03:36.395805 [info ] [MainThread]: Running with dbt=1.0.1
12:03:36.396183 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['dates'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
12:03:36.396348 [debug] [MainThread]: Tracking: tracking
12:03:36.396584 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11308ae20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11308aa90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11308ad30>]}
12:03:36.444659 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
12:03:36.444818 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
12:03:36.448283 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ec5ce9e7-519f-4010-b3fa-2e3186a56152', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1131a10d0>]}
12:03:36.451689 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ec5ce9e7-519f-4010-b3fa-2e3186a56152', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111ad61f0>]}
12:03:36.451823 [info ] [MainThread]: Found 7 models, 13 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
12:03:36.452517 [info ] [MainThread]: 
12:03:36.452721 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:03:36.453059 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
12:03:36.459073 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
12:03:36.459175 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
12:03:36.459242 [debug] [ThreadPool]: Opening a new connection, currently in state init
12:03:37.266443 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.81 seconds
12:03:37.268821 [debug] [ThreadPool]: On list_analytics: Close
12:03:37.443609 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
12:03:37.451444 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
12:03:37.451702 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
12:03:37.451818 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:03:38.187297 [debug] [ThreadPool]: SQL status: SUCCESS 7 in 0.74 seconds
12:03:38.191137 [debug] [ThreadPool]: On list_analytics_dbt: Close
12:03:38.372190 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
12:03:38.372867 [info ] [MainThread]: 
12:03:38.379334 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
12:03:38.379782 [info ] [Thread-1  ]: 1 of 1 START incremental model dbt.dates........................................ [RUN]
12:03:38.380706 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
12:03:38.380893 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
12:03:38.381083 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
12:03:38.389554 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
12:03:38.390163 [debug] [Thread-1  ]: finished collecting timing info
12:03:38.390305 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
12:03:38.418666 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:03:38.418891 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
12:03:38.418980 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:03:39.604768 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.19 seconds
12:03:39.618782 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:03:39.619117 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
12:03:39.756533 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.14 seconds
12:03:39.763549 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:03:39.763766 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
12:03:39.876875 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.11 seconds
12:03:39.891865 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:03:39.892222 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
12:03:40.008904 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.12 seconds
12:03:40.036348 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
12:03:40.038869 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:03:40.039015 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
12:03:40.168713 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.13 seconds
12:03:40.169776 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:03:40.170061 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
12:03:40.599276 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.43 seconds
12:03:40.600037 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:03:40.600277 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
12:03:40.801047 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.2 seconds
12:03:40.815595 [debug] [Thread-1  ]: finished collecting timing info
12:03:40.816020 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
12:03:40.994931 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ec5ce9e7-519f-4010-b3fa-2e3186a56152', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113516970>]}
12:03:40.995789 [info ] [Thread-1  ]: 1 of 1 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 2.61s]
12:03:40.996262 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
12:03:40.997617 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:03:40.997925 [info ] [MainThread]: 
12:03:40.998125 [info ] [MainThread]: Finished running 1 incremental model in 4.55s.
12:03:40.998308 [debug] [MainThread]: Connection 'master' was properly closed.
12:03:40.998405 [debug] [MainThread]: Connection 'model.learn_dbt.dates' was properly closed.
12:03:41.003879 [info ] [MainThread]: 
12:03:41.004207 [info ] [MainThread]: [32mCompleted successfully[0m
12:03:41.004458 [info ] [MainThread]: 
12:03:41.004651 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
12:03:41.004909 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1131d01f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1131c51f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11340f160>]}


============================== 2022-05-16 12:04:07.878110 | 82d4afbb-56c8-4d5c-8f6f-f886996fc7d7 ==============================
12:04:07.878110 [info ] [MainThread]: Running with dbt=1.0.1
12:04:07.878484 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['example.dates'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
12:04:07.878612 [debug] [MainThread]: Tracking: tracking
12:04:07.878839 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108207e80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1082074f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1082079d0>]}
12:04:07.926226 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
12:04:07.926357 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
12:04:07.929522 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '82d4afbb-56c8-4d5c-8f6f-f886996fc7d7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1081d10d0>]}
12:04:07.933047 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '82d4afbb-56c8-4d5c-8f6f-f886996fc7d7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105f614f0>]}
12:04:07.933183 [info ] [MainThread]: Found 7 models, 13 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
12:04:07.933847 [info ] [MainThread]: 
12:04:07.934059 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:04:07.934398 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
12:04:07.940500 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
12:04:07.940600 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
12:04:07.940666 [debug] [ThreadPool]: Opening a new connection, currently in state init
12:04:08.767554 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.83 seconds
12:04:08.770157 [debug] [ThreadPool]: On list_analytics: Close
12:04:08.959390 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
12:04:08.968613 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
12:04:08.968843 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
12:04:08.969184 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:04:09.843914 [debug] [ThreadPool]: SQL status: SUCCESS 7 in 0.87 seconds
12:04:09.847034 [debug] [ThreadPool]: On list_analytics_dbt: Close
12:04:10.033178 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
12:04:10.033840 [info ] [MainThread]: 
12:04:10.039527 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
12:04:10.039940 [info ] [Thread-1  ]: 1 of 1 START incremental model dbt.dates........................................ [RUN]
12:04:10.040853 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
12:04:10.041046 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
12:04:10.041241 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
12:04:10.050337 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
12:04:10.050876 [debug] [Thread-1  ]: finished collecting timing info
12:04:10.051017 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
12:04:10.079059 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:04:10.079260 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
12:04:10.079348 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:04:11.032993 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.95 seconds
12:04:11.044601 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:04:11.044929 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
12:04:11.167332 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.12 seconds
12:04:11.175213 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:04:11.175526 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
12:04:11.284652 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.11 seconds
12:04:11.295249 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:04:11.295477 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
12:04:11.396076 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.1 seconds
12:04:11.419486 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
12:04:11.422212 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:04:11.422352 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
12:04:11.595092 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.17 seconds
12:04:11.596436 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:04:11.596783 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
12:04:11.921616 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.32 seconds
12:04:11.922213 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:04:11.922416 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
12:04:12.125761 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.2 seconds
12:04:12.137167 [debug] [Thread-1  ]: finished collecting timing info
12:04:12.137496 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
12:04:12.315590 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82d4afbb-56c8-4d5c-8f6f-f886996fc7d7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1086a9790>]}
12:04:12.316440 [info ] [Thread-1  ]: 1 of 1 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 2.28s]
12:04:12.316905 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
12:04:12.318269 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:04:12.318785 [info ] [MainThread]: 
12:04:12.319134 [info ] [MainThread]: Finished running 1 incremental model in 4.38s.
12:04:12.319439 [debug] [MainThread]: Connection 'master' was properly closed.
12:04:12.319610 [debug] [MainThread]: Connection 'model.learn_dbt.dates' was properly closed.
12:04:12.326175 [info ] [MainThread]: 
12:04:12.326457 [info ] [MainThread]: [32mCompleted successfully[0m
12:04:12.326703 [info ] [MainThread]: 
12:04:12.326898 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
12:04:12.327166 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1083691f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10859a820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a4390a0>]}


============================== 2022-05-16 12:04:55.021116 | cf087061-08ff-49d3-a340-f7076d7a1825 ==============================
12:04:55.021116 [info ] [MainThread]: Running with dbt=1.0.1
12:04:55.021608 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['example.dates', 'example.my_first_dbt_model'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
12:04:55.021735 [debug] [MainThread]: Tracking: tracking
12:04:55.021966 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1058e27f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1058e2ca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1058e2d00>]}
12:04:55.070637 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
12:04:55.070771 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
12:04:55.074024 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cf087061-08ff-49d3-a340-f7076d7a1825', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1058cd220>]}
12:04:55.077489 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cf087061-08ff-49d3-a340-f7076d7a1825', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103d56100>]}
12:04:55.077621 [info ] [MainThread]: Found 7 models, 13 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
12:04:55.078346 [info ] [MainThread]: 
12:04:55.078545 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:04:55.078900 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
12:04:55.085012 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
12:04:55.085133 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
12:04:55.085199 [debug] [ThreadPool]: Opening a new connection, currently in state init
12:04:55.873724 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.79 seconds
12:04:55.876355 [debug] [ThreadPool]: On list_analytics: Close
12:04:56.054657 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
12:04:56.062970 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
12:04:56.063197 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
12:04:56.063353 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:04:56.865268 [debug] [ThreadPool]: SQL status: SUCCESS 7 in 0.8 seconds
12:04:56.867598 [debug] [ThreadPool]: On list_analytics_dbt: Close
12:04:57.049951 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
12:04:57.050574 [info ] [MainThread]: 
12:04:57.054704 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
12:04:57.055052 [info ] [Thread-1  ]: 1 of 2 START incremental model dbt.dates........................................ [RUN]
12:04:57.055899 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
12:04:57.056073 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
12:04:57.056232 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
12:04:57.065743 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
12:04:57.066348 [debug] [Thread-1  ]: finished collecting timing info
12:04:57.066481 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
12:04:57.095745 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:04:57.095962 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
12:04:57.096049 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:04:57.961676 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.87 seconds
12:04:57.975060 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:04:57.975418 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
12:04:58.108127 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.13 seconds
12:04:58.115847 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:04:58.116191 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
12:04:58.242695 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.13 seconds
12:04:58.256399 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:04:58.256721 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
12:04:58.429965 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.17 seconds
12:04:58.455037 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
12:04:58.457380 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:04:58.457570 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
12:04:58.583906 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.13 seconds
12:04:58.585007 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:04:58.585278 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
12:04:59.032910 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.45 seconds
12:04:59.034206 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:04:59.034499 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
12:04:59.209568 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.17 seconds
12:04:59.221755 [debug] [Thread-1  ]: finished collecting timing info
12:04:59.221977 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
12:04:59.404926 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cf087061-08ff-49d3-a340-f7076d7a1825', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105fb3070>]}
12:04:59.405651 [info ] [Thread-1  ]: 1 of 2 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 2.35s]
12:04:59.406006 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
12:04:59.406196 [debug] [Thread-1  ]: Began running node model.learn_dbt.my_first_dbt_model
12:04:59.406514 [info ] [Thread-1  ]: 2 of 2 START table model dbt.first_model........................................ [RUN]
12:04:59.406991 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.my_first_dbt_model"
12:04:59.407150 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.my_first_dbt_model
12:04:59.407305 [debug] [Thread-1  ]: Compiling model.learn_dbt.my_first_dbt_model
12:04:59.410556 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.my_first_dbt_model"
12:04:59.411358 [debug] [Thread-1  ]: finished collecting timing info
12:04:59.411513 [debug] [Thread-1  ]: Began executing node model.learn_dbt.my_first_dbt_model
12:04:59.420254 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.my_first_dbt_model"
12:04:59.421389 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.my_first_dbt_model"
12:04:59.421568 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.my_first_dbt_model"} */


      create or replace transient table analytics.dbt.first_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id

)

select * 
from source_data


/*
select *, True as first_variable
from source_data
where id >= 1
*/
      );
12:04:59.421700 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:05:00.868446 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.45 seconds
12:05:00.871500 [debug] [Thread-1  ]: finished collecting timing info
12:05:00.871839 [debug] [Thread-1  ]: On model.learn_dbt.my_first_dbt_model: Close
12:05:01.065618 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cf087061-08ff-49d3-a340-f7076d7a1825', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d92550>]}
12:05:01.066427 [info ] [Thread-1  ]: 2 of 2 OK created table model dbt.first_model................................... [[32mSUCCESS 1[0m in 1.66s]
12:05:01.067014 [debug] [Thread-1  ]: Finished running node model.learn_dbt.my_first_dbt_model
12:05:01.068424 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:05:01.068872 [info ] [MainThread]: 
12:05:01.069159 [info ] [MainThread]: Finished running 1 incremental model, 1 table model in 5.99s.
12:05:01.069429 [debug] [MainThread]: Connection 'master' was properly closed.
12:05:01.069566 [debug] [MainThread]: Connection 'model.learn_dbt.my_first_dbt_model' was properly closed.
12:05:01.077680 [info ] [MainThread]: 
12:05:01.078107 [info ] [MainThread]: [32mCompleted successfully[0m
12:05:01.078458 [info ] [MainThread]: 
12:05:01.078667 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
12:05:01.078995 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103970190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103d56340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106a5a670>]}


============================== 2022-05-16 12:10:00.532691 | c51c4908-74d6-4adf-9a99-99e60c89b6a0 ==============================
12:10:00.532691 [info ] [MainThread]: Running with dbt=1.0.1
12:10:00.533205 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/nigelbrown/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=['new'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
12:10:00.533335 [debug] [MainThread]: Tracking: tracking
12:10:00.533571 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108fd3730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108fd3af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108fd3640>]}
12:10:00.582152 [debug] [MainThread]: Partial parsing enabled: 1 files deleted, 2 files added, 2 files changed.
12:10:00.582393 [debug] [MainThread]: Partial parsing: added file: learn_dbt://models/new/schema.yml
12:10:00.582496 [debug] [MainThread]: Partial parsing: added file: learn_dbt://models/new/dates.sql
12:10:00.582658 [debug] [MainThread]: Partial parsing: update schema file: learn_dbt://models/example/schema.yml
12:10:00.582730 [debug] [MainThread]: Partial parsing: deleted file: learn_dbt://models/example/dates.sql
12:10:00.582848 [debug] [MainThread]: Partial parsing: updated file: learn_dbt://models/example/my_first_dbt_model.sql
12:10:00.588413 [debug] [MainThread]: 1603: static parser failed on new/dates.sql
12:10:00.596400 [debug] [MainThread]: 1602: parser fallback to jinja rendering on new/dates.sql
12:10:00.597565 [debug] [MainThread]: 1603: static parser failed on example/my_first_dbt_model.sql
12:10:00.599700 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/my_first_dbt_model.sql
12:10:00.599790 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'experimental_parser', 'label': 'c51c4908-74d6-4adf-9a99-99e60c89b6a0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10912f490>]}
12:10:00.612901 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c51c4908-74d6-4adf-9a99-99e60c89b6a0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1091760d0>]}
12:10:00.616130 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c51c4908-74d6-4adf-9a99-99e60c89b6a0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10906b580>]}
12:10:00.616257 [info ] [MainThread]: Found 7 models, 13 tests, 0 snapshots, 0 analyses, 179 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
12:10:00.616892 [info ] [MainThread]: 
12:10:00.617095 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:10:00.617398 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics"
12:10:00.623222 [debug] [ThreadPool]: Using snowflake connection "list_analytics"
12:10:00.623349 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics"} */

    show terse schemas in database analytics
    limit 10000
12:10:00.623417 [debug] [ThreadPool]: Opening a new connection, currently in state init
12:10:01.507413 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.88 seconds
12:10:01.508898 [debug] [ThreadPool]: On list_analytics: Close
12:10:01.688811 [debug] [ThreadPool]: Acquiring new snowflake connection "list_analytics_dbt"
12:10:01.697371 [debug] [ThreadPool]: Using snowflake connection "list_analytics_dbt"
12:10:01.697591 [debug] [ThreadPool]: On list_analytics_dbt: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "connection_name": "list_analytics_dbt"} */

    show terse objects in analytics.dbt
12:10:01.697752 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:10:02.201417 [debug] [ThreadPool]: SQL status: SUCCESS 7 in 0.5 seconds
12:10:02.204956 [debug] [ThreadPool]: On list_analytics_dbt: Close
12:10:02.362689 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
12:10:02.363203 [info ] [MainThread]: 
12:10:02.368726 [debug] [Thread-1  ]: Began running node model.learn_dbt.dates
12:10:02.369125 [info ] [Thread-1  ]: 1 of 1 START incremental model dbt.dates........................................ [RUN]
12:10:02.370157 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.learn_dbt.dates"
12:10:02.370492 [debug] [Thread-1  ]: Began compiling node model.learn_dbt.dates
12:10:02.370685 [debug] [Thread-1  ]: Compiling model.learn_dbt.dates
12:10:02.376183 [debug] [Thread-1  ]: Writing injected SQL for node "model.learn_dbt.dates"
12:10:02.376806 [debug] [Thread-1  ]: finished collecting timing info
12:10:02.376957 [debug] [Thread-1  ]: Began executing node model.learn_dbt.dates
12:10:02.406730 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:10:02.406919 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    

      create or replace temporary table analytics.dbt.dates__dbt_tmp  as
      (

select *
from "SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF10TCL"."DATE_DIM"
where d_date <=current_date


	and d_date > (select max(d_date) from analytics.dbt.dates)

      );
12:10:02.407009 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:10:04.090971 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.68 seconds
12:10:04.102904 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:10:04.103189 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates__dbt_tmp
12:10:04.228753 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.13 seconds
12:10:04.235152 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:10:04.235385 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table analytics.dbt.dates
12:10:04.337258 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.1 seconds
12:10:04.350030 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:10:04.350286 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */

    describe table "ANALYTICS"."DBT"."DATES"
12:10:04.597897 [debug] [Thread-1  ]: SQL status: SUCCESS 28 in 0.25 seconds
12:10:04.622337 [debug] [Thread-1  ]: Writing runtime SQL for node "model.learn_dbt.dates"
12:10:04.624761 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:10:04.624888 [debug] [Thread-1  ]: On model.learn_dbt.dates: /* {"app": "dbt", "dbt_version": "1.0.1", "profile_name": "learn-dbt", "target_name": "dev", "node_id": "model.learn_dbt.dates"} */
begin;
12:10:04.759366 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.13 seconds
12:10:04.760946 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:10:04.761152 [debug] [Thread-1  ]: On model.learn_dbt.dates: merge into analytics.dbt.dates as DBT_INTERNAL_DEST
        using analytics.dbt.dates__dbt_tmp as DBT_INTERNAL_SOURCE
        on 
            DBT_INTERNAL_SOURCE.d_date = DBT_INTERNAL_DEST.d_date
        

    
    when matched then update set
        "D_DATE_SK" = DBT_INTERNAL_SOURCE."D_DATE_SK","D_DATE_ID" = DBT_INTERNAL_SOURCE."D_DATE_ID","D_DATE" = DBT_INTERNAL_SOURCE."D_DATE","D_MONTH_SEQ" = DBT_INTERNAL_SOURCE."D_MONTH_SEQ","D_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_WEEK_SEQ","D_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_QUARTER_SEQ","D_YEAR" = DBT_INTERNAL_SOURCE."D_YEAR","D_DOW" = DBT_INTERNAL_SOURCE."D_DOW","D_MOY" = DBT_INTERNAL_SOURCE."D_MOY","D_DOM" = DBT_INTERNAL_SOURCE."D_DOM","D_QOY" = DBT_INTERNAL_SOURCE."D_QOY","D_FY_YEAR" = DBT_INTERNAL_SOURCE."D_FY_YEAR","D_FY_QUARTER_SEQ" = DBT_INTERNAL_SOURCE."D_FY_QUARTER_SEQ","D_FY_WEEK_SEQ" = DBT_INTERNAL_SOURCE."D_FY_WEEK_SEQ","D_DAY_NAME" = DBT_INTERNAL_SOURCE."D_DAY_NAME","D_QUARTER_NAME" = DBT_INTERNAL_SOURCE."D_QUARTER_NAME","D_HOLIDAY" = DBT_INTERNAL_SOURCE."D_HOLIDAY","D_WEEKEND" = DBT_INTERNAL_SOURCE."D_WEEKEND","D_FOLLOWING_HOLIDAY" = DBT_INTERNAL_SOURCE."D_FOLLOWING_HOLIDAY","D_FIRST_DOM" = DBT_INTERNAL_SOURCE."D_FIRST_DOM","D_LAST_DOM" = DBT_INTERNAL_SOURCE."D_LAST_DOM","D_SAME_DAY_LY" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LY","D_SAME_DAY_LQ" = DBT_INTERNAL_SOURCE."D_SAME_DAY_LQ","D_CURRENT_DAY" = DBT_INTERNAL_SOURCE."D_CURRENT_DAY","D_CURRENT_WEEK" = DBT_INTERNAL_SOURCE."D_CURRENT_WEEK","D_CURRENT_MONTH" = DBT_INTERNAL_SOURCE."D_CURRENT_MONTH","D_CURRENT_QUARTER" = DBT_INTERNAL_SOURCE."D_CURRENT_QUARTER","D_CURRENT_YEAR" = DBT_INTERNAL_SOURCE."D_CURRENT_YEAR"
    

    when not matched then insert
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")
    values
        ("D_DATE_SK", "D_DATE_ID", "D_DATE", "D_MONTH_SEQ", "D_WEEK_SEQ", "D_QUARTER_SEQ", "D_YEAR", "D_DOW", "D_MOY", "D_DOM", "D_QOY", "D_FY_YEAR", "D_FY_QUARTER_SEQ", "D_FY_WEEK_SEQ", "D_DAY_NAME", "D_QUARTER_NAME", "D_HOLIDAY", "D_WEEKEND", "D_FOLLOWING_HOLIDAY", "D_FIRST_DOM", "D_LAST_DOM", "D_SAME_DAY_LY", "D_SAME_DAY_LQ", "D_CURRENT_DAY", "D_CURRENT_WEEK", "D_CURRENT_MONTH", "D_CURRENT_QUARTER", "D_CURRENT_YEAR")

;
12:10:05.398784 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.64 seconds
12:10:05.400230 [debug] [Thread-1  ]: Using snowflake connection "model.learn_dbt.dates"
12:10:05.400643 [debug] [Thread-1  ]: On model.learn_dbt.dates: commit;
12:10:05.720342 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.32 seconds
12:10:05.732909 [debug] [Thread-1  ]: finished collecting timing info
12:10:05.733166 [debug] [Thread-1  ]: On model.learn_dbt.dates: Close
12:10:05.916386 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c51c4908-74d6-4adf-9a99-99e60c89b6a0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c0558e0>]}
12:10:05.917662 [info ] [Thread-1  ]: 1 of 1 OK created incremental model dbt.dates................................... [[32mSUCCESS 1[0m in 3.55s]
12:10:05.918201 [debug] [Thread-1  ]: Finished running node model.learn_dbt.dates
12:10:05.919648 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:10:05.920116 [info ] [MainThread]: 
12:10:05.920395 [info ] [MainThread]: Finished running 1 incremental model in 5.30s.
12:10:05.920635 [debug] [MainThread]: Connection 'master' was properly closed.
12:10:05.920767 [debug] [MainThread]: Connection 'model.learn_dbt.dates' was properly closed.
12:10:05.927132 [info ] [MainThread]: 
12:10:05.927392 [info ] [MainThread]: [32mCompleted successfully[0m
12:10:05.927634 [info ] [MainThread]: 
12:10:05.927826 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
12:10:05.928090 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c0513d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10906b220>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10956c190>]}
